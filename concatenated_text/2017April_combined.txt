Board of Governors of the Federal Reserve SystemFederal Deposit Insurance Corporation The Federal Deposit Insurance Corporation (FDIC) and the Federal Reserve Board on Monday announced that Wells Fargo had adequately remediated the deficiencies in its 2015 resolution plan. As a result, the firm will no longer be subject to growth restrictions imposed last year. Resolution plans, required by the Dodd-Frank Act and commonly known as living wills, must describe the company's strategy for rapid and orderly resolution under bankruptcy in the event of material financial distress or failure of the company. In December 2016, the agencies determined that Wells Fargo had not remedied two of the three deficiencies identified previously by the agencies and imposed restrictions on the growth of the firm's international and non-bank activities. Following that determination, Wells Fargo submitted a revised plan in March 2017 that adequately remediated the remaining deficiencies. Wells Fargo is next required to file a new resolution plan by July 1, 2017, addressing vulnerabilities to orderly resolution as noted in guidance issued by the agencies last year. If the vulnerabilities noted in the guidance are not satisfactorily addressed, the agencies may jointly determine that the plan is not credible or would not facilitate an orderly resolution under the U.S. Bankruptcy Code. The determination made Monday by the agencies pertains solely to Wells Fargo's 2015 resolution plan and not to any future resolution plan. The Federal Reserve Board is also releasing the feedback letter issued to the firm, detailing the specific steps taken by the firm to resolve the previously identified deficiencies. The decision received unanimous support from the FDIC and Federal Reserve boards.
Governor Jerome H. Powell at The Global Finance Forum, Washington, D.C. Thank you for inviting me to speak here today.1I will begin by looking back at the global financial crisis and the great recession, which were arriving on the horizon at about this time 10 years ago. For the United States and many other countries, this would turn out to be the most painful economic crisis since the Great Depression. The fact that we had a severe recession but not another depression is a tribute to the aggressive response of those who were in a position to act at that time.2 In the event, the financial system avoided collapse but incurred severe damage and proved incapable, for a time, of performing its key functions. That was true of the largest investment and commercial banks, several of which either failed or required taxpayer support to survive. It was also true of the many pieces of the financial market infrastructure whose structural weaknesses contributed to the crisis, such as the triparty repurchase agreement (repo) market, the over-the-counter derivative market, and prime money market funds. The financial turmoil caused heavy damage to the real economy. Payroll employment declined by almost 9 million; over 7 million people lost their homes.3Many young people entered a terrible job market; research shows that this may adversely affect their careers for many years. Many experienced workers who lost their jobs may suffer permanently lower income prospects.4 The nation faced two big tasks after the crisis. We had to get the economy growing again so people could get back to work and rebuild their financial lives. And we had to return the financial system to good health and address the many structural weaknesses that had become apparent. Today, the first of those tasks is well along. We have gone eight years without a subsequent recession--one of the longest recoveries on record. Employment is now almost 7 million jobs higher than its pre-crisis peak, with all of the net gains coming from the private sector. And with unemployment at 4.5 percent, we are at or close to full employment. But all is not well. Although job growth has been strong, gross domestic product has increased only about 2 percent annually since the crisis, held down by the weakest sustained period of labor productivity growth since World War II. Labor productivity--the increase in output per hour--has increased only 1/2 percent per year since 2011, about a quarter of its post-war average. The productivity slowdown has profound implications for our national well-being. This slowdown is a worldwide phenomenon, so it is likely that there are global forces at work. The slowdown has been associated with weak investment and a decline in output gains from technological innovation. We need a national focus on increasing the sustainable growth rate of our economy.5That means investing in our workforce to give them the skills and aptitudes they need to compete in the global economy. It means policies that reward work, and policies that support investment and research. For the most part, these policies are not in the purview of the Federal Reserve. What about the second goal? As with the economy, we have made great progress toward our goals. Today, our financial system is without a doubt far stronger than it was before the crisis. The largest financial institutions now hold much higher levels of higher-quality capital. They hold higher levels of liquidity as well and are much less reliant on runnable short-term funding. They are subject to rigorous, forward-looking capital stress tests that recognize the dynamic nature of financial risks. And they have submitted several rounds of resolution plans that are helping to ensure that they could be safely reorganized should all these other safeguards prove insufficient. Our financial market infrastructures are also much stronger. The amount of intraday credit extended in the triparty repo market has been drastically reduced. Last year, the Securities and Exchange Commission implemented reforms that address weaknesses in the structure of prime money funds. And about 75 percent of interest rate and credit default swaps are now centrally cleared, which allows for greater transparency and more consistent risk management.6While the move to central clearing has made the system safer, we need to make sure that the central counterparties have the resources and risk-management practices to withstand plausible but severe shocks.7 Many of the statutory provisions and regulations put in place to effect these changes were novel; it is not likely that we would have gotten everything exactly right on the first attempt. This is a good time to step back and ask what changes have worked and where adjustments should be made. Indeed, along with the other financial regulatory agencies, the Federal Reserve is contributing to just such an exercise by the Treasury Department. As I share some of my views on these issues, I should emphasize that I speak for myself and not for my Board colleagues or for the new colleagues who will soon join us. A few themes can guide us in this next phase. First, after years of raising capital and liquidity standards, and of stress tests and living wills, our financial system is much stronger now. We should protect these core reforms and avoid a return to the highly vulnerable system that existed before the crisis. Second, in too many cases new regulation has been inappropriately applied to small and medium-sized institutions. We need to go back and broadly raise thresholds of applicability and look for other ways to reduce burden on smaller firms. Third, the new rule book is excessively complex. We need to look for ways to simplify the rules so that they support our goals but also improve the efficiency of regulation. For example, we need to allow boards of directors and management to spend a smaller portion of their time on technical compliance exercises and more time focusing on the activities that support sustainable economic growth. Fourth, we need to continue to strive to provide an appropriate level of transparency to supervised firms and the public regarding our expectations. Some aspects of the new regulatory program are proving unnecessarily burdensome and should be better tailored to meet our objectives. Some provisions may not be needed at all given the broad scope of what we have put in place. I support adjustments designed to enhance the efficiency and effectiveness of regulation without sacrificing safety and soundness or undermining macroprudential goals. One example where some adjustments are warranted is our supervisory relationship with the boards of directors of banking firms. After the crisis, there was a broad increase in supervisory expectations for these boards. But it is important to acknowledge that the board's role is one of oversight, not management. We need to ensure that directors are not distracted from conducting their key functions by an overly detailed checklist of supervisory process requirements. Rather, boards of directors need to be able to focus on setting the overall strategic direction of the firm, while overseeing and holding senior management accountable for operating the business profitably, but also safely, soundly, and in compliance with applicable laws. We are currently reassessing whether our supervisory expectations for boards need to change to ensure that these principles, and not an ever-increasing checklist, are the basis of our supervisory work related to boards. I am sure that there are other areas where laws, regulations, and supervisory practices could be adjusted in a way that preserves the gains in safety and soundness but helps financial institutions devote as much of their resources as possible to supporting economic growth. I look forward to our discussion. 1. The views I express here are my own and not those of the Federal Reserve.Return to text 2. Ben S. Bernanke,The Courage to Act: A Memoir of a Crisis and Its Aftermath(New York: Norton, 2015).Return to text 3. Source: CoreLogic, completed foreclosures.Return to text 4. See, for example, Lisa B. Kahn, "The Long-Term Labor Market Consequences of Graduating from College in a Bad Economy,"Labour Economics17(2) (April 2010): 303-16.Return to text 5. Jerome H. Powell, "Recent Economic Developments and Longer-Run Challenges"(speech delivered at the Economic Club of Indiana, Indianapolis, November 29, 2016).Return to text 6. Timothy Massad, "Remarks before the 2016 P.R.I.M.E. Finance Annual Conference" (The Hague, the Netherlands, January 25, 2016).Return to text 7. The Alternative Reference Rates Committee is working to strengthen another key segment of the financial infrastructure. The Committee will select its preferred alternative to U.S. dollar London Interbank Offered Rate (or, LIBOR) and is expected to complete its plans to promote the use of this rate this year.Return to text
Governor Daniel K. Tarullo At The Woodrow Wilson School, Princeton University, Princeton, New Jersey Tomorrow is my last day at the Federal Reserve. So in this, my final official speech, it seems appropriate to offer a broad perspective on how financial regulation changed after the crisis. In a moment, I shall offer a few thoughts along these lines. Then I am going to address in some detail the capital requirements we have put in place, including our stress testing program. Eight years at the Federal Reserve has only reinforced my belief that strong capital requirements are central to a safe and stable financial system. It is important for the public to understand why this is so, especially at a moment when there is so much talk of changes to financial regulation. The Post-Crisis Regulatory ResponseTo understand the regulatory changes made in response to the 2007 to 2009 financial crisis, it is useful to recall the circumstances with which regulators and legislators were confronted. First, of course, was the sheer magnitude of the impact on the economy, which suffered its worst recession since the Great Depression. Second was the dramatic freezing up of many parts of the financial market, risking successive waves of fire sales that would send asset values plummeting anew. Third was the rapid deterioration of financial firms. Hundreds of smaller banks eventually failed. Bear Stearns, Merrill Lynch, Wachovia, and Countrywide were all close to failure when they were acquired by other financial firms with one or more forms of government support or assistance. American International Group was rescued directly by the government. Lehman Brothersdidfail, which set off the most acute phase of the crisis. The impact of Lehman's bankruptcy seemed to confirm fears that failure of the largest financial firms risked the complete implosion of the financial system. This, of course, is the too-big-to-fail problem: government officials may feel compelled to save private financial firms with public (that is, taxpayer) capital. Meanwhile, financing markets had nearly frozen up. Hence the extraordinary government actions that followed. Public capital was injected into all of the nation's largest remaining banking firms following congressional enactment of the Troubled Assets Relief Program (TARP). The Federal Reserve and the Department of the Treasury provided financing and backstops, respectively, for money market funds and various forms of securitized assets. The Federal Deposit Insurance Corporation extended its guarantees to bank deposits and the senior debt of banks. These and other measures ultimately proved successful in placing a floor under the downward spiral of the financial system. But it was against the backdrop of the need for massive taxpayer-backed assistance--to firms and to markets more generally--that Congress and financial regulators developed responses to the woefully inadequate capital levels of prudentially regulated firms; the systemic consequences of stress at previously non-prudentially regulated firms such as the free-standing investment banks; the widespread failures of risk management within these firms; the parallel failures in supervision of these firms; and the fragility of a financial system that had become characterized by large amounts of runnable short-term funding. The first and, to my mind, still the most important element of regulatory strengthening was to increase the amount of capital held by banks to ensure they remained viable financial intermediaries that could finance economic activity. In fact, this effort began as part of the emergency stabilization efforts in early 2009, when we conducted a stress test of the 30 largest banking firms. Where we determined a firm did not have enough capital, we required that it either raise equity in the public markets or take some of the remaining government TARP capital. The quick action in assessing the firms, recapitalizing them where needed, and sharing the results of the stress tests with the public stands as one of the turning points in the crisis. From there, we pursued a strategy of gradually strengthening ongoing capital requirements. With a few exceptions, the approach we took from the fall of 2009 onward allowed the banks to use retained earnings to build their capital. We also began development of the first quantitative liquidity regulations to be used in prudential regulation by the U.S. banking agencies. This initiative was, of course, a direct response to the liquidity squeezes encountered during the crisis itself. The capital and liquidity efforts were well underway by the time Congress passed the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) in mid-2010. And Congress was, of course, aware of these efforts. So it is perhaps not surprising that the provisions of the Dodd-Frank Act relating to capital set some important qualitative standards for capital regulation rather than addressing capital levels as such. A law as long and wide-ranging as the Dodd-Frank Act cannot be reduced to a single key premise or concern, excepting its general focus on financial stability and systemic risk.1However, with respect to the too-big-to-fail problem, I do think it fair to say--on the basis of both the text itself and its legislative history--that a pivotal choice was to make tighter the prudential regulation of the practices and activities of large banking organizations the presumptive approach to taming too-big-to-fail problems. The alternative, much discussed at the time and since, would have been a structural approach. One such approach could have been something like the old Glass-Steagall Act separation of commercial banking from investment banking, whichprohibitedrather than simply regulated certain activities in different types of firms. Another structural approach would have been outright size limitation resulting in the breakup of some of the largest financial firms. The Dodd-Frank Act does give regulators authority to require divestitures by firms posing risks to financial stability. But these authorities, which contain only the most general of standards, seem intended to be used only if the panoply of other measures in the legislation have failed to contain the too-big-to-fail problem. Thus, at least in the first instance, the Dodd-Frank Act forgoes structural solutions, which might have been cleaner conceptually, but perhaps much more complicated as a practical matter. Instead, it imposes a host of restrictions and requirements. So we have counterparty credit limits, risk retention requirements, incentive compensation constraints, resolution planning requirements, and others. These new statutory measures were meant to, and do, coexist with the capital and liquidity requirements put in place by the banking agencies under their pre-existing authority, as enhanced by the Dodd-Frank Act. An important corollary of this basic approach was that the Dodd-Frank Act requires that many of these regulations be progressively more stringent as applied to firms of greater systemic importance. From this perspective, then, it is not surprising that the Dodd-Frank Act implementation has been a major undertaking, that banks (and sometimes supervisors) feel overwhelmed by the breadth of the resulting compliance effort, and that there is some overlap among some of the regulations. This outcome was, in effect, the price of the largest banks not being subject to a direct structural solution such as breakup. None of this is to say that the Dodd-Frank Act got the mix of restrictions just right. To the contrary, it would have been surprising for such a major piece of legislation passed in the immediate aftermath of the crisis to have done so. Usually, a law like the Dodd-Frank Act would have been followed some months later by another law denominated as containing technical corrections, but also usually containing some substantive changes deemed warranted by analysis and experience. But partisan divisions prevented this from happening. And the novelty of many of the forms of regulations adopted by financial regulators, either in implementing the Dodd-Frank Act or under existing authorities, almost assures that some recalibration and reconsiderations will be warranted on the basis of experience. So there are clearly some changes that can be made without endangering financial stability. Foremost among these are the various bank size thresholds established in the Dodd-Frank Act or in agency regulations for the application of stricter prudential requirements. For example, as I have said for several years now, we have found that the $50 billion in assets threshold established in the Dodd-Frank Act for banks to be "systemically important," and thus subject to a range of stricter regulations, was set too low. Similarly, the $10 billion asset threshold for banks to conduct their own required stress tests seems too low. And the fact that community banks are subject at all to some of the Dodd-Frank Act rules seems unnecessary to protect safety and soundness, and quite burdensome on the very limited compliance capabilities of these small banks. Beyond the thresholds issue, though, are there statutory provisions or regulations whose substance could be adjusted to better match economic or compliance costs with financial stability benefits? Again, it would be very surprising if this did not prove to be the case over time. It would also be surprising if we did not find areas in which rules needed to be strengthened in order to achieve financial stability goals, particularly as financial markets change. Generally, I think it is a bit early to judge the balance of costs and benefits of many of the new rules. Some are not yet fully implemented. Firms are still in the process of adjusting to the new rules. And it is still somewhat difficult to determine, for example, what should be considered "normal" levels of liquidity or lending, insofar as the pre-crisis period was one in which high levels of both lending and liquidity proved unsustainable. Moreover, given the healthy increases in lending over the last several years and the record levels of commercial bank profits recorded in 2016, it would seem a substantial overreach to claim that the new regulatory system is broadly hamstringing either the banking industry or the economy. But there are areas where I think the case for change has become fairly strong. The Volcker rule is one. During the debates on what became the Dodd-Frank Act, former Chairman Paul Volcker offered a fairly straightforward proposal: no insured depository institution or affiliate thereof should be permitted to engage in proprietary trading. It seemed then, and seems now, like an idea that could contribute to the safety and soundness of large financial firms. However, several years of experience have convinced me that there is merit in the contention of many firms that, as it has been drafted and implemented, the Volcker rule is too complicated. Achieving compliance under the current approach would consume too many supervisory, as well as bank, resources relative to the implementation and oversight of other prudential standards. And although the evidence is still more anecdotal than systematic, it may be having a deleterious effect on market making, particularly for some less liquid issues. There are three problems--two in the statute and one in the regulatory approach--that I think are related. The first statutory problem is that five different agencies are involved. While the statute does not require a single regulation agreed upon by all five, it understandably calls for coordination and consistency in rulemaking and implementation. The joint or parallel rulemaking among multiple agencies required in various parts of the Dodd-Frank Act has advantages and disadvantages that differ across subject matter. Here, though, the disadvantages seem to dominate. Because almost any effort to distinguish market making from proprietary trading, for example, is impossible to sensibly reduce to a formula or precise rule across all traded instruments, there is ongoing and substantial need for context-specific, data-heavy judgment. Efforts to achieve consistency in treatment across agencies have been both time-consuming and, at times, unsuccessful. The second problem is that the approach taken in the regulation in pursuit of consistency was one that essentially contemplated an inquiry into the intent of the bankers making trades to determine, for example, whether the trades were legitimate market making. The agencies knew this approach would be complicated when we adopted it, but it seemed the best way to achieve consistency, at least over time. I think the hope was that, as the application of the rule and understanding of the metrics resulting from it evolved, it would become easier to use objective data to infer subjective intent. This hasn't happened, though. I think we just need to recognize this fact and try something else. Had there been an obviously better approach, we would have taken it five years ago. My suspicion is that it lies in reviewing and monitoring the trading limits established on all trading desks. As contemplated in the statute, capital requirements might also be used as a complementary tool, such as by requiring progressively higher amounts of capital as trading inventories age--a pretty good indicator that market making is morphing into proprietary trading. Whether a consistent approach can be developed while five agencies continue to be involved is not clear, but it is certainly worth trying. The third problem, also in the statute, is that the Volcker rule applies to a much broader group of banks than is necessary to achieve its purpose. As I have said before, the concerns underlying the Volcker rule are simply not an issue at community banks.2Many regional banks have few or no trading assets of any sort, so proprietary trading is obviously not a concern there either. While the regulatory agencies have tried to tailor the rules so as to avoid burdening these banks, even the process of figuring out that the rules do not constrain them is a compliance cost that should be eliminated. One approach would be to exempt all banks with less than $10 billion in assets and other banks that report less than some nominal amount of trading assets. Capital RegulationLet me now turn to capital. The history of financial regulation over the last several decades is in many respects defined by an increasing emphasis on capital requirements and, specifically, higher minimum ratios based on a more rigorous definition of what constitutes loss-absorbing capital. This tendency can be explained by the fact that capital is a particularly supple prudential tool. As activity and affiliation restrictions on banks have been loosened, and as the integration of traditional lending with capital markets has created new financial products at a rapid pace, capital requirements can provide a buffer against losses fromanyactivities. No single measure of capital is sufficient to ensure an adequate buffer however. Simple leverage ratios are a good check on banks becoming too debt dependent, but they encourage more risk-taking, insofar as they impose the same capital charge for every asset, no matter how risky. Standardized risk-based capital ratios implement the intuitively appealing notion that a bank's capital should depend on the riskiness of its assets. But the grouping of individual loans and securities into necessarily broad categories of risk weights (e.g., residential mortgages) can be arbitraged. And a firm holding lots of assets that look very low-risk in normal times can be vulnerable if its total leverage is high during stress periods. Models-based capital requirements can better distinguish among risks to some degree, and they can be made more forward-looking than static leverage or risk-based ratios. But, to the extent that banks' internal models are used, it is difficult to monitor whether banks are intentionally or unintentionally running models that understate their risks. And, of course, they are subject to the usual limitations of models that are based only on past experience and correlations. In the post-crisis period, we have continued the previous U.S. practice of using complementary leverage ratio and standardized risk-weighted capital requirements, though at higher levels and with more reliance on common equity as the preferred measure of true capital strength on a going concern basis. We have added a stress test, now based on a supervisory model. We, along with some other jurisdictions that are home to banks of global systemic importance (G-SIBs), have also applied surcharges to the leverage and risk-weighted requirements of such banks. The rationale for this feature of our capital regime is that the potential negative externalities caused by the stress or failure of a G-SIB warrant a higher level of capital.3Graduated capital surcharges have the additional policy benefit of providing these firms with an incentive to reduce the size and scope of their activities so as to present lesser risk to the financial system. The U.S. banking agencies based post-crisis capital requirements on historical loss experiences so as to require banks to have a capital buffer that could absorb losses associated with a significant economic downturn and remain viable financial intermediaries in the eyes of customers, counterparties, and financial markets.4But our researchers, like those at some other official-sector entities, have been using more formal economic analysis to estimate the level of capital requirements that best balances the benefits associated with reduced risk of financial crisis with the costs of banks funding with capital rather than debt. A recent study by three Federal Reserve Board researchers concludes that the tier 1 capital requirement5that best achieves this balance is somewhere in the range of 13 percent to 26 percent, depending on reasonable choices made on some key assumptions.6By this assessment, current requirements for the largest U.S. firms are toward the lower end of this range, even when one takes account of the de facto capital buffers imposed on most firms in connection with the stress test. This assessment, when added to our original historically-based approach and the methodology used in developing the capital surcharges, suggests strongly that a reduction in risk-based capital requirements for the U.S. G-SIBs would be ill-advised. In fact, one might conclude that a modest increase in these requirements--putting us a bit further from the bottom of the range--might be indicated. This conclusion is strengthened by the finding that, as bank capital levels fall below the lower end of ranges of the optimal trade-off, the chance of a financial crisis increases significantly, whereas no disproportionate increase in the cost of bank capital occurs as capital levels rise within this range. In other words, in trying to avoid a future financial crisis, it is wise to err somewhat toward the higher end of the range of possible required capital levels for this group of firms. On the other hand, it seems reasonably apparent that the increased granularity of the standardized risk-weighted capital requirements put in place after the crisis, while necessary to deal with the range of risks in larger banks, is unduly complicated for community banks. It's not that these requirements have increased appreciably the amount of capital community banks hold, but more that the complexity of compliance and reporting imposes costs that are disproportionately much greater for these banks, given that they have much smaller balance sheets over which to amortize the associated costs. For this reason, I believe we should be moving toward a much simpler capital regime for community banks. The federal banking agencies have already taken some steps in this direction, and they can take a few more. But it may be helpful to amend the law so as to make clear that the agencies would have the flexibility to create a simple capital regime applicable only to community banks. There has been much discussion of late of the leverage ratio requirement, from multiple perspectives. There are proposals to make a higher leverage ratio requirement either mandatory or optional for banks, which would then be relieved of risk-weighted capital requirements and many other prudential regulations. There are also those who have questioned the relative cost-benefit tradeoff of the "enhanced supplementary leverage ratio," the 2 percent surcharge applicable to all eight U.S. G-SIBs. Increasing the current 4 percent or 5 percent leverage ratio requirement to, say, 10 percent would certainly yield a very well-capitalized set of banks based on thecurrentbalance sheets of large banks. But one needs to look at the dynamic effects of such a requirement. Since a higher leverage ratio would also make banks less profitable, and with the constraints of risk-based capital and liquidity requirements lifted, they would be strongly incentivized to change the composition of their balance sheets dramatically, shedding safer and more liquid assets like Treasuries in exchange for riskier but higher-yielding assets.7After all, with a leverage ratio as the only significant constraint, the regulatory cost of holding a short-term Treasury bill is identical to that of a junk bond. It is this very limitation of a leverage ratio that led to the creation of a complementary risk-based capital requirement in the 1980s. To truly assure the safety and soundness of the financial system, a leverage ratio serving as the sole or dominant form of prudential regulation would probably have to be set considerably higher, at a level where the impact on financial intermediation could be quite substantial. As to the impact of the 2 percent enhanced supplementary leverage ratio, our experience leads me to believe that it may be worth changing to account for the quite different business operations of the G-SIBs, particularly those in the custody business. The complementarity of risk-based capital requirements and leverage ratios suggests that there should be some proportionality between the two. This is, of course, the current situation with respect to the standards applicable to non-systemic banks, with the leverage ratio requirement being sensibly set somewhat below the risk based requirement. However, with the additional standards applicable only to the eight systemically important firms, we have a sliding scale of risk-based surcharges but an across-the-board 2 percent leverage ratio surcharge. In practical terms, the asymmetry is most significant for the two banks that are dominantly custodial and transactional in nature, rather than lending and trading firms. These banks have had the lowest risk-based surcharges of the eight G-SIBs--currently 1-1/2 percent--but their leverage surcharge is 2 percent. This is especially problematic for their operations, since they prudently reinvest custody customer deposits into safe and liquid assets. I think it would be sensible for the banking agencies to consider altering the enhanced supplementary leverage ratio requirement so that it would be set with an eye toward the risk-based surcharge. One, but certainly not the only, way to do this would be for the enhanced supplemental leverage ratio to be 1 percent for the firms with a 1 percent to 1-1/2 percent risk-based surcharge, 1-1/2 percent for those with a 2 percent or 2-1/2 percent risk-based surcharge, and 2 percent for those at 3 percent or above. An alternative approach to mitigating the distortionary effects of the leverage ratio requirements is to exclude certain "riskless" assets from the denominator. Some central bankers around the world have been arguing to exclude central bank reserves from the leverage ratio denominator, on the ground that they are "safe" and that including them may make monetary policy harder to execute in a period of unusually large central bank balance sheets. But this would defeat the whole purpose of a leverage ratio, which is to place a cap on total leverage, no matter what the assets on the other side of the balance sheet may be. Cash holdings, for example, are not excluded. This proposal would also create a classic slippery slope risk, which was illustrated during a discussion in which I participated last year. When a central banker raised the idea of excluding reserves, a finance ministry official mused aloud that perhaps sovereign debt should also be excluded. Stress TestingRaising the minimum ratios in leverage and risk-based capital standards, requiring that qualifying regulatory capital be truly loss absorbing, and setting higher requirements for the most systemically important banks have been important steps toward the goal of a well-capitalized, and thus safer, financial system. But the stress testing system begun during the crisis, and continually refined since, has been the key innovation in capital regulation and supervision and makes those other measures more effective. The success of the 2009 stress test in restoring confidence in the financial system during the crisis encouraged Congress to make stress testing a required and regular feature of large-firm prudential regulation. As the term suggests, stress tests evaluate the capacity of banks to absorb losses that may be associated with major economic adversity and remain not only technically solvent, but also viable financial intermediaries. They are explicitly forward-looking, in that they involve creating unlikely but plausibly severe economic scenarios and then modeling the likely impact of those scenarios on bank assets and earnings. The Federal Reserve has tied the results of stress tests into capital regulation by requiring that bank capital distributions be consistent with maintaining viability in the event the severe scenario were to materialize. That is, dividends and share repurchases cannot bring the bank's capital level below the sum of minimum capital requirements and the amount of losses that could be sustained in the stress event. By looking at the impact of such scenarios on the considerable part of the financial industry accounted for by the larger bank holding companies subject to the requirement, the Federal Reserve's approach gives insight into how substantial economic or financial shocks would affect the financial system and the real economy. One virtue of stress testing is that it allows a forward-looking assessment of potential losses that is customized to the portfolios and business models of each bank, while still being consistent across the banks. The Federal Reserve uses independent supervisory models to estimate losses and revenues under stress, both to achieve more comparability across the results for different banks and to preclude any temptation for banks to game their own models. This linkage of stress testing to bank capital requirements has been a good way for regulators to regularize exercise of their broad statutory discretion to set individual capital requirements on a bank-by-bank basis.8Banks subject to the supervisory stress tests have generally found it to be their binding capital constraint. This is as it should be, insofar as stress testing is meant to help set capital requirements for when they will most be needed--that is, in a serious economic downturn. From the first stress test performed in the winter of 2009, the Federal Reserve has publicly disclosed progressively more information about its supervisory model, the scenarios, and the results. During the crisis, disclosure was intended to help restore confidence in the banking system. Our continuation and expansion of disclosure helps market participants, analysts, academics, and the public better evaluate both the condition of the banks and the rigor of supervisory oversight. It thus serves the dual purpose of market discipline and government agency accountability. To serve its important financial stability purpose, stress testing must never become static. As the financial system evolves, with the creation of new products and new correlations among asset price movements, the supervisory model must account for these changes. And as salient risks to the financial system arise, the scenarios must test for these new risks. Apart from the inherent need for adaptation, though, there is one respect in which the Federal Reserve's stress testing program is incomplete and other respects in which it is still in transition from a crisis and post-crisis measure to a permanent and central feature of prudential oversight. The significant way in which the stress testing program is incomplete is that it has only limited features with which to assess the condition of participating banks from a macroprudential perspective.9For example, it generally does not directly take account of second-round effects of stress on the financial system, such as the possible fire sale of assets by financial firms in need of capital or funding, which can further depress asset values of other firms below levels resulting from the initial economic or financial shock.10These effects are harder to model but very important for a stress test designed to achieve financial stability objectives. The Federal Reserve has begun a research program to try to develop, over the next few years, sound macroprudential elements to incorporate into the stress test alongside some of the countercyclical features that have already been added. The transition of stress testing from crisis program to a permanent feature of prudential oversight is unfinished in both Federal Reserve regulations and supervisory practice. The de facto capital requirements produced by the stress test have not been fully integrated into, and reconciled with, other applicable capital rules. Thus, for example, our stress testing program assumes that a firm will continue to make its planned capital distributions during a stress period even though the regulatory capital rules now include a capital conservation buffer to limit such distributions. As to supervision--because the failure of a firm to meet Federal Reserve expectations with respect to its capital risk-management and planning processes can lead to a "qualitative" objection to its capital distribution plans--firms (and, at times, perhaps supervisors) have placed more emphasis on these matters than on other issues raised in the supervisory process throughout the year. It is probably worth noting at this juncture that one of the features of the stress testing program that some banks have found most troubling is that it culminates in the annual announcements of whether the Federal Reserve objects to each participating bank's capital plan--an event that still garners considerable investor and public attention.11The potential for embarrassing, public objections to their plans has been disconcerting to some banks, which pointed out that--by design--they were not given the supervisory model for calculating post-stress minimum capital levels and that they might not be able to predict when supervisory concerns with some aspects of their capital planning processes would ripen into a public objection. It is certainly the case that this feature of our stress testing program was intended to, and has, focused the minds of banks' senior management on their capital positions and capital planning processes. Motivating management with the stress test was appropriate in a time when capital needed to be built up and when serious shortcomings of pre-crisis risk management at many large U.S. banks needed to be remedied. To be honest, I was stunned in my first few months at the Federal Reserve to find out that many of these banks were unable to aggregate their total exposure to particular counterparties across the many parts of the bank in anything like a reasonable time. Some firms did not have ready access to basic information about the location and value of collateral that they held. As recently as a couple of years ago, we were still seeing some significant problems with data and modelling reliability in banks' internal risk-management processes. Still, the question was always how long we would need this highly focused set of annual determinations. Several years ago we took a first step to reduce the potential for a quantitative objection by giving any bank whose planned distributions would have brought it below the post-stress minimum capital requirements a short time in which to adjust its plan.12Last fall, I gave a speech in which I previewed the Board's additional thinking on this subject, following the Board's year-long review of the stress testing program.13One point was our intention to remove the "qualitative" part of the annual stress testing exercise for participating banks with less than $250 billion in assets. We have since done just that, in recognition of the fact that these firms had generally met the supervisory expectations for capital planning and risk management put in place after the crisis. In that speech I also indicated that the Board of Governors was considering a significant revision to our stress testing program that would both integrate it into other applicable capital requirements and begin to reduce the amount of attention directed at the annual announcement of stress test results. The proposal for what our staff has called a "stress capital buffer" (SCB) would simplify our capital regime by replacing the existing 2.5 percent fixed capital conservation buffer applicable to all banks with a buffer requirement equal to the maximum decline in a firm's common equity ratio under the severely adverse scenario of the stress test.14This change would, of course, apply only to the roughly 30 banks that participate in the supervisory stress test. This buffer would be recalculated after every year's stress test. Then, through the succeeding year, a bank would have to observe the constraints on capital distributions written into our point-in-time capital requirements if its capital ratio fell below the sum of our minimum capital requirement and the applicable stress capital buffer. Because the capital surcharge on the eight G-SIBs already exists as a part of our regular capital rules, the stress capital buffer approach would effectively add the surcharge to our estimates of the amount of capital needed under stress. The surcharges were put in place because the material distress or failure of a G-SIB would have an adverse impact on the financial system as a whole that is far greater than the impact on the financial system of the distress or failure of a non-G-SIB firm.15Accordingly, G-SIBs should face capital surcharges that compel internalization of those external costs. Because the difference in the external costs of the distress or failure of a G-SIB as compared to a non-G-SIB is likely to be at least as high during times of macroeconomic and financial market stress as during ordinary times, there is no reason why the G-SIB surcharge should not be a part of the post-stress capital regime. A complementary point is that the extra buffer required by the G-SIB surcharge reflects the fact that even the best-conceived annual stress scenarios cannot capture all tail risks in the financial system.16 The SCB proposal would thus raise somewhat the capital requirements of the eight G-SIBs. This outcome is consistent with analysis of the costs and benefits of capital requirements that I discussed earlier, as well as the rationale for surcharges.17It is also consistent with the intuition, itself having some analytic backing, that because Congress decided against fundamental structural measures to deal with the too-big-to-fail problem, we should err somewhat on the side of higher capital requirements for these firms. Indeed, there are some academics and others who continue to make a case for even higher capital requirements. The inclusion of the surcharges would allow the Federal Reserve to relax some of the conservative assumptions currently made in the stress test without lowering the overall post-stress capital requirements for G-SIBs.18While conservative assumptions were appropriate coming out of the financial crisis in the early days of the stress test, the SCB and its inclusion of the surcharges would offer an opportunity to update these assumptions without reducing the overall capital requirements for G-SIBs. At the same time, relaxing these assumptions would result in a modest decline in the effective capital requirements of the non-G-SIB participating banks when, as I hope and expect, the Board of Governors moves forward with a rulemaking implementing the SCB idea.19 Adoption of the SCB should remove a bit more of the drama originally associated with the annual announcement of the stress test results. But some would remain, particularly given the possibility of a qualitative objection, even where the supervisory model shows that the firm would have enough capital to remain a viable intermediary in the event something like the severely adverse scenario came to pass. Although the largest firms, unlike those with less than $250 billion in assets, are not yet generally meeting all supervisory expectations around stress testing and capital planning, they have each made substantial progress since 2009. With a few exceptions, the issues observed during recent Comprehensive Capital Analysis and Review (CCAR) cycles are less fundamental than those we were seeing even a few years ago. So I think the time may be coming when the qualitative objection in CCAR should be phased out, and the supervisory examination work around stress testing and capital planning completely moved into the normal, year-round supervisory process, even for the G-SIBs. Coupled with adoption of the SCB, and the changes in modeling and assumptions associated with that proposal, the elimination of the qualitative objection process would integrate the process and substance of stress testing into the rest of the Federal Reserve's prudential oversight activities. In doing so, it should alleviate the apprehension of banks that they may be subject to objections to their capital plans that are both very public and hard to fully anticipate. The SCB itself would continue the Federal Reserve's efforts to tier prudential requirements even among larger banks, with the G-SIBs having somewhat higher capital requirements commensurate with the damage their failure would inflict on the broader economy, and the regional banks subject to modestly lower requirements than those that effectively apply at present. Having just described some good directions for the evolving stress testing regime, let me comment on what I regard as some ill-advised ideas circulating in current policy discussions. One is to detach the stress test from any limitations on capital distributions. This would, in effect, make the stress test simply an informational exercise for supervisors and markets and would, accordingly, presumably be treated less seriously by all concerned. Were we to do so, the very virtues of the stress test that I recounted earlier would be lost, as we would return to using only general, backward-looking risk weights. Of course, it would also reduce capital requirements for the largest banks, which may be one of the motivations for the idea. I have heard two arguments for this idea. One is that Congress did not require that the stress test be used to limit capital distributions. The other is that it is somehow an unacceptable encroachment on the prerogatives of bank boards of directors to limit their discretion to declare dividends or authorize stock repurchases. While Congress did not explicitly call for stress tests to be used to assure adequate capital levels in larger banks, it did call for increasingly stringent capital measures as the systemic importance of banks increased. Section 165 of the Dodd-Frank Act, which contains the stress testing requirement, is singularly focused on achieving financial stability objectives. Moreover, as I noted earlier, Congress in the 1980s gave the federal banking agencies authority--within their discretion--to set capital requirements individually for specific banks. Again, as noted earlier, using stress tests to do so is not only wholly within that discretion. It is a more regularized way of doing so than an ad hoc judgment on a bank-by-bank basis. The argument that bank boards should not be constrained in making capital distributions amounts to an argument that there should be no capital regulation, since even traditional capital regulations limited boards from, say, declaring a dividend that would take the bank below minimum capital levels. And those who make this argument seem to have forgotten that some banks continued to pay dividends in 2007 and 2008 even as their situations became increasingly precarious. Another unwise idea would be to give the supervisory model to the banks. Some have argued that it is only fair to do so, because otherwise banks cannot know exactly what their capital requirements will be. For example, if a bank doesn't know with precision what capital charge will effectively be applied to a certain class of home equity loans, it will be handicapped in deciding how many such loans to offer, and on what terms. In fact, observation of the stress test results over time has given the banks--as well as analysts and other outside parties--a reasonable idea of the loss functions and other elements of the supervisory model. And the Federal Reserve has increased over time the amount of information it discloses about its stress test models. But there are very good reasons not to publish the model itself. In the first place, remember why this exercise is called a stresstest. This is not a case of using a model to set a regulation that stands on its own as a constraint, and then testing to see if there is compliance with the rule. There, the model is essentially the reasoning by which the regulation was set. Even in a case where the test is independent of the regulatory end, risks exist, as we saw in the Volkswagen case, where the company is said to have designed its cars to pass the required emissions test but not to actually achieve the regulatory goal of reduced emissions. In the financial area, the dangers of disclosure are much greater. We are trying to evaluate what may happen to a bank's assets under stress. If a bank has the model, it will be able to optimize its balance sheet for the day on which the stress test is to apply by shifting into assets for which relatively lower loss functions apply. But it can then shift those assets back over succeeding days or weeks. Thus, the test will give a misleading picture of the actual vulnerabilities of the firm. In this and other ways, banks would use the models to guide changes in their behavior that do not change the risk they pose to financial stability, but do change the measured results of the stress test. Regulators and academics have long recognized that this type of behavior by banks, known as regulatory capital arbitrage, has been a persistent threat to financial stability. Additionally, giving the firms the model will likely encourage increased correlations in asset holdings among the larger banks--a trend that increases systemic risk, since everyone will be exposed should those asset classes suffer reversals.20 Releasing the computer code used in the model projections would repeat a serious error made a quarter century ago. In 1992, Congress established revised capital standards for the Federal National Mortgage Association (Fannie Mae) and the Federal Home Loan Mortgage Corporation (Freddie Mac), the centerpiece of which was a stress test. However, for reasons that foreshadowed many of the arguments adduced today, all the details of the model were made public and any changes went through the standard notice and comment process. As a result, the government-sponsored enterprises (GSEs) and the public clearly understood the model. With the model in the hands of the GSEs, even a scenario of the severity of the 2006 to 2008 experience produced only mild losses for them. Of course, this result stands in stark contrast to the actual losses, which were sufficient to drive them into conservatorship in September 2008. In short, we should recognize that what might appear to be a reasonable transparency measure in publishing the models will in fact result in less protection for the financial system. Thus, if the model were to be published, I would suggest that the minimum required capital levels would need to be materially increased in order to take account of the dynamics I just described.21 There are a couple of ways to respond to bank concerns without courting these dangers. One would be to add some granularity in the definition of asset categories subject to a specific loss function. At times, some banks have felt that the breadth of certain categories of assets used by the supervisory model means there is a good bit of divergence in the risks associated with assets within the same category. The other would be for the Federal Reserve to publish a set of hypothetical portfolios with the model-implied losses on these portfolios. To that end, staff have been working on "control portfolio" level disclosures. These would permit a fairly accurate inference of the expected losses on any given set of assets. At the same time, they would not permit participants to game the models by scrutinizing them for the precise points where they were weakest.22 ConclusionMuch as I would have liked to touch upon important topics such as the need for credible resolution mechanisms for large banks and for adaptable regulatory processes to respond to new forms of shadow banking, I needed to be selective in drafting this speech. I concentrated on capital regulation because it is the single most important element of prudential financial regulation. The new features of G-SIB surcharges and stress testing help guard against a severe new financial crisis and contain the too-big-to-fail problem. As proposals for regulatory change swirl about, it is crucial that the strong capital regime be maintained, especially as it applies to the most systemically important banks. Neither regulators nor legislators should agree to changes that would effectively weaken that regime, whether directly or indirectly. It would be tragic if the lessons of the financial crisis were forgotten so quickly. 1. See Daniel K. Tarullo (2012), "Financial Stability Regulation," speech delivered at the Distinguished Jurist Series, University of Pennsylvania Law School, Philadelphia, PA, October 10.Return to text 2. See Daniel K. Tarullo (2014), "A Tiered Approach to Regulation and Supervision of Community Banks," speech delivered at the Community Bank Symposium, Chicago, IL November 7.Return to text 3. As implemented in the United States, the surcharge for G-SIBs was calibrated to provide a sufficient amount of additional capital to sufficiently reduce the chances of a G-SIB's failure so that the impact of its failure, discounted by the probability of that failure occurring, would approximately equal the impact of the failure of a large bank holding company that is not a G-SIB, discounted by the somewhat higher probability of its failure (because its capital ratio is lower without a surcharge). For a fuller explanation of this "expected impact" approach, see Board of Governors of the Federal Reserve System (2015), "Calibrating the G-SIB Surcharge (PDF)," white paper (Washington: Board of Governors of the Federal Reserve System, July 20).Return to text 4. See, for example, Daniel K. Tarullo (2011), "The Evolution of Capital Regulation," speech delivered at The Clearing House Business Meeting and Conference, New York, NY, November 9.Return to text 5. The post-crisis amendments to the banking agencies' capital regulations strengthened the definition of tier 1 capital by having at its core common equity tier 1 capital, the most loss-absorbing form of capital comprised primarily of common equity and related surplus, retained earnings, accumulated other comprehensive income, and limited amounts of common equity tier 1 minority interest. Specifically, tier 1 capital consists of common equity tier 1 capital plus additional tier 1 capital instruments which include qualifying non-cumulative preferred stock, related surplus, and limited additional amounts of tier 1 minority interest.Return to text 6. Simon Firestone, Amy Lorenc and Ben Ranish (2017), "An Empirical Economic Assessment of the Costs and Benefits of Bank Capital in the U.S. (PDF)," Finance and Economic Discussion Series 2017-034 (Washington: Board of Governors of the Federal Reserve System).Return to text 7. Some market observers and participants believe that current capital requirements have impinged somewhat on market liquidity for Treasuries. While this claim is hard to prove with existing data, particularly given the difficulties of determining optimal levels of liquidity, it seems reasonable to assume that a very high leverage ratio would seriously constrict market making in Treasuries.Return to text 8. See 12 USC 3907(a) (1).Return to text 9. The stress testing program does have some macroprudential elements, which have been modestly enhanced in recent years. For example, we vary the market shock over time to reduce the incentive for firms to correlate their asset holdings or adopt correlated hedging strategies that are treated relatively favorably under one particular market shock scenario.Return to text 10. See, for example, Fernando Duarte and Thomas M. Eisenbach (2013), "Fire-Sale Spillovers and Systemic Risk (PDF)," Federal Reserve Bank of New York Staff Report no. 645 (New York: Federal Reserve Bank of New York, October).Return to text 11. An objection can be forthcoming either because the bank's proposals for capital distributions would leave it with less capital than our modeling determines is necessary were the severely adverse scenario to be realized or because our supervisors have found substantial flaws in a bank's capital planning and capital risk-management processes.Return to text 12. This change did not lead to any reduction in the post-stress capital requirements. It simply gave the firm an opportunity to reduce its planned capital distributions so that they would not lead to a quantitative objection.Return to text 13. For more information on the Federal Reserve's recent review of the Comprehensive Capital Analysis and Review (CCAR) program, see Daniel K. Tarullo (2016), "Next Steps in the Evolution of Stress Testing," speech delivered at the Yale University School of Management Leaders Forum, New Haven, CT, September 26.Return to text 14. The SCB would be floored at 2.5 percent such that if a firm's maximum common equity tier 1 capital ratio decline under the severely adverse scenario is less than 2.5 percent, its SCB would be 2.5 percent.Return to text 15. Board of Governors, "Calibrating the G-SIB Surcharge."Return to text 16. An argument against inclusion of the G-SIB surcharge offered by some is that macroprudential risks facing G-SIBs are lower in the aftermath of a financial crisis. We looked into this argument and concluded that experience actually shows that there is no lower probability of another serious reversal in a year following an initial serious reversal.Return to text 17. Some have argued that incorporating the G-SIB surcharge into post-stress capital expectations is not warranted because doing so would be duplicative of the stress test's global market and counterparty default shocks, which apply only to G-SIBs, and because post-crisis resolvability measures have lessened the likelihood that a G-SIB would fail. The first argument reflects a misunderstanding of CCAR's shocks, which apply only to G-SIBs because G-SIBs are the only firms in CCAR for which these exposures are material and are not designed to capture the adverse impact that a G-SIB failure would have on the financial system as a whole, as the G-SIB surcharge is. The second argument fails to acknowledge that making the largest firms more resolvable and strengthening their resiliency are two separate goals.Return to text 18. This would likely include replacing the supervisory model's current assumption that a firm's balance sheet increases during the severely adverse scenario with a simpler assumption under which a balance sheet and risk-weighted assets remain constant and relaxing the assumption that all of a firm's planned dividends and share repurchases would proceed during CCAR's two-year planning horizon. Instead, given the SCB's continuous constraint on distributions, we would assume a firm will maintain its dividends for one year while reducing its share repurchases.Return to text 19. Based upon data from the 2015 and 2016 CCAR exercises, Federal Reserve staff estimates that the SCB would reduce by at least $10 billion the aggregate amount of common equity tier 1 capital the non-G-SIBs would need to maintain to avoid limitations on capital distributions.Return to text 20. Incentives toward greater asset correlations can be a concern even with a non-disclosed supervisory stress test model, since banks can approximate relevant risk loss functions based on their experience and observation of supervisory results. That is why the stress test and scenarios need to be regularly modified to take account of changing risks and correlations. It is also another reason why development of macroprudential features of the stress test is important. Finally, it is a reason to continue to require firms to conduct their own internal stress tests.Return to text 21. Some have also suggested that the stress tests have caused banks to change the way they allocate credit to various types of borrowers. At one level, this could be said of any risk-based capital standard including the old Basel I standards. However, this criticism fundamentally mischaracterizes the nature and purpose of stress tests, which is to determine whether a bank can remain a going concern and continue to make loans through a severe recession, like the one we experienced from 2007 to 2009. To achieve these goals, the Federal Reserve's projections of stressed losses are highly sensitive to the full range of risks posed by the underlying assets, especially the risk that the asset will perform poorly during a downturn. The standard in stress testing is therefore whether lending practices are sustainable during tough times or not, as was the case in the 2007 to 2009 recession and other credit crises.Return to text 22. The negative effects of such a disclosure regime are exemplified by the now-infamous cutoff of many securitization programs at FICO scores of 620. Because of the transparency of the pre-crisis models used by credit rating agencies, loan originators understood that by getting their riskiest borrowers to improve their credit scores to 620, they could be included in various securitization programs.Return to text
The Federal Reserve on Thursday announced two enforcement actions against Deutsche Bank AG that will require the bank to pay a combined $156.6 million in civil money penalties. The bank will pay a $136.9 million fine for unsafe and unsound practices in the foreign exchange (FX) markets, as well as a $19.7 million fine for failure to maintain an adequate Volcker rule compliance program prior to March 30, 2016. In levying the FX fine on Deutsche Bank, the Board found deficiencies in the firm's oversight of, and internal controls over, FX traders who buy and sell U.S. dollars and foreign currencies for the organization's own accounts and for customers. The firm failed to detect and address that its traders used electronic chatrooms to communicate with competitors about their trading positions. The Board's order requires Deutsche Bank to improve its senior management oversight and controls relating to the firm's FX trading. The Board is also requiring the firm to cooperate in any investigation of the individuals involved in the conduct underlying the FX enforcement action and is prohibiting the organization from re-employing or otherwise engaging individuals who were involved in this conduct. Separately, the Board found gaps in key aspects of Deutsche Bank's compliance program for the Volcker rule, which generally prohibits insured depository institutions and any company affiliated with an insured depository institution from engaging in proprietary trading and from acquiring or retaining ownership interests in, sponsoring, or having certain relationships with a hedge fund or private equity fund. The Board also found that the firm failed to properly undertake certain required analyses concerning its permitted market-making related activities. The consent order requires Deutsche Bank to improve its senior management oversight and controls relating to the firm's compliance with Volcker rule requirements. Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955 Board Votes
The Federal Reserve Board announced on Tuesday that it isaccepting applicationsfrom individuals who wish to be considered for membership on the Community Advisory Council (CAC). Formed in 2015, the CAC advises the Board on issues affecting consumers and communities. The CAC is made up of a diverse group of experts and representatives of consumer and community development organizations and interests, including affordable housing, community and workforce development, small business, and asset and wealth building. CAC members meet semiannually with members of the Board of Governors in Washington, D.C. to provide a range of perspectives on the economic circumstances and financial services needs of consumers and communities, with a focus on the concerns of low- and moderate-income individuals and areas. It complements two of the Board's other advisory councils--the Federal Advisory Council and the Community Depository Institutions Advisory Council--whose members represent depository institutions. The Board plans to announce the appointment of CAC members in the fall of 2017. In this application cycle, the Board welcomes applications from all areas of expertise but is keenly interested in gaining perspectives on local labor and workforce developments to complement the national and regional representation on the Council. Additional information about the selection process, including instructions for submitting an application, can be found in the attachedFederal Registernotice. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Wednesday announced its approval of the application under section 3 of the Bank Holding Company Act of 1956 by Community Bank System, Inc., DeWitt, New York, to acquire Merchants Bancshares, Inc., South Burlington, Vermont. Attached is the Board's order relating to this action. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Thursday announced its approval of the application by Nordea Bank AB (publ), Stockholm, Sweden, to establish a branch in New York, New York. Attached is the Board's order relating to this action. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Friday announced its approval of the application under section 3 of the Bank Holding Company Act of 1956 by Simmons First National Corporation, Pine Bluff, Arkansas, to merge with Hardeman County Investment Company, Inc. and thereby indirectly acquire First South Bank, both of Jackson, Tennessee. Attached is the Board's order relating to this action. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Friday announced its approval of the applications under section 3 of the Bank Holding Company Act by United Bankshares, Inc., Charleston, West Virginia, and UBV Holding Company, LLC, Fairfax, Virginia, to acquire Cardinal Financial Corporation and thereby indirectly acquire Cardinal Bank, both of McLean, Virginia. The Board also approved applications under section 18(c) of the Federal Deposit Insurance Act and section 9 of the Federal Reserve Act by United Bank, Fairfax, Virginia, to merge with Cardinal Bank and to establish and operate branches at the locations of Cardinal Bank's main office and branches. Attached is the Board's order relating to this action. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Thursday announced the termination of the enforcement action listed below: Devon Bancorp, Inc., Chicago, IllinoisWritten Agreement dated March 13, 2013Terminated April 4, 2017 Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Tuesday announced the termination of the enforcement action listed below: The Baraboo Bancorporation, Inc., Baraboo, WisconsinWritten Agreement issued April 30, 2013Terminated April 7, 2017 Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955.
The Federal Reserve is committed to maintaining the security of confidential FOMC information. We cooperated fully with the independent law enforcement investigation into an unauthorized disclosure in 2012. We appreciate the diligent efforts made to bring this matter to its conclusion. For media inquiries, call 202-452-2955.
Vice Chairman Stanley Fischer At The IBRN-IMF conference: The Transmission of Macroprudential and Monetary Policies Across Borders, Washington, D.C. I appreciate your invitation to participate in this afternoon's panel discussion. In my remarks, I will discuss how U.S. monetary policy actions affect our foreign trading partners, with particular focus on how foreign economies have responded to the Federal Open Market Committee's (FOMC) ongoing normalization of policy rates.1 Spillovers from the Fed's Unconventional PoliciesExtensive empirical research on spillovers--including by Federal Reserve and International Monetary Fund (IMF) staff members--indicates that spillovers from the actions of major central banks occur through several important channels.2While the exchange rate is a key channel of transmission and gets a great deal of attention in the public debate about monetary spillovers, it is not the only channel. U.S. monetary policy also affects foreign economies by influencing U.S. domestic demand and by affecting global financial conditions. My reading of the evidence is that the Fed's highly accommodative monetary policy during the Global Financial Crisis and its aftermath probably raised foreign gross domestic product (GDP) overall.3While U.S. monetary easing caused the dollar to depreciate, which reduced foreign GDP by shifting demand toward cheaper U.S. goods, foreign economies benefited from a stronger expansion in U.S. domestic demand. Moreover, U.S. monetary easing also stimulated foreign GDP by depressing foreign bond yields and raising the prices of risky assets. Of course, there were considerable differences in how foreign economies were affected by the Fed's policies. Because the advanced foreign economies (AFEs) also experienced slow growth after the financial crisis, their central banks adopted similar policies. By contrast, the Fed's accommodative policies put further upward pressure on asset prices and currencies in some emerging market economies (EMEs) that were already experiencing rapid output growth. Thus, EME central banks had to navigate between tightening policy more--and hurting exports through a bigger exchange rate appreciation--and maintaining an accommodative stance closer to the Fed's, but with a higher risk of overheating.4These tradeoffs faced by EME central banks underscore some of the challenges posed by monetary policy divergence with the United States--a tradeoff with which I am personally very familiar. Spillovers from Recent Policy TighteningMonetary policy divergence remains a familiar theme today, but the focus has obviously shifted to the consequences of tighter U.S. monetary policy for the global economy. Policy divergence is an ongoing concern given that most AFEs and many EMEs have continued to pursue highly accommodative monetary policies that remain appropriate in light of their weaker cyclical positions and subdued levels of underlying inflation. Many observers point to the "taper tantrum" in 2013 as illustrating how monetary tightening by the Federal Reserve can potentially have strong contractionary effects on foreign financial conditions. Subsequently, the expectation that a steadily improving U.S. labor market would call for tighter U.S. monetary policy--and hence imply greater monetary divergence with our trading partners--helped drive a sharp appreciation of the dollar between the middle of 2014 and the end of last year that was accompanied by capital outflows from many EMEs. Against this backdrop and the concerns it raises, the reaction in financial markets to the FOMC's decisions to increase the target range for the federal funds rate following its December 2016 and March 2017 meetings--by a cumulative total of 50 basis points--seems benign. The yields on risky foreign bonds, especially in EMEs, have continued to decline to below historical norms, and global stock prices have risen. The dollar has depreciated since mid-December, especially against EMEs, and the EMEs have experienced capital inflows. In my view, this favorable reaction partly reflects a view by market participants that the rate hikes are a signal of the FOMC's confidence in the underlying prospects for the U.S. economy that in turn has increased confidence in the global outlook: A strong U.S. economy is a major plus for the global economy. But the main reason for the positive market reaction is that foreign output expansions appear more entrenched, and downside risks to those economies noticeably smaller than in recent years. In Europe, unemployment has fallen steadily; inflation and inflation expectations are moving toward central bank targets; and, while Brexit entails many unknowns, so far it has not resulted in significant financial market disruptions. China's economy also appears to be on a more solid footing, which has helped stabilize the renminbi as well as support growth in other EMEs. The IMF staff has taken these developments into account in the April 2017World Economic Outlook(WEO) and forecasts that world GDP growth will be noticeably higher over the next two years than in 2016--a slight upward revision relative to the October 2016 WEO.5There may well even be some chance that foreign economies kick into gear enough that U.S. and foreign business conditions become reasonably well aligned, as occurred during the U.S. monetary tightening cycles that began in 1999 and in 2004. In both of those episodes, U.S. exports grew substantially against the backdrop of a brisk expansion in foreign activity and a stable or even slightly depreciating dollar. Of course, it is hard to predict whether foreign economies continue to strengthen so that the global economy will move more in sync--as I hope--or if a substantial gap will remain between the business cycle positions of the United States and our foreign trading partners. However, even if monetary policy divergence remains substantial, there is good reason to think that spillovers to foreign economies will be manageable. First, I expect that the Fed's removal of accommodation will be driven by a continued expansion of the U.S. economy; thus, foreign economies are likely to benefit from the developments that induce the FOMC to tighten. Second, most foreign central banks should be able to mitigate an undesirable tightening of their own financial conditions through appropriate policy actions. An important lesson of the taper tantrum was that effective communication and actions by major central banks, including the European Central Bank and the Bank of England, were helpful in quickly pushing bond yields down to levels that these central banks regarded as appropriate to their economic situation. Third, many EMEs have markedly improved fundamentals--including smaller current account deficits and more anchored inflation expectations--that should allow them to better withstand the effects of U.S. tightening, though some vulnerabilities remain. Finally, I expect that U.S. policy normalization will be gradual under likely scenarios for the evolution of output and inflation. A gradual and ongoing removal of accommodation seems likely both to maximize the prospects of a continued expansion in the U.S. economy and to mitigate the risk of undesirable spillovers abroad. References Ammer, John, Michiel De Pooter, Christopher Erceg, and Steven Kamin (2016). "International Spillovers of Monetary Policy," IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8. Bernanke, Ben S. (2015). "Federal Reserve Policy in an International Context (PDF)," Mundell-Fleming lecture presented at the 16th Jacques Polak Annual Research Conference, International Monetary Fund, Washington, November 5. Fischer, Stanley (2016). "U.S. Monetary Policy from an International Perspective," speech delivered at the 20th Annual Conference of the Central Bank of Chile, Santiago, November 11. Fratzscher, Marcel, Marco Lo Duca, and Roland Straub (2013). "On the International Spillovers of U.S. Quantitative Easing (PDF)," Working Paper Series 1557. Frankfurt: European Central Bank (June). International Monetary Fund (2017).World Economic Outlook.Washington: IMF, April. Neely, Christopher J. (2015). "Unconventional Monetary Policy Had Large International Effects,"Journal of Banking and Finance, vol. 52 (March), pp. 101-11. Rogers, John H., Chiara Scotti, and Jonathan H. Wright (2014). "Evaluating Asset-Market Effects of Unconventional Monetary Policy: A Multi-Country Review,"Economic Policy, vol. 29 (October), pp. 749-99. Sahay, Ratna, Vivek Arora, Thanos Arvanitis, Hamid Faruqee, Papa N'Diaye, Tommaso Mancini-Griffoli, and an IMF Team (2014). "Emerging Market Volatility: Lessons from the Taper Tantrum (PDF)," IMF Staff Discussion Note SDN/14/09. Washington: International Monetary Fund, September. 1. The views expressed are mine and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. I am grateful to Chris Erceg for his assistance.Return to text 2. There is a large empirical literature assessing the spillovers from Federal Reserve policy actions, including those from unconventional policies such as large-scale asset purchases--for example, Fratzscher, Lo Duca, and Straub (2013); Rogers, Scotti, and Wright (2014); Neely (2015); and Sahay and others (2014).Return to text 3. My November 11, 2016, speech (Fischer, 2016) provides a more detailed discussion of spillovers from U.S. monetary policy, including some quantitative estimates that draw on the analysis of Ammer and others (2016).Return to text 4. For a more detailed discussion, see Fischer (2016) and Bernanke (2015).Return to text 5. See International Monetary Fund (2017).Return to text
The Federal Reserve Board on Tuesday released the minutes of its interest rate meetings from February 13 through March 15, 2017. The minutes are attached. For media inquiries, call 202-452-2955.
The Federal Reserve Board and the Federal Open Market Committee on Wednesday released the attached minutes of the Committee meeting held on March 14-15, 2017. A summary of economic projections made by Federal Reserve Board members and Reserve Bank presidents for the meeting is also included as an addendum to these minutes. The minutes for each regularly scheduled meeting of the Committee ordinarily are made available three weeks after the day of the policy decision and subsequently are published in the Board's Annual Report. The descriptions of economic and financial conditions contained in these minutes and in the Summary of Economic Projections are based solely on the information that was available to the Committee at the time of the meeting. FOMC minutes can be viewed on the Board's website athttp://www.federalreserve.gov/monetarypolicy/fomccalendars.htm Minutes of the Federal Open Market CommitteeMarch 14-15, 2017:HTML|PDF For media inquiries, call 202-452-2955
Vice Chairman Stanley Fischer At the Columbia University School of International and Public Affairs, New York, New York I will address the topic of central bank communications, with a particular emphasis on those times when financial markets and the central bank have different expectations about what a central bank decision will be. Such situations lead to surprises and often to market volatility. Of course, not all surprises are equal. For one, communications that shift or solidify expectations that are diffuse or not strongly held are less likely to be disruptive than communications that run counter to strongly held market beliefs. Further, there are worse things than surprises. The central bank must provide its views regarding the likely evolution of monetary policy, even when this view is not shared by market participants. A concern for surprising the market should not be a constraint on following or communicating the appropriate path of monetary policy. That said, there are good reasons to avoid unintended surprises in the conduct of policy.1 Why should central banks avoid surprising financial markets? In recent decades, it has been increasingly acknowledged that monetary policy implementation relies importantly on the management of market expectations.2In theory, clarity about the central bank's reaction function--that is, how the central bank adjusts the stance of monetary policy in response to changing economic conditions--allows the market to alter financial conditions smoothly. This typically helps meet the bank's policy targets, with the result that the markets are working in alignment with the policymaker's goals. Under this theory, repeated market surprises that raise questions about the central bank's reaction function could threaten to disrupt the relationship between the central bank and the markets, making the central bank's job more difficult in the future.3 How can the Fed avoid surprising markets? Clear communication of the Federal Open Market Committee's (FOMC's) views on the economic outlook and the likely evolution of policy is essential in managing the market's expectations. The Committee has a number of communication outlets, including the policy statement, the Chair's news conference, and the Summary of Economic Projections (SEP). The SEP in particular has been useful in providing information on policymakers' assessments of the potential growth rate of the economy and r*, the equilibrium real interest rate, both of which help guide the market's expectations of the eventual path of policy. However, avoiding unintended market reactions has not always been easy. The example that immediately comes to mind is the taper tantrum of mid-2013. To recap, over the course of May and June in 2013, the yield on 10-year Treasury securities increased almost 1 percentage point amid increased market discussion of the eventual tapering of Fed asset purchases and some key communications on the topic (figure 1).4In particular, the 10-year yield rose about 10 basis points after then Chairman Bernanke discussed tapering in public for the first time during the question-and-answer session of his Joint Economic Committee testimony on May 22, commenting that the FOMC could reduce the pace of purchases "in the next few meetings" if it saw continued improvement in the labor market that it was confident would be sustained.5Yields rose even more sharply after the June FOMC meeting, when, during his postmeeting press conference, Chairman Bernanke noted that if the economy evolved as expected, the FOMC anticipated reducing the pace of purchases in the latter part of 2013 and halting purchases altogether by the middle of 2014.6 Information gathering is an important part of managing market expectations--for the simple reason that you do not know if you are going to surprise the market unless you have a good estimate of what the market is expecting. A remarkable feature of the taper tantrum is that it was a surprise that should not have been a surprise, at least from the perspective of the information the FOMC had at the time. In assessing market expectations for policy, the FOMC reviews a variety of market indicators and also draws heavily on the Federal Reserve Bank of New York's Survey of Primary Dealers, whose respondents are the market makers in government securities and the New York Fed's trading counterparties. This survey, conducted about one week prior to each FOMC meeting, gauges primary dealers' expectations about the economy, monetary policy, and financial market developments.7 In the June 2013 primary dealer survey, the median expectation was for tapering to start in December 2013, with purchases ending in June 2014, a path not significantly different from that laid out by Chairman Bernanke in his postmeeting press conference. Thus, one could view Chairman Bernanke's remarks during his June 2013 press conference as consistent with "market expectations." Why did markets react so sharply to the apparent confirmation of the median expectation? One simple possibility is that the median expectation of the primary dealers was not reflective of the median expectation of a wider range of market participants. Respondents to the primary dealer survey are more likely to be Fed watchers and therefore more likely in tune with Fed thinking than the average market participant. For example, as seen infigure 2, a comparison of the June 2013 primary dealer survey with the contemporaneous Blue Chip Economic Indicators survey, which draws from a wider sample of forecasters, reveals that Blue Chip respondents were more likely to expect a later start of tapering and thus more likely to have been surprised by Chairman Bernanke's communications. In a related argument, former Federal Reserve Board Governor Jeremy Stein gave an insightful speech in May 2014 addressing how diversity in market expectations could have contributed to the taper tantrum.8Jeremy pointed out that it is unhelpful to view the "market" as a single individual, a theme that has been explored by Hyun Song Shin of the Bank for International Settlements.9Rather, the market is a collection of agents that can have widely divergent but perhaps strongly held beliefs at the individual level. Jeremy attributes the taper tantrum to the existence ofhighly leveraged quantitative easing optimists--in other words, individuals who expected the Federal Reserve to continue to accumulate assets much longer than the median expectation and who put little weight on the median market expectation. Once Chairman Bernanke affirmed the median expectation, these optimists had to quickly unwind their trades, with consequent sharp movements in asset prices. Where does that leave us? The problem, to quote Jeremy at length, "is that in some circumstances there are very real limits to what even the most careful and deliberate communications strategy can do to temper market volatility. This is just the nature of the beast when dealing with speculative markets, and to suggest otherwise--to suggest that, say, 'good communication' alone can engineer a completely smooth exit from a period of extraordinary policy accommodation--is to create an unrealistic expectation."10 Jeremy was speaking about ending the accumulation of assets onto the Fed's balance sheet. As reported in the minutes for the March 2017 meeting, the FOMC is now discussing a different inflection point, the phasing out of reinvestment and the shrinking of the balance sheet.11Question: How concerned should we be about a repeat of the taper tantrum as we move through this new inflection point? We should start answering such a question by recognizing that there is always a chance of some market volatility. Nonetheless, we need to take into account that the New York Fed's Open Market Desk enhanced its information-gathering efforts after and, in part, as a response to the experience of the taper tantrum along two important dimensions. First, in 2014, the Desk augmented its Survey of Primary Dealers with a Survey of Market Participants, going some way to addressing concerns that primary dealers alone were not providing sufficient coverage of market beliefs.12Second, more recently, questions have been added to the surveys to identify uncertainty about reinvestment policyfor each individual survey respondentand not just the dispersion of beliefs about the expected changeacrossrespondents. Starting with the market participant survey, as I noted earlier, one informational constraint that complicated the Fed's understanding of market dynamics around the taper tantrum was the possible divergence of beliefs between the primary dealers, who were surveyed, and the market at large. The differences between the expectations of the primary dealers and those of the panel for the Blue Chip Economic Indicators, shown in figure 2, provide some support for the view that the primary dealers' views may well have differed from those of a wider range of market participants, but it would have been preferable to have a poll of market participants rather than forecasters. Not long after the taper tantrum, in January 2014, the Desk began its separate Survey of Market Participants. The survey panel currently consists of 30 so-called buy-side firms, including hedge funds and asset managers. Turning now to measures of individual uncertainty, in the April 2013 primary dealer survey, just prior to the taper tantrum, dealers were mostly questioned on their point estimates regarding the timing and conditions under which tapering would commence. Respondents were asked to provide their expectation for the monthly pace of asset purchases after each of several upcoming policy meetings. They were also asked to provide point estimates, or estimates of single particular values, for the quarter and year during which they expected asset purchases in Treasury and agency mortgage-backed securities to be completed. While these questions did provide some notion of the variation in beliefs across respondents, they did not provide much information on how strongly these beliefs were held by the individual respondents, nor on the extent to which their individual beliefs might have been reflected in the size of their market positions and, in particular, the amount of leverage underlying those positions.13 In contrast, the most recent primary dealer and market participant surveys, conducted prior to the March 2017 FOMC meeting, asked survey participants to indicate their view of their own uncertainty over several different aspects of policy. For example, in addition to their point estimates, participants were asked to indicate the percent chance they assigned to the federal funds rate being at various levels when the FOMC first announces a change to the reinvestment policy. They were also asked to assign probabilities to different dates for the first announced change in reinvestment policy. Why is this information important? To go back to Jeremy Stein's argument about the taper tantrum, Jeremy pointed out that market participants' expectations for tapering varied widely, but he conjectured that some of the participants were very certain in their expectations and that it was primarily their reaction that fueled the taper tantrum. When the surveys reported only point estimates, we had a measure of dispersion across market participants, but we were in the dark on how firmly held these beliefs were. By asking participants to provide a distribution of outcomes, we also obtained a measure of how certain they are of a particular outcome. To highlight some results from the March 2017 surveys, as shown infigure 3, the primary dealers' median projection for the level of the target federal funds rate when the FOMC first announces a change in its reinvestment policy was reported to be 1.63 percent. The 25th percentile of the distribution across respondents was 1.38 percent, and the 75th percentile was 1.88 percent, suggesting a fairly tight range around the median expectation. The reported range was even tighter for the market participants around a median projection of 1.63 percent. However, it would be a mistake to infer from the narrowness of these ranges a firmness in expectations. As shown infigure 4, when respondents of each survey were asked to indicate the percent chance assigned to different fed funds target levels when the change in policy is announced, the average of all of their reported distributions was wide and flat. The primary dealer survey places roughly equal weight on rates between 1.26 and 2.00 percent. In the underlying nonpublic data for the individual responses, the reported distributions were somewhat narrower but still reflected significant uncertainty, with no primary dealer placing more than 50 percent probability on any particular target range. Like the dealers, the market participants also report wide individual distributions of beliefs. Likewise, when primary dealers were asked about the timing of the announced change in reinvestment policy, the average of their responses was a relatively flat distribution of possible dates, with almost equal probability on the announcement occurring in the fourth quarter of 2017, the first two quarters of 2018, or the second half of 2018 (figure 5). Again, the individual distributions were narrower but still showed a significant amount of uncertainty. Highlighting the usefulness of also surveying market participants, expectations in the market survey are distinctly shifted toward an early announcement date relative to the expectations of the primary dealers. The surveys reveal that while beliefs are dispersedacrossparticipants, importantly individual survey participants are also significantly uncertain--in other words, any given participant does not appear to have firmly decided on the likely path of policy. The general point is that while we often measure and report differences in views across individuals, the uncertainty that individuals feel internally is also relevant. Recent survey results that show that market participants assign a positive probability to a wide range of outcomes also suggest that the factors that exacerbated the taper tantrum--dispersed but firmly held beliefs--may be less pronounced in current circumstances than they were at the time of the taper tantrum. The market reaction to the release of the minutes of the March 2017 FOMC meeting supports this interpretation of the interaction of uncertainty and Fed policy communications. The minutes reported that, "provided that the economy continued to perform about as expected, most participants anticipated that gradual increases in the federal funds rate would continue and judged that a change to the Committee's reinvestment policy would likely be appropriate later this year."14As was shown in figure 5, in the March 2017 surveys, respondents placed the most weight, 71 percent for the primary dealers and 57 percent for the market participants, on an announced change in reinvestment policy not occurring until 2018 at the earliest. Presumably, the April survey will reveal a shift in these distributions. It is noteworthy, however, that even though the statement in the minutes of the March FOMC meeting regarding Committee members' expectations for announcing changes in the reinvestment policy was not aligned with market expectations, there was only a muted market reaction.15Perhaps in part, that is because the market participant survey actually revealed a considerable amount of weight, though not the majority, on an announcement occurring this year. Or it is also possible that the diffuse expectations on timing prior to the release of the minutes were a factor in tamping down market volatility as market participants adjust their expectations.16 My tentative conclusion from market responses to the limited amount of discussion of the process of reducing the size of our balance sheet that has taken place so far is that we appear less likely to face major market disturbances now than we did in the case of the taper tantrum. But, of course, as we continue to discuss and eventually implement policies to reduce our balance sheet, we will have to continue to monitor market developments and expectations carefully. I would like to conclude by briefly discussing two issues. First, a question: Can the Fed be too predictable? And, second, I will add a short comment on the SEP, the quarterly Summary of Economic Projections of the participants in the FOMC. With regard to whether the Fed can be too predictable, it is hard to argue that predictability in our reaction to economic data could be anything but positive. To reference the beginning of my talk, clarity about the Fed's reaction function allows markets to anticipate Fed actions and smoothly adjust along with the path of policy. But there is a circumstance where it might be reasonable to argue that the Fed could be too predictable--in particular, if the path of policy is not appropriately responsive to the incoming economic data and the implications for the economic outlook. Standard monetary policy rules suggest that the policy rate should respond to the level of economic variables such as the output gap and the inflation rate. As unexpected shocks hit the economy, the target level of the federal funds rate should adjust in response to those shocks as the FOMC adjusts the stance of policy to achieve its objectives. Indeed, it is these unexpected economic shocks that give rise to the range of uncertainty around the median federal funds rate projection of FOMC participants, represented through fan charts, which was recently incorporated into the SEP. The Federal Reserve could be too predictable if this type of fundamental uncertainty about the economy does not show through to uncertainty about the monetary policy path, which could imply that the Federal Reserve was not being sufficiently responsive to incoming data bearing on the economic outlook. Let me conclude with a few words on the SEP results as portrayed in the dot plots. The SEP is a highly useful vehicle for providing information to market participants and others for whom Fed actions are important. But we need to remind ourselves that the SEP data for an individual show that person's judgment of the appropriate path of future fed funds rates and the corresponding paths of other variables for which the SEP includes forecasts. Thus, one may say that the SEP shows the basis from which each participant in the FOMC discussion is likely to start. But the task of moving from that information to an interest rate decision is not simple and requires a great deal of analysis and back-and-forth among FOMC participants at each meeting. References Bernanke, Ben S. (2004). "The Logic of Monetary Policy," speech delivered at the National Economists Club, Washington, December 2. -------- (2013a). "Communication and Monetary Policy," speech delivered at the National Economists Club Annual Dinner, Herbert Stein Memorial Lecture, Washington, November 19. -------- (2013b). "Statement of Hon. Ben Bernanke, Chairman of the Board of Governors of the Federal Reserve System, Washington, DC (PDF)," inThe Economic Outlook, hearing before the Joint Economic Committee, Congress of the United States,May 22, Senate Hearing 113-62, 113 Cong. Washington: Government Printing Office. -------- (2013c). "Transcript of Chairman Bernanke's Press Conference (PDF)," June 19. Board of Governors of the Federal Reserve System (2017). "Minutes of the Federal Open Market Committee, March 14-15, 2017," press release, April 5. Shin, Hyun Song (2017). "How Much Should We Read into Shifts in Long-Dated Yields?" speech delivered at the U.S. Monetary Policy Forum, New York, March 3. Spicer, Jonathan (2017). "Fed Could Promptly Begin Shedding Bonds This Year: Dudley,"U.S. News,March 31, http://money.usnews.com/investing/news/articles/2017-03-31/fed-could-begin-trimming-bond-portfolio-this-year-dudley. Stein, Jeremy C. (2014). "Challenges for Monetary Policy Communication," speech delivered at the Money Marketeers of New York University, New York, May 6. Woodford, Michael (2005). "Central Bank Communication and Policy Effectiveness (PDF)," inThe Greenspan Era: Lessons for the Future,proceedings of a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., Aug. 25-27. Kansas City, Mo.: Federal Reserve Bank of Kansas City, pp. 399-474. 1. I am grateful to Joseph Gruber and Don Kim of the Federal Reserve Board for their assistance. The views expressed are mine and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee.Return to text 2. Bernanke (2004, 2013a) and Woodford (2005) underscore how central bank efforts to shape market expectations can enhance policy effectiveness. The critical role of market expectations in determining asset prices and reactions to policy changes has long been recognized; it is the explicit recognition of this link in formal models and the analysis of policy that is the recent major achievement.Return to text 3. Historically, there have been times when central banks have preferred to surprise markets--most notably, when changing the value of exchange rate pegs during the era of fixed exchanges. Indicating that a change in the peg was coming would invite an immediate run on the currency, at a significant cost to the central bank's foreign reserves--even in economies with extensive capital controls.Return to text 4. Also notably, Eurodollar futures rates and OIS (overnight index swap) forward rates for intermediate horizons rose sharply, likely in part because some investors who were surprised by the tapering news also revised their expectations about the path of the policy rate.Return to text 5. See Bernanke (2013b), p. 11.Return to text 6. See Bernanke (2013c).Return to text 7. The responses to the survey are received by the Federal Reserve Bank of New York's Markets Group typically by the penultimate Monday before the FOMC meeting. At the time of the taper tantrum, there were 21 primary dealer participants. Currently, there are 23 primary dealers. Past survey results can be found on the Federal Reserve Bank of New York's website athttps://www.newyorkfed.org/markets/primarydealer_survey_questions.html.Return to text 8. See Stein (2014).Return to text 9. For a recent example, see Shin (2017). Shin suggests using caution when extrapolating "market" expectations from movements in asset prices, pointing to examples where technical factors likely complicate the interaction of market participants' actions relative to their expectations.Return to text 10. See Stein (2014), paragraph 12.Return to text 11. See Board of Governors (2017).Return to text 12. Past market participant surveys can be found on the Federal Reserve Bank of New York's website athttps://www.newyorkfed.org/markets/survey_market_participants.html.Return to text 13. Participants in the April 2013 survey were asked for their probability distribution across the total holdings of the System Open Market Account portfolio at year-end 2013 and year-end 2014, providing some, though incomplete, indication of the extent of uncertainty among market participants.Return to text 14. See Board of Governors (2017), p. 3.Return to text 15. The immediate reaction in yields was a slight rise, but the action quickly reversed, and yields ended the afternoon down 3 to 4 basis points.Return to text 16. Of note, Federal Reserve Bank of New York President William Dudley's comments on March 31, mentioning "sometime later this year or sometime in 2018" (as quoted in Spicer (2017), paragraph 2)) for the timing of a reinvestment policy change, may also have been a factor behind the muted market reaction to the March FOMC minutes.Return to text Accessible Version
Governor Jerome H. Powell At "Expanding the Impact: Increasing Capacity and Influence," the 2017 Interagency Minority Depository Institution and Community Development Financial Institution Bank National Conference, Los Angeles, California Thank you, Donna. Good morning and welcome to the Federal Reserve. We are honored to have you here today as we host the biennial Interagency Minority Depository Institution (MDI) and Community Development Financial Institution Bank Conference. My colleagues from the Federal Reserve Bank of San Francisco and I are especially honored to be hosting you in Los Angeles. As you probably know, all of the previous Interagency MDI conferences have been held on the East Coast, mainly in Washington, D.C. However, because the largest concentration of minority banks is located here in Southern California, it seemed natural to bring this conference west. The Federal Reserve seeks to support MDIs in a number of ways, including our Partnership for Progress, our program for outreach and technical assistance to MDIs. Both the Office of the Comptroller of the Currency and Federal Deposit Insurance Corporation share our goal of preserving and promoting MDIs because you are critical institutions to the communities you serve and the larger U.S. economy. And I note that Congress has also recognized your importance, mandating our respective agencies to help support MDIs. From the perspective of someone who sits on the Federal Open Market Committee, I see many ways that the Federal Reserve can not only support MDIs but is itself also supported by them, and I would like to talk about four of these ways today. First, half of our monetary policy mandate is maximum sustainable employment. That means that we need to be aware of employment trends across all communities in America, not just the top-line averages, since unemployment rates vary significantly across races and geographies. For the first time, last year, we put into ourMonetary Policy Reportto Congress a section that detailed how post-recession economic gains have been distributed across races.1You, as MDIs, are committed to understanding and serving these diverse communities. I know that, for example, your small business loans to minority business owners make a difference in the employment rates of minority communities. I thank you for that work, and we will continue to work closely with you to better understand the employment dynamics of underserved and minority communities. Second, the Fed is unique as a research institution. We have many economists on staff and therefore have the ability to engage in wide-ranging research that may be useful to your firms and communities. Specific to MDIs, we commissioned two new research papers for this conference to better understand trends in the MDI banking field. In addition, we have two new research papers on MDIs out of the Chicago Fed, one that explores MDI primary markets, and one that looks at MDI small business lending. Tomorrow you'll have an opportunity to hear about and discuss this new research, which will be finalized later this year. Third, we have a great deal of expertise in community banks, which I know most of you are. Of the 829 state member banks that the Federal Reserve directly supervises, 97 percent are community banks. Therefore, we spend a good deal of time thinking about the issues facing community banks and how to help them be competitive in today's economy. I recognize that as MDIs you share many of the same issues as other community banks, and also some issues that are unique to your sector. We want to work with you to better understand those issues and to help you, where possible, to better serve your communities. Fourth, and last, the Fed has a unique Community Development function that seeks to mobilize ideas, networks, and approaches that address a wide range of community and economic development challenges. One thing that makes our Community Development function unique is that we have deep geographic coverage at the 12 Reserve Banks and their Branch locations. Last year, we combined the resources of our Supervision and Regulation division with those of our Community Development department to staff our Partnership for Progress. By bringing in Community Development, we brought in a new perspective, one that has an explicit focus on low- and moderate-income communities. We know that you serve many of these same individuals and communities, and we are asking our Community Development staff around the country to reach out to you to gather your perspectives on the communities you serve to identify emerging issues of which we should be aware. In closing, your institutions are important to the American economy and our understanding of that economy. Therefore, on behalf of the Federal Reserve, I'd like to once again thank you for the work you do in your communities and welcome you to Los Angeles. 1.Board of Governors of the Federal Reserve System,Monetary Policy Report(Washington: Board of Governors, June 21, 2016),www.federalreserve.gov/monetarypolicy/files/20160621_mprfullreport.pdf.Return to text
Governor Lael Brainard At the Northwestern Kellogg Public-Private Interface Conference on "New Developments in Consumer Finance: Research & Practice" We can learn a lot from the evolution of smartphones as we try to envisage where the fintech ecosystem--and banks' role within it--might be heading in the future. Smartphones have ushered in an age when different companies can easily work with each other's products to seamlessly provide services to consumers. Today I want to reflect on what we might learn from that model about the increasingly interconnected world of financial services. On the 10th anniversary of the iPhone, a Wired.com article revealed that even Steve Jobs hadn't predicted the smartphone's potential as a platform.1Apple was just trying to design an iPod that made phone calls. Today, the average American spends five hours a day on their phone, unlocking it an average of 80 times daily.2Even the Supreme Court has noted that smartphones are now "such a pervasive and insistent part of daily life that the proverbial visitor from Mars might conclude they were an important feature of human anatomy."3 Of course, we aren't using these appendages primarily to make phone calls. Instead, we mainly use our smartphones to access applications (apps).4In June of last year, Apple announced that over 2 million apps were available on its App Store.5For the most part, these apps were not createdor even envisagedby Apple. These apps have been downloaded 130 billion times, generating over $50 billion in revenue for third-party developers.6 The iPhone is a key platform on which that app ecosystem operates. How did that happen? Apple essentially made the smartphone a toolkit for third-party developers to experiment, innovate, build, and scale new apps. It did so by investing heavily in developing open application programming interfaces (APIs) that provided third-party developers clear instructions and open access to the iPhone platform. This strategy enabled those outside developers to build new applications that delivered Apple's customers additional value by taking advantage of the existing functionality of the iPhone. Specifically, this open architecture makes available to outside developers clear instructions that enable them to use the iPhone's various sensors, processors, displays, and other interfaces in combination with their own code to develop new products. On top of that, a robust secondary layer of developers use the APIs ofotherdevelopers in their technology stacks to quickly assemble new business models. Take ride-sharing services, for instance. They have built multibillion-dollar businesses that are, in large part, dependent on combinations of APIs from different companies. They may use Google Maps' APIs for location services, Stripe or Braintree's APIs for payments, Twilio's APIs for text messaging, and Amazon Web Services' or IBM's APIs for computing power. All of these products, and more, work seamlessly together in real time to provide products that are so ubiquitous that we now use them as verbs for how we navigate the world. We "Uber" to the store or "Snapchat" a friend. Risks and Opportunities in an Increasingly Interconnected WorldThere is every reason to expect financial services to make a similar transition to an increasingly interconnected digital world. By now, we've all heard estimates of the thousands of fintech companies that have launched in the past few years and the billions of investment dollars that are flooding into this sector.7But for all of the talk of "disruption," I want to underscore an important point: More often than not, there is a banking organization somewhere in the fintech stack. Just as third-party app developers rely on smartphone sensors, processors, and interfaces, fintech developers need banks somewhere in the stack for such things as: (a) access to consumer deposits or related account data, (b) access to payment systems, (c) credit origination, or (d) compliance management.8For instance, account comparison services rely on access to data from consumers' bank accounts. Savings and investment apps analyze transactions data from bank accounts to understand how to optimize performance and manage the funds consumers hold in those accounts. Digital wallets draw funds from payment cards or bank accounts. Marketplace loans most often depend on loan origination by a bank partner. And payment innovations often "settle up" over legacy payment rails, like the automated clearinghouse system.9In short, the software stacks of almost all fintech apps point to a bank at one layer or another. So as fintech companies and banks are catching up to the interconnected world, the various players are sorting out how best to do the connecting. Much of the work so far has been focused on the technical challenges, which are notable. Most banks' core systems are amalgams of computing mainframes built decades ago before the Internet or cloud computing were widely available and, in many cases, stitched together over the course of mergers and consolidations.10It takes a lot of investment to securely convert that infrastructure to platforms that can operate in real-time with ready access for Internet-native third-party developers. But important policy, regulatory, and legal questions also demand attention. And that is where the smartphone analogy loses its power. On balance, bank activities are much more highly regulated than smartphones. Those regulations enable consumers to trust their banks to secure their funds and maintain the integrity of their transactions. While "run fast and break things" may be a popular mantra in the technology field, it is ill suited to an arena where a serious breach could undermine confidence in the payments system. Indeed, some of the key underpinnings of consumer protection and safety and soundness in the banking world--that consumers should be exceptionally careful in granting account access, that in certain conditions banks could be presumed to bear liability for unauthorized charges, and that banks can be held responsible for ensuring that service providers and vendors do right by their customers--sit uneasily alongside the requisites of openness, connectivity, and data access that enable today's app ecosystem.11For instance, before entering an outsourcing arrangement, a bank is expected to consider whether the service provider's internal processes or systems (or even human error at the outside party) could expose the bank and its customers to potential losses or expose the bank's customers to fraud and the bank to litigation; whether the service provider complies with applicable laws and regulation; and whether poor performance by that outside party could materially harm the bank's public reputation. The smartphone app ecosystem developed without the regulations or associated guardrails pertaining to institutions that people trust to hold their life savings. For instance, when Pokmon Go was first launched, its creator, Niantic, used an outdated Google API to verify consumer identities. This created confusion about whether millions of consumers had unwittingly granted Niantic full access to their e-mails, contact lists, and calendars.12However, it did not stand in the way of Pokmon Go subsequently being downloaded a half billion times.13In contrast, these kinds of mistakes in the banking sector could raise grave concerns about consumer data privacy and security and the integrity of consumer transactions data. That's why banks are expected to conduct extensive risk assessments and due diligence of their service providers, extending even to operations and internal controls, among other requirements.14While that helps ensure a safe and sound banking system, that also makes it more challenging for both the banks and fintech companies to harness safely the interconnectivity that has powered other parts of the digital world. Different Approaches to the Fintech StackBecause of the high stakes, fintech firms, banks, data aggregators, consumer groups, and regulators are all still figuring out how best to do the connecting. There are a few alternative approaches in operation today, with various advantages and drawbacks. A number of large banks have developed or are in the process of developing interfaces to allow outside developers access to their platforms under controlled conditions. Similar to Apple opening the APIs of its phones and operating systems, these financial companies are working to provide APIs to outside developers, who can then build new products on the banks' platforms.15It is worth highlighting that platform APIs generally vary in their degree of openness, even in the smartphone world. If a developer wants to use a Google Maps API to embed a map in her application, she first must create a developer account with Google, agreeing to Google's terms and conditions. This means she will have entered a contract with the owner of the API, and the terms and conditions may differ depending on how sensitive the particular API is. Google may require only a minimum amount of information for a developer that wants to use an API to display a map. Google may, however, require more information about a developer that wants to use a different API to monitor the history of a consumer's physical locations over the previous week. And in some cases, the competitive interests of Google and a third-party app developer may diverge over time, such that the original terms of access are no longer acceptable.16 The fact that it is possible and indeed relatively common for the API provider--the platform--to require specific controls and protections over the use of that API raises complicated issues when imported to the banking world. As banks have considered how to facilitate connectivity, the considerations include not only technical issues and the associated investment, but also the important legal questions associated with operating in a highly regulated sector. The banks' terms of access may be determined in third-party service provider agreements that may offer different degrees of access. These may affect not only what types of protections and vetting are appropriate for different types of access over consumers' funds and data held at a bank in order to enable the bank to fulfill its obligations for data security and other consumer protections, but also the competitive position of the bank relative to third-party developers. There is a second broad type of approach in which many banks have entered into agreements with specialized companies that essentially act as middlemen, frequently described as "data aggregators." These banks may lack the budgets and expertise to create their own open APIs or may not see that as a key element in their business strategies. Data aggregators collect consumer financial account data from banks, on the one hand, and then provide access to that data to fintech developers, on the other hand.17Data aggregators organize the data they collect from banks and other data sources and then offer their own suite of open APIs to outside developers. By partnering with data aggregators, banks can open their systems to thousands of developers, without having to invest in creating and maintaining their own open APIs. This also allows fintech developers to build their products around the APIs of two or three data aggregators, rather than 15,000 different banks and other data sources. And, if agreements between data aggregators and banks are structured as data aggregators performing outsourced services to banks, the bank should be able to conduct the appropriate due diligence of its vendors, whose services to those banks may be subject to examination by safety and soundness regulators.18 Some banks have opted for a more "closed" approach to fintech developers by entering into individual agreements with specific technology providers or data aggregators.19These agreements often impose specific requirements rather than simply facilitating structured data feeds. These banks negotiate for greater control over their systems by limiting who is accessing their data--often to a specific third party's suite of products. Likewise, many banks use these agreements to limit what types of data will be shared. For instance, banks may share information about the balances in consumers' accounts but decline to share information about fees or other pricing. While recognizing the legitimate need for vetting of third parties for purposes of the banks fulfilling their responsibilities, including for data privacy and security, some consumer groups have suggested that the standards for vetting should be commonly agreed to and transparent to ensure that banks do not restrict access for competitive reasons and that consumers should be able to decide what data to make available to third-party fintech applications.20 A third set of banks may be unable or unwilling to provide permissioned access, for reasons ranging from fears about increased competition to concerns about the cost and complexity of ensuring compliance with underlying laws and regulations. At the very least, banks may have reasonable concerns about being able to see, if not control, which third-party developers will have access to the banking data that is provided by the data aggregators. Accordingly, even banks that have previously provided structured data feeds to data aggregators may decide to limit or block access.21In such cases, however, data aggregators can still move forward to collect consumer data for use by fintech developers without the permission or even potentially without the knowledge of the bank. Instead, data aggregators and fintech developers directly ask consumers to give them their online banking logins and passwords. Then, in a process commonly called "screen scraping," data aggregators log onto banks' online consumer websites, as if they were the actual consumers, and extract information. Some banks report that as much as 20 to 40 percent of online banking logins is attributable to data aggregators. They even assert that they have trouble distinguishing whether a computer system that is logging in multiple times a day is a consumer, a data aggregator, or a cyber attack. For community banks with limited resources, the necessary investments in API technology and in negotiating and overseeing data-sharing agreements with data aggregators and third-party providers may be beyond their reach, especially as they usually rely on service providers for their core technology. Some fintech firms argue that screen scraping--which has drawn the most complaints about data security--may be the most effective tool for the customers of small community banks to access the financial apps they prefer--and thereby necessary to remain competitive until more effective broader industry solutions are developed. Clearly, getting these connectivity questions right, including the need to manage the consumer protection risks, is critically important. It could make the difference between a world in which the fintech wave helps community banks become the platforms of the future, on the one hand, or, on the other hand, a world in which fintech instead further widens the gulf between community banks and the largest banks. TradeoffsThe different approaches to integrating banks into the fintech stack represent different risks and tradeoffs. Connectivity solutions that require intermediaries such as data aggregators and rely on screen scraping potentially create repositories of consumer credentials for hackers to target. Banks argue that if such a repository is breached, thousands of banks could be impacted.22Further complicating things, because screen scrapers operate without contractual relationships with the banks from which they pull information, banks have little leverage or ability to vet the security of the screen scrapers' systems and methods or their overall risk. In these circumstances, some commentators have noted that if a data aggregator or third-party developer is breached, it may not be clear who would bear responsibility for any losses--the bank, the data aggregator, the fintech developer, or the consumer. Some third-party developers have included terms and conditions that specifically limit their liability to consumers.23It is not clear the extent to which many consumers understand the risks involved with sharing their banking credentials, the more limited liability accepted by many third-party developers relative to their bank or credit card issuer, and the fact that the third-party developers may in turn provide those credentials to others in some instances. On the other side of the debate, fintech companies are concerned that banks could use their control over consumer data access in the context of bilateral contracts with data aggregators to leverage their position in order to impede competition elsewhere in the stack. This argument about access and competition echoes similar concerns in the smartphone arena.24 Further, third-party developers argue that open standards for data access can help banks meet consumers' expectations for mobile banking by providing access to the fintech apps that best serve their needs. The relatively open architecture of the iPhone platform means that Apple profits from outside developers' products without having to design or invest in them directly. For instance, Apple didn't include a home-grown mapping app during the first few years of the iPhone.25Instead, it relied on Google to provide that important function for its smartphones before trying to build its own mapping tool--a process that took a number of iterations before getting it right. Open platform strategies may mean that banks can essentially outsource product development to fintech firms.26This could be a boon--particularly for small community banks that would not have to worry about developing the best consumer interface, mobile app, digital wallet, or lending product. The bank would only have to worry about getting the connections to an open API right and then reap the benefits of the innovation by third parties. Regulatory DevelopmentsAs regulators, we have a responsibility to ensure that the institutions subject to our supervision are operated safely and soundly and that they comply with applicable statutes and regulations. More broadly, we have a strong interest in permitting socially beneficial innovations to flourish, while ensuring the risks that they may present are appropriately managed, consistent with the legal requirements. We do not want to unnecessarily restrict innovations that can benefit consumers and small businesses through expanded access to financial services or greater efficiency, convenience, and reduced transaction costs. Nor do we want to drive these activities away from regulated banks and toward less governed spaces in the financial system. Regulators in the United Kingdom and continental Europe have recently outlined new approaches to facilitate connectivity in financial services, while attempting to mitigate the associated risks. In August 2016, the UK Competition & Markets Authority (CMA) released a package of mandates aimed at increasing competition for consumer and small business current accounts (akin to U.S. checking accounts).27This year nine of the country's largest banks were required to create open APIs to share nonsensitive, non-consumer-specific information, like pricing, fees, terms, and conditions as well as branch and automated teller machine locations.28This initial limited sharing of information has started communication and collaboration across the industry on areas like data standards and organizational governance, which will facilitate work on more contentious questions. Before March 2018, the CMA is scheduled to enforce a broader package of reforms, including mandating that the nine banks create APIs that allow third-party banks and nonbanks to access consumer accounts for reading transaction data and payment initiation. In the European Union, beginning in 2018, member states will be required to start implementing the European Parliament's revised Payment Services Directive (PSD2).29Among other elements, PSD2 created licensing regimes for third parties that access bank accounts for purposes of initiating payment orders or consolidating information with consumers' consent.30The directive mandates that banks allow these licensed third parties to access their consumer accounts (with consumer permission) without premising such access on contractual agreements with the banks. Indeed, PSD2 requires that credit institutions not block or hinder access to payment accounts and that licensed third parties have access to credit institutions' payment accounts services in an objective, nondiscriminatory, and proportionate manner. When credit institutions do reject access, they are required to provide the relevant authorities detailed reasoning for the rejection. The directive attempts to mitigate the attendant data-security and consumer-protection risks with a number of measures that, by and large, are not readily available policy options in the United States. Importantly, third parties that access bank accounts will be subject to licensing and registration requirements, as well as associated capital and insurance requirements. Moreover, the directive envisions that electronic payments will be authorized by two-factor authentication--for example "something you know" and "something you are."31 The United States is likely to address these issues in a different way, at least initially, given that regulatory authorities are more broadly distributed, and the relevant statutory language predates these technological developments. The Consumer Financial Protection Bureau (CFPB) issued a Request for Information last fall to explore issues surrounding consumers' granting access to account information to third parties.32Of course, safety and soundness regulation--and with it, concerns about data security, cyber security, and vendor risk management--is distributed among a number of regulators. For instance, there may be value to examining the vendor risk management guidance so that it facilitates banks connecting more securely and efficiently with the fintech apps that consumers prefer.33Similarly, it could be useful to periodically assess whether and how authority under the Bank Service Company Act might pertain to developments in the fast evolving fintech sector. In addition, the private sector is continuing to actively experiment with a variety of different approaches to the connectivity question and may itself move toward one or more widely accepted standards. Accordingly, efforts to craft approaches that enhance connectivity while mitigating the associated risks will likely benefit from the engagement of multiple agencies, along with input from the private sector and other stakeholders. Separately, the Office of the Comptroller of the Currency (OCC), which is responsible for administering national bank charters, has announced that it is exploring offering "special purpose national bank charters" to fintech companies.34As envisioned by the OCC, obtaining a special purpose charter would have the practical effect of allowing certain fintech companies (companies that make loans, make payments, or accept deposits) to potentially bypass the need for connecting to a bank for certain purposes in favor of becoming licensed as banks themselves. The OCC's proposal raises interpretive and policy issues for the Federal Reserve regarding whether charter recipients would become Federal Reserve members or have access to Federal Reserve accounts and services, such as direct access to payment systems. If the OCC proposal is finalized, the Federal Reserve would have to closely analyze these issues with respect to any fintech firms that express an interest in moving forward with an application. When Apple launched the iPhone in 2007, who could have predicted that it would net billions from a game like Pokmon Go, which involved no investment, development, or advertising on Apple's part beyond opening its platform to developers? It is still too early to have any confidence that we know which fintech innovations will prove to be the most long-lasting or widely adopted. By the same token, the fintech industry is still figuring out the fundamental questions of the best ways to make the necessary connections to the banking platforms to facilitate consumers' ability to better monitor and manage their financial lives, while providing the level of data security and protection they have come to rely on from their banks.35Change is surely coming, as financial products and services move onto interconnected platforms. As the sector evolves, it's important that all parties involved pay close attention not only to the technical questions, but to the requisite regulatory, policy, and legal considerations to ensure continued trust and confidence in the financial system. I am grateful to Kelvin Chen for his assistance in preparing this text. 1. David Pierce, "Even Steve Jobs Didn't Predict the iPhone Decade," Wired, January 9, 2017, www.wired.com/2017/01/apple-iphone-10th-anniversary/.Return to text 2. Mary Meeker, Internet Trends 2016Code Conference, June 1, 2016,www.slideshare.net/kleinerperkins/2016-internet-trends-report/109-KPCB_INTERNET_TRENDS_2016_PAGE109Average(slide 109); and Ben Bajarin, "Apple's Penchant for Consumer Security," TechOpinions, April 18, 2016, https://techpinions.com/apples-penchant-for-consumer-security/45122.Return to text 3. See Riley v. California, 134 S. Ct.2473, 2484 (2014),www.supremecourt.gov/opinions/13pdf/13-132_8l9c.pdf.Return to text 4. For instance, the average American now spends nearly an hour a day on Facebook's mobile platforms alone. See, e.g., James B. Stewart, "Facebook Has 50 Minutes of Your Time Each Day. It Wants More," New York Times, May 5, 2016, www.nytimes.com/2016/05/06/business/facebook-bends-the-rules-of-audience-engagement-to-its-advantage.html. This count includes Facebook, Messenger, and Instagram, but not WhatsApp.Return to text 5. See, e.g., Jordan Golson, "Apple's App Store Now Has over 2 Million Apps," The Verge, June 13, 2016, www.theverge.com/2016/6/13/11922926/apple-apps-2-million-wwdc-2016.Return to text 6. See, e.g., Sarah Perez, "Apple's App Store hits 2M apps, 130B downloads, $50B paid to developers," TechCrunch June 13, 2016, https://techcrunch.com/2016/06/13/apples-app-store-hits-2m-apps-130b-downloads-50b-paid-to-developers/. On August 3, 2016, Apple CEO Tim Cook noted on Twitter that the $50 billion figure had been surpassed. Tim Cook, Twitter, Aug. 3, 2016, https://twitter.com/tim_cook/status/760929629226041345 (last accessed April 4, 2017).Return to text 7. In 2015 KPMG estimated that global investment in fintech had risen six-fold in the prior three years. KPMG, "'Fintech 100'--Announcing the World's Leading Fintech Innovators for 2015," December 2015, https://home.kpmg.com/xx/en/home/media/press-releases/2015/12/fintech-announcing-the-world-leading.html. In the lending sector alone, Goldman Sachs estimates that $11 billion of annual profit is at risk of leaving the banking system. Ryan M. Nash and Eric Beardsley, The Future of Finance Part 1: The Rise of the New Shadow Bank (New York: Goldman Sachs, March 3, 2015), www.betandbetter.com/photos_forum/1425585417.pdf. McKinsey & Company estimates that there are over 2,000 fintech startups, which have attracted nearly $23 billion of venture capital and growth equity over the past five years. See Miklos Dietz, Somesh Khanna, Tunde Olanrewaju, and Kausik Rajgopal, "Cutting Through the Noise around Financial Technology," McKinsey & Company, February, 2016, www.mckinsey.com/industries/financial-services/our-insights/cutting-through-the-noise-around-financial-technology.Return to text 8. See Miklos Dietz, Somesh Khanna, Tunde Olanrewaju, and Kausik Rajgopal, "Cutting Through the Noise around Financial Technology," McKinsey & Company, February, 2016, www.mckinsey.com/industries/financial-services/our-insights/cutting-through-the-noise-around-financial-technology.Return to text 9. While Bitcoin is a notable exception, many consumers still rely on connecting their bank accounts with Bitcoin exchanges to convert their fiat currency to virtual currency and vice-versa.Return to text 10. See, e.g., Bryan Yurcan, "Is a Turning Point Near for Core Systems?" American Banker, April 20, 2016, www.americanbanker.com/news/is-a-turning-point-near-for-core-systems (noting survey findings that 70 percent of U.S. bankers do not feel that their current processes can quickly adapt to market changes, and that 53 percent of survey respondents identified new products/innovation as the top benefit of investing in new core systems); Tom Groenfeldt, "Updating, Replacing, Surrounding Core Banking System," Forbes, July 21, 2015, www.forbes.com/sites/tomgroenfeldt/2015/07/21/updating-replacing-surrounding-core-banking-system/#2e019cd61282.Return to text 11. See, e.g., 12 CFR 1005.1(b); appendix C to 12 CFR part 1005, comment 2(m)-2 ("If a consumer furnishes an access device and grants authority to make transfers to a person (such as a family member or co-worker) who exceeds the authority given, the consumer is fully liable for the transfers unless the consumer has notified the financial institution that transfers by that person are no longer authorized."); Division of Banking Supervision and Regulation and Division of Consumer and Community Affairs, Board of Governors of the Federal Reserve System, "Guidance on Managing Outsourcing Risk (PDF)," December 5, 2013.Return to text 12. See, e.g., Olivia Solon, "Have You Given Pokmon Go Full Access to Everything in Your Google Account?" Guardian, July 12, 2016, www.theguardian.com/technology/2016/jul/11/pokemon-go-privacy-security-full-access-google-account. ("The discovery sparked a wave of fear that playing the game might allow its developers, Niantic Labs, to read and send email, access, edit and delete documents in Google Drive and Google Photos, and access browser and maps histories. In fact, both Google and Niantic Labs, say that 'full access' counterintuitively means nothing of the sort, a claim backed up by independent security researchers. The issue appears to stem from the fact that Niantic Labs uses an outdated version of Google's shared sign-on service.")Return to text 13. See, e.g., Ben Gilbert, "Pokmon Go Has Been Downloaded over 500 Million Times," Business Insider, September 7, 2016, www.businessinsider.com/pokemon-go-500-million-downloads-2016-9.Return to text 14. See, e.g., Division of Banking Supervision and Regulation and Division of Consumer and Community Affairs, Board of Governors of the Federal Reserve System, "Guidance on Managing Outsourcing Risk (PDF)," December 5, 2013.Return to text 15. See, e.g., Citigroup, "Citi Launches Global API Developer Hub to Enable Open Banking," press release, November 10, 2016, www.citigroup.com/citi/news/2016/161110b.htm; BBVA, "BBVA API Market, the Platform for Financial Innovators," press release, May 4, 2016, www.bbva.com/en/news/general/bbva-api-market-platform-financial-innovators/; Mark Boyd, "Capital One Launches First True Open Banking Platform in U.S., Programmable Web," March 11, 2016, www.programmableweb.com/news/capital-one-launches-first-true-open-banking-platform-us/2016/03/11; Penny Crosman, "Fintech Glasnost: Why U.S. Banks are Opening Up APIs to Outsiders," American Banker, July 8, 2015, www.americanbanker.com/news/fintech-glasnost-why-us-banks-are-opening-up-apis-to-outsiders; see also Pymnts.com, "Mastercard Turns Up the API Volume," September 28, 2016, www.pymnts.com/mastercard/2016/mastercard-turns-up-the-api-volume/; Visa Inc., "Visa Opens its Global Network with Launch of Visa Developer," press release, February 4, 2016, www.businesswire.com/news/home/20160204006175/en/Visa-Opens-Global-Network-Launch-Visa-Developer. Indeed, over five years ago, French bank Credit Agricole used open APIs to launch an app store of its own. The bank even connects its customers with developers, using message boards so that customers (or even other banks) can post ideas for developers to build. See, e.g., Karen Epper Hoffman, "Open API for Bank Apps: Can Credit Agricole's Model Work Here?" American Banker, July 29, 2013; CA Store, www.creditagricolestore.fr/catalogue-d-applications.html (last visited April 4, 2017) (as of April 2017, the site features 47 apps and 62 ideas); Mary Wisniewski, "Will Banks Become App Stores? This De Novo Wants To," American Banker, February 18, 2016, www.americanbanker.com/news/will-banks-become-app-stores-this-de-novo-wants-to.Return to text 16. The Financial Times reported that Uber will invest half a billion dollars into developing its own mapping software as it continues its push into driverless cars, thereby reducing its reliance on Google Maps. Leslie Hook, "Uber to Pour $500m into Global Mapping Project," Financial Times, July 31, 2016, www.ft.com/cms/s/0%2Fe0dfa45e-5522-11e6-befd-2fc0c26b3c60.html?ft_site=falcon&desktop=true#axzz4G0M5oyu8.Return to text 17. For example, one major data aggregator reports that about 70 percent of the data it collects from over 15,000 sources is collected via "structured feeds" under contractual agreements with financial institutions. See Envestnet, Inc., 2016 Annual Report, at 28, March 24, 2016.Return to text 18. See, e.g., 12 USC  1861-67; Division of Banking Supervision and Regulation and Division of Consumer and Community Affairs Federal Reserve System, "Guidance on Managing Outsourcing Risk (PDF)," December 5, 2013; Steven Boms, "Yodlee Response to Consumer Financial Protection Bureau Request for Information Regarding Consumer Access to Financial Records," Docket No. CFPB 2016-0048, February 21, 2017. ("Yodlee . . . has complied with hundreds of bank audits and with examinations by the Office of the Comptroller of the Currency throughout its history.")Return to text 19. See, e.g., "Finicity and Wells Fargo Ink Data Exchange Deal," press release, April 4, 2017, www.finicity.com/press-release-finicity-wells-fargo-ink-data-exchange-deal/; Wells Fargo & Co., "Intuit Signs New Data-Exchange Agreement with Wells Fargo," press release, February 3, 2017, www.wellsfargo.com/about/press/2017/intuit-agreement_0203/; Intuit, "Chase, Intuit to Give Customers Greater Control of Their Information," press release, January 25, 2017, www.intuit.com/company/press-room/press-releases/2017/Chase-Intuit-to-Give-Customers-Greater-Control-of-Their-Information/; Wells Fargo & Co., "Wells Fargo, Xero Agree on New Data-Exchange Method," press release, June 7, 2016, www.wellsfargo.com/about/press/2016/new-dataexchange-method_0607/; Silicon Valley Bank, "Xero and Silicon Valley Bank Partner to Offer Innovative Companies Next-Generation Financial Management," press release, July 16, 2014, www.svb.com/News/Company-News/Xero-and-Silicon-Valley-Bank-Partner-to-Offer-Innovative-Companies-Next-Generation-Financial-Management/.Return to text 20. See, e.g., Center for Financial Services Innovation, "Consumer Data Sharing Principles: A Brief on the Framework for Industry-Wide Collaboration," October 20, 2016. Indeed, many of the developers that make use of the bank data obtained by data aggregators are actuallyotherbanks. Steven Boms, "Yodlee Response to Consumer Financial Protection Bureau Request for Information Regarding Consumer Access to Financial Records," Docket No. CFPB 2016-0048, February 21, 2017. ("Over our almost two-decade history, Yodlee has built a client base that includes 12 of the 20 largest banks in the United States and the largest banks in more than 20 countries.")Return to text 21. See, e.g., Envestnet, Inc., 2016 Annual Report, March 24, 2016. ("[O]ne or more of our current customers could decide to limit or block our access to the data feeds we currently have in place with these customers due to factors outside of our control such as more burdensome regulation of our or our customers' industry, increased compliance requirements or changes in business strategy. If the sources from which we obtain information that is important to our solutions limit or restrict our ability to access or use such information, we may be required to attempt to obtain the information, if at all, through end user-permissioned data scraping or other means that could be more costly and time-consuming, and less effective or efficient. . . . The legal environment surrounding data scraping and similar means of obtaining access to information on third-party websites is not completely clear and is evolving, and one or more third parties could assert claims against us seeking damages or to prevent us from accessing information in that manner.")Return to text 22. According to one banking trade organization, "[t]his is a rich reward for a single hack, either of an aggregated database of personally identifiable information or of a single consumer's multiple accounts, makes data aggregators an attractive target for criminals. [Hackers would] obtain the key not to just a single room, but the key ring with keys to all the rooms." The Clearing House, "Comment Letter to Bureau-2016-0048 Request for Information Regarding Consumer Access to Financial Records (PDF)," February 21, 2017.Return to text 23. See, e.g, "Personal Capital Terms of Use" (last updated February 22, 2017), www.personalcapital.com/content/terms-of-use/ (last visited April 16, 2017). ("TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THE LIABILITY OF PERSONAL CAPITAL, ITS AFFILIATES, LICENSORS AND AGENTS TO YOU SHALL NOT EXCEED ONE HUNDRED U.S. DOLLARS ($100).") Further, Personal Capital requires that consumers submit to pre-dispute arbitration agreements and waive any rights to pursue relief in a class action proceeding as part of its terms of use. This would mean that if a data breach were to occur, each affected consumer would have to seek relief on his own, with a maximum possible recovery of $100. In addition, Personal Capital's terms and conditions specify that the arbitrator can require that the consumer pay Personal Capital's legal fees, if Personal Capital is to prevail.Return to text 24. When the iPhone first launched, for instance, one phone provider paid a premium for exclusive access to the smartphone. This meant that, for several years, consumers that wanted the iPhone also had to enter relationships with the only Internet service provider platform that offered the phone. See, e.g., Saul Hansell, "Why AT&T Wants to Keep the iPhone Away from Verizon," New York Times, April 22, 2009, https://bits.blogs.nytimes.com/2009/04/22/why-att-wants-to-keep-the-iphone-away-from-verizon/ ("AT&T is paying Apple an unusually high subsidy on top of the $199 and $299 paid by iPhone buyers. But it appears to be getting quite a return on that investment.") At the same time, Apple has used its own iPhone platform to affect the development of products further up the stack. While much of the iPhone is an open platform for third-party developers, developers do not have access to the iPhone's secure element and Near Field Communication (NFC) antenna--key components of digital wallet technologies. This means that Apple Pay is the only "tap-to-pay" NFC digital wallet available for iPhones--and that Apple Pay competitors, like Android Pay and Samsung Pay, are unable to access 40 percent of the smartphones in the United States. See, e.g., Philip Elmer-DeWitt, "About Apple's 40% Share of the U.S. Smartphone Market," Fortune, February 11, 2016, http://fortune.com/2016/02/11/apple-iphone-ios-share/. When a group of Australia's largest banks recently petitioned the country's antitrust authority to allow them to band together to require Apple to unlock access to the NFC antenna, for use by their digital wallets, their request was denied. See, e.g., Simon Sharwood, "Banking Group Denied Access to iPhones' NFC Chips for alt.Apple.Pay," Register, April 3, 2017, www.theregister.co.uk/2017/04/03/banking_group_denied_access_to_iphones_nfc_chips_for_altapplepay/.Return to text 25. See, e.g., Chance Miller, Apple Maps Now Used 3x as Often as Google Maps on iOS, Serving 5B Requests per Week, 9to5Mac, December 7, 2015, https://9to5mac.com/2015/12/07/apple-maps-usage-numbers/.Return to text 26. For example, small business lender Kabbage, Inc. has entered agreements with large banks, where Kabbage licenses its data analysis-heavy customer acquisition platform to banking partners who then go on to originate, fund, and service the underlying loans. See, e.g., Kabbage Inc., "Kabbage and Santander UK Partner to Accelerate SMB Growth," press release, April 3, 2016, www.kabbage.com/blog/kabbage-santander-uk-partner-accelerate-smb-growth/.Return to text 27. UK Competition & Markets Authority, "CMA Paves the Way for Open Banking Revolution," press release, August 9, 2016. ("[O]lder and larger banks do not have to compete hard enough for customers' business, and smaller and newer banks find it difficult to grow. This means that many people are paying more than they should and are not benefiting from new services. To tackle these problems, the CMA is implementing a wide-reaching package of reforms. Central to the CMA's remedies are measures to ensure that customers benefit from technological advances and that new entrants and smaller providers are able to compete more fairly."); UK Competition & Markets Authority, "Retail Banking Market Investigation: Final Report (PDF)," August 9, 2016.Return to text 28. The nine banks include the five largest banks in Great Britain (Lloyd's Banking Group, Royal Bank of Scotland, HSBC Group, Barclays, and Santander UK plc); three leading banks in Northern Ireland (Allied Irish Bank, Bank of Ireland, and Danske Bank) and the largest UK building society, Nationwide Building Society.Return to text 29. Directive (EU) 2015/2366 of the European Parliament and of the Council, November 25, 2015,http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32015L2366(last visited Feb. 1, 2017).Return to text 30. Specifically, Payment Initiation Service Providers (PISPs) initiate payment orders at the request of a user with respect to funds held in another entity's bank account; Account Information Service Providers (AISPs) are online services that consolidate information, with consumers' consent, from those consumers' accounts at other entities.Return to text 31. With limited exceptions, such as for de minimis transactions.Return to text 32. Richard Cordray, "Prepared Remarks of CFPB Director Richard Cordray" at the Lendit USA Conference, March 6, 2017; Richard Cordray, "Prepared Remarks of CFPB Director Richard Cordray" at Money 20/20, October 23, 2016; Consumer Financial Protection Bureau, "Request for Information Regarding Consumer Access to Financial Records," Federal Register, November 22, 2016.Return to text 33. See, e.g., Lael Brainard, "The Opportunities and Challenges of Fintech" at the Conference on Financial Innovation at the Board of Governors of the Federal Reserve System, December 2, 2016.Return to text 34. See Office of the Comptroller of the Currency, "Exploring Special Purpose National Bank Charters for Fintech Companies (PDF)," December 2016.Return to text 35. See, e.g., Jennifer Booton, "Apple Will Make $3 Billion Playing Pokmon Go," MarketWatch, July 21, 2016, www.marketwatch.com/story/apple-stands-to-make-billions-from-pokemon-go-2016-07-20 (citing report by analyst Lauren Martin).Return to text