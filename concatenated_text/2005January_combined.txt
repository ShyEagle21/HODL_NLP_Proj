The Federal Reserve Board on Wednesday announced the execution of a Written Agreement by and among Prineville Bancorporation, Prineville, Oregon; the Community First Bank, Prineville Oregon; the Oregon Division of Financial and Corporate Securities, Salem, Oregon; and the Federal Reserve Bank of San Francisco. A copy of the Written Agreement is attached.
Remarks by Governor Donald L. Kohn At the Wharton/Sloan/Mercer Oliver Wyman Institute Conference, "Financial Risk Management in Practice," Philadelphia, Pennsylvania January 6, 2005 Crisis Management: The Known, the Unknown, and the Unknowable In pursuing its policy objectives, a central bank must make decisions in the face of uncertainty related to incomplete knowledge about the evolving condition of the economy and the financial system as well as about the potential effects of its actions. This uncertainty implies that the central bank must incorporate into its decisions the risks and consequences of several alternative outcomes. That is, it needs to assess not only the most likely outcome for a particular course of action but also the probability of the unusual--the tail event. And it needs to weigh the welfare costs of the possible occurrence of those tail events. This risk-management approach has been articulated by Chairman Greenspan for monetary policy, and it is equally applicable to a central bankï¿½s decisions regarding crisis management, the topic I will focus on today. Crises are themselves tail events, and the policy response to them is focused on the possibility and cost should the outcome be especially adverse. As I am sure we will hear time and again today, knowledge--reliable information--is essential to managing risks. In a financial crisis, however, information inevitably will be highly imperfect. The very nature of a crisis means that the ratio of the unknown and unknowable will be especially large relative to the known, and this, in turn, can influence how policymakers judge risks, costs, and benefits. Although the subject of my contribution to this panel is crisis management, I want to emphasize at the outset that the far-preferable approach to financial stability is to reduce the odds on such crises developing at all. To this end, central banks seek to foster macroeconomic stability, encourage sound risk-taking practices by financial market participants, enhance market discipline, and promote sound and efficient payment and settlement systems. In this arena, an ounce of prevention is worth many pounds of cure. Before going further, I should say that the views I will express today are my own and not necessarily those of other members of the Board of Governors or its staff. Costs, Benefits, and Policy Options But even prevention has costs that must be weighed along with its benefits. No financial system that is efficient and flexible is likely to be completely immune from episodes of financial instability from time to time, and policymakers will be forced to make judgments about the costs and benefits of alternative responses with very incomplete information. In a financial crisis, the potential cost of inaction or inadequate action is possible disruption to the real economy, which would damp activity and put undesirable downward pressure on prices. Such disruptions can come about because crises heighten uncertainty about the financial status of counterparties and about the eventual prices of assets. In an especially uncertain environment, lenders may become so cautious that credit supplies are cut back more than would be justified by an objective assessment of borrowersï¿½ prospects; concerns about counterparty risk can impair the smooth functioning of payment and settlement systems, interfering with a wide variety of markets; asset prices can be driven well away from equilibrium values; and confidence can be undermined. These types of tail events could depress economic activity for a time and, if prolonged, could also adversely affect efficiency and productivity by impairing the ability of financial markets to channel savings into the most productive investments. Although policy action may be able to reduce the odds of adverse effects or alleviate their impact, some policy responses to a crisis can themselves have important costs that need to be balanced against their possible benefits. In short, intervening in the market process can create moral hazard and weaken market discipline. If private parties come to believe in the possibility of policy actions that will relieve them of some of the costs of poor decisions or even just bad luck, their incentives to appropriately weigh risks in the future will be reduced and discipline on managers watered down. Weaker market discipline distorts resource allocation and can sow the seeds of a future crisis. The possible real costs of policy actions implies that they should be taken only after the determination that, in their absence, the risk is too high that the crisis will disrupt the real economy. Once that judgment is reached, the central bank and other authorities have a variety of instruments to use, and the degree of potential moral hazard created will depend on the instrument chosen. Approaches that work through the entire market rather than through individual firms run a lower probability of distorting risk-taking. Thus, a first resort to staving off adverse economic effects is to use open market operations to make sure aggregate liquidity is adequate. Adequate liquidity has two aspects: First, we must meet any extra demands for liquidity that might arise from a flight to safety; if they are not satisfied, these extra demands will tighten financial markets at exactly the wrong moment. This was an important consideration after the stock market crash of 1987, when demand for liquid deposits raised reserve demand; and again after 9/11, when the destruction of buildings and communication lines impeded the flow of credit and liquidity. Second, we must determine whether the stance of monetary policy has to be adjusted to counteract the effects on the economy of tighter credit supplies and other consequences of financial instability. Policy adjustments also can help head off some of those effects in that, by showing that the central bank recognizes the potential seriousness of the situation, they bolster confidence. As a consequence, meetings of the Federal Open Market Committee (FOMC)--often in conference calls if the situation is developing rapidly--have been an element in almost every crisis response. Those meetings allow us to gather and share information about the extent of financial instability and its effects on markets and the economy as we also discuss the appropriate policy response. Some critics have argued that the FOMCï¿½s policy adjustments in response to financial instability encourage undue risk-taking in the financial markets and the economy. However, to the extent that the conduct of policy successfully cushions the negative macroeconomic effects of financial instability, it genuinely lowers risk and that fact should be reflected in the behavior of private agents. Other instruments to deal with instability--discount window lending, moral suasion, actions to keep open or slowly wind down ailing financial institutions--are much more likely than monetary policy adjustments to have undesirable and distortionary effects on private behavior. By making credit available to individual firms on terms more favorable than would be available in the market, or by affording a measure of protection to existing creditors, these other instruments carry substantial potential for moral hazard. Hence, they are and should be used only after a finding that more generalized instruments, like open market operations, are likely to be inadequate to stave off significant economic disruption. If it is determined that actions to support the credit of specific firms are necessary, such actions should be designed to minimize moral hazard. Sometimes moral suasion will be sufficient--simply by calling attention to the potential consequences of withholding payments or credit, private parties may be persuaded that avoiding such an outcome is in their self-interest. But central banks must be careful that moral suasion is not perceived as coercion or an implied promise of official indemnification for private losses. If the central bank concludes that it must lend to individual depository institutions to avoid significant economic disruption, in most situations any such loans should be on terms sufficiently onerous to discourage reliance on public-sector credit. The Federal Reserve tries to find the approach that reduces the odds on economy-wide spillover effects while interfering as little as possible with the market and allowing people and institutions to suffer the consequences of decisions that turn out to be bad. Nearly every major bout of financial instability has called for some degree of monetary easing--most often only temporarily until the threat of the low-probability but high-cost economic disruption has passed. Other tools have been used occasionally, and an assessment of their costs and benefits has depended on the nature of the crisis. Moral suasion was an element in dealing with the panicky private-sector actions associated with the sharp and apparently self-feeding market price breaks of 1987 and 1998. Lending through the discount window helped to promote an orderly unwinding of distressed institutions in the period of prolonged and widespread problems among important intermediaries in the late 1980s and early 1990s. And such lending was crucial in getting liquidity to the right places after the disruption of 9/11. In each case, the nature of the response has depended on the state of the economy and financial markets before the event. When the economy is strong and financial systems robust, a shock to the financial system is less likely to feed back on the economy. Information Flows in a Crisis Clearly, judgments in a crisis must balance a number of difficult considerations in rapidly changing circumstances in which up-to-date, accurate, information is scarce. Our experience suggests some of the key questions that might arise when confronting a crisis: How large is the financial disruption--how many firms or market participants are involved and how large are they? What is the potential for direct and indirect contagion, both domestic and international? Who are the counterparties and what is their exposure? Who else has similar exposures and might be vulnerable to further changes in asset prices that could be triggered by a firmï¿½s failure and unwinding of positions? How long are the financial disruptions likely to last? Are substitute providers of financial services available, and how easily and quickly can they be employed? And, critically, what are the initial and expected states of the macroeconomic and financial environments under various scenarios? Coming to grips with these questions requires a considerable amount of detailed, up-to-the-minute information--more than can be known ahead of time. Even in the best of circumstances, much of the information on variables relevant to decisions about whether or how to intervene will be unknown (especially if a crisis materializes quickly) or unknowable. Published balance sheets and income statements--or old examination reports--give only a starting place for analysis when asset prices and risk profiles are changing rapidly and in ways that had not been anticipated. In addition, crises invariably reveal previously unknown interdependencies among financial intermediaries and among intermediaries and the ultimate suppliers and demanders of funds. Central banks and others that might be involved in crisis management must take steps to push back the frontiers of the ï¿½unknownï¿½ before a crisis hits and to develop procedures for obtaining the ï¿½knowableï¿½ quickly when needed. More information is not just a ï¿½nice to have.ï¿½ Policymakers want to choose the path with the lowest moral hazard consequences. But they are in a difficult position in a crisis. The costs of not acting forcefully enough will be immediate and obvious--additional disruption to financial markets and the economy. The costs of acting too forcefully--of interfering unnecessarily in markets and creating moral hazard--manifest themselves only over a longer time and may never be traceable to a particular policy choice. The natural tendency to take more intrusive actions that minimize the risk of immediate disruptions is probably exacerbated by ignorance and uncertainty; the less you know, the easier it is to imagine bad outcomes and the more reliant you may be on people in the market whose self-interest inevitably colors the information they are giving you. Each episode of financial instability is different and teaches us something new about what information is useful and who needs to call whom to share information. For example, clearing mechanisms for futures and options were an issue in the 1987 crash; capital impairment of depositories, its effect on lending, and the response of regulators took center stage in the late 1980s and early 1990s; the importance of market liquidity came to the fore in 1998 when even the prices of off-the-run Treasury securities took a beating; and physical infrastructure issues dominated developments after the terrorist attacks on 9/11. Although a knowledge base is helpful, the answers to the questions I posed earlier will depend critically on a free flow of new information. In a world of financial institutions with a presence in many lines of business crossing national boundaries, obtaining such information and developing cogent analysis requires widespread cooperation among many agencies. The Federal Financial Institutions Examination Council--in which all U.S. depository institution regulators participate--is a forum for developing information and relationships within the regulatory community. The Presidentï¿½s Working Group itself was a product of the 1987 stock market crash, which revealed a need for better communication and coordination among all financial regulators. In addition, we build bilateral relationships with foreign authorities through participation in various international groups, such as the Basel Committee on Banking Supervision, the Committee on Payment and Settlement Systems, the Financial Stability Forum, and so on. A number of the phone calls I made and received in the hours and days after 9/11 were with people in other central banks with whom I had established working relationships on monetary policy groups or in international preparations for Y2K. But although agency-to-agency communication is important, it is in a sense only a secondary source of information. The primary and best sources are the contacts we all develop with major financial participants as we carry out our daily operations and oversight responsibilities. Whatever the origin of the crisis, the Federal Reserve has usually found itself near the center of the efforts to assess and manage the risks. To be sure, we have some authorities and powers that other agencies do not. But in addition, we bring a unique perspective combining macro- and microeconomic elements that should help us assess the likelihood of disruptions and weigh the consequences of various forms of intervention. Because of our responsibility for price and economic stability, we have expertise on the entire financial system and its interaction with the economy. Central banks need to understand--to the limited extent anyone can--how markets work and how they are likely to respond to a particular stimulus. Our role in operating and overseeing payment systems gives us a window into a key possible avenue for contagion in a crisis. At the Federal Reserve, our supervisory responsibilities provide us with knowledge of the banking system and the expertise to interpret information we get from other agencies. We have people at the Board and Reserve Banks who are expert in macroeconomics, in banking, in payment and settlement systems, and in various financial markets, and all have market contacts; our colleagues at the Federal Reserve have proven to be our best source and filter of information in the midst of a crisis. Despite our efforts, much will still be unknown and some things will be unknowable as we make decisions in a crisis. Financial instability is by definition a tail event, and it is the downside possibilities of that tail event that concern the authorities. Market participants are reacting under stress, on incomplete and often false information, in situations they have not faced before. Uncertainty--in the Knightian sense of unquantifiable risk--is endemic in such situations. Uncertainty drives people to protect themselves--to sell the asset whose price is already declining, to avoid the counterparty whose financial strength might conceivably be impaired, to load their portfolios with safe and liquid assets. Market mechanisms are tested in ways that cannot be modeled ahead of time. Contagion is always a key underlying issue in trying to assess the potential for sustained disruption of the financial system and the economy. Contagion, in turn, is partly a question of psychology--how will people react under conditions of stress? So, too, is moral hazard--once the stressful situation passes, how will people adapt their behavior as a consequence of any intervention? Thus, much of the most desirable information is ï¿½unknowableï¿½ in any quantitative sense. The authorities must rely, therefore, on judgment, based on experience and on as much information as can be gathered under adverse circumstances. The Changing Financial System and the Known, the Unknown, and the Unknowable The evolution of financial markets and institutions over recent years may well have made the financial system more resilient and reduced the need for intervention. The lowering of legal and regulatory barriers across financial services and geography, the development of derivative markets, and the securitization of so much credit has enabled intermediaries to diversify and manage risk better, reduced the number of specialized lenders who would be vulnerable to sector- or area-specific shocks, and left borrowers far less dependent on particular lenders and consequently the economy much less vulnerable to problems at individual or even classes of institutions. In the past few years, the financial markets have come through an extraordinarily stressful period, but one that was not marked by the sort of financial-sector distress that accompanied and intensified the economic problems in many previous such episodes. I attribute that relatively good record, in no small part, to greater diversification of risk, to the growing sophistication of risk management techniques being applied at more and more institutions, and to stronger capital positions going into the period of stress. This may be the typical experience in the future; one hopes so, and the regulators are working in various ways to make it so--through the Basel II effort as one prominent example. But, unfortunately, we cannot count on that outcome. Crises remain a threat, and the increasing complexity of the financial system and of the laws governing it are affecting how crises are likely to be managed. The greater variety and utilization of risk transfers will put new demands on information flows to answer the questions I posed earlier. The growing reach of major financial institutions across industry boundaries and national borders is increasing the necessity for cooperation and coordination among regulators here in the United States and around the world. At the same time, institutions manage risk on an integrated basis and understanding and dealing with the effect of financial instability and the feedback of their actions on markets and other institutions will call for an integrated overview. No institution can be ï¿½too big to fail.ï¿½ Handling the failure of a large, complex organization--imposing the costs of failure on management, shareholders, and uninsured creditors while minimizing the effects on the wider economy--will certainly be complicated. But we cannot allow the public interest in containing moral hazard to be held hostage to complexity. Indeed, U.S. law requires that we do not. In dealing with the failure of an insured depository institution, the authorities are required to use the method that yields the least cost to the insurance fund unless they find that the least-cost method entails systemic risk and that a more costly method would mitigate that risk. In setting out a procedure to follow in such circumstances and holding authorities explicitly accountable for their decisions against a reasonably clear set of objectives, the law puts a premium on preparing for the type of analysis that will be needed. The Federal Reserve is in continuing conversations with other agencies on approaches to these issues. The growing complexity of institutions elevates the importance of avoiding crises, rather than managing them. We must continue to adapt our supervision of financial institutions and payment systems to encourage and reward good risk management and enhance market discipline. Footnotes Alan Greenspan (2004), ï¿½Risk and Uncertainty in Monetary Policy,ï¿½ American Economic Review, vol. 94 (May), pp. 33-40. Edward C. Ettin, Myron L. Kwast, and Patrick M. Parkinson, of the Boardï¿½s staff, provided valuable ideas and comments.
For immediate release The Federal Reserve Board on Friday named eleven new members to its Consumer Advisory Council for three-year terms and designated a new Chair and Vice Chair of the Council for 2005.
Remarks by Governor Ben S. Bernanke At the Annual Meeting of the American Economic Association, Philadelphia, Pennsylvania January 7, 2005 Panel Discussion: The Transition from Academic to Policymaker I appreciate the opportunity to reflect on my two and a half years as an academic turned policymaker. One difference I have noticed since moving to Washington is that people seem to find my ideas and insights of greater interest than they used to--although, so far as I know, I have not become any smarter in the past few years. This increase in interest is particularly marked in regard to my views on current policy issues and the economic outlook. So, for the sake of truth in advertising, I should say at the outset that I will not be commenting on current issues today, except in the most general terms. Instead, keeping with the theme of this panel, I will offer a few thoughts on my transition from academia to the policy world--in particular, how the former experience has prepared me for the latter. Obviously, I will be speaking for myself and not the Federal Reserve Board. I should also note that my policy experience has been limited to my time at the Federal Reserve--in some ways, a unique institution in Washington--and may not generalize to other contexts. I always thought I would be an academic lifer. I went straight to graduate school from college and never considered any job other than an academic position when I graduated. Before I was appointed to the Board of Governors in August 2002, my adult work experience consisted of six years teaching at Stanfordï¿½s Graduate School of Business, seventeen years at Princeton (a joint appointment in the economics department and the Woodrow Wilson school of public policy), and several years spent as a visiting faculty member at other institutions, including MIT (my graduate alma mater). The sum of my political experience consisted of two terms on the local school board, six grueling years during which my fellow board members and I were trashed alternately by angry parents and angry taxpayers. On the administrative side, I served seven years as the chair of the Princeton economics department, where I had responsibility for major policy decisions such as whether to serve bagels or doughnuts at the department coffee hour. Academia appealed to me as a young person because of the freedom it offered to explore old ideas and develop new ones. I also liked the relaxed dress code. The biggest downside of my current job is that I have to wear a suit to work. Wearing uncomfortable clothes on purpose is an example of what former Princeton hockey player and Nobel Prize winner Michael Spence taught economists to call ï¿½signaling.ï¿½ You have to do it to show that you take your official responsibilities seriously. My proposal that Fed governors should signal their commitment to public service by wearing Hawaiian shirts and Bermuda shorts has so far gone unheeded. Although the dress code continues to be a drawback, I am pleased to be able to report that the intellectual challenges of my new job have been as rewarding as those I encountered as an academic. The Federal Reserveï¿½s responsibilities are quite broad, including not only monetary policy but the regulation and supervision of banks, oversight of the payments system, the making and enforcement of various regulations to protect consumers in their financial dealings, and the promotion of financial stability generally, among others. Getting up to speed on these diverse topics required some concentrated effort on my part. Much of what I had to absorb was institutional detail--some interesting, some less so--but I have also come to appreciate that the dictum that ï¿½the devil is in the detailsï¿½ applies with great force to all serious policy work. My academic training has helped considerably by leading me always to focus on the underlying conceptual framework on which the legal, procedural, and institutional details depend. With an underlying framework in mind, seeing what is at stake and making a reasonable and coherent decision on a policy issue becomes easier, though rarely easy. The development and implementation of consumer protection regulation provide one example. As economists, we have a predisposition in favor of free markets, but we also understand that missing or asymmetric information can undermine the efficiency and fairness of market-determined allocations. Financial contracts are inherently complex and consequently difficult for consumers to understand fully, even if the other party to the contract has no intention to mislead or deceive. From an economistï¿½s perspective, the proper objective of consumer protection regulation is not to prohibit voluntary financial transactions but to ensure that consumers receive the information they need to make rational decisions at the lowest possible social cost. Setting industry standards for what information must be disclosed to consumers and, perhaps, for the format of the disclosure is one means by which a regulator can achieve this objective. Ideally, a regulator like the Federal Reserve serves as a coordinating device to help financial institutions as well as consumers minimize informational problems and transaction costs in the financial marketplace. Following guidelines established by the Congress, the Fed and other regulators can also improve market functioning by clarifying property rights of various kinds--for example, by making rules about the use of personal information collected in the course of financial relationships. Of course, to achieve its social objectives as efficiently as possible, a regulator needs to gather as much information as it can from market participants. The Fed never imposes a substantive regulation without extensive consultation with those who will be affected--in this case, both financial institutions and consumers--through formal comment periods, policy advisory groups, and a variety of more-informal contacts. Bank supervision and regulation, also a major responsibility of the Fed, provides another example of how conceptual frameworks developed by researchers inform the policy process. Many economists (myself included) have studied the special features of the banking industry, documenting its important role in the economy but also noting the potential instability of institutions that finance long-term, illiquid investments with short-term, liquid deposits. Deposit insurance and other government protections reduce the risk of banking instability but create the potential for moral hazard and other problems. The challenge for bank supervisors is to ensure the safety and soundness of banking institutions--that is, to minimize moral hazard and to protect the deposit insurance fund--without inhibiting economically valuable activities or technological innovation by banks. Designing regulations to accomplish these objectives has become markedly more difficult as banking organizations have become larger and more complex. The new Basel II international capital accord, which the Fed helped to design in collaboration with other banking regulators from the United States and around the globe, may well be the most economically sophisticated regulation scheme ever devised. The new system is designed to use information provided by the banks themselves about their loss experience, together with algorithms that mimic the most up-to-date risk-management techniques, to establish minimum capital standards for banks that approximate the appropriate level of economic capital. In addition, Basel II provides for enhanced supervisory oversight and public disclosure of financial information by banks. As many economists have noted, greater transparency on the part of financial institutions improves the efficiency with which financial markets price financial claims on banks, including equity and subordinated debt. By aggregating private-sector information about banksï¿½ financial condition, prices and yields determined in financial markets may in turn provide important information to regulators. Difficult challenges lie ahead in implementing the new capital accord, and I do not want to enter into a full discussion of the many issues raised by Basel II today. My point here is only that Basel II is not your grandfatherï¿½s bank regulatory scheme; it is an approach that draws on the most sophisticated financial methodologies as well as on extensive research on banking and bank supervision. As with most other policy issues, getting the myriad details right will be critical to the success of this new regulatory regime. But the general design of Basel II owes a great deal to research conducted both in academia and in central banks. As in the case of consumer financial regulation, I have found my academic background to be quite helpful for understanding the critical issues in bank supervision policy. I have enjoyed very much being introduced to the wide range of Fed policy activities. However, because my professional background is in macroeconomics and monetary economics, monetary policy remains for me the most interesting aspect of my job at the Fed. Once again, I have found the knowledge and habits of thinking developed in my academic days to be quite useful. The models and forecasting methods used by the Federal Reserve staff, for example, draw heavily on decades of academic research and thus feel comfortably familiar. Academic research (by which I mean to include technical research done in central banks and other non-academic institutions) also bears directly on many strategic aspects of monetary policymaking. For example, the Federal Open Market Committee has recently been engaged in developing its communications strategy, a topic which I believe to be of vital importance and on which I have spoken on numerous occasions. My thinking on this and numerous other aspects of monetary policy is heavily influenced by contemporary research in monetary economics, as can be seen by the footnotes and citations in my speeches. A part of monetary policymaking for which my background left me imperfectly prepared is what central bankers call ï¿½current analysis.ï¿½ One of the biggest practical challenges of making monetary policy--and a prerequisite for any serious forecasting exercise--is getting an accurate assessment of the current economic situation. Doing this well requires a deep knowledge of the data mixed with a goodly dose of economic theory and economic judgment. Members of the Board staff continuously analyze the arriving data to learn what they can about the level and composition of economic activity, inflation, and other key aggregates. At the most mechanical level, this exercise requires a detailed understanding of how the U.S. statistical agencies use the information in current data releases to estimate economic aggregates--how the components of retail sales are linked to estimates of personal consumption, for example. But often the linkages between data releases and the key economic aggregates are not so straightforward. For example, drawing the implications of a surprisingly favorable employment report for consumer spending requires the analyst to take a view on how households are likely to respond to increased labor income and improved labor market conditions. A certain amount of uncertainty in the estimates is unavoidable, of course; indeed, identifying the sources of uncertainty is an important part of the analysis. However, the requirements of internal consistency--production must always equal sales plus inventory investment, for example--provide numerous cross-checks and substantial discipline on this process. More generally, all of us involved in the monetary policy process must try to synthesize a range of disparate information, including official data, anecdotes, and qualitative developments, to construct a ï¿½storyï¿½ about how the economy is evolving: What forces are determining economic activity now, and what do they portend for the future? Chairman Greenspan is, of course, a master of current analysis and near-term forecasting, and many members of the National Association for Business Economics have finely honed these skills as well. Current analysis is not taught in graduate school, probably for good reason; it seems more amenable to on-the-job training. It is, nevertheless, an intellectually challenging activity--analogous, it seems to me, to the efforts of a detective to reconstruct a sequence of events from a range of diverse and subtle clues--and I have enjoyed the opportunity to become more proficient at it. I will close with a personal observation. In focusing today on the substantial intellectual continuities between academia and the policy world, I have not yet mentioned an important aspect of the policymakerï¿½s job: the satisfaction of public service. For me, knowing that I am using my skills to further the commonweal and the national interest is an important compensation for the personal sacrifices that a policy position can entail--a view that I know to be widely shared among my colleagues at the Federal Reserve. Whether you are a veteran economist or just starting out in the profession, I urge you to consider seriously any opportunity that arises to serve in a policymaking capacity, be it as a principal or as a supporting staff member. You will feel good about it, and you will learn a lot. Footnotes As a member of the Basel Committee, Fed Vice Chairman Roger W. Ferguson, Jr., has played a particularly key role in the development of Basel II.
Remarks by Governor Donald L. Kohn At the Annual Meeting of the American Economic Association, Philadelphia, Pennsylvania January 9, 2005 Central Bank Communication A basic tenet of economics is that markets work better--reflect underlying economic forces, efficiently allocate resources--with more information. Because central banks are key players in financial markets, a better public understanding of central bank behavior should improve pricing in those markets. Over my career, I have witnessed notable efforts by central banks to improve the public's understanding of their behavior by increasing the amount of "talk" they do about policy and the economy. The trend toward more talk reflects several interrelated developments. The demand for information has expanded along with the size and sophistication of financial markets; financial assets have increased far faster than gross domestic product, and a much greater variety of instruments are priced. At the same time, rising wealth has meant that increasing numbers of people have a stake--and an interest--in the forces determining the prices in those markets. Technological change--including the ubiquitous Internet--has made it easier to cater to and feed this interest by making more information available more quickly and cheaply. And, in part as the result of academic progress on the topic, central banks better appreciate that more-accurate expectations of market participants can help improve the performance of the economy and the achievement of economic objectives. Changes in the political environment surrounding central banks have reinforced the increased demand for transparency. Greater support for independent central banks with goals set by the political process was one of the results of the lessons of the great inflation of the 1970s. But an arm's-length distance from immediate political pressures requires accountability and reporting to elected representatives. The quid pro quo is most evident in many of those countries that have shifted to inflation targeting, but the United States followed the same pattern earlier--in the late 1970s. In that period, laws for the first time established goals for monetary policy, albeit not as specific as inflation targets, and imposed reporting requirements in the form of reports and testimony to the Congress. Given the trends I have mentioned and the benefits of greater transparency, people sometimes wonder why central bank transparency has evolved as slowly as it has and why some central banks do not take additional steps to talk more--especially about what they see coming in the future. I will give you my own answer to this question, which I hasten to add, does not necessarily reflect the views of my colleagues on the Federal Open Market Committee or its staff. The answer, I believe, is that more is not necessarily always better, and at each step of the way central banks have needed to take account of the potential costs as well as the benefits of greater transparency. One consideration involves the nature of information and its relationship to market pricing. In fact, economists do not fully understand how markets incorporate information. Herding behavior, information cascades, multiple equilibria, and the amount of investment in financial research all pose puzzles about markets and information. The situation is complicated still more when an important participant is seen as having superior information owing to its investment in research or its understanding of its own behavior. In such circumstances, certain types of central bank talk might actually impinge on welfare-enhancing market pricing by being misunderstood and receiving too much weight relative to private judgments. We need to be particularly careful that people understand how limited our knowledge actually is--the uncertainty and conditionality around any statement we make about future developments. Moreover, what we are doing is complicated and involves weighing many factors; we should not misrepresent it for the sake of clarity in communication. The publication of useful information is complicated further by the fact that, in most countries, policy is made by a committee; representing the thinking of a diverse group is difficult and limits what can be said. A second type of consideration that has constrained the pace of increase in transparency is its potential interaction with monetary policy decisions. What we say is important, but what we do over time will ultimately determine economic outcomes. We should not allow a desire for clarity of expression to deflect our decisions from those that would contribute best to overall economic performance and which may be difficult to explain easily. And we must take care that policy expectations engendered by communication do not unduly constrain policy action. Furthermore, we cannot allow transparency to limit discussion in the Committee out of concern about how its publication will affect markets and the economy. Every decision about additional transparency is a balancing of possible costs and benefits. The preexisting structure of central bank talk reached its state for particular reasons; changing it entails adjusting the balance that previous Committees found. And reversing movements toward greater communication in the event of unforeseen consequences could be difficult. But circumstances change; markets change; we gain experience through our own actions or those of other central banks. More information, generally, is better, and markets and central bank governance have greatly benefited from the steps taken around the world to increase transparency over recent decades. Talk about "Policy Inclination" and "Economic Outlook" How many central banks weigh the costs and benefits of additional transparency can be illustrated by differentiating communication along the lines offered in the paper Brian Sack and I wrote that is part of this session. We separated the effect of talk between policy inclination--the likely near-term path of the policy interest rate--and the economic outlook--the evolution of prices and output over the intermediate and longer term. Experience shows that central bankers generally have been much more comfortable talking about the economic outlook than about policy inclination. Policy Inclination This difference in comfort level relates in part to our evaluation of the interaction of each type of talk with market prices. The risks seem more sizable that markets will overweight our discussion of the possible path of policy interest rates than they will our discussion of the economic outlook. After all, if we possess any private information, it is most likely to be about the steps we might take in the immediate future. But we are concerned that markets will not appreciate the degree of conditionality behind our expectations in this regard and take them as a firmer precommitment than they were intended to be. The market reaction to our words could well be heightened by the behavior of market analysts, who tend not to place probabilities on their predictions of our actions over the next few meetings but instead tend to make "zero/one" calls. In any case, the risks of herding, of overreaction, of too little scope for private assessments of economic developments to show through, would seem to be high for central bank talk about policy interest rates. Because of concern about market interpretation, policymakers often see talk about policy inclination also as having the potential for constraining future decisions in ways that might interfere with the most-effective achievement of policy objectives. The stronger the market expectations about near-term policy actions, the greater the risk of roiling markets and creating confusion in the event the decision differs from those expectations. The possibility that discussions of future policy, even nonspecific, could create presumptions about a string of policy actions makes finding a consensus among policymakers on what to say about future interest rates quite difficult--more so than agreeing on the policy today. It is no accident that the Reserve Bank of New Zealand stands out as about the only central bank to publish such a path and as one of the few in which decisions are the responsibility of only one individual. Sack and I found that actions, not words, dominated the policy inclination factor. However, the study was completed before the Federal Reserve became more explicit about future policy rates in the summer of 2003. The unusual situation at that time shifted our assessment of the balance of costs and benefits in favor of a public statement about our expectations for the near-term path of policy. Markets appeared to be anticipating that inflation would pick up soon after the expansion gained traction, and therefore that interest rates would rise fairly steeply. This expectation was contrary to our own outlook. We saw economic slack and rapid productivity growth keeping inflation down for some time. Our expectations about policy also took account of the fact that the level of inflation was already low--lower than it had been for several decades. We thought that our reaction to a strengthening economy would be somewhat different this time than it had been in many past economic expansions and unlike what the markets seemed to anticipate. Under most circumstances, this sort of disconnect between the central bank and the markets would not be a big problem; we could compensate for the market's tendency to raise intermediate and long-term rates unduly by keeping policy easier for longer. But with the federal funds rate already at 1 percent, our scope for that was limited; and if the economy suffered any downward shocks, policy could reach the constraint of a zero federal funds rate, with uncertain consequences. Under these circumstances, giving markets more information about our policy inclination, and thereby holding down longer-term interest rates, seemed to be the less-risky way to stabilize inflation at a reasonable level and encourage a vigorous expansion. I would judge the outcome to have been successful. We did influence rates to better reflect the actual path of policy; economic outcomes have been good; and, to date, our discussion of the path for rates has not constrained our actions. That is partly because we have been able to pull back gradually on the degree of commitment on our near-term actions in a way consistent with incoming data and without roiling markets. As the FOMC's minutes make clear, however, our experience has also illustrated how difficult it can be for a diverse committee to talk about the future course of rates. I take from this experience the lesson that, despite their drawbacks much of the time, conditional statements from the central bank about the near-term course of policy can be useful in certain circumstances. These circumstances might include a situation in which the policymakers and the markets seemed to have substantially conflicting forecasts about the economy and the path of policy; such differences persist despite the central bank's efforts to explain its outlook; and the effect of those divergent views on financial conditions threaten to detract from economic performance. Economic Outlook Monetary policy committees generally judge the costs and benefits of talking about the economic outlook much more favorably than discussing the path of rates. Of course markets can often infer from a discussion of the economy how the central bank thinks rates will evolve. But limiting communication to the economic outlook allows the markets to work out an expected path for rates by combining the central bank's judgment about the economy with its own and with its understanding of the central bank's reaction function. This gives greater scope for private assessments to show through to market prices, which itself can be helpful to a central bank trying to gauge public attitudes and expectations. In my view, the most useful service the central bank can provide in this arena is its analysis of the forces bearing on the outlook--the determinants of aggregate demand, potential supply, and inflation. This type of discussion can help the public interpret developments and allow markets to respond constructively to surprises in the data. Forecasts can be used as a framework for such a discussion, but the public should appreciate the limits of a numerical forecast. The relationship of the forecast to the policy decision is loose. Inevitably, point forecasts will be incorrect; they should be seen as the centers of wide distributions of possible outcomes; and low-probability outcomes can be very important in policy decisions in certain circumstances. Moreover, quite often, the FOMC can reach a consensus on policy without reaching one on a specific forecast--only a general agreement on the general degree of strength in economic activity and the likely tilt to inflation if alternative policy paths are chosen. Sack and I note the power of even nonspecific central bank talk about the economic outlook to greatly influence expectations embodied in intermediate- and long-term interest rates. Is it too much, as some argue? Is central bank talk about the economy crowding out other legitimate perspectives? This is an empirical question, and I do not think we yet have the studies to provide an answer. One way to frame the question would be to ask whether market forecasts over the intermediate and longer run have improved or deteriorated as central banks have ramped up their talk. I suspect that the greater provision of informed analysis from central banks has led to an improvement. In the United States, we have some indirect evidence that crowding out of private views has not increased even as the Federal Reserve has become more talkative. Market interest rates have continued to respond substantially to surprises in economic data. The degree of the reaction to individual indicators has risen or fallen depending on the economic situation and the focus of policymakers; for example, the reaction to price data decreased in recent years as low, steady inflation became more firmly established, and the reaction to labor market data increased as the "jobless recovery" became more of a focus. But we do not see a general falloff in the strength of response, as one might expect if markets were relying more on central bank views and less on their own interpretation of data. That markets continue to react strongly to incoming data is not surprising. Predicting interest rates far enough into the future is not just about what others--including the central bank--think; over time those rates should be tied to objective factors--for example, the forces of productivity and thrift. Differing views about these factors give scope for opportunities to profit from independent research and betting against the crowd. Earlier Release of the Minutes As evidence that our communication policy is a work in progress, the FOMC has recently shifted its views in favor of expediting the release of its minutes. Minutes of FOMC meetings necessarily contain elements of both policy inclination and economic outlook. Benefits flow from a more timely release of a fuller, more nuanced explanation of why the policy decision was made than is possible in an announcement. The Committee's discussion, and the minutes of it, help to spell out the linkage the Committee may see between any policy inclination and its economic outlook. The explanation can convey the conditionality of Committee thinking and the role of any concerns about the implications of low-probability events on its current or expected policy actions. Not surprisingly, Sack and I found a correlation between the amount of talk and its effect on expectations. Reactions to the minutes could be sizable, as they were last Tuesday, but because the minutes do elaborate on the rationale for the Committee's decisions and outlook, these reactions should help markets anticipate policy actions and price assets in ways that foster economic stability. In addition, the minutes are another chance for the Committee, as a whole, to talk. One advantage is that they should give the public a broader context in which to interpret the many statements by individual members between meetings. In that regard, the fact that the minutes convey the range of Committee members' views should be helpful. The minutes are not an attempt to articulate a single consensus explanation of our actions or outlook, but rather, reflecting a strength of the FOMC, they summarize the give and take in Committee discussion arising from differing perspectives on difficult issues. Early release of the minutes could have costs if Committee members became more guarded in their discussion out of concern about the effects of their remarks when reported or if, over time, the minutes themselves became less comprehensive. In my view, neither of these developments is an inevitable consequence of the new schedule, and I am sure the Committee will resist any temptation to allow them to occur. Early release had been considered before, but recent experience convinced members that the balance had swung in its favor. Successful dry runs alleviated concerns about the practical problems of getting timely agreement on minutes from nineteen geographically dispersed members. On one or two occasions in recent years, longer delays in release of the minutes had resulted in market confusion because the minutes were interpreted as pertaining to the most recent decision, not the one at the preceding meeting for which the minutes were prepared. Finally, the difficulty of structuring talk about the future in the brief announcement released immediately after the meeting has enhanced the perceived value of the minutes for this purpose. Expedited release is an incremental step. The market will not have information it did not eventually have before, but it will have it sooner. Conclusion Over the past several decades, central banks have become considerably more open about their decisions and the reasons for them. Progress has been incremental--and may have seemed slow to some--but we have been adapting to changing circumstances in financial markets and in the governance of central banks in democratic societies. In addition, we have tried to be careful not to allow steps toward greater transparency to impinge on discussions or deflect us from making the best possible decisions to reach our objectives. Finally, we have been conscious of the limits of our knowledge and desirous of allowing other views to be incorporated in asset prices. We have done a lot, but I am sure more can be accomplished and the Committee will look carefully at proposals as they are brought forward. Over time, I anticipate further steps toward explaining our views, but at a pace that is likely to be measured. Footnotes Vincent R. Reinhart, of the Board's staff, provided valuable advice and comments in the preparation of these remarks. Donald L. Kohn and Brian P. Sack (2003), " ; Finance and Economics Discussion Series 2003-55 (Washington: Board of Governors of the Federal Reserve System, November). A discussion of the effect of these statements on interest rates is in Ben S. Bernanke, Vincent R. Reinhart, and Brian P. Sack (2004), Finance and Economics Discussion Series 2004-48 (Washington: Board of Governors of the Federal Reserve System, September). Jeffery D. Amato, Stephen Morris, and Hyun Song Shin (2002), Oxford Review of Economic Policy , vol. 18 (December), pp. 495-503. The Committee unanimously decided on December 14 to expedite the release of the minutes of each of its regularly scheduled meetings by issuing them three weeks after the date of the policy decision. The new schedule began with the release, on January 4, 2005, at 2 p.m. EST, of the minutes of the December 14, 2004, meeting. The previous practice had been to release the minutes of a regularly scheduled meeting on the Thursday following the subsequent regularly scheduled meeting.
No content found
Remarks by Vice Chairman Roger W. Ferguson, Jr. At the Stanford Institute for Economic Policy Research, Stanford, California Presented at the Real Estate Roundtable, Washington, D.C. January 27, 2005 January 12, 2005 Recessions and Recoveries Associated with Asset-Price Movements: What Do We Know? Thank you for inviting me to address the associates of the Stanford Institute for Economic Policy Research; it is a pleasure to be here. As you know, the U.S. economy is currently continuing its recovery from the relatively mild recession in 2001, which ended the longest period of economic expansion in our nation's recorded business-cycle history. The 1990s will be remembered not only for this remarkably long period of prosperity but also for the excitement of the "new economy" and, less happily, for the sharp decline in equity prices that marked its end. This market correction was most dramatic in sectors of the economy associated with new technologies, the very sectors that had experienced the most pronounced run-up in equity prices. The quick occurrence of a recession following soon after this significant asset-price correction prompted some observers to suggest that the boom-bust cycle in asset valuations was the proximate trigger of the economic downturn But a number of aspects of that argument have not yet been fully examined. In the interest of advancing the understanding on this issue, I will use this opportunity to provide a retrospective on the performance of the U.S. economy and of some other industrialized economies during and following recessions over the past three decades or so. In particular, I will focus on the role that asset prices may have played in expansions and recessions. Before going any further, however, I should emphasize that the views I will express today are my own and are not necessarily shared by my colleagues in the Federal Reserve System. What Happens during Asset-Price Run-Ups? Asset prices serve multiple roles in a modern economy. They exert a direct influence by affecting the net worth of the assets' owners. Consumers who hold assets become richer during an asset-price advance. This so-called wealth effect--always a key determinant of consumption--can be quite important during significant asset-price run-ups as consumers spend out of their capital gains. Historical evidence suggests that this effect ultimately raises the level of consumption spending by between 2 cents and 5 cents per dollar of increase in wealth. Similarly, asset prices also affect business balance sheets. Rising prices for assets raise the net worth of companies that own the assets. The value of the assets that a borrower owns is an important determinant of his or her creditworthiness. In the event of a default and foreclosure on a secured debt, collateral that caries a high price provides the lender with a high recovery rate, which makes lending less risky. During an asset-price boom, the creditworthiness of borrowers rises, the interest rates at which they borrow decline because of lower risk spreads, and business investment increases as firms take advantage of the relatively lower interest rates they face. A consequence of the positive influence of asset prices on investment is that if prospects for profitability as reflected in asset prices in one sector of the economy are advancing relative to asset prices in all other sectors, investment in that sector will outpace investment in the rest of the economy, all else equal. This circumstance may have important and potentially adverse allocative consequences on the economy. In particular, if asset prices do not accurately reflect the productive potential of the underlying asset, investment will be channeled to the wrong sectors. However, an asset-price boom in a specific sector might simply reflect investor expectations of higher productivity rather than a bubble, a term I will define in a few moments. Investment would still tend to be channeled to that sector, but for good reason in this instance. One example of a sector-specific jump in asset prices and an associated investment increase is the case of the U.S. technology sector in the late 1990s. Over the five years from the end of 1994 to the end of 1999, prices of nontech stocks tripled while those of tech stocks more than quintupled. Correspondingly, the average level of real investment in computers and other high-tech capital goods was more than 100 percent higher over the 1995-99 period than its level during 1994, while spending on other types of fixed capital was only about 15 percent higher than in 1994. Asset-Price Busts By definition, an asset-price bust is preceded by an asset-price boom. If a run-up reflects a bubble, the ensuing price bust could obviously be viewed as its bursting. Alternatively, asset prices may have been driven up by expectations of a productivity boom, which would lead to improved earnings. In that case, if the expected productivity boom does not subsequently materialize, asset prices will fall. The end result in this case would not be termed the bursting of a bubble. Nonetheless, this case may be indistinguishable from such an experience: Among other common elements, one could also see an investment overhang in the sector that saw its asset prices rise and subsequently fall. Recessions are almost always accompanied by asset-price declines. But such declines sometimes appear to be the source of adverse surprises, and asset-price busts may subsequently have disproportionately adverse consequences. Falling asset prices create a negative wealth effect and restrain consumption. By making collateral less valuable, they also increase the risk of lending to businesses and thereby worsen the lending terms faced by borrowers. When asset prices fall substantially, lenders may also find themselves holding substantial amounts of nonperforming loans that are backed by what may have become, in some cases, worthless collateral. For this reason, recessions that are preceded by asset-price booms and busts may also be associated with problems in the banking industry. In such episodes, the ensuing loss of intermediation may serve as an additional force acting to prolong and deepen what might otherwise have been a milder recession. Concerns about the severity of downturns that follow significant asset-price collapses suggest that the identification and analysis of boom-bust asset-price cycles could be useful for policy. For that reason, I would next like to briefly review some of the issues associated with detecting asset-price bubbles. Detecting Bubbles The word bubble is sometimes employed to describe any quick and large increase in asset prices, but a more precise definition would associate bubbles with only those increases in asset prices that are not due to economic fundamentals. Under such a definition, a bubble is present when investors buy assets at prices above their fundamental values in the expectation of being able to sell them at even higher prices in the future. To be sure, such departures from fundamentals may start small, but over time they could grow explosively. The fundamental price of an asset typically is defined in terms of the discounted present value of the income stream or equivalent services that the asset is expected to provide over time. For stock prices, for example, this is the present discounted value of dividends; for real estate, it is the discounted value of the rents or services that are expected to accrue to the owner over time. In theory, the existence of bubbles, defined in this way, is possible in standard asset-pricing models and may even be consistent with rational, profit-maximizing behavior. Ascertaining the existence of bubbles in practice is a very different matter. An immediate difficulty is that the theoretical notion of the fundamental price does not have an easily measured empirical counterpart. In part as a result of this measurement problem, statistical tests using historical data cannot easily distinguish bubbles from failures of the standard asset-pricing model in some other dimensions, or no failure of the model at all. Indeed, for every study of historical data that finds evidence of a bubble, often another shows that the findings could be explained by an alternative specification of the fundamentals in the absence of bubbles. That is, even with the benefit of hindsight, statistical tests attempting to confirm the existence of bubbles in historical episodes can remain inconclusive. Of greater relevance for policy discussions, however, is not whether economists can identify a bubble long after it occurs, but whether the presence of a bubble could be detected in real time, when the information might be useful for policy decisions. Unfortunately, detection of a bubble, which is problematic even ex-post, is an even more formidable task and arguably becomes virtually impossible in real time. Indeed, in real time, it is not uncommon for economists and market participants to fail to recognize important shifts in underlying trends that may subsequently be viewed as the source of significant changes in market fundamentals. Current statistical methods are simply not up to the task of "detecting" asset-price bubbles, especially not in real time, when it matters most. "Detecting" a bubble appears to require judgment based on scant evidence. It entails asserting knowledge of the fundamental value of the assets in question. Unsurprisingly, central bankers are not comfortable making such a judgment call. Inevitably, a central bank claiming to detect a bubble would be asked to explain why it was willing to trust its own judgment over that of investors with perhaps many billions of dollars on the line. The issue of detecting bubbles notwithstanding, it is of interest to know whether recessions related to sizeable asset-price busts differ from other recessions in some way that might be important for policy considerations. Are Recessions That Are Related to Asset-Price Busts Different? Two of the longest periods of economic weakness observed in the industrialized world during the twentieth century are often identified with the asset-price busts that preceded them: the Great Depression in the United States and the "lost decade" of the 1990s in Japan. In each case, rapidly falling asset prices, exacerbated by banking problems, marked the beginning of painfully long periods of economic malaise. In part because of these two experiences, it is sometimes suggested that asset-price booms more generally lead to imbalances in the economy, and that asset-price busts and the correction of these imbalances lead to recessions that are longer, deeper, and associated with a greater fall in output and investment than other recessions. But what is the evidence on this question? Additionally, can one make any other generalizations concerning recessions that follow asset-price booms and busts and how they differ from other recessions? To address those questions, it is instructive to examine recession episodes in the Group of Seven economies since 1970. Figure 1 presents a bird's-eye view of the evolution of asset prices and the economy from 1970 to 2003 for three of these economies, the United States, the United Kingdom, and Japan. For each country, the top panel of the figure shows the evolution of an aggregate inflation-adjusted index of asset prices--which consists of an average of stock prices and residential and commercial real estate prices. The shaded areas cover recession periods, as determined by the business cycle dating committee of the National Bureau of Economic Research in the United States, and a comparable methodology for the other countries. The bottom panels show the evolution of gross domestic product in these economies together with a historical estimate of the economy's potential. The relationship of asset prices to the economy near turning points shows varying patterns (figure 1, top and bottom panels). In some episodes, asset-price declines do not appear to have preceded the recession. During some recessions, asset prices appear to have simply moved sideways, not registering substantial declines at all. But in other episodes, significant asset-price booms and subsequent declines do appear before the onset of a recession and continue during the downturn. For the United States, for example, the figure highlights the long run-up and subsequent fall in asset prices before the 2001 recession. The size of these recent movements dominates earlier boom-bust cycles in the U.S. economy in this sample. For Japan, one can see the remarkable run-up of the 1980s and its agonizing reversal during the 1990s. For the United Kingdom, one may notice the asset-price boom-bust cycle of the early 1970s followed by the painful recession beginning in 1974. Indeed, these three episodes stand out as perhaps the clearest suggestions of an asset-price boom-bust cycle significantly influencing or possibly triggering a subsequent recession and recovery. How do these three cyclical turning points compare with other recessions? To be sure, such a comparison rests on (1) our identification of these three episodes as the ones that appear to have been preceded by significant asset-price booms and busts and (2) separating these recessions from the rest. Such a classification necessarily involves some element of ambiguity, but the three episodes highlighted in figure 1, the U.S. recession in 2001, the Japanese recession in 1992, and the U.K. recession in 1974, do appear to stand out. We have compared the average path of asset prices around the onset of the recession in these three episodes to the average path of asset prices in the other episodes in our sample (figure 2, top panel). The vertical line marks the quarter in which the recession began. The dotted curve shows the average of the three asset-price related episodes, and the solid curve shows the average of the remaining twenty-two recession episodes in the sample. This comparison suggests that in recessions related to asset-price busts, asset prices fall before the recession more, on average, than they do in other episodes. This is, of course, as it should be, given our selection criteria for the classification of the three episodes. The more interesting question is whether these recessions are different in other dimensions as well. Consider, for example, the average paths of estimated output gaps during asset-price busts relative to the remaining recessions (figure 2, middle panel). The data are centered as they were for asset prices, but the output gap is normalized to equal zero in the first quarter of a recession. As one would expect, the output gap for both groups of episodes on average falls after recessions start, but it falls less for the asset-price-bust episodes. Finally, looking at investment (figure 2, bottom panel), the data also suggest that, on average at least, investment, like the output gap, was not affected more adversely in the three asset-price-bust episodes. If anything, these three episodes on average appear to be slightly shallower in terms of output losses and investment declines than the average of other recessions. But the comparisons of the averages provided in figure 2 could obscure valuable insights that might be obtained by looking at each of our three asset-price-bust episodes individually, as I do next. Three Asset-Price-Bust Episodes Let us first examine the U.K. recession of 1974. To put that episode in perspective, we present an overview of the U.K. economy for the 1970-2003 period (figure 3). The boom-bust cycle that preceded the 1974 cyclical peak is the most pronounced (and, by the way, not just for the United Kingdom but for all of the G-7 countries). The large fall in average asset prices (figure 3, top panel) followed the 1973-74 oil crisis, which is also associated with somewhat smaller asset-price declines in numerous other nations. We take a closer look at the components of the aggregate asset-price index and compare their evolution around this U.K. cyclical peak to their average evolution during all recessions excluding our three asset-price-bust episodes ( ). Equity prices registered a remarkably sharp decline in this episode. But arguably a more distinctive characteristic of this asset-price boom-bust episode is the swing in real estate prices. Residential real estate prices, and especially commercial real estate prices ( ), also registered rather dramatic declines in this episode. It may thus be surprising that this recession does not appear to have been deeper than the average of recessions excluding the three asset-price-bust episodes. The output gap ( ) fell along with asset prices before the recession, but the decline was from an unsustainably overheated level. And investment ( ) stayed relatively strong compared with other recessions. Despite this episode being associated with rather severe declines in equity and commercial real estate prices, no evidence of an investment overhang appears in this comparison. Next, let us turn to the Japanese experience. The Japanese economy saw rapidly increasing equity and real estate prices during the 1980s ( ), a remarkably long period of stability and prosperity. These run-ups in asset prices were accompanied by a rapid expansion of bank credit, which was especially important for financing real estate purchases. But asset prices collapsed at the turn of the decade. This "bursting of the bubble," as the episode is often referred to by Japanese officials, was followed by a decade of relative stagnation marked by three arguably related recessions. Concentrating attention on just the first of these three recessions, beginning in 1992, proves insufficient to capture the severity of the overall problem. The detailed comparisons of the 1992 recession with other episodes ( and ) do not indicate unusual weakness associated with the 1992 recession. Rather, the 1990s in Japan are more notable for the succession of incomplete recoveries than for the recessions themselves ( ). The bursting of the bubble importantly shaped subsequent developments in this case. The asset-price collapse hit the Japanese banking system hard, eroding bank capital. The ensuing disintermediation subsequently proved an important impediment to the economy's recovery. However, the extent of the problem was not fully appreciated at the time by policymakers. Despite steps toward an expansionary policy, the monetary easing of the early 1990s was insufficient to mitigate the underlying weakness during the expansion from 1994 to 1996. The continued fragility of the financial system arguably left the Japanese economy especially vulnerable to additional disturbances that could have otherwise been easily weathered. An economic crisis in Southeast Asia, coupled with a previously planned increase in consumption taxes, resulted in a larger-than-anticipated drag on domestic demand and set the stage for the recession that started in 1997. Following a brief recovery, monetary policy was tightened in 2000, and the third recession in a decade followed soon after. The Japanese experience offers a reminder of the importance of monitoring the health of the financial system and the need to be especially wary of signs of fragility following a period of sharp asset-price declines. It also serves to highlight how the behavior of the banking system during the asset-price run-up may influence subsequent outcomes. Lastly, it points to the potentially crucial role played by fiscal and monetary policies in recoveries following asset-price-bust recessions. Last, let us examine the U.S. recession of 2001 and the subsequent, ongoing recovery. We have prepared the U.S. data in the same manner as in the U.K. and Japanese cases ( - ). The evolution of disaggregated asset prices ( ) shows that the unusually large changes surrounding the 2001 recession reflected the movement of equity prices alone. Relative to the average episode, commercial real estate prices neither fell much during the recession nor rose a lot during the expansion. And instead of declining during the recession, residential real estate prices continued their upward trend. The behavior of real economic activity around the recent cyclical peak ( ) suggests a second interesting comparison. Relative to other recessions, this recession was shallow and did not appear to impart an unusual drag on investment, despite the sharp asset-price correction. Why was the 2001 recession relatively short and shallow even though the preceding swing in asset prices was so severe? In my opinion, two reasons stand out. The first regards the health of the financial sector. During the 1980s and early 1990s, the U.S. banking sector faced a succession of challenges: the savings and loan crisis of the early 1980s, the international debt crisis of the mid-1980s, waves of bank failures and consolidation, and the need to build capital in response to the adoption of the Basel I standards in 1988. But by the mid-1990s the banking sector had regained a solid footing, and regulators were careful to keep it that way. Prudential regulation coupled with good risk management meant that financial firms limited their exposure to risk during the boom years of the late 1990s. This approach paid off handsomely when the asset-price break occurred. Despite the recession, banks remained well capitalized, and their strength eliminated the threat of a vicious credit crunch or the risk of fragility in the system. As a result, the elements that appear to have been so detrimental for the recovery of the Japanese economy during the 1990s were absent during this episode. Following the "bursting of the bubble" in Japan, the banking system found itself holding a substantial amount of bad loans. And, as already seen, the woes of the banking system turned into a recessionary force in itself, curtailing the recovery. This comparison points to a useful policy lesson: A healthy financial sector and strong prudential regulation during an asset-price boom offer valuable insurance in case the boom turns to bust with an asset-price break. The second, and perhaps equally important, reason that the recent U.S. episode was unusually benign was, in my view, the quick response of policy. Both fiscal and monetary policy were eased quickly and effectively in this episode. The Federal Reserve cut the federal funds rate rapidly to create monetary accommodation and maintained conditions of substantial monetary policy ease for a considerable period well into the expansion. As well, the Administration and the Congress took quick steps early in the recession to provide fiscal stimulus that helped to prop up aggregate demand. Placing the policy response in its proper historical context may be critical for drawing the appropriate policy lessons for the future. Countercyclical fiscal and monetary policies are unlikely to have been as swift and strong during 2001 had earlier policies not set the stage for such action. On the fiscal side, the budgetary prudence of the 1990s yielded comfortable surpluses at the onset of the 2001 recession that facilitated the large fiscal policy easing. And on the monetary side, the successful completion of the last stage on the long path to price stability during the 1990s allowed substantial easing in response to the downturn. As policymakers stressed repeatedly, the prevalence of low- and well-anchored inflation expectations ultimately facilitates pursuit of such countercyclical policy. A clear lesson emerges from this experience for policy over the long haul. By pursuing fiscal prudence and price stability during booms, policymakers greatly enhance their ability to take swift, effective countercyclical action when it is needed most. Conclusions In closing, let me reiterate some of the key points and lessons I draw from this review. First, as already understood, detecting asset-price overvaluations and undervaluations is controversial in hindsight and arguably impossible in real time. As a result, although asset-price booms and busts are often linked to recessions, a clear-cut policy response to suspected waves of exuberance cannot be suggested. Second, sweeping generalizations regarding asset-price-bust recessions and subsequent recoveries are not easily made. Idiosyncrasies dominate comparisons in the historical data. As such, each recession-and-recovery episode would seem to call for its own tailor-made policy response. Third, to the extent that comparisons across recessions are informative, asset-price-bust recessions do not appear to be necessarily more costly than other recession episodes. Specifically, at a macroeconomic level, recessions that follow swings in asset prices are not necessarily longer, deeper, and associated with a greater fall in output and investment than other recessions. That said, particular industrial segments and classes of investment, such as the high-tech sector in the recent U.S. episode, may suffer disproportionately during such recessions. Also, the health of the financial system, the strength of the banking sector, and the ability and willingness of policy to take appropriate countercyclical action seem to importantly influence the economic outcomes of an asset-price-bust. Which brings me to my last point: Over the long haul, preparation for a potential problem seems to be the best course of action. Prudential supervision and good risk management in banking, and the pursuit of fiscal prudence and price stability during booms, may ultimately serve as the best insurance for dealing with the inevitable occasional asset-price breaks observed in our modern economy. Footnotes My presentation is based on work with and . See, for example, Morris A. Davis and Michael G. Palumbo (2001), Finance and Economics Discussion Series 2001-9 (Washington: Board of Governors of the Federal Reserve System, February). In this comparison, I use the Nasdaq composite index as a proxy for the high-tech sector and the Dow Jones industrials index as a proxy for the nontech sector. See John H. Cochrane (2001), Asset Pricing (Princeton: Princeton University Press), p. 402. Such a bubble would be called a "rational bubble." It is also conceivable that bubbles are present because some investors are not pricing assets rationally; for an introduction to that notion, see Annette Vissing-Jorgensen (2004), "Perspectives on Behavioral Finance: Does 'Irrationality' Disappear with Wealth? Evidence from Expectations and Actions," in Mark Gertler and Kenneth Rogoff, eds., NBER Macroeconomics Annual 2003 (Cambridge, Mass.: MIT Press), pp. 139-94. See, for example, Jean Tirole (1985), "Asset Bubbles and Overlapping Generations," Econometrica , vol. 53 (November), pp. 1499-528; and Dilip Abreu and Markus K. Brunnermeier (2003), "Bubbles and Crashes," Econometrica , vol. 71 (January), pp. 173-204. See, for example, Lubos Pastor and Pietro Veronesi (2004), NBER Working Paper Series 10581 (Cambridge, Mass.: National Bureau of Economic Research, June). They argue that the high level of uncertainty about the future growth rate of dividends of tech firms helps explain these firms' stock prices without resorting to a bubble. The difficulty of satisfactorily "detecting" bubbles is well known in the economics literature. For a recent survey see Refet Gurkaynak (2005), Finance and Economics Discussion Series 2005-4 (Washington: Board of Governors of the Federal Reserve System, January). For uniformity across countries, all data shown in this figure, and data discussed later on, including those for the United States, are drawn from international institutions. The asset-price data have been kindly provided by the Bank for International Settlements (BIS). For detailed explanations of these data see C. E.V. Borio, N. Kennedy, and S.D. Prowse (1994), "Exploring Aggregate Asset Price Fluctuations across Countries: Measurement, Determinants, and Monetary Policy Implications," BIS Economic Papers 40 (Basel: Bank for International Settlements). To be sure, business cycle chronologies may differ somewhat depending on the underlying methodology. The dates of peaks and troughs in economic activity for the analysis that follows are from the Economic Cycle Research Institute. For the United States, these match the dates determined by the National Bureau of Economic Research (NBER). For other nations, the institute's methodology yields dates that are comparable to the NBER dates for the United States, which facilitates comparisons across countries. Recession dating is monthly. To obtain the quarterly time series used here, we converted the monthly expansion/recession phases to a quarterly frequency by designating the cyclical peak (the first quarter of recession) as the quarter containing the first full recession month--that is, the month following the monthly peak designation. Table 1 shows the dates of all recessions in the sample. Table 1 Business Cycles of G7 Countries Country Peak Trough United States 1969:Q4 1970:Q3 United States 1973:Q4 1975:Q1 United States 1980:Q1 1980:Q2 United States 1981:Q3 1982:Q3 United States 1990:Q3 1991:Q1 United States 2001:Q1 2001:Q3 Japan 1973:Q4 1974:Q4 Japan 1992:Q2 1993:Q4 Japan 1997:Q1 1999:Q2 Japan 2000:Q3 2003:Q1 Britain 1974:Q3 1975:Q2 Britain 1979:Q2 1981:Q1 Britain 1990:Q2 1992:Q1 Canada 1981:Q4 1982:Q3 Canada 1990:Q1 1992:Q1 Germany 1973:Q3 1975:Q2 Germany 1980:Q1 1982:Q3 Germany 1991:Q1 1994:Q1 Germany 2001:Q1 2003:Q2 Italy 1970:Q4 1971:Q2 Italy 1974:Q2 1975:Q1 Italy 1981:Q2 1983:Q1 Italy 1992:Q1 1993:Q3 France 1974:Q3 1975:Q2 France 1979:Q3 1980:Q2 France 1982:Q2 1984:Q4 France 1992:Q1 1993:Q2 The quarterly peak and trough dates shown are based on the monthly business cycle chronology from the Economic Cycle Research Institute. This episode is excluded because it begins outside of the sample period. This episode is excluded because it coincides with German reunification. Estimates of real gross domestic product (GDP), the output gap, potential output, and real investment are from the Economic Outlook database of the Organisation for Economic Co-operation and Development. The investment data (shown in later displays) reflect total fixed investment. In , both actual and potential output are expressed relative to the value of actual real GDP in 1985. By definition, output should equal the economy's potential--and the corresponding measure of the output gap should equal zero--when productive factors in the economy are employed at their normal levels. Output is below the economy's potential when resources are underutilized and above it when the economy is overheated. To be sure, assessing the economy's potential with much accuracy is inherently difficult, and historical estimates of the implicit output gap are highly imprecise; however, these measures can serve as helpful summary indicators in historical comparisons such as those discussed below. There are at least two reasons for the ambiguity in such classifications. The first relates to how one defines an asset-price bust. The second relates to the dating of cyclical peaks, which, as noted earlier, may differ somewhat depending on the methodology underlying business cycle chronologies. The three episodes on which I concentrate my attention are relatively uncontroversial in that the recessions followed rather substantial asset-price boom-bust cycles. But other recessions, which followed milder boom-bust cycles, could be added to this list. Examples would be the recessions that started in 1974 in the United States, in 1981 in Canada, and in 1990 in the United Kingdom. To compute these averages, we first centered the path of asset prices around each recession episode. The quarter in which the recession began is marked as zero, and quarters from -8 to +8 denote the preceding and subsequent two years. Asset prices in each episode are normalized to 100 at the quarter marking the recession start. United States 1969:Q4 1970:Q3 United States 1973:Q4 1975:Q1 United States 1980:Q1 1980:Q2 United States 1981:Q3 1982:Q3 United States 1990:Q3 1991:Q1 United States 2001:Q1 2001:Q3 Japan 1973:Q4 1974:Q4 Japan 1992:Q2 1993:Q4 Japan 1997:Q1 1999:Q2 Japan 2000:Q3 2003:Q1 Britain 1974:Q3 1975:Q2 Britain 1979:Q2 1981:Q1 Britain 1990:Q2 1992:Q1 Canada 1981:Q4 1982:Q3 Canada 1990:Q1 1992:Q1 Germany 1973:Q3 1975:Q2 Germany 1980:Q1 1982:Q3 Germany 1991:Q1 1994:Q1 Germany 2001:Q1 2003:Q2 Italy 1970:Q4 1971:Q2 Italy 1974:Q2 1975:Q1 Italy 1981:Q2 1983:Q1 Italy 1992:Q1 1993:Q3 France 1974:Q3 1975:Q2 France 1979:Q3 1980:Q2 France 1982:Q2 1984:Q4 France 1992:Q1 1993:Q2
For immediate release The Federal Reserve Board on Tuesday announced its approval of the proposal filed by Toronto-Dominion Bank, Toronto, Canada, to acquire 51 percent of the voting shares of Banknorth Group, Inc., and its subsidiary bank, Banknorth, National Association, both in Portland, Maine. Attached is the Board’s Order relating to this action.
Remarks by Governor Susan Schmidt Bies To Financial Executives International Baltimore Chapter, Baltimore, Maryland January 18, 2005 The Economy and Challenges in Retirement Savings I am very pleased to join you for this meeting of The Baltimore Chapter of Financial Executives International. Today I want to begin with a brief assessment of the economic outlook before discussing financial conditions of households and businesses in more detail. Then, I will turn to some important trends in retirement savings, including the responsibilities that both businesses and households have in planning for the financial security of workers later in life. I also need to add that I am expressing my own opinions, which are not necessarily those of my colleagues on the Board of Governors or on the Federal Open Market Committee. The Economic Outlook As you know, the economy has been expanding at a healthy pace lately. Real gross domestic product grew at an annual rate of 4 percent in the third quarter and growth in the fourth quarter looks to have remained solid, although the further widening of our trade deficit was disappointing. Labor markets have continued to improve gradually, with private nonfarm payroll employment posting a sizable gain in 2004. Consumer spending appears to have been robust during the holiday season, despite some restraint from higher energy prices, and business outlays for capital equipment are on an upward trend. And with financial conditions still accommodative, I expect that the economy will continue to expand at a solid pace this coming year. On the inflation front, broad measures of consumer inflation have risen somewhat faster than they did in the year-earlier period, boosted by higher energy prices. Focusing on the core price index, which excludes food and energy, it has been a bit higher than it was the year before. This reflects changes in the pattern of prices of goods (as opposed to services) purchased by consumers, as prices of goods that had been falling in 2003 began to stabilize and rise slightly in 2004. These effects should taper off and I expect that core inflation will remain in its current range. Moreover, surveys indicate that inflation expectations over the longer-term appear to have remained well-anchored. I believe that, with underlying inflation expected to moderate, the Federal Reserve can continue to remove its policy accommodation at a measured pace, consistent with its commitment to maintain price stability as a necessary condition for maximum sustainable economic growth. Household Financial Conditions Continued economic expansion depends importantly on consumer spending, so let me spend a few minutes on the financial condition of the household sector. Some analysts have expressed concern about the rapid growth in household debt in recent years and the decline in the household saving rate. They fear that households have become overextended and will need to rein in their spending to keep their debt burdens under control. My view is considerably more sanguine. Although pockets of financial stress exist among households, the sector as a whole appears to be in good shape. It is true that households have taken on quite a bit of debt over the past several years. According to the latest available data, total household debt grew at an annual rate of about 10 percent between the end of 1999 and the third quarter of 2004; in comparison, after-tax household income increased at a rate of about 5 percent over this period. This rapid growth in household debt largely reflects a surge in mortgage borrowing, which has been fueled by historically low mortgage interest rates and strong growth in house prices. Indeed, many homeowners have taken advantage of low interest rates to refinance their mortgages, some having done so several times over the past couple of years. Survey data suggest that homeowners took out cash in more than one-half of these "refis," often to pay down loans having higher interest rates. On net, the resulting drop in the average interest rate on household borrowings, combined with the lengthening maturity of their total debt, has damped the monthly payments made by homeowners on their growing stock of outstanding debt. The Federal Reserve publishes two data series that quantify the burden of household obligations. The first series, the debt-service ratio, measures the required payments on mortgage and consumer debt as a share of after-tax personal income. The second series, the financial-obligations ratio, is a broader version of the debt-service ratio that includes required household payments on rent, auto leases, homeowners insurance, and property taxes. Both ratios rose during the 1990s, and both reached a peak in late 2002. Since then, however, the debt-service ratio has been stable and the financial obligations ratio has receded a bit, an indication that households, in the aggregate, have been keeping an eye on their financial commitments. Consistent with these patterns, delinquency rates for a wide range of household loans either have drifted down over the past year or held about steady at levels below recent highs. The low interest rates of the past few years, however, will give way as the economy continues to expand, and we have already seen an uptick in mortgage rates and on some other consumer loans during this past year. To be sure, some households will be pressured by the higher rates, but I believe that concerns about their effect on repayment burdens can be overstated. First, most household debt--mortgage and consumer debt combined--carries a fixed interest rate, which slows the adjustment of interest costs to rising rates. Second, although interest rates on some variable-rate loans will rise quickly, the adjustment for a large number of variable-rate loans could occur rather slowly. For example, many adjustable-rate mortgages start off with a fixed rate for several years, providing households with some protection from rising rates. Another concern is that house prices will reverse and erase a considerable amount of home equity built up in recent years. Recent gains in house prices have been notable: the average house price rose 13 percent in the year through the third quarter of 2004, and cumulative gains since 1997 now top 60 percent. Despite a rise in mortgage debt, the current loan-to-value ratio for outstanding mortgages is estimated to be around 45 percent, roughly the level that has prevailed since the mid-1990s. It is true that some households have considerably less equity in their homes, and these households tend to have lower income and fewer other financial assets to cushion shocks. Based on the 2001 Survey of Consumer Finances (SCF), a small share, 7 percent, of households had a loan-to-value ratio of 90 percent or more. Unfortunately, we cannot characterize the current share as accurately, at least not until the 2004 survey becomes available early next year, but it is unlikely that the share has risen by a lot. While new originations of mortgages with high loan-to-value ratios in recent years would push this share up, the substantial house price appreciation in that same period likely improved the financial positions of the households with high loan-to-value ratios in 2001. This relatively upbeat assessment of household credit quality seems to be shared by lenders and by investors in securities backed by consumer debt. According to the Federal Reserve's survey of senior loan officers, banks were in a relatively neutral stance, neither tightening nor easing on net, with respect to lending standards for consumer loans or mortgage loans through most of last year. Moreover, credit spreads on securities backed by auto loans and credit card receivables have narrowed in recent months. Some analysts have also expressed concerns about the decline in the personal saving rate. Aggregate personal saving, measured by the Bureau of Economic Analysis, averaged about 1 percent of disposable income during the first three quarters of 2004, more than 6 percentage points lower than the average that has prevailed since the early 1960s. The saving rate, measured by the Board's flow of funds accounts is higher, at 5 percent of disposable income, though it, too, is significantly lower than its average level in the past. Analysis by Board staff using data from the SCF indicate that households in the top income quintile can account for nearly all of the decline in the aggregate saving rate since 1989. Given that these higher-income households have more financial resources to weather shocks, the significant decline in savings is less troublesome than if it had occurred in the lower part of the income distribution. This points out two different perspectives on household financial health. While analysts usually focus on the savings rate as a share of current income and funds flow, some argue that a more relevant measure of saving adequacy is the change in net worth. And in this regard, the picture of household saving looks more favorable than suggested by the saving rate. The ratio of net worth-to-disposable income has come down from its peak in 2000, but remains at a high level relative to the past few decades, because capital appreciation on household assets, such as equities and real estate, has considerably outpaced income gains. This is a passive perspective on savings, though, where households rely on the markets to raise the value of their assets over time. But to create these assets, households need to consistently set aside some of their current earnings to invest for their future needs. While the experience of the past three years of exceptionally low interest rates and lower expected stock returns encouraged a rational consumer to spend and not save, as the markets return to more long-term trends, we should see consumers moderate their behavior as well. Financial Conditions of Businesses The business sector is in good financial shape--a dramatic turnaround from the situation in 2001. Firms have reduced leverage and restructured their liabilities, responding in part to investors' concerns arising from some high-profile unanticipated meltdowns in the early part of this decade. In addition, firms have significantly cut costs through dramatic gains in productivity, which has boosted profits. In my view, even with a rise in interest rates and some moderation in profit growth, the business sector should remain financially strong and continue to expand. The improvement in corporate balance sheets in the past few years has been substantial. Firms have taken advantage of low long-term interest rates to refinance high-cost debt. Businesses have also improved their balance sheet liquidity by substituting long-term debt for short-maturity debt and by building up their cash positions. In addition, many firms--especially in the most troubled industries--have retired debt through equity offerings and asset sales, and others have used their mounting profits to retire debt. As a result, nonfinancial corporate debt grew at an annual rate of less than 2-1/2 percent in the past few years, its slowest pace since the early 1990s. These repairs to balance sheets have also reduced the exposure of many firms to rising interest rates, especially in the near term. In particular, the replacement of short-term debt by long-term bonds means that less debt will have to be rolled over in the near term at higher rates. In addition, because much of the long-term debt has a fixed rate, interest payments typically are unaffected over the life of the bond. Moreover, research by the Board staff suggests that firms that rely more on floating-rate debt, and for that reason might be more vulnerable to rising rates, have in recent years tended to use derivatives to hedge some of their exposure to interest rate risk. Thus, for many firms, the effect of rising interest rates will be mitigated and spread out over time. Also, as we learned from the episode of policy tightening in 1994, rising interest rates have little detrimental effect on the financial health of the corporate sector when the rate increases occur in the context of an expanding economy. Indeed, corporate credit quality improved on balance after 1994 with the pickup in economic activity and corporate profits. Some of the improvement in financial conditions among businesses is due to significant belt-tightening by many firms. Over the past few years, the drive to cut costs and boost efficiency has generated rapid productivity gains. Fuller utilization of the capabilities of capital already in place, ongoing improvements in inventory management, and streamlined production processes requiring fewer workers, to name but a few examples of efficiency enhancements, have boosted corporate profitability. The pickup in revenue growth since mid-2002, combined with outsized productivity gains, has produced a dramatic recovery in overall corporate profitability. The profits of nonfinancial corporations as a share of sector output continued to climb and reached almost 11 percent in the third quarter of last year. This share lies above its long-run average over the past few decades and well above the cyclical trough of 7 percent in 2001. To be sure, the profit share likely will slip a bit from its high level as the expansion gains steam and businesses hire new workers more aggressively. But some decline in the profit share is to be expected and will not, in my view, significantly impair the financial health of companies. This favorable view is reflected in risk spreads on corporate bonds, which have dropped dramatically from their historic highs in the fall of 2002. And firms that have turned to capital markets for financing have found them to be accommodative. A remaining financial hurdle for some companies is the underfunding of defined benefit retirement plans, though this burden is notably less than it was two years ago. At the end of 2002, the majority of S&P 500 plans were underfunded, with a net shortfall that had grown to more than $200 billion, as stock market losses from 2000-02 eroded the value of assets and declining interest rates raised the current value of plan liabilities. Since then, companies have made large cash contributions to shore up these plans and equity prices have risen, reducing the aggregate underfunding for S&P 500 companies to around $125 billion at the end of 2004. In addition, plan sponsors received some temporary relief from federal legislation passed early last year that allowed firms to use a discount rate for their liabilities based on corporate bond yields rather than one based on Treasury yields. The replacement effectively reduced the stated value of liabilities and thus estimates of underfunding and required cash payments for tax purposes. Nonetheless, important longer-term issues regarding defined benefit plans remain. In decades past, workers might spend most or all of their careers at a single firm and might receive generous preset benefits from traditional defined benefit plans, with a guaranteed benefit to be provided by the Pension Benefit Guaranty Corporation (PBGC), the government entity that insures defined benefit plans, if the firm were to go bankrupt. As workers began to change jobs more frequently, however, they increased their demand for defined contribution retirement plans because of their portability and the more-even pattern of benefit accruals over a worker's career. Also, many companies were attracted to these plans as a way to limit their future funding obligations for traditional defined benefit retirement plans. As a result, financially solvent older companies have been terminating their defined benefit plans and only a rare few companies have been starting new defined benefit plans. This trend weakens the PBGC because it is left increasingly with pension plan sponsors with relatively weak financial positions. Currently, the PBGC is facing a potential financial crisis. Its funding status deteriorated in 2004, for the fourth consecutive year, with the value of its assets now falling short of its liabilities by nearly $24 billion. Most of the deterioration is due to the large number of firms with underfunded pension plans that declared bankruptcy in recent years. However, the legislation that offered relief to plan sponsors also contributed to the worsening position because it reduced not only the cash contributions made to plans but also the premiums to be paid to the PBGC. The PBGC has fundamental structural problems as well, which include the inability to raise premiums or to charge premiums based on the credit quality of the plan sponsor, and the lack of authority to mandate adequate contributions to defined benefit plans. These flaws, if left unaddressed, combined with the shift toward defined contribution plans, raise serious questions about the retirement security of workers currently under defined benefit plans. Retirement Savings The shift from defined benefit to defined contribution plans also raises significant issues about how effectively employees are handling their new freedoms and responsibilities and what the appropriate role for employers should be in helping workers plan for their retirement. A particularly popular type of defined contribution plan is the 401(k), which lets workers make pre-tax contributions to retirement accounts through payroll deduction. Twenty-five years ago, such plans did not exist. Today, they cover more than 40 million workers, take in $150 billion in annual contributions, and hold assets of about $2 trillion. And with a decline in the number of workers being covered by defined benefit plans over this period, the growth of 401(k) plans has put greater responsibility on the part of individuals to actively manage their retirement wealth. For example, workers must decide whether to participate in the plan, how much to contribute every pay period and in what type of assets, and when to rebalance their asset mix. In addition, they need to decide what to do with balances when changing jobs. Economic theory provides the basis for making these types of choices, but the average employee may not have developed the skills or the interest to formally evaluate the alternatives. And, in fact, recent research has found some troubling patterns: Many workers do not participate, contribute only a small portion of their wages if they do participate, and make questionable investment and distribution choices. Let me take a couple of minutes to cite some telling facts about individual savings in 401(k) plans, suggesting that workers may not be giving adequate attention to their savings in the retirement plans sponsored by their employer. First, despite the tax advantages of 401(k) contributions, one-quarter of workers eligible for 401(k) plans do not participate at all, even if the employer would match a portion of their own contributions. These workers are effectively giving up a pay raise. And among those that contribute, many save just a little. In a survey last year, one-quarter of firms reported that their rank-and-file 401(k) participants saved an average of less than 4 percent of pay. Another concern relates to the way employees manage their 401(k) plans. Some participants simply invest contributions equally across the investment options or according to plan defaults, which in many cases is a low-risk, low-return money market fund. And, as has been publicized widely in recent years, many 401(k) participants invest heavily in employer stock. Among companies that offer company stock as an investment option, more than one-quarter of 401(k) balances are in company stock. This high concentration cannot be attributed entirely to an employer match that is required to be held in company stock. Instead, employees appear to voluntarily purchase abundant amounts of company stock, despite the obvious risk of linking their current income and retirement wealth to the financial health of their employer. These patterns are troubling because they raise doubts about the financial security of workers in later life. Fortunately, new research in the discipline of behavioral finance provides some important insights into the behavior of 401(k) participants and suggests some promising changes that can lead workers to make savings choices that will leave them better prepared for retirement. Contrary to predictions of traditional finance theory, the way the retirement-plan options are framed affects the choices made by participants. As compelling evidence that framing matters, researchers have found that "opt-out" plans--those that automatically enroll workers unless they actively choose not to enroll--have substantially higher participation rates. Moreover, when defaults are designated, many workers tend to enroll using the default contribution rates and investment options and to leave these in place for many years after enrollment, even though the default may be set too low to allow for the accumulation of sufficient retirement assets. Moreover, the default investment choice is often a low risk asset that, while safe, does not allow for sufficient expected returns to build up retirement wealth. If workers are influenced by how choices are offered, then employers can make changes to the plans to help participants make better decisions. For example, employers might set default contribution rates to rise as workers receive pay raises, or set the default investment option to a diversified portfolio that adjusts as the worker ages. In addition, employees have increasingly expressed interest in employer-provided financial education, and firms are responding. In this regard, the Congress passed legislation in December 2001 that removes obstacles for employers to hire a third-party to provide financial advice. Previously, firms had been reluctant to provide investment advice for fear of being held liable should such advice lead to losses, even if an adviser was considered to be competent. Reportedly, more firms now provide access to a third-party who will, for a fee, advise employees about how much to contribute and how to invest their contributions. Some employers will be reluctant to move in this direction because they will appear to be paternalistic. But a significant and inescapable implication of this line of research is that employers cannot avoid responsibility in this area because there is no "neutral" plan design. Whatever design they choose will affect the retirement wealth of employees. To wrap up, employers play an important role in their workers' financial security in later life and will continue to do so even with the shift away from defined benefit to defined contribution plans. An increasing amount of evidence indicates that how firms set up these plans will affect worker participation and contribution rates and what types of assets they will buy. As research continues to further our understanding of the connection between plan design and worker choices, changes can be instituted to promote financial security. For their part, workers have a responsibility to improve their financial literacy and develop the skills and confidence to practice strategies for effective financial management. This improvement of financial literacy will become even more crucial if individual accounts are introduced as a modification to the current Social Security system, as proposed by the Administration. Footnotes Office of Federal Housing Enterprise Oversight . Deloitte and Touche, Deloitte and Touche, Nellie Liang and Scott Weisbenner (2001), FEDS Working Paper 2002-36 and NBER Working Paper W9131; James Choi, David Laibson, Brigitte Madrian, and Andrew Metrick (2001), NBER Working Paper W8651. Sarah Holden and Jack VanDerhei (2004), "401(k) Plan Asset Allocation, Account Balances, and Loan Activity in 2003," ICI Perspective (August). Brigitte Madrian and Dennis Shea (2001), Quarterly Journal of Economics. James Choi, David Laibson, and Brigitte Madrian (2004), NBER Working Paper W10486. Shlomo Benartzi and Richard Thaler (2004), "Save More Tomorrow: Using Behavioral Economics to Increase Employee Saving," Journal of Political Economy.
Remarks by Governor Ben S. Bernanke At the C. Peter McColough Roundtable Series on International Economics, Council on Foreign Relations Presented at the University of Arkansas at Little Rock Business Forum, Little Rock, Arkansas, February 24, 2005 January 19, 2005 Productivity Almost certainly, the most important economic development in the United States in the past decade has been the sustained increase in the rate of growth of labor productivity, or output per hour of work. From the early 1970s until 1995, productivity growth in the U.S. nonfarm business sector averaged about 1-1/2 percent per year--a disappointingly low figure relative both to historical U.S. experience and to the performance of other industrial economies over the same period. Between 1995 and 2001, however, the rate of productivity growth picked up significantly, to about 2-1/2 percent per year--a figure that contributed to a growing perception that the United States might be entering a new economic era. Talk of the "new economy" faded with the sharp declines in the stock valuations of high-tech firms at the turn of the millennium; yet, remarkably, productivity growth continued to rise. The pace of productivity gains averaged better than 4 percent per year since 2001 despite adverse developments that included the 2001 recession, the September 11 terrorist attacks, corporate governance scandals, and, most recently, a sharp rise in energy costs. Why is the rate of productivity growth so important? Economists agree that, in the long run, productivity growth is the principal source of improvements in living standards. The link between productivity growth and the standard of living of the average person is somewhat looser in the short-to-medium run, as factors such as the share of the population that is employed and the division of income between capital and labor also play a role. Nevertheless, the rate of productivity growth influences the economy in important ways even in the short run, affecting key variables such as output growth, employment growth, and the rate of inflation. In my remarks today, I will discuss the pickup in U.S. productivity growth and its implications for the economy. I will first review our current understanding of the causes of the recent productivity resurgence. With that background, I will next consider the near-term prospects for productivity growth. Finally, I will discuss briefly how the evolving productivity picture affects both the economic outlook and the appropriate stance of monetary policy. As always, my remarks today do not necessarily reflect the views of my colleagues at the Federal Reserve. The U.S. Productivity Resurgence and Its Causes Why has productivity growth increased? The favored explanation of the rise in productivity growth since about 1995 has evolved somewhat over time. By 2000 or so, an emerging consensus held that the pickup in productivity growth was, for the most part, the product of rapid technological progress and increased investment in new information and communication technologies (ICT) during the 1990s (Jorgenson and Stiroh, 2000; Oliner and Sichel, 2000). According to this view, rapid developments in ICT promoted U.S. productivity growth in two ways. First, technological advances allowed the ICT-producing sectors themselves to exhibit rapid productivity growth. For example, the development of more reliable semiconductor manufacturing equipment and faster wafer-inspection technologies increased the rate at which companies such as Intel were able to produce microprocessors. In part as a reaction to heightened competitive pressures, Intel also shortened its product cycle and increased the frequency of new chip releases, shifting its product mix toward more-powerful (and, consequently, higher-value) chips. Both the more-rapid pace of production and the higher average quality of output raised productivity at Intel and competing firms. Second, ICT advances also promoted productivity growth outside the ICT-producing sector, as firms in a wide range of industries expanded their investments in high-tech equipment and software and used the new technologies to reduce costs and increase quality (McKinsey, 2001). For example, some large retailers, most notably Walmart, developed ICT-based tools to improve the management of their supply chains and to increase their responsiveness to changes in the level and mix of customer demand. Securities brokers and dealers achieved substantial productivity gains by automating their trading processes and their back-office operations. In the durable goods sector, General Motors and other automobile producers developed programmable tooling systems to increase the flexibility of their manufacturing processes--for example, to permit vehicles based on different platforms to be produced on the same assembly line. One study found that nearly two-thirds of U.S. industries, comprising about 70 percent of total employment, experienced an acceleration of productivity in the latter part of the 1990s. Significantly, the study also found the gains to be the greatest in industries using ICT capital most intensively (Stiroh, 2002). Undoubtedly, the ICT revolution and the productivity resurgence in the United States after 1995 were closely connected, but several puzzles have arisen that challenge the view that ICT investment leads mechanically to higher productivity. First, the United States was not the only country to see a rapid expansion in ICT investment, as other industrial countries also invested heavily in these technologies in the 1980s and 1990s. Yet, with a few exceptions, productivity growth in other advanced countries has not increased recently to the extent seen in the United States. The comparison with the member states of the European Union is particularly interesting. Throughout most of the post-World War II period, labor productivity growth in Europe exceeded that in the United States, reflecting, first, rapid gains during the postwar reconstruction and then a gradual convergence of European technology and business practices to American standards. By one estimate, on average, European productivity increased from 44 percent of the U.S. level in 1950 to 94 percent in 1995 (Gordon, 2004). However, since about 1995, productivity growth in Europe has slowed, in contrast to the U.S. experience, and productivity levels in the United States and Europe have begun to diverge. Researchers have made the important point that U.S.-European differences in productivity growth do not appear to have been particularly large in the ICT- producing sectors, where U.S. strengths in the development of information technologies have been offset by European leadership in communications. Rather, the U.S. advantage has been most evident in the ICT- using sectors, which have performed better in the United States than elsewhere. What accounts for the apparent U.S. advantage in applying ICT to a wide range of industries? One popular hypothesis, put forth by Alan Greenspan (2000) and Martin Feldstein (2001), holds that European economies have been less successful in applying new technologies because of a relatively heavy regulatory burden that inhibits flexibility. For example, taking full advantage of new information and communication technologies may require extensive reorganization of work practices and the reallocation of workers among firms and industries. Regulations that raise the cost of hiring and firing workers and reduce employers' ability to change work assignments, as exist in a number of European countries, may make such changes difficult to achieve. Likewise, the presence of government-owned firms with a degree of monopoly power, together with restrictions on the entry of new firms, may diminish competitive pressures that often foster innovation and greater efficiency (Nicoletti and Scarpetta, 2003). Recent empirical research has generally found that economies with highly regulated labor and product markets are indeed less able to make productive use of new technologies (Gust and Marquez, 2004). Industry-specific regulations may also be an important barrier to productivity improvement; for example, some writers have argued that restrictions on land use and on shopping hours in Europe have impeded the development of "big box" retail outlets, denying European firms the economies of scale that have been important for productivity growth in the U.S. retail sector (Gordon, 2004). Differences in regulatory burden do not appear to be a complete explanation of comparative productivity performance, however. For example, the United Kingdom, whose approach to the regulation of labor and product markets is closer to that of the United States than to that of continental Europe, has not done noticeably better in the productivity arena than other advanced European countries (Basu, Fernald, Oulton, and Srinivasan, 2003). A shortage of workers with appropriate skills may be part of the problem in the United Kingdom, as average educational attainment in that country is lower than in many other industrial countries. Skill shortages may have also been a factor in continental Europe, possibly because high youth unemployment has reduced opportunities for workers to acquire new skills on the job. Other suggested explanations for the relatively better productivity performance of the United States in recent years include the depth and flexibility of U.S. capital markets, its relatively open immigration policies (at least before 9/11), and the role of U.S. research universities in fostering innovation. Further study of the productivity differentials among the United States, Europe, and other regions clearly is warranted. A second puzzle that challenges the conclusion that advances in ICT are the primary source of recent productivity gains is the observation that, over the past twenty years or so, increases in ICT investment have not been followed reliably and in short order by increases in productivity growth. Instead, the lag between investments in new technologies and their putative productivity benefits appears to be long and variable. For example, ICT investment in the United States began in earnest in the 1980s, but productivity did not begin to accelerate until the mid-1990s. Indeed, an oft-quoted quip by economist Robert Solow held that, as of the late 1980s, "computers are everywhere except in the productivity statistics." Likewise, although ICT investment declined sharply after the meltdown in tech stocks in 2000, productivity growth has continued to rise in recent years, as I have already noted. Perhaps the link between investment in high-tech capital and improving productivity is not so tight as we thought. In attempting to explain the relatively loose temporal link between ICT investment and productivity growth, economists have emphasized that much more than the purchase of new high-tech equipment is needed to achieve significant gains in productivity. First, managers must have a carefully thought-out plan for using new technologies before they acquire them. Case studies of individual industries show that, in some cases, the planning for technological modernization has not always been adequate, with the result that some purchases of high-tech equipment and software have not added much to productivity or profits. The idea that managers can buy the hardware first and then decide what to do with it--sometimes heard as an explanation for the apparently delayed effects of ICT investments made during the late-nineties boom--does not square with the case-study evidence. Effective planning alone does not guarantee that ICT investments will be beneficial, however. Some observers have characterized the new information and communications technologies as general-purpose technologies (GPTs), which means that--like earlier GPTs such as electrification and the internal combustion engine--they have the potential to revolutionize production and consumption processes in a wide variety of contexts (Bresnahan and Trajtenberg, 1995). To make effective use of a GPT within a specific firm or industry, however, managers must supplement their purchases of new equipment with investments in research and development, worker training, and organizational redesign--all examples of what economists call intangible capital . For example, to realize the benefits of its ICT investments, Walmart had to reorganize work assignments, retrain workers, develop new relationships with suppliers, and modify its management systems. Although investments in intangible capital are (for the most part) not counted as capital investment in the national income and product accounts, they appear to be quantitatively important. One recent study estimated that, by the late 1990s, investments in intangible capital by U.S. businesses were as large as investment in traditional, tangible capital (Corrado, Hulten, and Sichel, 2004). Recognizing the importance of intangible capital has several interesting implications. First, because investment in intangible capital is typically treated as a current expense rather than as an investment, aggregate saving and investment may be significantly understated in the U.S. official statistics. Second, firms' need to invest in intangible capital--and thus to divert resources from the production of market goods or services--helps to explain why measured output and productivity may decline initially when firms introduce new technologies. Finally, the importance of intangible investment explains to some degree why the lags between ICT investment and the resulting productivity gains can be long and variable. Because investments in high-tech capital typically require complementary investments in intangible capital for productivity gains to be realized, the benefits of high-tech investment may become visible only after a period of time. Medium-Term Prospects for Productivity Growth Historical analysis of the sources of the productivity acceleration is challenging, but not nearly so challenging as trying to predict how productivity will evolve over the next few years. However, because the rate of productivity growth is a primary determinant of economic performance, policymakers have few options other than to try to forecast future productivity gains. What can be said about the medium-term prospects for productivity growth? The task of trying to predict the medium-term behavior of productivity is complicated by the fact that productivity growth tends to vary with the business cycle. According to one popular hypothesis, this tendency reflects cyclical variations in the intensity with which labor is utilized. Because adjusting the size of a company's labor force may involve significant fixed costs (including training costs as well as costs of hiring and firing), employers are generally reluctant to add or subtract workers at the first sign of a change in the demand for their products. Thus, in the earliest stages of a contraction, for example, employers may choose not to dismiss workers but instead to use them less intensively or assign them tasks that do not involve current production, such as maintenance or training. Measured productivity growth consequently declines when the economy enters a recession. Similarly, during the early stages of an economic recovery, employers may hesitate to add new workers and instead may ask existing employees to work harder, at least until the expansion seems better established. Output per hour of work thus tends to rise faster than its secular (long-run) rate early in the recovery. Finally, as the expansion matures and hiring picks up, productivity growth tends to slow again as the level of employee effort returns to normal and as the need to devote firm resources to hiring and training new workers detracts from current production. At present, three years from the official end of the 2001 recession, the U.S. economy has likely entered this latter stage, as productivity growth appears to be falling from its recent high levels to a rate that is likely below its longer-term trend. Cyclical factors tend to unwind, however; and so, looking ahead a couple of quarters, say, to the second half of 2005, we can reasonably assume that productivity growth will approach its secular trend. What is that trend? Using various econometric methods, together with a liberal dose of judgment, several leading economists have recently offered estimates for secular productivity growth of about 2-1/2 percent per year, close to the rate of productivity growth achieved during 1995-2001 (Baily, 2003; Gordon, 2003; Jorgenson, Ho, and Stiroh, 2004). If these estimates turn out to be correct--and they are certainly subject to a great deal of uncertainty, as I will discuss--then the increase in productivity growth of the mid-1990s may come to be seen as having initiated a new era for the U.S. economy. Of course, as the saying goes, past returns are not a guarantee of future results; not all the evidence supports the emerging consensus that secular productivity growth will remain at its current elevated level. For example, although spending on high-tech equipment and software has recovered smartly from its recent lows, growth in ICT spending still remains well below rates seen before the 2001 recession. Some industry participants have suggested that less-rapid growth in ICT spending reflects the absence of major new business applications for ICT--"killer apps,"as they are called--and that ICT investment for the foreseeable future will largely reflect replacement demands. Researchers have also found some evidence that the technological frontier may not have advanced as quickly recently as it did in earlier years; as one indicator, the price of computing power has recently declined more slowly than it did in the 1980s and 1990s. These caveats notwithstanding, I think the productivity optimists have a good case. Computing power may not be falling in price quite so rapidly now as in the late 1990s, but a dollar nevertheless buys a great deal more computational capacity today than it did even five years ago. And if rapidly improving information and communication technologies are truly general-purpose technologies, history suggests that they will continue to stimulate new ways of producing and of organizing production (DeLong, 2002). In particular, the enormous expansion in available computing power has already contributed to advances in other emerging fields, such as biotechnology. Moreover, even if the technological frontier advances more slowly during the next few years, further diffusion of the existing technologies and applications can continue to raise aggregate productivity. The available evidence suggests that this diffusion process is not complete. For example, a survey conducted in 2003 by the Institute of Supply Management and Forrester Research found that most managers consider their company to be at a relatively early stage in exploiting the potential gains from using the Internet for their purchasing activities. In a more formal analysis, Jason Cummins and Giovanni Violante constructed a measure of the "technological gap" in U.S. industry, defined as the difference in efficiency between state-of-the-art capital equipment and the actual mix of equipment held by firms (Cummins and Violante, 2002). As of 2000, the last year included in their study, the authors found this gap to be 40 percent and rising, suggesting that substantial opportunities remain for increasing productivity. This gap is unlikely to have declined much since 2000, for even if the rate of technological progress has slowed, so has the pace of ICT investment. I draw two conclusions: First, on the whole, the relatively optimistic estimates of secular productivity growth espoused by leading scholars in the field do not seem unreasonable, so that, for the longer term, continued growth in productivity in the range of, say, 2 percent to 2-1/2 percent per year probably represents a good baseline assumption. Second, qualifying the first conclusion, the range of uncertainty in forecasts of productivity growth is inevitably quite wide. For example, a 2004 study by three leading scholars produced an estimate of trend productivity growth of 2.6 percent, but with a range of plausible outcomes between 1.4 percent and 3.2 percent (Jorgenson, Ho, and Stiroh, 2004). This qualification naturally leads us to ask: Suppose that, over the next year, the incoming evidence suggests that the trend rate of productivity growth is either substantially higher or substantially lower than we currently expect. How would that development affect the economy and monetary policy? In the final portion of my remarks, I will address this important question. Implications for the Economy and Monetary Policy For concreteness, suppose that the pace of productivity gains in the latter part of 2005 and in 2006 proves disappointing, sufficiently so to suggest that current estimates of the sustainable rate of productivity growth may be overoptimistic. Let us first consider what this information would likely imply for the medium-term economic forecast. To anticipate the conclusion, we will see that the strength of the response of aggregate demand to productivity developments is the key determinant of their overall impact. In the first instance, incoming evidence of a secular slowdown in productivity would likely result in slower growth in consumption spending, capital investment, and aggregate output relative to what would have been otherwise expected. Consumption growth would weaken as downwardly revised profit expectations limit stock market gains, thereby reducing household wealth, and as more-foresighted consumers perceive that smaller productivity gains portend lower real wage growth. Lower expected rates of productivity growth should also tend to moderate growth in business investment by reducing the prospective return to capital. As consumption and investment spending make up more than four-fifths of aggregate output, slower productivity growth would perforce reduce output growth as well. What about inflation? In principle, the medium-term effect of slowing productivity growth on inflation is ambiguous. As a number of analysts have noted, under the reasonable assumption that nominal wages adjust slowly, slower productivity growth results in a more rapid rise in unit labor costs (the nominal-wage cost of producing a unit of output). All else equal, a more rapid increase in unit labor costs will tend to increase inflation as well. However, the effect of higher unit labor costs may be offset if the decline in consumption and investment spending induced by the productivity slowdown is particularly sharp. Indeed, a large deceleration in spending could conceivably cause inflation to slow following a productivity slowdown, as firms' markups contract more than unit labor costs rise. The effect of a productivity slowdown on employment growth is likewise ambiguous in the medium term. Slower output growth depresses employment growth as firms face weaker demand, but slower productivity growth implies that firms need more workers to produce a given level of output. As in the case of inflation, the strength of the spending response is crucial. The more sharply spending and output decline following a productivity slowdown, the more adverse the effects on employment will be. Both the late 1990s and the more recent period illustrate the central role of the spending response in determining the macroeconomic effects of a change in productivity growth, although (as I have discussed today) in both of these episodes the productivity surprise was to the upside rather than the downside. The rise in productivity growth after 1995 was accompanied by surges in both consumption and investment spending, supported by a booming stock market. Employment rose and unemployment fell, as the strength of aggregate demand induced employers to hire, the increases in productivity notwithstanding. Inflation remained fairly stable during this period, as upward pressures from increased aggregate demand were balanced by downward pressures on unit labor costs (for any given level of wages) and by the increase in aggregate supply created by higher productivity. In contrast to the experience of the late 1990s, during the early part of the new millennium the response of spending to rising productivity growth was comparatively weak. Investment spending was particularly slow to respond to the further increase in productivity growth, for reasons that are still debated. Possible explanations for the weak investment response include an unusually high degree of corporate caution, cost-cutting pressures, and the after-effects of the corporate governance scandals of 2002. An explanation suggested by my discussion today is that, for most of this period, companies were enjoying the fruits--in terms of higher productivity--of earlier investments in both tangible and intangible capital. The extra productive capacity created by those investments, together with a recovery whose durability in the early stages was not assured, may have implied little need for further investment, at least until relatively recently. Whatever the cause, the weaker response of spending in the more-recent period, coupled with impressive gains in productivity, helped to generate both a pattern of slow job growth (the "jobless recovery") and the worrisome decline in inflation in 2003. What are the implications of these observations for current monetary policy? Certainly, monetary policy makers should pay close attention to developments on the productivity front, as the effects of changing productivity trends permeate the economy. However, as we have seen, the appropriate policy response to any perceived change in the trend rate of productivity growth will depend to a significant degree on the response of private-sector spending. For example, if productivity growth appears poised to decelerate, but (for whatever reason) aggregate private spending does not slow materially in response, then inflation risks would rise, but employment would not be adversely affected. The appropriate response in this case would be a tightening of monetary policy (or a more rapid removal of accommodation). On the other hand, if slower productivity growth were accompanied by a sufficiently large slowdown in aggregate demand and economic activity, then easier monetary policy (or a slower removal of policy accommodation) might be called for. My best guess--and it is only a guess--is that future responses of consumption and investment spending to changes in the pace of productivity growth are likely to be less powerful than those of the late 1990s, if for no other reason than that we may have learned to be more careful in our enthusiasms. If so, then the principal effect of an unexpected slowdown in productivity growth during the next few years would likely be higher inflation, with the short-term impact on the growth of output and employment likely to be relatively minor. In this scenario, the appropriate monetary policy response would be toward less accommodation. By similar reasoning, if productivity growth were to accelerate in the next few years, then easing inflation pressures and slowing employment growth would likely allow for less-restrictive policies. As I have emphasized, however, these conclusions depend on other developments in the economy, most importantly on how strongly aggregate spending responds to any perceived change in secular productivity growth. Of course, it should go without saying that the world is more complicated than theoretical arguments suggest. Notably, imperfect data and the difficulties of distinguishing permanent from temporary changes will make changes in secular productivity growth exceptionally difficult to identify in real time, both for the private sector and for the Federal Reserve. The need to discern the underlying economic forces and to react appropriately in an environment of incomplete information makes monetary policy an exceptionally challenging endeavor. Footnotes I will use "labor productivity" and "productivity" interchangeably in my remarks today. An alternative productivity concept, multifactor productivity, measures the quantity of output that can be produced by a fixed combination of capital and labor. Changes in labor productivity generally reflect changes in both multifactor productivity and the amount of capital per worker. I thank Board staff members , Charles A. Fleischman, , and for excellent assistance and comments. Correcting for national differences in productivity measurement in some cases reduces the apparent differential in recent productivity growth but does not eliminate it. See Ahmad and others (2003) and Gordon (2004). In fairness to ICT proponents, Solows claim that computers were "everywhere" in the 1980s is somewhat exaggerated. Aggregate ICT investment was considerably higher in the 1990s than in the 1980s. Software is one intangible investment that is treated as part of business fixed investment in the U.S. national accounts. See Basu and Fernald (2001) for a discussion. Kohn (2003) explores some of the issues of this section in greater detail. Braun (1984) and Ball and Moffitt (2001) discuss the effect on inflation of a change in the rate of productivity growth. References Ahmad , Nadim, Franois Lequiller, Pascal Marianna, Dirk Pilat, Paul Schreyer, and Anita Wlfl (2003). OECD Science, Technology, and Industry Department, working paper 2003-14. Baily, Martin (2003). Institute for International Economics, working paper 01-09. Ball, Laurence, and Robert Moffitt (2001). "Productivity Growth and the Phillips Curve," in A. Krueger and R. Solow, eds., The Roaring Nineties: Can Full Employment be Sustained? New York: Russell Sage Foundation and Century Foundation Press. Basu, Susanto, and John Fernald (2001). "Why is Productivity Procyclical? Why Do We Care? in C. Hulten, E. Dean, and M. Harper, eds., New Developments in Productivity Analysis, Cambridge, Mass.: National Bureau of Economic Research. Basu, Susanto, John Fernald, Nicholas Oulton, and Sylaja Srinivasan (2003). Federal Reserve Bank of Chicago, working paper 2003-08. Braun, Steven (1984), "Productivity and the NIIRU," Board of Governors of the Federal Reserve System, National Income Section and Wages, Prices, and Productivity Section, working paper 34. Bresnahan, Timothy, and Manuel Trajtenberg (1995). "General Purpose Technologies: 'Engines of Growth?'" Journal of Econometrics , vol. 65, pp. 83-108. Corrado, Carol, Charles Hulten, and Daniel Sichel (2004). Board of Governors of the Federal Reserve System, Finance and Economics Discussion Series 2004-65. Cummins, Jason, and Giovanni Violante (2002). Review of Economic Dynamics , vol. 5, pp. 243-84. DeLong, J. Bradford (2002). "Productivity Growth in the 2000s," unpublished paper, University of California, Berkeley, March. Feldstein, Martin (2001). "Comments and Analysis," Financial Times , June 28. Gordon, Robert J. (2003). "Exploding Productivity Growth: Context, Causes, and Implications," Brookings Papers on Economic Activity , 2, pp. 207-98. Gordon, Robert J. (2004). National Bureau of Economic Research, working paper 10661. Greenspan, Alan (2000). speech before the Economic Club of New York, January 13. Gust, Christopher, and Jaime Marquez (2004). "International Comparisons of Productivity Growth: The Role of Information Technology and Regulatory Practices," Labour Economics , vol. 5, pp. 33-58. Jorgenson, Dale, and Kevin Stiroh (2000). "Raising the Speed Limit: U.S. Economic Growth in the Information Age," Brookings Papers on Economic Activity, 1, pp. 125-211 . Jorgenson, Dale, Mun Ho, and Kevin Stiroh (2004). Federal Reserve Bank of New York, Current Issues , December, pp.1-7. Kohn, Donald (2003). at the Federal Reserve Bank of Philadelphia Monetary Seminar, Philadelphia, Pennsylvania, September 24. McKinsey and Company (2001). U.S. Productivity Growth 1995-2000: Understanding the Contribution of Information Technology Relative to Other Factors. Washington: McKinsey Global Institute. Nicoletti, Guiseppe, and Scarpetta, Stefano (2003). OECD Economics Department, working paper 347. Oliner, Stephen, and Daniel Sichel (2000). "The Resurgence of Growth in the Late 1990s: Is Information Technology the Story?" Journal of Economic Perspectives, vol. 14, pp. 3-22. Stiroh, Kevin (2002). "Information Technology and the U.S. Productivity Revival: What Do the Industry Data Say?' American Economic Review , vol. 92, pp.1559-76.
For immediate release The Federal Reserve Board on Tuesday announced its approval of the application filed by The Colonial BancGroup, Inc., Montgomery, Alabama, to acquire 100 percent of the voting shares of Union Bank of Florida, Lauderhill, Florida. Attached is the Board's Order relating to this action.
For immediate release The Federal Reserve Board on Wednesday announced its approval of the applications under section 3 of the Bank Holding Company Act, the Bank Merger Act, and section 9 of the Federal Reserve Act for Westamerica Bancorporation ("Westamerica"), San Rafael, California, to merge with Redwood Empire Bancorp, Santa Rosa, California, and by Westamerica's subsidiary bank, Westamerica Bank, to effect the following transactions: (1) merge with National Bank of the Redwoods ("Redwood Bank"); and (2) retain and operate branches at the location of Redwood Bank's main office and branches. Attached is the Board's Order relating to this action.
Joint Press Release Board of Governors of the Federal Reserve System Federal Deposit Insurance Corporation Office of the Comptroller of the Currency Office of Thrift Supervision For Immediate Release January 27, 2005 Agencies Issue Statement on Implementation of Basel II Framework The federal banking and thrift agencies today released an interagency statement on implementation of the Basel II framework and the qualification process for the framework's "advanced approaches." The interagency statement is attached. Agencies Issue Statement on Implementation of Basel II Framework The federal banking and thrift agencies today released an interagency statement on implementation of the Basel II framework and the qualification process for the framework's "advanced approaches." The interagency statement is attached. Media Contacts: Federal Reserve Andrew Williams 202-452-2955 FDIC David Barr 202-898-6992 OCC Kevin Mukri 202-874-5770 OTS Erin Hickman 202-906-6677
Joint Press Release Board of Governors of the Federal Reserve System Federal Deposit Insurance Corporation Office of the Comptroller of the Currency For Immediate Release January 28, 2005 Banking Agencies Announce Implementation of Web-Based Central Data Repository for Bank Financial Data The federal banking agencies announced today a new implementation plan for the Central Data Repository (CDR)--an Internet-based system created to modernize and streamline how the agencies collect, validate, manage, and distribute financial data submitted by banks in quarterly "Call Reports." While banks will not be required to submit Call Report data to the CDR until October 2005, the agencies plan to make the CDR available for testing by banks and software vendors early this summer. Originally scheduled for implementation in October 2004, rollout of the CDR was postponed to address industry feedback and allow more time for system testing and enrollment. The new implementation plan resulted from discussions with industry representatives including software vendors, trade associations, and a number of banks from across the country that participate in the Financial Institutions Focus Group for the CDR project. The new plan provides additional time for each group to participate in testing to help ensure a smooth integration of the new technology into the Call Reporting process. Beginning this summer, the CDR will be made available to banks for enrollment and testing of their ability to access the system. Also, during this period, software vendors will be working with the agencies to prepare for the final test of system readiness in August. Full system implementation, planned for October, will mark the first time all institutions will be required to file their Call Report data using the new CDR. Through the use of new open data exchange standards (known as "eXtensible Business Reporting Language," or XBRL), the CDR system will facilitate faster delivery of accurate Call Report data. All users of the data--financial institutions, the public, and banking regulators--are expected to benefit from this improved, timelier flow of financial institution information. This initiative--the Call Report Modernization Project--is an interagency effort under the auspices of the Federal Financial Institutions Examination Council (FFIEC). Additional project details and other important information are posted on the FFIEC's Web site at . Federal Reserve Susan Stawick 202-452-2955 FDIC David Barr 202-898-6992 OCC Dean DeBuck 202-874-5770