Governor Susan Schmidt Bies At the Mortgage Bankers Association Presidents Conference, Half Moon Bay, California Good morning. It is a pleasure to be here today, and I thank you for the invitation. It almost goes without saying that over the past several years, residential housing markets have been attracting considerable attention, and they have been a strong contributor to the overall growth of the U.S. economy. Today I would like to offer some thoughts on the current state of both residential and commercial mortgage markets and then discuss some ways in which U.S. bank supervisors are trying to ensure that bank lending in those markets is safe and sound. Conditions in Real Estate MarketsResidential Real Estate MarketsActivity in U.S. housing markets is slowing. Incoming data point to a decided, but so far moderate, cooling. Starts of single-family houses fell appreciably in March and April. Because construction had been spurred in the preceding months by unusually mild weather, some slowing in the spring was natural. However, the level of housing starts lately has fallen below not just the elevated winter pace but also the pace of last fall. Indeed, construction permit issuance for single-family homes, which is less affected by the weather, has been declining since September. Sales of new and existing homes have dropped noticeably from their highs of last year. In addition, inventories of unsold homes have increased, and your own MBA index of loan applications for home purchases has trended lower in recent months. Although a slowdown in housing activity is apparent in a wide range of indicators, it seems to be occurring in a gradual way. Notwithstanding their recent slip, both home construction and home sales are still at relatively high levels. The underlying fundamentals of housing demand also remain favorable. Real disposable income is growing at a solid pace. In the aggregate, household balance sheets appear to be in a good position, even though risks clearly exist for some households. Long-term mortgage rates, although up substantially from last summer's level, remain low relative to their historical experience. The latest data on house prices from the Office of Federal Housing Enterprise Oversight suggest that house-price appreciation has moderated but that prices in the aggregate continue to move up. Between the first quarter of 2005 and the first quarter of this year, the price index for existing homes sold in repeat transactions increased 10 percent--a solid gain but down a bit from the record pace for the period mid-2004 to mid-2005. Focusing on the first quarter of 2006 alone, prices increased at an annual rate of 7.3 percent. However, quarterly figures should be treated with a good degree of caution given the volatility of this data series. Given the slowing conditions in the housing market, spending for the construction of new housing is unlikely to be an important direct source of overall GDP growth this year, after having contributed close to ½ percentage point last year. In addition, the slackening of house-price appreciation could hold back growth in consumption spending through the so-called wealth effect, or the effect that lower overall housing wealth has on consumption. Estimates from various econometric models of consumer spending suggest that each dollar of change in wealth is associated with a change in consumption of approximately 3½ cents, with roughly half of the effect occurring within a year. Of course, these consumption estimates are just that--estimates. Beyond the usual issues of measurement and interpretation associated with any statistical estimate, one can easily point to some specific risks in estimating how housing wealth affects spending. First, econometric modeling has had difficulty distinguishing between the effects of movements in housing wealth and movements in other components of household balance sheets, even though housing may be a unique asset in a number of ways. Thus, the estimate of change in consumption that I cited is based on the historical relationship between spending and changes in overall wealth. Changes in housing wealth may have a somewhat different effect. Second, the linkages between housing wealth and consumption may change over time. For example, these linkages may be stronger now than in the past because financial innovation has made it easier and less costly for households to tap their accumulated housing equity. Third, a pronounced deceleration in house prices could have an outsized effect on consumer confidence, and such a decline in confidence could be an additional damping force on consumption. Another housing-related issue that bears watching is mortgage debt accumulation. Since the end of 2002, home mortgage debt outstanding has risen about 50 percent. The increase has substantially pushed up homeowners' mortgage payments in relation to their income, in spite of historically low mortgage rates, the growing use of interest-only mortgages, and the lengthening of average loan maturities over the past few years. That said, homeowners appear to be able to manage these higher payments: we have seen only a little deterioration in mortgage credit quality as yet, and overall delinquency rates remain low. Going forward, I expect aggregate homeowner mortgage payments to continue to rise, especially as adjustable-rate mortgages reach their initial reset dates. However, these reset adjustments are expected to be gradual, and only a modest number of outstanding mortgages are expected to reset during 2006 and 2007. To date, consumers appear to be managing changes in their mortgage payments quite well. One area of potential concern relates to the portion of home sales accounted for by investors, as opposed to owner-occupants. Historically, only around 5 percent of U.S. homes were purchased each year by investors; in 2005, it appears that figure was considerably higher. In many cases, investors purchased homes because they believed prices were going to rise further, not necessarily because they wanted to retain the property over time for rental income. As prices level off or even decline, it will be important to see whether this investor activity subsides significantly, and if so, the impact on mortgage markets more broadly. Commercial Real Estate MarketsIn addition to monitoring residential markets, the Federal Reserve keeps a close watch on developments in commercial real estate markets. Overall, conditions in this sector appear to be improving. Demand for commercial space has been growing moderately, while the construction of new space has generally remained tame, restrained in part by steep land prices and high construction costs. The result has been a widespread decline in vacancy rates over the past few years. Reflecting this improved balance between demand and supply, rents on commercial properties have been increasing after a prolonged period of softness. Although the level of commercial construction remains well below its peak in 2000, the latest data indicate what may be the beginning of a pickup. Census Bureau data on nonresidential construction put in place suggest that real spending rose in April for the sixth consecutive month. Leading indicators of commercial construction spending, such as billings by architectural firms for design work, point to further increases in activity in coming months. An upturn in commercial construction could offset part of what is anticipated to be a waning contribution to GDP growth from the housing sector. The performance of commercial real estate loans has generally been very good, due in large part to the low interest rates of recent years and the substantial appreciation of property values that has resulted in sizable equity positions for building owners. Delinquency rates on loans held by commercial banks and life insurance companies remain low by historical standards, and delinquencies on commercial mortgage-backed securities have reversed the modest increase that occurred from 2000 to 2003. The latest information on property prices hints at some moderation in price increases in the first quarter from the rapid price appreciation of last year. But, as in the housing market, commercial real estate prices are continuing to rise in the aggregate. Recent Supervisory Guidance Relating to Real Estate LendingThe Federal Reserve will continue to monitor developments in the residential and commercial real estate markets very closely. In addition to scrutinizing the effect of these developments on the economy, we are also, in our role as bank supervisors, monitoring banks' mortgage lending practices. Last year, the federal bank regulatory agencies issued draft guidance on both residential and commercial mortgage lending. The agencies have received many comments on the proposed guidance, including comments from your association, which we will consider as we discuss what steps to take next. I will address the guidance on residential mortgage lending first. Nontraditional Mortgage ProductsOver the past few years, the agencies have observed an increase in the number of residential mortgage loans that allow borrowers to defer repayment of principal and, sometimes, interest. These loans, often referred to as nontraditional mortgage loans, include interest-only (IO) mortgage loans, for which the borrower pays no loan principal for the first few years of the loan, and payment-option adjustable-rate mortgages (option ARMs), for which the borrower has flexible payment options--and which could result in negative amortization. IOs and option ARMs are estimated to have accounted for almost one-third of all U.S. mortgage originations in 2005, compared with fewer than 10 percent in 2003. Despite their recent growth, however, it is estimated that these products still account for less than 20 percent of aggregate domestic mortgages outstanding of nearly $9 trillion. Although the credit quality of residential mortgages generally remains strong, the Federal Reserve and the other banking supervisors are concerned that banks' current risk-management techniques may not fully address the level of risk inherent in nontraditional mortgages, a risk that would be heightened by a downturn in the housing market. Mortgages with some of the characteristics of nontraditional mortgage products have been available for many years; however, they have historically been offered to higher-income borrowers. More recently, nontraditional mortgages have been offered to a wider spectrum of consumers, including subprime borrowers, who may be less suited for these types of mortgages and may not fully recognize their embedded risks. These borrowers are more likely to experience an unmanageable payment shock during the life of the loan, meaning that they may be more likely to default on the loan. Further, nontraditional mortgage loans are becoming more prevalent in the subprime market at the same time risk tolerances in the capital markets have increased. Banks need to be prepared for the resulting impact on liquidity and pricing if and when risk spreads return to more "normal" levels and competition in the mortgage banking industry intensifies. Supervisors have also observed that lenders are increasingly combining nontraditional mortgage loans with weaker mitigating controls on credit exposures--for example, by accepting less documentation in evaluating an applicant's creditworthiness and not evaluating the borrower's ability to meet increasing monthly payments when amortization begins or when interest rates rise. These "risk layering" practices have become more and more prevalent in mortgage originations. Thus, although some banks may have used some elements of nontraditional mortgage products successfully in the past, the recent easing of traditional underwriting controls and the sale of nontraditional products to subprime borrowers may contribute to losses on these products. Supervisors are concerned that banks may not be fully aware of the potential risks of using risk-layering practices with nontraditional mortgage products. These practices may have become more widespread over the past couple of years as competition for borrowers and declining profit margins may have forced lenders to loosen their credit standards to maintain their loan volume. In the Federal Reserve Board's most recent Senior Loan Officer Survey, conducted this past April, more than 10 percent of the surveyed institutions reported having eased their underwriting standards for residential mortgage loans. Only one of the surveyed lenders reported having tightened standards. Additionally, information from other sources seems to show continued growth in the number of borrowers purchasing real estate with no equity using simultaneous second liens. Naturally, we are watching for any signs that defaults may be on the rise. Some industry evidence indicates that delinquencies may be on the uptick; delinquency rates for loans issued in 2005 are, in most cases, higher than those for comparable loans issued in earlier years. Some industry observers believe that the increase in delinquencies for loans issued in 2005 is directly related to the continued easing of underwriting standards and the increased use of risk-layering practices. The industry trends I have just described, taken together, were the justification for the issuance of draft guidance on nontraditional mortgage products by the Federal Reserve and the other banking agencies. The proposed guidance emphasizes that an institution's risk-management processes should allow it to adequately identify, measure, monitor, and control the risk associated with these products. It reminds lenders of the importance of assessing a borrower's ability to repay the loan, both now and when amortization begins and interest rates rise. Nontraditional mortgage products warrant a bank having strong risk-management standards as well as appropriate capital and loan-loss reserves. Further, bankers should consider the impact of prepayment penalties for ARMs. Lenders should provide enough information so that borrowers clearly understand, before choosing a product or payment option, the terms of and risks associated with these loans, particularly the extent to which monthly payments may rise and negative amortization may increase the amount owed above the amount originally borrowed. Lenders should recognize that certain nontraditional mortgage loans are untested in a stressed environment; for instance, nontraditional mortgage loans to investors that rely on collateral values could be particularly affected by a housing-price decline. As noted, investors have represented an unusually large share of recent home purchases. Past loan performance has indicated that investors are more likely than owner-occupants to default on a loan when housing prices decline. When credit standards are eased and risks are layered, institutions should compensate for the increased risk with mitigating factors that support the underwriting decision. Among other credit enhancements, these factors generally include requiring borrowers to have higher credit scores, lower loan-to-value and debt-to-income ratios, and significant liquidity and net worth. Finally, lenders should establish appropriate allowances for estimated credit losses in their nontraditional mortgage portfolios and hold capital commensurate with the risk characteristics inherent in these products. One final subject that is not addressed explicitly in our draft guidance, but that I believe is still important to supervisors and bankers, is mortgage fraud. There appears to have been a substantial upswing in suspected fraud related to residential mortgages in the past decade. Types of fraud include falsification of loan applications, identity theft, misuse of loan proceeds, and inflated appraisals. According to the Financial Crimes Enforcement Network, there were more than 18,000 reports of suspected mortgage fraud in 2004 (the latest year for which we have complete data), compared with fewer than 2,000 reports in 1997. And in the first six months of 2005 alone, there were more than 11,000 reports of suspected mortgage fraud. The increase may be attributable in part to an increase in the number of originators required to file Suspicious Activity Reports (SARs). Notably, the more widespread use of nontraditional loan products may present greater opportunity for fraud, as these products sometimes lack some of the quality checks typical of more-traditional mortgages. In general, we consider mortgage fraud to be a serious issue and one that bankers and supervisors must continue to confront. Of course, supervisors want to hear the industry's perspective on fraud in mortgage lending. Commercial Real EstateThe U.S. banking agencies recently issued proposed guidance on commercial real estate (CRE) lending. A major portion of that guidance focuses on CRE concentrations. Before I discuss the importance of managing CRE concentrations, I want to emphasize that the proposed CRE guidance relates to "true" CRE loans. It is not directed at commercial loans for which a bank looks to a business's cash flow as the source of repayment and accepts real estate collateral as a secondary source of repayment. The proposed guidance addresses bank loans for commercial real estate projects for which repayment depends on third-party rental income or on the sale, refinancing, or permanent financing of the property. The latter are "true" commercial real estate loans, in that repayment depends on the condition and performance of the real estate market. I also want to mention up front that the proposed guidance is not intended to cap or restrict banks' participation in the CRE sector but rather to remind institutions that proper risk management and appropriate capital are essential elements of a sound CRE lending strategy. In fact, many institutions already have both of these elements in place and may not need to adjust their practices very much. I believe we are all aware of the central role that CRE lending played in the banking problems of the late 1980s and early 1990s. One reason supervisors are proposing CRE guidance at this point is that we are seeing high and rising concentrations of CRE loans relative to capital. For certain groups of banks, such as those with assets of between $100 million and $1 billion, the average CRE concentration level is about 300 percent of total capital. In the late 1980s and early 1990s, the concentration level for this same bank group was about 150 percent, or half the current level. Therefore, banks should not be surprised by the emphasis in the proposed CRE guidance on concentrations and the importance of portfolio risk management. Historically, CRE has been a highly volatile asset class. In the past, problems in CRE, even at well-managed banks, have generally come at times when the broader market was encountering difficulties. In an effort to generate cash flow, borrowers and bankers with properties in distress may disrupt their local real estate market by cutting rents or offering leasehold improvements and other incentives to attract or keep tenants. These actions can have a negative effect on the entire local real estate market, including good projects. In most years, CRE credit losses are relatively low compared with many other types of bank loans. But in times of stress, the loss rate can jump considerably higher. Because CRE losses tend to be greater during times of stress, bankers must focus more intently on their risk appetite as their CRE concentration grows. Bankers must consider how much capital will be placed at risk if the CRE portfolio hits a stress period and compare that loss exposure with the relative returns of CRE lending. In other words, bankers need to practice risk management. While banks' underwriting standards are generally stronger than they were in the 1980s and 1990s, the agencies are proposing the guidance now to reinforce sound portfolio-management principles that a bank should have in place when pursuing a commercial real estate lending strategy. A bank should be monitoring performance both on an individual-loan basis as well as on a collective basis for loans collateralized by similar property types or in the same markets. Some institutions' strategic- and capital-planning processes may not adequately acknowledge the risks from their CRE concentrations. CRE lending in recent years has occurred under fairly benign credit conditions, but those conditions are unlikely to continue indefinitely. The ability of banks with significant concentrations to weather difficult market conditions will depend heavily on their risk-management processes and their level of capitalization. From a risk-management and capital perspective, institutions should generally focus on the emerging conditions in their real estate markets and on the potential cumulative impact on their portfolios if conditions deteriorate; they should also take other measures to help identify CRE vulnerabilities. Of course, these measures should vary according to the size of the organization and the level of the concentration. All of these steps are key elements of a sound strategy to manage concentrations. While supervisors continue to underscore the importance of having robust risk-management practices for CRE and other lending concentrations, we do acknowledge that banks may pursue a variety of approaches. In some cases, such as when there is not enough market data available or the relevant geographic market is small, banks may have to turn to less- quantitative approaches. Nonetheless, those approaches should be robust, well documented, and transparent. This is consistent with the broader theme that risk management should be scaled to the institution. Along those same lines, we are not necessarily expecting smaller banks to be able to conduct regular, extensive, and sophisticated quantitative stress tests around their lending concentrations. However, we do want bankers at smaller organizations to have clear and coherent methods for evaluating the various potential outcomes associated with their CRE concentrations and with all their exposures more broadly. ConclusionIn the past several decades, real estate markets, both residential and commercial, have affected the U.S. economy in both negative and positive ways. Naturally, the Federal Reserve monitors these markets to gauge their impact on broader economic activity. In addition, because banks are substantially involved in both residential and commercial real estate markets, as a supervisor, we must ensure that bank lending in these markets is conducted in a safe and sound manner. One tool we use to help maintain the safety and soundness of banks is supervisory guidance, which can point out areas requiring additional monitoring, suggest ways in which banks can improve risk management, and remind bankers that they should continue to exercise discipline in their lending activities to ensure that they are accounting for all their risks. The recently issued draft guidance on nontraditional mortgage products and on CRE lending, as I have noted, is not an attempt to stifle lending in these sectors, which, if conducted properly, can continue to be profitable businesses for bankers. Indeed, we recognize the important role that banks play in real estate lending. That is why we want to ensure that banks maintain good practices when operating in those markets. As a final point, if both sets of guidance are finalized, we aim to implement them as consistently as possible across institutions. We do understand bankers' concerns about this issue. Of course, it is always a challenge to ensure that there is consistent application of guidance throughout the industry, especially when bank-specific factors--such as portfolio concentrations and individual risk-management practices--might affect the manner in which the guidance needs to be applied to each bank. But if the guidance is indeed finalized, we plan to undertake considerable efforts across our agencies, including extensive communication and coordination, so that banks are not subject to needlessly differing treatment.
Governor Susan Schmidt Bies At the Financial Women’s Association Washington Briefing, Washington, D.C. Thank you for the invitation to speak here today. I am impressed by the range of interesting subjects covered in your program, and I hope that my remarks on enterprise risk management will be informative as well. Today I will look at some recent cases in which we believe bankers and supervisors have learned some key lessons about enterprise risk management, or ERM. These lessons demonstrate how good risk management increases business efficiency and profitability. Naturally, what we've learned from the banking industry can be more broadly applied to other industries and sectors. Indeed, one could argue that ERM can improve management of many different types of entities, including government agencies and nonprofit organizations. But before I start discussing particular examples, I want to take a step back and give you my thoughts on ERM generally. General Thoughts on Enterprise Risk ManagementThe financial services industry continues to evolve to meet the challenges posed by emerging technologies and business processes, new financial instruments, the growing scale and scope of financial institutions, and changing regulatory frameworks. The Federal Reserve, as the supervisor of state member banks and bank and financial holding companies, has been working with other regulators and financial institutions to improve the effectiveness and relevance of regulation and supervision in this changing environment. The Federal Reserve has long emphasized the need for appropriate and strong internal controls in institutions we supervise, and we have taken a continuous-improvement approach to our risk-focused examinations. For many years, enterprise risk management across multiple organizational units within an entity has received increased scrutiny. In some cases, firms may be practicing good risk management on an exposure-by-exposure basis, but they may not be paying close enough attention to aggregation of exposures across the entire organization. Rapid growth can place considerable pressure on, among other areas, an organization's management information systems, change-management controls, strategic planning, credit concentrations, and asset/liability management. An organization must also understand how its various business components, some of which can be quite sophisticated and complex, dynamically interact. A successful ERM process can help an organization to meet many of these challenges. Of course, enterprise risk management is a fairly broad topic that can mean different things to different people. For our purposes here today, I will define ERM as a process that enables management to effectively deal with uncertainty and associated risk and opportunity, enhancing the capacity to build stakeholder value. Borrowing from ERM literature, I would say that ERM includes Some of you are probably familiar with the ERM framework published over a year ago by the Committee of Sponsoring Organizations of the Treadway Commission, or COSO. The COSO framework provides a useful way to look at ERM and helps generate further discussion. In the COSO framework, ERM consists of eight interrelated components derived from the way management runs an enterprise and integrated with the management process: (1) internal environment, (2) objective setting, (3) event identification, (4) risk assessment, (5) risk response, (6) control activities, (7) information and communication, and (8) monitoring. Each of these is described in more detail in the COSO literature. Notably, the COSO framework states explicitly that, while its components will not function identically within every entity, its principles should apply to all sizes of institutions. Small and mid-size entities, for example, may choose to apply the framework in a less formal and less structured way and scale it to their own needs--as long as quality is maintained. This underscores the message from bank supervisors that good risk management is expected of every institution, regardless of size or sophistication. Naturally, there will still be some tension between what supervisors expect and what bankers do, but we hope that supervisory expectations for risk management are becoming more and more aligned with the way that bankers run their businesses. I would now like to discuss a few recent examples from banking that highlight the importance of ERM. With the benefit of hindsight, the financial regulators and the industry have been trying to distill the lessons learned from these recent breakdowns in risk management and internal control in the financial services sector. Compliance RiskOne area in which ERM provides tangible value is the area of compliance risk, which can be defined as the risk of legal or regulatory sanctions, financial loss, or damage to an organization's reputation and franchise value. This type of risk may arise when an organization fails to comply with the laws, regulations, or codes of conduct that are applicable to its business activities and functions. The Federal Reserve expects banking organizations to have in place an infrastructure that can identify, monitor, and effectively control the compliance risks that they face. Needless to say, the infrastructure should be commensurate with the nature of the organization's compliance risk. For a large complex banking organization, dealing with compliance risk can be particularly challenging unless it has a well-developed risk-management program. To create appropriate compliance-risk controls, organizations should first understand compliance risk across the entire entity. Understandably, this can be a daunting task, but I think most would agree that an effective risk assessment is critical. Managers should be expected to evaluate the risks and controls within their scope of authority at least annually. An enterprise-wide compliance-risk management program should be dynamic and proactive. It should constantly assess evolving risks when new business lines or activities are added, when existing activities and processes are altered or when there are regulatory changes. The process should include an assessment of how those changes may affect the level and nature of risk exposures, and whether mitigating controls are effective in limiting exposures to targeted levels. To avoid having a program that operates on autopilot, an organization must continuously reassess its risks and controls and communicate with all employees who are part of the compliance process. If compliance is seen as a one-off project, an organization risks facing a situation down the road where its compliance program has not kept up with the changes in its organization. Also, the board of directors needs to ensure the organization has a top-to-bottom compliance culture that is well communicated by senior management so that all staff members understand their compliance responsibilities. Clear lines of communication and authority help to avoid conflicts of interest. Compliance-risk management can be more difficult for management to integrate into an organization's regular business processes because it often reflects mandates set out by legislation or regulation that the organization itself does not view as key to its success. For example, bankers understand how vital credit-risk management and interest-rate risk management are to their organizations, because they reduce the volatility of earnings and limit losses. However, regulations enacted for broader societal purposes can be viewed as an expensive mandate. For example, the Patriot Act requires significant reporting of transactions to the government, and many in industry have expressed frustration about the burden associated with such reporting. I can assure you, we recognize banking organizations' investment in and commitment to compliance with regulatory requirements, including those imposed by anti-money-laundering and counter-terrorism regulations. The Federal Reserve will continue to work with our counterparts in the federal government to encourage enhanced feedback on how reporting is contributing to our common fight against money laundering and terrorism. Operational RiskOver the past few years, the Federal Reserve has been increasing its focus on operational risk. For many nonfinancial organizations, the largest share of enterprise risk is likely to be operational risk, as opposed to credit and interest-rate risk. Banks have learned much from the practices that nonfinancial firms have developed over the years. Operational risk has more relevance today for bankers largely because they are able to shed much of their interest-rate and credit risk through sales of loans, use of financial derivatives and sound models to manage the risks that are retained. Further, the revenue streams that are growing the fastest are increasingly related to transaction processing, servicing accounts, and selling sophisticated financial products. To be successful, organizations must have complex systems to execute these activities. Banks are also utilizing advanced models to estimate and manage credit-risk and market-risk exposures. Growing use of sophisticated models requires stronger risk-management practices since weaknesses in the models' operational design and data integrity can lead to significant losses. Thus, effective risk management requires financial institutions to have more-knowledgeable employees to identify system requirements, monitor their effectiveness, and interpret model results appropriately. We have learned quite a bit about operational risk from our examinations of banking organizations. For example, during routine examinations we look at the adequacy of banks' procedures, processes, and internal controls. Such reviews include transaction testing of control routines in higher-risk activities. For example, a bank's wire transfer activities and loan administration functions are often targeted for review, and our experiences have identified some common weaknesses in operational control that are worthy of attention. With wire transfers and similar transactions, a banking organization could suffer a significant financial loss from unauthorized transfers and incur considerable damage to its reputation if operational risks are not properly mitigated. A few recurring recommendations from our reviews are to (1) establish reasonable approval and authorization requirements for wire transactions to ensure that an appropriate level of management is aware of the transaction and to establish better accountability; (2) establish call-back procedures, passwords, funds transfer agreements, and other authentication controls related to customers' wire transfer requests; and (3) pay increased attention to authentication controls, since this area may also be particularly susceptible to external fraud. Loan administration is another area where banking organizations could suffer significant financial losses from inappropriate segregation of duties or lack of dual controls. An institution could also incur considerable damage to its reputation if operational risk factors are not properly mitigated. A few recurring recommendations from these types of reviews that may be applied to corporations more generally are to (1) ensure that loan officers do not have the ability to book and maintain their own loans; (2) confine employee access to only those loan system computer applications that are consistent with their responsibilities; and (3) provide line staff with consistent guidance, in the form of policies and procedures, on how to identify and handle unusual transactions. Operational Risk Arising In Recent Financial RestatementsRisks can sometimes quickly appear where they were not traditionally expected. For example, consider the changes we have seen in financial reporting quality of corporations in all industries. In 2005, there were approximately 1,200 restatements of previously filed financial statements by publicly traded companies--twice the rate for 2004. The complexity of generally accepted accounting principles and a more stringent, literal interpretation of the application of those standards by auditors and regulatory bodies, primarily the Securities and Exchange Commission, are two major factors that have led to the restatements. Examples of prominent restatements include FAS 133 hedge accounting and lease accounting issues. In the area of hedge accounting, the restatements generally resulted from the misapplication of the "short-cut" method. The organizations in question did not satisfy all of the criteria for use of the short-cut method but, nonetheless, utilized hedge accounting treatment allowed by this method. In the area of lease accounting issues, most companies simply failed to apply longstanding accounting standards related to revenue recognition reserves, accruals and contingencies, and equity accounting. Most companies believed they were actually reporting correctly prior to the restatements. Virtually all of these companies were audited by auditing firms that are now registered with the Public Company Accounting Oversight Board (PCAOB). The PCAOB's inspection process, which involves close scrutiny of registered firms, may be a factor in the increased number of restatements. Section 404 of the Sarbanes-Oxley Act of 2002 requires each annual report of a public company to include a report by management on the company's internal control over financial reporting. Restatements by banking organizations alone resulted in the revision of a number of material weaknesses in internal control for the 2004 reporting period, fifty-two from the thirty-seven originally reported. This increase implies a significant amount of operational risk associated with the accounting process. Generally, examiners review the Sarbanes-Oxley 404 process to determine whether the organization has a clear understanding of the roles of the audit committee, management, internal audit, and the external auditor and whether the organization has implemented an effective plan to achieve the objectives and requirements of Sarbanes-Oxley 404. Examiners also review the Sarbanes-Oxley 404 process to determine whether the organization has an effective follow-up strategy for the remediation of significant deficiencies and material weaknesses. Examiners are encouraged to utilize the results of the Sarbanes-Oxley 404 process, where possible, in their overall assessment of the organization's risk-management and control process and in the risk scoping of safety-and-soundness examinations and inspections. Information SecurityIssues involving information security and identity theft have received quite a bit of attention from the federal government over the past several years. In fact, just recently, President Bush signed an executive order that created an Identity Theft Task Force for the purpose of strengthening federal efforts to protect against identity theft. The heads of the federal bank regulatory agencies are designated members of this task force; and as supervisors of financial institutions, I believe we can offer a unique perspective on this issue. As you have probably noticed, cyber attacks and security breaches involving nonpublic customer information appear in the headlines almost every week. These events have cost the financial services industry millions of dollars in direct losses and have done considerable reputational damage. The cost of identity theft to affected consumers is also significant. With banking organizations increasingly using the Internet to interact with customers, business partners, and service providers, concerns about the use of the Internet as a communication and delivery channel have resulted in the need for and use of more-sophisticated control mechanisms, such as enterprise-wide firewall protections, multifactor authentication schemes, and virtual private-network connections. While many of the widely publicized information security breaches have involved parties outside the affected banking organization accessing the organization's customer information, organizations also remain at risk for breaches or misuses of information by an insider. During our examination activities, we have seen breakdowns in internal control, resulting in operating losses that were traced back to weak controls over insiders' access to information technology systems interfacing with electronic funds transfer networks. Further investigation into these situations suggests that the duration and magnitude of the fraud and resulting losses is a direct function of the internal party's access to accounting and related systems. Several lessons have emerged. First, institutions should tightly control logical access to funds transfer systems and ensure that access settings enforce separation of duties, dual controls, and management sign-offs. Second, an institution's senior management should be restricted from regular access to business-line functional systems, especially funds transfer systems. When such restriction is impractical, additional controls must be in place and functioning effectively. Finally, effective management of information security risk, even when focused on a specific function, requires an enterprise-wide approach to yield a true and complete evaluation of the associated risks. Mutual FundsWell-publicized instances of late trading and market timing at mutual fund firms, and the related investigations, have involved many businesses, including banking, securities, and insurance firms. These types of breakdowns in internal control result in sanctions or financial loss and adversely affect a firm's reputation and franchise value. I would like to highlight a few lessons learned from our experience in investigating control breaches in these mutual fund cases. One of the most obvious is the need to critically evaluate unusual client relationships that require variances from standard procedures. If a high percentage of compensation is derived from a single client, a red flag should immediately go up. Also, organizations should have a formal process for reviewing and approving unique products, customers, and services at the inception of the client relationship. Furthermore, it is always a good idea to shine some light on areas historically labeled "low risk" to validate that assessment. The low occurrence of loss from an activity should not be the only factor considered when assessing risk. Finally, compensation systems that reward employees for sales without adequately monitoring their internal control breaches can create a conflict between the interest of employees and the interest of the enterprise. As companies move away from straight salaries to more incentive-based systems, it is important that personnel departments be included in an effective enterprise-wide risk-management program to consider how changes in compensation practices affect risks to the enterprise. Credit DerivativesI would now like to turn to one more issue that has relevance to ERM, and that is the importance of companies including an ERM perspective as they design and build new lines of business. As many of you might know, last year a dialogue between supervisors and credit derivatives dealers was initiated to support industry efforts to address weaknesses in the operations surrounding credit default swaps (CDS). While we view these new instruments as an effective way to diversify and mitigate risks related to credit exposures from corporations, an industry-led study, the Counterparty Risk Management Policy Group II report, identified significant weaknesses in the infrastructure supporting sales and risk monitoring of these instruments. While the report identified forty-seven recommendations, regulators in the United States and other countries have focused on two major weaknesses. One weakness relates to the lack of discipline in enforcing contract terms. Any time an instrument is traded over the counter, it is important to know with whom you are doing business. Since an exchange does not stand between the two sides of the trade, parties make payments directly to each other to honor the terms of the contracts. The market practice is to use collateral or pricing to mitigate the risk that the other side of the trade cannot perform according to the agreement. The recent industry study also found that competitive pressures were such that brokers were not enforcing the standard CDS agreement, because their counterparties were routinely assigning the trade to another party without the broker's prior consent. As a result, dealers often did not have a real-time understanding of the counterparty exposure. Obviously, this can significantly change the risk profile of a transaction and also make it very difficult to settle payments in a timely manner. Another weakness is related to the success of the product. Trading volume has grown so quickly and reached such a significant level that broker-dealers' paper-based systems to record the trades and document the transactions have not been able to keep up. As a result, significant backlogs of confirmations of these over-the-counter derivatives built up. This creates concerns that information feeding risk-management systems--information about the volume, term, and counterparty to the trade--is not complete. This problem would be exacerbated in a stress situation, when positions need to be changed very quickly to mitigate risk. A few months ago, fourteen major market participants published a letter reiterating their commitment to improving the infrastructure that supports the credit derivatives markets. The market participants are committed to the development and implementation of a set of industrywide guidelines that include a targeted reduction in each market participant's confirmation backlogs and assurance that agreement terms will be enforced. Additionally, the fourteen participants will work to create a largely electronic marketplace in which all trades will be processed through an industry-accepted platform, develop a new set of processing standards for those trades that cannot be confirmed electronically, and establish a new procedure for settlement following a credit event. We are generally pleased with both the industry's self-identification of the issues and its commitment to making improvements. But for purposes of our discussion of ERM today, the problems surrounding CDS sales highlight the challenges risk managers face when market pressures make the firm's line management reluctant to initiate appropriate controls on their own. It also illustrates that in new lines of business, sometimes ERM must go outside the enterprise and work with competitors to support the growth of shared systems and standards to mitigate risks. ConclusionAt the Federal Reserve, we believe that all banking organizations need good risk management. An enterprise-wide approach is appropriate for setting objectives across the organization, instilling an enterprise-wide culture, and ensuring that key activities and risks are being monitored regularly. In many ways, bankers have learned from nonfinancial industries about ERM. In other cases, banks' application of ERM may hold lessons for entities outside the financial sector. Whichever the case, it is clear that there is always an opportunity to improve upon ERM strategies and maintain the proper discipline to implement them effectively.
The federal bank and thrift regulatory agencies today announced the availability of the 2006 list of distressed or underserved nonmetropolitan middle-income geographies in which bank revitalization or stabilization activities will receive Community Reinvestment Act (CRA) consideration as "community development." The 2006 list is the first to incorporate a one-year lag period for geographies that were designated as distressed or underserved in 2005, but were not designated as such in the 2006 release. Geographies subject to the one-year lag period are eligible to receive consideration for community development activities for the twelve months following publication of the 2006 list. In addition, the 2005 list of distressed or underserved nonmetropolitan middle-income geographies was revised after discrepancies were identified in calculations that were used to qualify geographies as "distressed" or "underserved." Although the discrepancies were minor, the revised list includes several additional geographies that were not previously included, thus expanding the list of geographies eligible for CRA consideration. "Distressed nonmetropolitan middle-income geographies" and "underserved nonmetropolitan middle-income geographies" are defined in CRA regulations. The criteria used to designate these areas are available on the Federal Financial Institutions Examination Council (FFIEC) web site (www.FFIEC.gov/cra). Both the 2006 list and the revised 2005 list can also be found on the FFIEC web site, along with the data source information used to generate the list of distressed or underserved geographies.
The Federal Reserve Board on Thursday announced its approval of the notice under section 4 of the Bank Holding Company Act by Banco Latinoamericano de Exportaciones S.A., Panama City, Republic of Panama, to act as a certification authority in connection with financial and nonfinancial transactions and engage in other related activities. Attached is the Board's Order relating to this action.
The Federal Reserve Board on Monday announced its approval of the proposal by BB&T Corporation, Winston Salem, North Carolina, to acquire First Citizens Bancorp, Cleveland, and its subsidiaries: The Bank/First Citizens Bank, Cleveland; The Home Bank of Tennessee, Maryville; and The Home Bank, Ducktown, all of Tennessee. Attached is the Board's Order relating to this action.
The Federal Reserve Board on Thursday approved action by the Board of Directors of the Federal Reserve Bank of San Francisco, increasing the discount rate at the Bank from 6 percent to 6-1/4 percent, effective immediately.
The Board of Governors of the Federal Reserve System, the Federal Deposit Insurance Corporation, and the Office of the Comptroller of the Currency today issued the host state loan-to-deposit ratios that the banking agencies will use to determine compliance with section 109 of the Riegle-Neal Interstate Banking and Branching Efficiency Act of 1994. These ratios update data released on July 7, 2005. In general, section 109 prohibits a bank from establishing or acquiring a branch or branches outside of its home state primarily for the purpose of deposit production. Section 109 also prohibits branches of banks controlled by out-of-state bank holding companies from operating primarily for the purpose of deposit production. Section 109 provides a process to test compliance with the statutory requirements. The first step in the process involves a loan-to-deposit ratio screen that compares a bank's statewide loan-to-deposit ratio to the host state loan-to-deposit ratio for banks in a particular state. A second step is conducted if a bank's statewide loan-to-deposit ratio is less than one-half of the published ratio for that state or if data are not available at the bank to conduct the first step. The second step requires the appropriate banking agency to determine whether the bank is reasonably helping to meet the credit needs of the communities served by the bank's interstate branches. A bank that fails both steps is in violation of section 109 and is subject to sanctions by the appropriate banking agency. The updated host state loan-to-deposit ratios are attached. Attachment (39 KB PDF)
The Federal Reserve Board announced Thursday that it is seeking nominations for appointments to its Consumer Advisory Council. The Council advises the Board on the exercise of its responsibilities under various consumer financial services laws and on other matters. The group meets in Washington, D.C., three times a year. Ten new members will be appointed to serve three-year terms beginning in January 2007. Nominations should include a résumé and the following information about nominees: Nominations should also include the complete name, organization name, title, address, telephone, e-mail address, and fax number for the nominator. Letters of nomination with complete information, including a résumé for each nominee, must be received by August 25, 2006. Nominations not received by August 25 may not be considered.Electronic nominations are preferred. The appropriate form can be accessed at:http://www.federalreserve.gov/forms/cacnominationform.cfm. If electronic submission is not feasible, the nominations can be mailed (not sent by facsimile) to Sheila Maith, Assistant Director and Community Affairs Officer, Division of Consumer and Community Affairs, Board of Governors of the Federal Reserve System, Washington, DC 20551. The Board's notice is attached.
The Federal Reserve Board announced Tuesday that the Consumer Advisory Council will hold its next meeting on Thursday, June 22. The meeting will take place in Dining Room E, Terrace level, in the Board's Martin Building. The session will begin at 9:00 a.m. EDT and is open to the public. Anyone planning to attend the meeting should, for security purposes, register no later than Tuesday, June 20, by completing the form found on-line at:https://www.federalreserve.gov/secure/forms/cacregistration.cfmAdditionally, attendees must present photo identification to enter the building. The Council's function is to advise the Board on the exercise of its responsibilities under various consumer financial services laws and on other matters. Time permitting, the Council will discuss the following topics: Reports by committees and other matters initiated by the Council members may also be discussed. The Board invites comments from the public on any of these matters. The Board's notice is attached.
Governor Susan Schmidt Bies At the Western Independent Bankers Annual CFO & Risk Management Conference, Coronado, California I am pleased to be here today and thank you very much for the invitation. The focus of this conference is risk management, which I think is an excellent discussion topic for bankers, regardless of their institution’s size. In fact, I am quite pleased to see more and more conferences devoted exclusively to risk management, analyzing its different facets and exploring ways to tailor it to specific institutions and situations. There is growing understanding that good risk management can be an integral part of running any type of business. Risk Management in Financial ServicesWith respect to financial services, the Federal Reserve Board, as the primary supervisor of state member banks and the consolidated supervisor of financial holding companies, has been working with other regulators and financial institutions to improve the effectiveness of banks’ risk management in order to keep pace with changing business practices and strategies. The Federal Reserve has long emphasized the need for appropriate and strong internal controls in the institutions we supervise, and we have taken a continuous-improvement approach to our risk-focused examinations. For many years, enterprise risk management across an entire entity has received increased scrutiny. Of course, bankers are the ones who have led the way in continuing to improve the risk-management and risk-measurement processes at their institutions. To be more effective competitors and to control and manage their losses, banks have created many new techniques to improve their risk management and internal economic capital measures. By more clearly defining risk exposures, identifying the causes of their losses, and establishing controls to limit future losses, bank managers have been better able to integrate decisions about risk-taking into their strategic and tactical decision making. Banks that integrate risk measurement into their business-line goals often find that this helps them to implement their strategic plans more effectively. That is because strategic planning tends to focus more on alternative “most likely” scenarios. By including a risk management analysis in the strategy discussion, bankers can more clearly identify the inherent operational and environmental factors that can significantly affect the realization of strategic goals. Thus, banks can design in, at the start, the appropriate internal controls and management information systems to improve the execution of the strategy. In some cases, firms may be practicing good risk management on an exposure-by-exposure basis, but they may not be paying close enough attention to the aggregation of their exposures or concentrations that arise in the resulting portfolios of business. Also, rapid growth can place considerable pressure on an organization's management information systems, change-management controls, strategic planning, credit concentrations, and asset/liability management, among other areas. Many of the companies that have attracted public attention in recent years due to serious breaks in controls failed to focus on process changes and critical investments in their risk management and control systems that were needed to successfully support their business plans. An organization must also understand how its various business components dynamically interact. A successful enterprise-wide risk management process can help to meet many of these challenges. At the same time, it is clear that risk management practices need to be applied in a manner appropriate to the size and complexity of the organization. While the leading-edge risk-management practices used at the largest, most complex banks may have some applicability at smaller, less complex banks, data and cost limitations require greater use of more generalized models and the use of outsourcing to supplement the knowledge base of the institution. And as most of you know, running a smaller or less complex bank presents different types of challenges and requires a risk-management framework appropriately tailored to the institution. For example, transactions may be conducted more on a relationship basis and may be less data-intensive. In such a case, bank management needs to develop risk-management tools that allow it to ensure that risks are still being appropriately addressed. Further, smaller organizations often face a challenge of ensuring independent review of processes and decisions since officers and staff often have multiple responsibilities that can present conflicts of interest. Many of you are probably familiar with the enterprise risk management framework published over a year ago by the Committee of Sponsoring Organizations of the Treadway Commission, or COSO. The COSO framework provides a useful way to look at enterprise risk management. Notably, the COSO framework states explicitly that, while its components will not function identically in every entity, its principles should apply to institutions of all sizes. Small and mid-size entities, for example, may choose to apply the framework on a less-formal and less-structured basis and scale it to their own needs--as long as quality is maintained. This underscores the message from bank supervisors that good risk management is expected of every institution, regardless of size or sophistication. Naturally, some tension will still exist between what supervisors expect and how bankers want to run their business. But we hope that supervisory expectations for risk management are becoming more and more aligned with the way that bankers run their businesses. I would now like to turn to two examples highlighting the importance of risk management for smaller banks: credit concentrations and business disruptions. Lending ConcentrationsAs any banker worth his or her salt knows, lending concentrations must be carefully identified, monitored, and managed. It is one of the basics of banking to understand the consequences of placing all your eggs in one basket. Naturally, supervisors from time to time have concerns about growing credit risk concentrations at banks and bankers’ ability to manage them. A current example is commercial real estate (CRE). The U.S. banking agencies recently issued proposed guidance on CRE lending, and a major portion of that guidance is directed at CRE concentrations. The agencies have received many comment letters on the proposed guidance. These comments will be very helpful as we discuss what steps to take next. Before I discuss the importance of managing CRE concentrations, I want to emphasize that the proposed CRE guidance is intended to encompass “true” CRE loans. It is not focused on commercial loans for which a bank looks to a business’s cash flow as the source of repayment and accepts real estate collateral as a secondary source of repayment. That is, the proposed guidance addresses bank loans for commercial real estate projects in which repayment is dependent on third-party rental income or on the sale, refinancing, or permanent financing of the property. These are “true” commercial real estate loans in that repayment depends on the condition and performance of the real estate market. I also want to mention up front that the proposed guidance is not intended to cap or restrict banks’ participation in the CRE sector but rather to remind institutions that proper risk management and appropriate capital are essential elements of a sound CRE lending strategy. In fact, many institutions already have both of these elements in place and may not need to adjust their practices very much. I believe we are all aware of the central role that CRE lending played in the banking problems of the late 1980s and early 1990s. One reason supervisors are proposing CRE guidance at this point is that we are seeing high and rising concentrations of CRE loans relative to capital. For certain groups of banks, such as those with assets of between $100 million and $1 billion, average CRE concentrations are about 300 percent of total capital. In the late 1980s and early 1990s, the concentration level for this same bank group was about 150 percent, or half the current level. Therefore, banks should not be surprised by the emphasis in the proposed CRE guidance on concentrations and the importance of portfolio risk management. Historically, CRE has been a highly volatile asset class. In the past, problems in CRE even at well managed banks have generally come at times when the broader market encounters difficulties. Borrowers and bankers with properties in distress can disrupt their local real estate market by cutting rents or offering leasehold improvements and other incentives to attract or keep tenants in an effort to generate cash flow. This can negatively affect the local real estate market as a whole, and adversely affect even good projects. CRE is a highly volatile asset class in that credit losses in most years are relatively low compared with many other types of bank loans. But in times of stress, the loss rate on CRE can jump considerably higher relative to the good years, compared with the behavior of other types of loans. Since CRE losses tend to be concentrated in these times of stress, bankers must focus more intently on their risk appetite for losses as their concentration grows. This means considering how much capital can be placed at risk if the portfolio of CRE loans hits a stress period and comparing that loss exposure to the relative returns in CRE lending, i.e., practicing risk management. While banks’ underwriting standards are generally stronger than they were in the 1980s and 1990s, the agencies are proposing the guidance now to reinforce sound portfolio-management principles that a bank should have in place when pursuing a commercial real estate lending strategy. A bank should be monitoring performance both on an individual-loan basis as well as on a collective basis for loans collateralized by similar property types or in the same markets. Some institutions’ strategic- and capital-planning processes may not adequately acknowledge the risks from their CRE concentrations. CRE lending in recent years has occurred under fairly benign credit conditions and, naturally, those conditions are unlikely to continue indefinitely. The ability of banks with significant concentrations to weather difficult market conditions will depend heavily on their risk-management processes and their level of capitalization. From a risk-management and capital perspective, institutions should generally focus on the emerging conditions in their real estate markets and on the potential cumulative impact on their portfolios if conditions deteriorate, and they should take other measures to help identify CRE vulnerabilities. Of course, these measures should vary according to the size of the organization and the level of the concentration. All of these steps are key elements of a sound strategy to manage concentrations. In evaluating the impact of their CRE concentrations, bankers should also pay attention to geographic factors. Many banks conduct successful CRE lending within a certain geographic area, but problems can arise when banks begin to lend outside their market or “footprint,” where they normally have better market intelligence. In recent years, supervisors have observed banks lending outside their established footprint--to maintain a customer relationship--into real estate markets with which they have less experience. The challenge is heightened when theborroweris also venturing into a new market. These practices led to significant losses in prior CRE credit downturns. I noted that CRE underwriting appears substantially better compared with the late 1980s and early 1990s. However, we have noticed some slippage recently. Therefore, the proposed CRE guidance underscores the existing interagency guidance on real estate lending standards. That is, it offers some reminders about risk-management practices for individual exposures. For example, banks may occasionally be inclined to make some compromises and concessions to borrowers in order to attract new business and sustain loan volume. As supervisors, we want to ensure that loan-to-value standards and debt-service-coverage ratios are meeting the organization’s policies--and that there is not an undue increase in the exceptions to those standards and ratios. We also continue to monitor whether lenders routinely adjust covenants, lengthen maturities, or reduce collateral requirements. To be clear, we have not yet seen underwriting standards fall to unsatisfactory levels on a broad scale, but we are concerned about some of the downward trend in these standards. It is important to note that no element of the proposed guidance is intended to act as a “trigger” or “hard limit” for immediate cutback or reversal of CRE lending; rather, the guidance is a reminder to institutions that certain risk-management standards are vitally important for banks involved in the business. Additionally, the agencies intend to use the proposed thresholds in the guidance only as a “first cut” or “screen” to identify institutions that may have heightened CRE concentration risk. The thresholds are intended to serve as benchmarks to identify banks where further information on portfolio risk management is needed. In some cases, after more careful review, supervisors may actually find that given the characteristics of its CRE portfolio an institution has sound risk management and is holding appropriate capital. In general, the proposed guidance is intended to be applied quite flexibly and in a manner consistent with the size and complexity of each organization. While supervisors continue to underscore the importance of having robust risk-management practices for CRE and other lending concentrations, we do acknowledge that banks may pursue a variety of approaches. In some cases, such as when there is not enough market data available or the relevant geographic market is small, banks may have to turn to less quantitative approaches. Nonetheless, those approaches should be robust, well documented, and transparent. This is consistent with the broader theme that risk management should be scaled to the institution. Along those same lines, we are not necessarily expecting smaller banks to be able to conduct regular, extensive and sophisticated quantitative stress tests around their lending concentrations. However, we do want bankers at smaller organizations to have clear and coherent methods for evaluating the various potential outcomes associated with such concentrations, and their exposures more broadly. Managing Business DisruptionsA number of events in the past half decade, including terrorist attacks and natural disasters, have reminded us of the importance of planning and preparation. Most recently, Hurricane Katrina underscored the critical role of business-continuity planning and disaster response for small businesses and small banks in local communities. Most financial institutions in the affected areas responded admirably to the extreme challenges posed by the hurricane and subsequent flooding, and the benefits of planning and preparation showed. I am sure that many of you in the audience today have studied the lessons from Katrina and improved your own plans for dealing with business disruptions. But I want to offer a supervisory perspective on potential lessons for bankers. Banks, like businesses everywhere, can be subject to wide-scale disruptions resulting from both natural and man-made disasters. Potential problems include destruction of facilities, missing personnel, power and communications outages, lack of transportation and fuel, interruption of mail and other delivery services, and health and safety crises. In short, services and activities normally taken for granted can be suddenly disrupted--and in some cases for an extended time. In 2003, U.S. supervisors issued revised guidance on business continuity planning that explicitly advises banks to factor the risk of a wide-scale disruption into their business continuity and disaster response plans. The experiences of bankers during and after Katrina confirmed the essential elements of good business-continuity management laid out in the guidance. As the first step in preparing for business disruptions, large or small, the guidance advises bankers to conduct a full evaluation of what it takes to run their business effectively and provide necessary services to their customers. This evaluation should include a variety of scenarios and possible events that could cause a business disruption. Bankers should then analyze the business impact of these possible disruptions, which could include a prolonged recovery period, and fashion appropriate responses. Once the business-continuity plan is developed, it should be implemented and tested regularly. It should also be updated whenever the bank expands or changes its business activities and when it gathers new information from tests or real-life events. When developing business-continuity plans, bankers need to understand that people are the most vital resource. Bankers should plan for ways to track and communicate with personnel through a range of channels, including ways to reach personnel if phone and electrical services are down, as they were after Katrina. For banks operating in smaller geographic markets, it may be worthwhile to establish communication contacts outside of the region to be used by both employees and customers. Depending on the cause of the disruption, bankers should also expect that some of their personnel may be dealing with family emergencies that will limit their ability to work. Therefore, it is especially important to identify and train backup personnel to handle critical operations and services. Business-impact analysis and planning requires that bankers understand not only their business lines but also the systems and processes that support those business lines. The bank’s planning should address how these support systems and processes could be recovered if they are disrupted, including the effect such a disruption would have on the bank’s facilities, equipment, and other physical property. The bank may have to operate from backup or some type of recovery facilities for an extended period in order to provide critical services to customers. Employees may also need to be prepared to perform services manually if computer systems become unavailable. Hurricane Katrina also reminds us that unlike a fire, which may interrupt only the bank’s own activities as the community continues business as usual, a more widespread event causes banks to serve as agents of recovery for both their immediate and larger communities. I am sure that all of you understand, first, the importance of providing financial services in any community and, second, that you have a responsibility to provide those services to your customers and neighbors during a crisis. Accordingly, you should try to understand and coordinate your plans with the disaster-response programs for your neighborhood, city, and state. In fact, bankers’ knowledge of their critical systems needs can very often assist local government and utility company managers in better evaluating the impact of their preparedness on local customers. By the same token, you can improve your institution’s ability to respond by understanding the strengths and limitations of infrastructure around your bank, and the manner in which the community’s disaster-response efforts may unfold. Naturally, we cannot expect bankers to prepare for every conceivable event or plan for them with equal intensity. As with any aspect of risk management, bankers should assess the probability of an event and its potential consequences. We certainly understand that planning, preparation, and testing consume time, energy, and money. Accordingly, institutions should determine the most cost-effective way to mitigate risks and continue to assess which possible events deserve greater attention and preparation. ConclusionOur ongoing supervision of banking organizations indicates that a preponderance of institutions continue to be sound and well managed. This strong performance has occurred concurrently with institutions’ continued efforts to improve their risk-identification and management strategies. That said, certain areas in banking operations, such as credit concentrations and business continuity planning, are placing pressures on risk-management systems. In turn, supervisors are increasingly scrutinizing these and other relevant areas to ensure that management is fully aware of their risks and has made any necessary risk-management upgrades. Of course, bankers may be somewhat concerned about the impact that supervisory initiatives--even proposed guidance--could have on their business. We hear your concerns about regulatory burden, but I think it is helpful to remember that our job as regulators is to ensure that the United States has a safe and sound banking system. In other words, supervisors are in the business of monitoring “downside risk” to the financial system, so we must act appropriately when we see possibly excessive risk taking or inappropriate risk management. We also have a role in helping banks to prepare for potentially disruptive events. While most U.S. banking organizations today operate in a safe and sound manner and enjoy substantial profitability, they need to remember that continued business success depends on their ability to prepare for unexpected, and potentially much less favorable, events and outcomes. As institutions continue to offer new products and services, they face the challenge of incorporating the associated risks into their existing risk-management framework. This is true for institutions of all sizes. But the manner in which risk-management challenges are addressed can--and should--vary across institutions, based on their size, complexity, and individual risk profile. Additionally, as supervisors, we want to ensure that institutions are not only identifying, measuring, and managing their risks but also developing and maintaining appropriate corporate-governance structures to keep up with their business activities and risk taking. Our hope is that the guidance we offer to bankers on these various topics is becoming more consistent with their own practices for running an effective and profitable business.
The Board of Directors of the Federal Reserve Bank of Philadelphia today announced that Charles I. Plosser, a professor of economics and former dean at the William E. Simon Graduate School of Business Administration at the University of Rochester, has been named president of the Philadelphia Bank. The appointment was jointly approved by the Board of Governors of the Federal Reserve System and the Philadelphia Bank Board. Dr. Plosser will assume his new position August 1, 2006, and replaces Dr. Anthony M. Santomero, who resigned March 31, 2006. "Professor Plosser is extremely well qualified to be president as he brings both deep economic and management credentials to the position," said Philadelphia Federal Reserve Board Chairman Doris M. Damm. "An economist of international distinction, he will bring intellectual depth and fresh ideas to the Fed at a time when we must evolve and adapt to a changing economic and financial landscape." Dr. Plosser, 57, is the John M. Olin Distinguished Professor of Economics and also serves as director of the Bradley Policy Research Center at the Simon School, where he served as dean from 1993-2003. During his tenure as dean, he strengthened the school's financial position, recruited new talent, created new programs, and expanded the school's facilities. Dr. Plosser has been a member of the Simon School faculty since 1978, and his teaching interests have included macroeconomics, economic growth, econometrics, finance, and money and banking. A member of the Shadow Open Market Committee since 1991, he currently serves as co-chair of the nationally recognized group of economists that monitors and comments on U.S. economic policy. The author of numerous academic articles, Dr. Plosser has lectured to academic and business audiences worldwide and has worked as a consultant with many corporations in planning and forecasting. When asked about his new position, Dr. Plosser replied, "I am delighted and honored to have been chosen to lead the Philadelphia Federal Reserve Bank. President Santomero has provided exceptional leadership during his tenure, and I look forward to building on his accomplishments. The Bank has an outstanding group of employees that has contributed to its success and reputation. Bank presidents play an important role in monetary policy deliberations at the System level, but they also play a critical role in their District. I am eager to develop the relationships with banking, business, and community leaders in the Third District that are an important and essential part of the institution's mission." Dr. Plosser is editor of theJournal of Monetary Economicsand theCarnegie-Rochester Conference Series on Public Policy. He has served as an advisory board member of the Rochester New Enterprise Forum, as chairman of The Consortium for Graduate Study in Management and the Graduate Management Admission Council, and served on the board of directors of ViaHealth, Inc., and RGS Energy Group. Currently, he also serves on the advisory board of the University Technology Seed Fund, LLC. While on sabbatical during 2003-04, Dr. Plosser was a visiting scholar at the Federal Reserve Bank of Minneapolis and an advisor on monetary policy and research at the Bank of England. In commenting on Dr. Plosser's appointment, First Vice President of the Federal Reserve Bank of Philadelphia William H. Stone, Jr. said, "Dr. Plosser has a long and distinguished career analyzing monetary policy and macroeconomic issues and will bring similar insightful thinking to issues the Fed faces in payments and the banking system. We look forward to working with him." Dr. Plosser earned his doctoral degree in economics and his master's degree in business administration from the University of Chicago. He received his bachelor's degree in engineering from Vanderbilt University. The Federal Reserve Bank of Philadelphia is one of 12 regional Reserve Banks in the United States that, together with the Board of Governors in Washington, D.C., make up the Federal Reserve System - the nation's central bank. The System's primary role is to ensure a sound financial system and a healthy economy. The Philadelphia Fed is responsible for helping formulate and implement monetary policy, supervising banks and bank holding companies, and providing financial services to depository institutions and the federal government. The Philadelphia Fed serves the Third District, which is composed of eastern Pennsylvania, southern New Jersey, and Delaware.
Chairman Ben S. Bernanke At the Massachusetts Institute of Technology 2006 commencement, Cambridge, Massachusetts President Hockfield, members of the faculty, alumni, families and friends of graduates, and, especially, members of the 2006 graduating class: I am honored to speak at the 140thcommencement exercises of this distinguished institution. It is wonderful to be back at MIT. I graduated from the Institute with a Ph.D. in economics in 1979. That year, President Weisner gave the commencement address. He spoke about, among other things, the nation’s transition from an era of cheap energy to one of energy scarcity and about the need for new technologies to aid in this transition. Obviously, these issues still confront us. One cannot help but wonder whether that theme will feel as current twenty-seven years from now as it does today. As for today, you may have been surprised at some point to learn that an economist rather than an engineer or scientist would be serving as your commencement speaker. But in my remarks, I hope to illustrate that this address continues a long and productive tradition of collaboration at MIT between economics and the engineering and scientific disciplines for which the Institute is so well-known. Building on that theme, I will discuss the essential complementarity of technology and economics in modern economies. Finally, I will have a few words to say about what you, as MIT graduates, can do to strengthen our economy and our society even as you pursue your personal and professional goals. A Short History of Economics at MITIf you will bear with me, I would like to begin with a short history of economics at MIT. The MIT Economics Department is, of course, the part of the Institute that I know best, and I hope to persuade you that it has played a special and unique role in this institution. MIT’s connection to economics dates at least to 1881, when Francis A. Walker became the institution’s third president. To say that Walker had already had a distinguished career would be an understatement. He was named a brevet brigadier general at the end of the Civil War, at the age of twenty-four. He served as the superintendent of the 1870 and 1880 Censuses of the United States and was one of the leading economists of his era. The year he arrived at MIT, he taught the first economics course ever offered at the Institute. The course covered political economy and was so popular that it was soon accorded its own course classification as "Course IX, General Studies." Walker helped found the American Economic Association, still the leading professional association for economists. During his tenure at MIT, he moonlighted both as the first president of that association and as president of the American Statistical Association. In the early twentieth century, the economics program at MIT aimed to prepare undergraduates for leadership roles in business. During those years, economics as a discipline was gaining greater prominence both here and abroad. But the modern era of economics at MIT began in 1940--the year that Paul Samuelson, not yet having even received his doctorate, was persuaded to emigrate here from a somewhat less technically proficient institution located on another stretch of the Charles River. In part, Samuelson was willing to leave Harvard because hisFoundations of Economic Analysis--a book now universally recognized by economists as inaugurating the modern mathematical approach to economics--was not well received by the old guard at the Harvard Economics Department. MIT’s Ph.D. program in economics was established a year after Samuelson arrived. Right from the start, the department attracted strong graduate students: The very first of these, Lawrence Klein, received the Nobel Prize in Economics in 1980 for his work in econometric modeling. With support from MIT’s administration, the department expanded rapidly after World War II, and MIT led the development of a more mathematically rigorous approach to economics. Given the emphasis on quantitative reasoning at MIT, it makes perfect sense that the Economics Department here was in the vanguard of those using mathematics as a framework for organizing economic thought. These developments laid the foundation for economics as a discipline in the second half of the twentieth century, and the department quickly rose to the top of national rankings. Besides Samuelson, many economists contributed to the department’s outstanding reputation--Franco Modigliani, Robert Solow, Charles Kindleberger, Rudiger Dornbusch, and Stanley Fischer, to name just a few. Modigliani, Samuelson, and Solow won Nobel Prizes for their research. In addition, nine other economists with MIT connections have won Nobels. Mathematical approaches to economics have at times been criticized as lacking in practical value. Yet the MIT Economics Department has trained many economists who have played leading roles in government and in the private sector, including the current heads of four central banks: those of Chile, Israel, Italy, and, I might add, the United States. One of my teachers at MIT, Stan Fischer, is a sterling example of what MIT training can produce. Stan followed a brilliant career as a researcher and teacher at MIT with important work as a public servant, including top positions at the World Bank, the International Monetary Fund, and, currently, the Bank of Israel. Why did economics at MIT become so successful? Perhaps Paul Samuelson and the people he helped to attract here could have been equally successful anywhere. But I suspect that the placement of economics in a milieu where quantitative reasoning and the scientific method are the coin of the realm was an important contributing factor. The Sloan School, with its close links both to the Economics Department and to other parts of the Institute, has benefited from the same milieu and has been the source of many fundamental advances as well. Notably, in recent years the global financial industry has been transformed by new quantitative approaches to pricing complex financial instruments such as derivatives and to measuring and managing risk. This transformation stemmed from the application of formal tools of mathematical economics that were developed to a substantial extent by faculty at the Sloan School, including Fischer Black, Robert Merton, and Myron Scholes--the latter two of whom won Nobel Prizes for their work. As MIT economics has benefited from its proximity to the scientific and engineering expertise of MIT, so the Institute has benefited from the presence of a world-class economics department, over and above the addition of still more luster to the MIT name. The exposure of students and faculty from other divisions to the discipline and approaches of economics has stimulated creative thinking about how technology can be used to improve the economic welfare of the average person. That thought brings me to my second topic: the link between technology and economic growth. Translating Technological Advances into Economic GrowthAs has always been the case, technological change and innovation are today in large part driving economic growth and the improvement of living standards. But it is important to understand that even the very best ideas in science or engineering do not automatically translate into broader economic prosperity. In large measure, the material benefits of innovation spring from complementarities between technology and economics, where I include in "economics" not only economic ideas but also economic policies and, indeed, the entire economic system. When the economics is right, scientific and technological advances promote economic development, which in turn, in a virtuous circle, may provide resources and incentives that help to foster more innovation. A negative example is the former Soviet Union, which certainly did not lack for scientific and engineering talent but which had an economic system that was poorly suited for translating scientific advances into economic progress. The experience of the United States over the past decade illustrates the essential complementarity of technology and economics, in my view. Before the mid-1990s, the growth of productivity--the amount of output produced per worker or per hour of work--had been relatively sluggish for more than two decades in this country. As productivity is perhaps the single most important determinant of average living standards--a country in which the average worker can produce a lot is usually also a place in which the average person can consume a lot--the so-called productivity slowdown of that earlier period was the source of much concern among economists and policymakers. In the mid-1990s, however, productivity growth picked up in the United States. The growth rate of productivity increased still further around the turn of the century and remains strong today. This productivity revival augurs well for the future of the U.S. economy. But why did it happen? You, of all people, will not be surprised to hear that the research suggests that the pickup in U.S. productivity growth in the mid-1990s was importantly related to advances in information and communication technologies.1But these technical advances in and of themselves can’t be the whole story. For example, even though the new technologies are widely available around the world, many other countries appear not to have derived the same degree of economic benefit from them as has the United States. Notably, productivity in Europe increased rapidly in the decades after World War II but then decelerated around the mid-1990s, at about the same time that U.S. productivity growth began to increase. Thus the gap between productivity levels in the United States and Europe, which had nearly closed by 1995, has been widening since then. What accounts for the apparently disparate effects of technology on growth here and abroad? Differences in economic policies and systems likely account for some of the differences in performance--another example of the complementarity of technology and economics. One leading explanation for the strong U.S. productivity performance is that labor and product markets in the United States tend to be more flexible and competitive, and that these market characteristics have allowed the United States to realize greater economic benefits from the new technologies. For example, taking full advantage of new information and communication technologies may require extensive reorganization of work practices, reassignment and retraining of workers, and ultimately some reallocation of labor among firms and industries. Regulations that raise the costs of hiring and firing workers and that reduce employers’ ability to change work assignments--like those in a number of European countries, for example--may make such changes more difficult to achieve. Likewise, in product markets, a high degree of competition and low barriers to the entry of new firms in most industries in the United States provide strong incentives for firms to find ways to cut costs and to improve their products. In some other countries, in contrast, the prominence of government-owned firms with a degree of monopoly power, together with a regulatory environment that protects large incumbent firms and makes the entry of new firms difficult, reduces the competitive pressure for innovation and the application of new ideas. Competition is one of the key benefits of free and open trade; companies that are exposed to global competition tend to be much more efficient and to produce goods of higher quality than companies that are sheltered from international competition. Other economic factors have probably been important in translating technological change into material progress.2Some observers point to the depth, liquidity, and sophistication of American financial markets as contributing to recent productivity gains. Sizable markets for venture capital and ready access to equity financing facilitate start-up enterprises, which are often the best means of bringing new technologies to the market. The United States also benefits from its high-quality research universities, which have shown both the willingness and the ability to collaborate with the private sector and, in some cases, with the government as well, in the development and commercialization of new ideas. For example, Intel was co-founded by an MIT graduate, and MIT graduates played key roles in designing and developing the Internet. Management practices also differ across countries, and these differences may also matter for productivity. A recent study found that business establishments in the United Kingdom that are owned by U.S. multinationals get higher productivity from information technology than do other establishments, and it tied this differential to the management and organization of U.S. firms.3Finally, relatively more positive attitudes toward competition and entrepreneurship in the United States--a factor that spans economics and sociology--may also stimulate innovation and its commercial application as well as economic policies that support innovation. Of course, there are factors that may restrain both technological innovation and its commercialization in the United States as well: I would put at the top of the list the relatively poor performance of our K-12 educational system in stimulating interest in and providing solid training in the sciences. One interesting feature of the U.S. and global experience with major innovations is that often a significant amount of time passes between the initial development and diffusion of new technologies and the realization of the associated productivity benefits. Computers were first commercialized in the 1950s, for example, and personal computers came into widespread use beginning in the early 1980s. But until the mid-1990s these developments had little evident effect on measures of productivity. Indeed, MIT’s Robert Solow famously quipped in 1987 that "computers are everywhere except in the productivity statistics." Moreover, despite the sharp decline in information-technology investment after the meltdown of tech-sector stocks earlier this decade, the growth rate of productivity actually increased further in recent years, as I mentioned. These long lags raise additional questions about the nature of the links between new technologies and the resulting productivity gains. Perhaps the answer lies in taking the longer view. Some research by economists has drawn an analogy between modern information and communication technologies and earlier so-called general-purpose technologies such as the steam engine, the electric motor, and the internal combustion engine. General-purpose technologies have broad application and thus have the potential both to revolutionize methods of production and to make a host of new goods and services available to businesses and consumers.4For example, when smaller electric motors replaced single-power sources, such as steam or water power, in manufacturing facilities, it became feasible to reorganize the layouts of plants to optimize the flow of materials rather than the distribution of power.5And the advent of air conditioning significantly expanded opportunities for economic development in the warmer regions of the United States and the world. However, in all cases, these developments evolved over a long period and required firms to make collateral investments in research and development, organizational structure, and employee training. These investments in learning how to make the best use of new technologies have been dubbed intangible capital, to distinguish them from investments in physical goods like new machines or facilities. In the case of information and communication technologies, new economic research suggests that the investments in associated intangible capital--figuring out what to do with the computer once it’s out of the box--are quite important indeed.6In my view, important investments in intangible capital remain to be made, as much still remains to be learned about how to harness these technologies most effectively. Thus, it should not be surprising that the benefits of these technologies have taken a long time to show up in the productivity statistics. This research also suggests that the current productivity revival still has some legs, as the full economic benefits of recent technological changes have not yet been completely realized. Looking to the FutureAs graduates of MIT, you will be at the heart of this critical process of developing new technologies and taking them to the marketplace. We are in an age in which technology and its fruits will be a dominant force not only in our economic lives but in the cultural, social, political, and personal aspects of our lives as well. Your training at MIT equips each of you exceptionally well to take the fullest advantage of the professional and personal opportunities that technological innovation and change will create. Each of you, because of your youth, your talent, your demonstrated commitment to learning, and your personal and intellectual attainments during your time at MIT, will soon find--to paraphrase Shakespeare--that the world is your oyster. I hope that you will contribute in some measure to economic progress, whether in the United States or elsewhere; and I hope you find some measure of financial reward. But the world has a great deal more to offer than money, and a key question each of you will face repeatedly in your lives is how to use the talent and education that you have been given and the knowledge that you have attained. With respect to your professional lives, I hope that when you make career choices, you will look first for opportunities that excite you intellectually, that allow you to use your creative powers to the fullest extent, and that let you continue to learn and grow. I hope you will not be afraid to be unconventional, to do something nobody else has thought of before. Remember that the path to success and fulfillment may not be well marked, the scaling of some predetermined ladder; it may instead be a road without signs or maps. And remember that it is OK to fail--really: New opportunities will always arise for those who seek them. If you remain nimble in searching out new and unexpected opportunities, it will not only benefit you, but it will also benefit the economy and our society, as long experience has shown that dynamism and creativity are the seeds of innovation and of progress. In the personal sphere, as you make your way in the world, I hope you will not forget the importance of your family and how much it has already contributed to your journey through life. Remember, too, family members are the ones who will still love you even when things aren’t going so well. Even as you focus intensively on your professional interests, I hope you will remain intellectually broad--well-read, well-informed, and open to new experiences. And finally, I hope you will remain engaged with the broader society. That may involve entering public service at some point, as many MIT graduates have chosen to do. But it need not. There are always opportunities to make a difference in the world, through volunteering, civic participation, charitable activities, or the type of work you choose to do. I congratulate all graduates and your families for what you have accomplished and wish you the very best for the future. Footnotes 1.See Stephen Oliner and Daniel Sichel (2000), "The Resurgence of Growth in the Late 1990s: Is Information Technology the Story?"Journal of Economic Perspectives,vol. 14, pp. 3-22. Also see Dale W. Jorgenson and Kevin J. Stiroh (2000), "Raising the Speed Limit: U.S. Economic Growth in the Information Age,"Brookings Papers on Economic Activity: 1, pp. 125-211.Return to text 2.For a discussion of some of these other factors, see Robert J. Gordon (2004), "Why Was Europe Left at the Station When America’s Productivity Locomotive Departed?" NBER Working Paper Series 10661 (Cambridge, Mass.: National Bureau of Economic Research, August).Return to text 3.See Nick Bloom, Raffaella Sadun, and John Van Reenen (2006), "It Ain’t What You Do, It’s the Way that You Do I.T.--Testing Explanations of Productivity Growth Using U.S. Affiliates" working paper (London: Centre for Economic Performance, London School of Economics, March).Return to text 4.See Timothy Bresnahan and Manuel Trajtenberg (1995), "General Purpose Technologies: 'Engines of Growth?'"Journal of Econometrics,vol. 65, pp. 83-108.Return to text 5.See Paul David (1990), "The Dynamo and the Computer: An Historical Perspective on the Modern Productivity Paradox,"American Economic Review,vol. 80 (May), pp. 355-61.Return to text 6.See Carol A. Corrado, Charles R. Hulten, and Daniel E. Sichel, (2006), "Intangible Capital and Economic Growth," NBER Working Paper Series 11948 (Cambridge, Mass.: National Bureau of Economic Research, January). Also see Erik Brynjolfsson, Lorin M. Hitt, and Shinkyu Yang (2002), "Intangible Assets: Computers and Organizational Capital"Brookings Papers on Economic Activity: 1,pp. 137-198.Return to text
Donald L. Kohn on Friday took the oath of office for a four-year term as Vice Chairman of the Board of Governors of the Federal Reserve System. The oath was administered in the Board Room by Chairman Ben S. Bernanke. Vice Chairman Kohn’s wife, Gail Kohn, and his mother, children and grandchildren were present. President Bush announced his intention to nominate Governor Kohn as Vice Chairman on May 18, and the Senate confirmed him on June 19. He originally took office on August 5, 2002, as a member of the Board for a term that expires January 31, 2016.
Chairman Ben S. Bernanke Before the Economic Club of Chicago, Chicago, Illinois In my remarks today, I would like to discuss the relationship between energy markets and the economy. As I am certain all of you are aware, the steep increases in energy prices over the past several years have had significant consequences for households, businesses, and economic policy. At least since the time of the first oil shock in October 1973, economists have struggled to understand the ways that disturbances to the supply and demand balance in energy markets influence economic growth and inflation. At the most basic level, oil and natural gas are just primary commodities, like tin, rubber, or iron ore. Yet energy commodities are special, in part because they are critical inputs to a very wide variety of production processes of modern economies. They provide the fuel that drives our transportation system, heats our homes and offices, and powers our factories. Moreover, energy has an influence that is disproportionate to its share in real gross domestic product (GDP) largely because of our limited ability to adjust the amount of energy we use per unit of output over short periods of time. Over longer periods, energy consumption can be altered more easily by, for example, adjusting the types of vehicles that we drive, the kind of homes that we build, and the variety of machines that we buy. Those decisions, in turn, influence the growth and composition of the stock of capital and the productive capacity of the economy. Over the past thirty-five years, the U.S. economy has experienced some wide swings in energy prices. The oil price increases of the 1970s were followed by price declines in the mid-1980s and then a price spike in 1990, with numerous fluctuations since then. From the mid-1980s until fairly recently, market participants tended to look through these price cycles and did not allow their longer-term expectations for oil prices to be greatly affected by short-run swings in spot prices. But beginning around 2003, futures prices began moving up roughly in line with the rise in spot prices. Thus, unlike in earlier episodes, the significantly higher relative price of energy that we are now experiencing is expected to be relatively long lasting and thus will likely prompt more-significant adjustments by households and businesses over time. This higher relative price of energy poses many important questions for economists and policymakers. Why have the prices of oil and natural gas risen so much? What is the outlook for energy supplies and prices in the medium term and in the long term? And what implications does the behavior of energy prices have for the ongoing economic expansion and inflation? I will touch briefly on each of these questions. Developments in Oil MarketsLet me begin with the market for crude oil. What accounts for the behavior of the current and expected future prices of petroleum? Supply and demand are among the most valuable concepts in the economist's toolkit, and I believe they are the key to understanding recent and prospective developments in oil markets. For the most part, high oil prices reflect high and growing demand for oil and limited and uncertain supplies. On the demand side, world oil consumption surged 4 percent in 2004 after rising a solid 2 percent in 2003. The rise in 2004 was much larger than had been expected and was, in fact, the largest yearly increase in a quarter-century. A significant part of the unexpected increase in oil consumption that year reflected rapidly growing oil use in the United States and East Asia, notably China. In 2005, growth of world oil consumption slowed to 1.3 percent, partly reflecting the restraining effects of higher prices. Nonetheless, the level of oil consumption was still high relative to earlier expectations. Thus far this year, underlying demand pressures have remained strong in the context of a global economy that has continued to expand robustly. On the supply side, the production of oil has been constrained by available capacity, hurricanes, and geopolitical developments. In 2003 and 2004, as oil consumption and prices rose briskly, Saudi Arabia and other members of the Organization of the Petroleum Exporting Countries (OPEC) pumped more oil. OPEC was able to boost production relatively quickly in response to changing market conditions by utilizing productive capacity that had been idle. By the end of 2004, however, OPEC's spare production capacity was greatly diminished. As a consequence, OPEC's oil production flattened out over the past year even as oil prices continued to soar. Oil production outside OPEC also leveled off last year, contrary to earlier expectations for continued growth. This development in part reflected the devastating effects of last year's hurricanes. Katrina and Rita were enormously disruptive for our nation's production of energy. At the worst point, 1.5 million barrels per day of crude oil were shut in, virtually all of the U.S. production in the Gulf of Mexico and nearly 2 percent of global oil production. Recovery of oil production in the Gulf has been slow, and the disruptions from last year's storms linger even as we enter this year's hurricane season. The cumulative loss in oil production attributable to Katrina and Rita amounts to more than 160 million barrels of oil, a figure equivalent to nearly half the present level of commercial crude oil inventories in the United States. With the background of strong demand and limited spare capacity, both actual production disruptions and concerns about the reliability and security of future oil supplies have contributed to the volatility in oil prices. The oil-rich Middle East remains an especially unsettled region of the world, but political risks to the oil supply have also emerged in nations outside the Middle East, including Russia, Venezuela, and Nigeria. Compounding these difficulties in markets for crude oil have been constraints and disruptions in the refining sector of the energy industry. In the wake of Hurricane Rita, one-quarter of domestic refining capacity was offline, and here, too, the period of recovery has been protracted. Even before last year's hurricanes, however, a mismatch appeared to be emerging between the incremental supply of crude oil, which tended to be heavy and sulfurous, and the demand by refiners for light, sweet crude, which can be converted more easily into clean-burning transportation fuels. These developments have highlighted the need for additional investments in refining capacity to bridge the gap between upstream supply and final demand. What about the longer term? We can safely assume that world economic growth, together with the rapid pace of industrialization in China, India, and other emerging-market economies, will generate increasing demand for oil and other forms of energy. In all likelihood, growth in the demand for energy will be tempered to some extent by continued improvements in energy efficiency which, in turn, will be stimulated by higher prices and ongoing concerns about the security of oil supplies. Such improvements are possible even without technological breakthroughs. For example, Japan is an advanced industrial nation that uses only about one-half as much energy to produce a dollar's worth of real output as the United States does. Of course, the Japanese and U.S. economies differ in important ways, but the comparison nevertheless suggests that there is scope to boost energy efficiency in the United States and other parts of the industrialized world. Newly industrializing economies such as China appear to be quite inefficient in their use of energy; but as they modernize, they can adopt energy-saving techniques already in use elsewhere, and their energy efficiency will presumably improve as well. Still, as the global economic expansion continues, substantial growth in the use of oil and other energy sources appears to be inevitable. How readily the supply side of the oil market will respond is difficult to predict. In a physical sense, the world is not in imminent danger of running out of oil. At the end of 2005, the world's proved reserves of conventional oil--that is, oil in the ground that is viewed as recoverable using existing technologies and under current economic conditions--stood at more than 1.2 trillion barrels, about 15 percent higher than the world's proved reserves a decade earlier and equal to about four decades of global consumption at current rates. These figures do not include Canada's vast deposits of oil sands, which are estimated to contain an additional 174 billion barrels of proved reserves. In addition, today's proved reserve figures ignore not only the potential for new discoveries but also the likelihood that improved technologies and higher oil prices will increase the amount of oil that can be economically recovered. The oil is there, but whether substantial new sources of production can be made available over the next five years or so is in some doubt. Some important fields are in locations that are technically difficult and time-consuming to develop, such as deep-water fields off the coast of West Africa, in the Gulf of Mexico, or off the east coast of South America. In many cases, the development of new fields also faces the challenge of recovering the oil without damaging delicate ecosystems. Perhaps most troubling are the significant uncertainties generated by geopolitical instability, as I have already noted. Much of the world's oil reserves are located in areas where political turmoil and violence have restrained both production and investment. In both the developed and the developing world, another factor holding back investment in oil infrastructure has been concern on the part of producers that oil prices might fall back as they did in the 1980s and 1990s. In light of that recognition, some oil producers have been reluctant to launch exploration projects even with today's high prices. Such concerns have been reinforced by the huge reserves of oil in several OPEC countries that could be extracted at very low cost if sufficient resources and expertise were directed toward doing so. Developments in the Natural Gas MarketThe story for natural gas shares some similarities with the story for oil, but there are important differences as well. In the 1990s, the U.S. spot price of natural gas at the Henry Hub averaged about $2 per million Btu. However, in recent years, the United States has seen a marked increase in the price of natural gas. The average spot price climbed to nearly $9 per million Btu in 2005, with the price spiking to $15 per million Btu following hurricanes Katrina and Rita. So far this year, natural gas prices have fallen back to around $7 per million Btu as an unusually warm winter curtailed consumption and boosted natural gas in storage to record levels. Futures markets currently anticipate that the price of natural gas will be about $9 per million Btu next year. Why have natural gas prices risen so sharply over the past few years, and why are they expected to remain elevated? As with oil, high prices of natural gas reflect strong demand and diminished supplies. Unlike the globally integrated market for oil, however, natural gas markets are regional, primarily because of the difficulty in transporting gas by means other than pipelines. Although the world's capacity to trade liquefied natural gas, which is transported by ships, is growing, it is still a small fraction of world supply and is not yet sufficient to fully integrate natural gas markets across continents. Demand for natural gas in North America has remained strong in recent years, particularly as environmental concerns have led clean-burning natural gas to become the fuel of choice for new electricity generation. Moreover, increases in oil prices have boosted the demand for energy substitutes such as natural gas. However, domestic production of natural gas has not kept up. Last year, U.S. production was 7 percent below its 2001 level, with less than half of that decline reflecting the impact of hurricanes Katrina and Rita. Increased trade can often mitigate price increases, but net imports of natural gas from Canada, which currently account for around 16 percent of U.S. consumption, have failed to increase in response to higher prices. Between 1988 and 2001, net imports from Canada tripled, but they have since flattened out. Both U.S. and Canadian gas fields have matured and are yielding smaller increases in output, despite the incentive of high prices and a substantial increase in the number of drilling rigs in operation. Trade in liquefied natural gas, or LNG, is also likely to increase over time, but perhaps at a slower pace than once envisioned. LNG imports into the United States nearly tripled from 2002 to 2004, but they actually fell a bit last year as production disruptions in a number of countries limited supply and as consumers in other countries competed for available cargoes. Thus, natural gas prices are likely to remain elevated for at least the coming few years. It is possible, however, that within a decade new supplies from previously untapped areas of North America could boost available output here, while imports of LNG will increase to more substantial levels as countries seek to bring their isolated natural gas reserves to market. Given time, these developments could serve to lower natural gas prices in the United States significantly. Nonetheless, because of the higher costs of producing these supplies relative to the traditional sources of natural gas, as well as the elevated cost of other energy sources such as oil, natural gas prices seem unlikely to return to the level of the 1990s. Thus, the supply-demand fundamentals seem consistent with the view now taken by market participants that the days of persistently cheap oil and natural gas are likely behind us. The good news is that, in the longer run, we have options. I have already noted the scope for improvements in energy efficiency and increased conservation. Considerable potential exists as well for substituting other energy sources for oil and natural gas, including coal, nuclear energy, and renewable sources such as bio-fuels and wind power. Given enough time, market mechanisms are likely to increase energy supplies, including alternative energy sources, while simultaneously encouraging conservation and substitution away from oil and natural gas to other types of energy. Economic and Policy Implications of Increased Energy PricesWhat are the economic implications of the higher energy prices that we are experiencing? In the long run, higher energy prices are likely to reduce somewhat the productive capacity of the U.S. economy. That outcome would occur, for example, if high energy costs make businesses less willing to invest in new capital or cause some existing capital to become economically obsolete. All else being equal, these effects tend to restrain the growth of labor productivity, which in turn implies that real wages and profits will be lower than they otherwise would have been. Also, the higher cost of imported oil is likely to adversely affect our terms of trade; that is, Americans will have to sell more goods and services abroad to pay for a given quantity of oil and other imports. For the medium term at least, the higher bill for oil imports will increase the U.S. current account deficit, implying a greater need for foreign financing. Under the assumption that energy prices do not move sharply higher from their already high levels, these long-run effects, though clearly negative, appear to be manageable. The U.S. economy is remarkably flexible, and it seems to have absorbed the cost shocks of the past few years with only a few dislocations. And conservation and the development of alternative energy sources will, over the long term, ameliorate some of the effects of higher energy prices. Moreover, ongoing productivity gains arising from sources such as technological improvements are likely to exceed by a significant margin the productivity losses created by high energy prices. In the short run, sharply higher energy prices create a rather different and, in some ways, a more difficult set of economic challenges. Indeed, a significant increase in energy prices can simultaneously slow economic growth while raising inflation. An increase in oil prices slows economic growth in the short run primarily through its effects on consumer spending. Because the United States imports much of the oil that it consumes, an increase in oil prices is, as many economists have noted, broadly analogous to the imposition of a tax on U.S. residents, with the revenue from the tax going to oil producers abroad. In 2004 as a whole, the total cost of imported oil increased almost $50 billion relative to 2003. The imported oil bill jumped again last year by an additional $70 billion, and given the price increases we have experienced in 2006, it appears on track to increase $50 billion further at an annual rate in the first half of this year. Coupled with the rising cost of imported natural gas, the cumulative increase in imported energy costs since the end of 2003 is shaping up to be $185 billion--equal to almost 1-1/2 percent of GDP. All else being equal, this constitutes a noticeable drag on real household incomes and spending. It is a tribute to the underlying strength and resiliency of the U.S. economy that it has been able to perform well despite the drag from increased energy prices. At the same time that higher oil prices slow economic growth, they also create inflationary pressures. Higher prices for crude oil are passed through to increased prices for the refined products used by consumers, such as gasoline and heating oil. When oil prices rise, people may try to substitute other forms of energy, such as natural gas, leading to price increases in those alternatives as well. The rise in prices paid by households for energy--for example for gasoline, heating oil, and natural gas--represent, of course, an increase in the cost of living and in price inflation. This direct effect of higher energy prices on the cost of living is sometimes called thefirst-round effecton inflation. In addition, higher energy costs may have indirect effects on the inflation rate--if, for example, firms pass on their increased costs of production in the form of higher consumer prices for non-energy goods or services or if workers respond to the increase in the cost of living by demanding higher nominal wages. A jump in energy costs could also increase the public's longer-term inflation expectations, a factor that would put additional upward pressure on inflation. These indirect effects of higher energy prices on the overall rate of inflation are calledsecond-round effects. The overall inflation rate reflects both first-round and second-round effects. Economists and policymakers also pay attention to the so-called core inflation rate, which excludes the direct effects of increases in the prices of energy (as well as of food). By stripping out the first-round inflation effects, core inflation provides a useful indicator of the second-round effects of increases in the price of energy. In the past, notably during the 1970s and early 1980s, both the first-round and second-round effects of oil-price increases on inflation tended to be large, as firms freely passed on rising energy costs to consumers, workers reacted to the surging cost of living by ratcheting up their wage demands, and longer-run expectations of inflation moved up quickly. In this situation, monetary policymaking was extremely difficult because oil-price increases threatened to result in a large and persistent increase in the overall inflation rate. The Federal Reserve attempted to contain the inflationary effects of the oil-price shocks by engineering sharp increases in interest rates, actions which had the consequence of sharply slowing growth and raising unemployment, as in the recessions that began in 1973 and 1981. Since about 1980, however, the Federal Reserve and most other central banks have worked hard to bring inflation and expectations of inflation down. An important benefit of these efforts is that the second-round inflation effect of a given increase in energy prices has been much reduced. To the extent that households and business owners expect that the Fed will keep inflation low, firms have both less incentive and less ability to pass on increased energy costs in the form of higher prices, and likewise workers have less incentive to demand compensating increases in their nominal wages. As I noted in remarks last week, although the rate of pass-through of higher energy and other commodity prices to core consumer price inflation appears to have remained relatively low in the current episode--reflecting the inflation-fighting credibility built by the Fed in recent decades the cumulative increases in energy and commodity prices have been large enough that they could account for some of the recent pickup in core inflation. In addition, some survey-based measures of longer-term inflation expectations have edged up, on net, in recent months, as has the compensation for inflation and inflation risk implied by yields on nominal and inflation-indexed government debt. As yet, these expectations measures have remained within the ranges in which they have fluctuated in recent years and inflation compensation implied by yields on government debt has fallen back somewhat in the past month. Nevertheless, these developments bear watching. In conclusion, energy prices have moved up considerably since the end of 2002, reflecting supply and demand factors. In the short run, prices are likely to remain high in an environment of strong world economic growth and a limited ability to increase energy supplies. Moreover, prices are likely to be volatile in the near term, given the small margins of excess capacity to produce crude oil or natural gas that traditionally have buffered short-run shifts in supply and demand. However, in the long run, market forces will respond. The higher relative prices of energy will create incentives for businesses to create new, energy-saving technologies and for energy consumers to adopt them. The market for alternative fuels is growing rapidly and will help to shift consumption away from petroleum-based fuels. Government can contribute to these conservation efforts by working to create a regulatory environment that encourages the growth in energy supplies in a manner that is consistent with our nation's environmental and other objectives. Given the extraordinary resilience of the U.S. economy, I am confident our nation will be up to this challenge.
The member agencies of the Federal Financial Institutions Examination Council (FFIEC) and the Conference of State Bank Supervisors today announced the release ofLESSONS LEARNED FROM HURRICANE KATRINA: Preparing Your Institution for a Catastrophic Event. The booklet relays financial institutions' experiences and lessons learned in the aftermath of Hurricane Katrina that other institutions may find helpful in considering their readiness for a catastrophic event. Financial institutions face a wide variety of disasters across the United States that could have potentially devastating consequences. Following Hurricane Katrina, institutions' existing disaster recovery and business continuity plans generally worked well in enabling institutions to restore operations swiftly. However, the unprecedented destruction and aftermath of the hurricane caused major disruptions that exceeded the scope of some institutions' disaster recovery and business continuity plans. Major hardships faced by these institutions included the following: Financial institutions demonstrated great resiliency, working together to create solutions that allowed them to successfully operate under very difficult circumstances and to assist customers and communities in recovering from the hurricane. The lessons learnedbookletis available on the FFIEC's web site athttp://www.ffiec.gov/as well as on each agency's web site. Insured depository institutions will soon receive a hard copy or an electronic copy of the booklet. Media Contacts:Federal ReserveDeborah Lagomarsino202-452-2955FDICDavid Barr202-898-6992OCCBryan Hubbard202-874-5770OTSKatie Fitzgerald202-906-6677NCUACherie Umbel703-518-6330CSBSMary White202-728-5715
The Federal Open Market Committee decided today to raise its target for the federal funds rate by 25 basis points to 5-1/4 percent. Recent indicators suggest that economic growth is moderating from its quite strong pace earlier this year, partly reflecting a gradual cooling of the housing market and the lagged effects of increases in interest rates and energy prices. Readings on core inflation have been elevated in recent months. Ongoing productivity gains have held down the rise in unit labor costs, and inflation expectations remain contained. However, the high levels of resource utilization and of the prices of energy and other commodities have the potential to sustain inflation pressures. Although the moderation in the growth of aggregate demand should help to limit inflation pressures over time, the Committee judges that some inflation risks remain. The extent and timing of any additional firming that may be needed to address these risks will depend on the evolution of the outlook for both inflation and economic growth, as implied by incoming information. In any event, the Committee will respond to changes in economic prospects as needed to support the attainment of its objectives. Voting for the FOMC monetary policy action were: Ben S. Bernanke, Chairman; Timothy F. Geithner, Vice Chairman; Susan S. Bies; Jack Guynn; Donald L. Kohn; Randall S. Kroszner; Jeffrey M. Lacker; Sandra Pianalto; Kevin M. Warsh; and Janet L. Yellen. In a related action, the Board of Governors unanimously approved a 25-basis-point increase in the discount rate to 6-1/4 percent. In taking this action, the Board approved the requests submitted by the Boards of Directors of the Federal Reserve Banks of Boston, New York, Philadelphia, Cleveland, Richmond, Atlanta, Chicago, St. Louis, Minneapolis, and Dallas.
Governor Mark W. Olson Subcommittee on Financial Institutions and Consumer Credit, Committee on Financial Services, U.S. House of Representatives Chairman Bachus, Representative Sanders, and members of the subcommittee, I am pleased to be here to discuss the uses and significance of the home loan data that are collected, reported, and publicly disclosed under the Home Mortgage Disclosure Act.The act, which I will refer to as HMDA, was enacted over thirty years ago. Since then, it has undergone major changes. Today, HMDA requires most home lenders, a substantial majority of the home loan market, to disclose selected information about the applications they receive and the loans they extend each year. This information can be used for at least three purposes: first, to help the public judge how well lenders are meeting the housing-credit needs of their communities; second, to facilitate efficient investment in housing and neighborhoods; and third, to enhance the enforcement of laws prohibiting discrimination in lending.HMDA promotes these goals through disclosure rather than substantive mandates or restrictions. The act does not direct lenders to make loans to any particular areas or persons. Nor does it direct lenders to make particular kinds of loans or to refrain from any particular loan terms or practices.Instead, HMDA prescribes lender disclosures that, taken together, form a public data set about lending patterns. Every reportable application for a loan occupies a unique line in the data set. In 2005, there were approximately 31 million reported loan applications. The information disclosed about each application includes the race, ethnicity, and income of the applicant, the type and amount of the loan applied for, whether the loan was originated or the application was denied, and the census tract of the property to be financed. For the public’s convenience, summary reports of the data are published by metropolitan area and by institution--for almost 9,000 depository and nondepository institutions. These summary reports are compiled by the Federal Reserve Board on behalf of the agency members of the Federal Financial Institutions Examination Council (FFIEC). The Board also processes and edits the transaction-level data, which the FFIEC makes available to members of the public, who may analyze and compile the data as they see fit.The information disclosed under HMDA constitutes a rich data set, but, of course, all data sets have their limitations. The HMDA data tell a great deal about lending patterns, but they do not tell the entire story. Nonetheless, by drawing attention to lending patterns, the data prompt discussion, investigation, analysis, and research that may deepen our understanding of why these patterns occur and allow us to increase fairness and efficiency in the home loan market. For example, in 1991, congressional amendments to HMDA resulted in the disclosure of data that, for the first time, revealed black and Hispanic applicants for mortgage loans were far more likely than non-Hispanic white applicants to have their applications denied. The publication of those data precipitated an important public discussion about the underlying causes--and about whether unlawful discrimination was one of the causes. That discussion helped bring about new initiatives for compliance and community development. Many lenders improved their lending policies and developed strong compliance and oversight programs. Lenders also expanded their outreach to underserved communities, often by strengthening ties with community-based organizations. The data also prompted supervisory and enforcement agencies to improve their fair lending oversight programs. In short, though denial disparities have persisted, HMDA’s disclosure of those disparities has helped to increase the fairness and efficiency of the home loan market.Last year we passed another HMDA milestone when the first loan-level information about mortgage loan prices was released. The public discussion that the release of these data has prompted is reminiscent of the discussion that took place after the initial release of loan-denial data fifteen years ago. Today, the focus of the discussion has shifted fromwhich consumersget home loans tothe termson which consumers get home loans--but the essential concern about the possible role of illegal discrimination is the same. I believe that the current public discussion about the new data will ultimately further the goals of fairness and efficiency in the mortgage market by prompting additional research, enhanced compliance and enforcement efforts, and more-effective investment in community development and financial literacy.The Federal Reserve has responsibilities that relate to each of these areas. In my testimony today, I will discuss four roles of the Federal Reserve that relate to the HMDA data. First, the Federal Reserve Board was entrusted by Congress to write implementing rules for HMDA. Acting in that capacity, the Board required lenders to report loan-price data. Second, as a supervisor of financial institutions, the Federal Reserve uses HMDA data, including the price data, to facilitate its supervision of institutions for compliance with laws prohibiting discrimination in home lending. Third, as a research institution, the Federal Reserve conducts and publishes analyses of the price data, and it encourages research by other parties as well. Fourth, the Federal Reserve supports efforts by other organizations to use the HMDA data to identify financial education and community development needs. The Federal Reserve also supports their efforts to respond to those needs.The Board’s Decision to Collect Price InformationAs I have said, it is a Board regulation, adopted under authority of HMDA, that requires lenders to disclose loan-price data. I will now provide some background on the Board’s decision to amend that regulation to include price data. Advances in information processing technology have expanded access to credit and homeownership opportunities for consumers. In the past, individuals seeking credit to purchase a home, or seeking to borrow for some other reason, either did or did not meet the specific underwriting criteria for a particular loan product; if they did, everyone paid about the same price for that product. Today, in part because of advances in credit scoring and underwriting technology, lenders can price loans according to risk, charging different borrowers different prices on the basis of a borrower’s estimated creditworthiness.The enhanced ability of lenders to assess credit risk gave rise to a segment of the mortgage market often referred to as subprime lending. In the subprime market, higher-risk borrowers pay higher prices. Subprime lending has grown rapidly, from less than 5 percent of all mortgage lending in 1994 to an estimated 20 percent in 2005, or over $600 billion. The wider range of loan pricing available in the subprime market helped to expand consumers’ homeownership opportunities and to increase their access to home equity. But this same price variability has raised concerns about unequal treatment of borrowers. It also has raised concerns about whether certain loan terms and lending practices are appropriate, whether consumers have the ability and knowledge to shop for the most beneficial loan terms, and whether the subprime market is sufficiently competitive.The Board responded to these concerns by amending Regulation C, the regulation that implements HMDA, to expand the available data on higher-priced lending. The data released by the FFIEC in September 2005, which covered lending activity in 2004, contained the first loan-level information on loan pricing ever available to the general public. The data contain price information for loans whose prices exceeded thresholds set by the Board. The thresholds were selected to target segments of the home loan market that have raised the most concern, taking into consideration the cost and burden of reporting. The thresholds generally correspond to an unofficial line separating the prime and subprime markets. But that line of separation is not always clear, and its correspondence with the reporting thresholds is in any event imprecise. Therefore, we call loans whose prices exceed the reporting threshold "higher-priced loans" rather than "subprime loans."This is only the second year in which price data will be publicly available under the Board’s regulation. The Board continues to monitor the effects of the regulation in an effort to understand both its benefits and costs.The Federal Reserve’s Use of HMDA Data in Fair Lending SupervisionI have spoken of the Federal Reserve’s role as the agency charged with implementing HMDA through regulations. The Federal Reserve also has a role as a supervisor of bank holding companies and state-chartered banks that are members of the Federal Reserve System. In that role, the Federal Reserve has long used HMDA data to help it supervise financial institutions’ compliance with fair lending laws. The new data on higher-priced loans are yet another "screen" to make our fair lending supervision more effective. The Federal Reserve also shared analyses of the 2004 price data with other supervisory and enforcement agencies to assist them with their oversight of the institutions they supervise.Before I discuss how the HMDA screen fits into the process of fair lending supervision, I want to describe that process more generally. Fair lending reviews are an integral part of the Federal Reserve’s supervision for consumer compliance and are performed regularly within each examination cycle. In addition, examiners may conduct targeted fair lending reviews whenever circumstances warrant. Moreover, the Federal Reserve examines institutions’ compliance with fair lending laws regardless of whether they report price data under HMDA. Indeed, the Federal Reserve was examining for potential price discrimination well before it adopted the HMDA price-reporting requirement. Although price reporting under HMDA is limited to higher-priced loans, examiners look for unlawful price discrimination at any pricing level. Furthermore, examiners seek to detect other forms of discrimination, such as underwriting discrimination (for example, denying credit on the basis of the applicant’s race) or redlining (for example, denying credit on the basis of the racial characteristics of the applicant’s neighborhood).Federal Reserve examiners use an institution’s HMDA data, including its accept-deny data for loan applications and any price data it may have reported on originations, in conjunction with other information about the institution to determine the focus of the institution’s fair lending examination. The HMDA data are incorporated into statistical management systems that produce analyses of lending patterns that aid the examination process. Starting in 2005, these analyses incorporated loan-price data. Other information that examiners use includes consumer complaints, the likely risks of an institution’s different business lines, and the adequacy of the institution’s compliance-risk management system. To gauge the risk of price discrimination, examiners consider, among other types of information, the presence of broad employee or broker discretion in pricing and the relationship, if any, between pricing and the compensation of loan officers or brokers. When examiners determine that a fair lending examination should focus on pricing, they collect additional information from the institution to evaluate whether pricing disparities can be fully attributed to legitimate factors or whether they are due, even in part, to unlawful discrimination.If unlawful discrimination is found, the institution is referred to the Department of Justice or the Department of Housing and Urban Development, as required by law. Depending on the outcome of the referral and the nature of the violation, the Federal Reserve may also take other action to fully resolve the matter. For example, the Federal Reserve may direct the institution to provide remedies to harmed parties and improve its fair lending compliance controls and policies.As the Federal Reserve has stated repeatedly, using the price and other HMDA data effectively in the supervisory process depends on a full understanding of the inherent limitations of those data. The HMDA data include valuable information, such as applicant or borrower income, loan amount, and the location of the property to be financed, but the data do not include many factors that lenders routinely consider in loan underwriting and pricing. Some of the typical credit-risk factors not included in the HMDA data are credit scores and loan-to-value ratios. Because the HMDA data lack such information, we cannot conclude from the HMDA data alone that an observed racial or ethnic difference in the prices of loans is the result of unlawful discrimination. That is why Federal Reserve examiners consider additional information about a lender, including information about its loan products and lending practices and its borrowers’ creditworthiness, before drawing conclusions about the lender’s compliance record.In addition to improving fair lending supervision and enforcement by government agencies, the new pricing data have spurred institutions to improve their own compliance. Although examiners have long considered institutions’ mortgage pricing as part of the fair lending review process, public disclosure of this pricing data appears to have given additional impetus to institutions’ compliance efforts. Many institutions have reexamined their pricing policies and procedures to ensure that they do not permit, even inadvertently, pricing differences that violate the fair lending laws. Many institutions have also reevaluated their controls to ensure that proper policies are followed. This increased attention by institutions to their own fair lending compliance is one of the principal benefits of HMDA.Research by Federal Reserve Staff and OthersSupervision for fair lending compliance deals with lending patterns at the institution level. But the HMDA data also reveal lending patterns at aggregate levels, across institutions. Disclosure of aggregate patterns can raise and focus attention on important policy questions concerning access to credit. To that end, researchers at the Federal Reserve have published numerous papers and articles. Most recently, staff published an article about patterns in the new loan-pricing data.1I will review a few of their findings.First, most home lenders make few, if any, higher-priced loans. In 2004, only about 500 out of the 8,850 reporting institutions made 100 or more higher-priced loans; the ten lenders with the largest volume of higher-priced loans accounted for about 40 percent of all such loans. (The FFIEC has not finished reviewing, processing, and editing the 2005 data, which were submitted in March of this year.)The 2004 data also show that 16 percent of borrowers took out higher-priced loans that year in the nation as a whole. This proportion may have increased from 2004 to 2005. For most loans, the Board’s regulation uses long-term interest rates to set the thresholds for reporting loan-price data, but mortgage loan rates more closely track short-term rates. Thus, a narrowing of the difference between short-term and long-term rates, such as occurred from 2004 to 2005, may increase the proportion of loans reported as higher-priced loans.The proportion of borrowers obtaining higher-priced loans is not geographically uniform but varies widely by region and by city. For example, in many of the metropolitan areas of the South and the Southwest, 30 percent to 40 percent of homebuyers taking out conventional loans in 2004 took out higher-priced loans. In other areas of the country, the proportion was much smaller. These differences may not be that surprising--other data show that credit scores tend to be lower on average in the South and the Southwest than elsewhere--but they may nonetheless warrant further analysis.Of course, public attention has focused on a notable variation in the incidence of higher-priced lending across racial and ethnic lines: blacks and Hispanics are much more likely than non-Hispanic whites to receive higher-priced loans. In 2004, 32 percent of black borrowers and 20 percent of Hispanic borrowers received higher-priced home purchase loans, but only 9 percent of non-Hispanic white borrowers did. In other words, black homebuyers received higher-priced loans more than three times as often as non-Hispanic white homebuyers, and Hispanic homebuyers received higher-priced loans more than twice as often as non-Hispanic whites.Certainly, differences of this magnitude are disturbing and raise important public policy questions. They also have led some to conclude that racial discrimination must play a role in the pricing of home loans. However, for the reasons I have explained above, we cannot use HMDA data alone to judge whether an institution has discriminated unlawfully or, therefore, whether unlawful discrimination is present in the market.Despite their limitations, the HMDA data supply a key insight into the aggregate disparities: they reflect in part a segmentation of the market by race and ethnicity. Black and Hispanic borrowers are more likely to obtain mortgage loans from institutions that tend to specialize in subprime lending. Now, at least part of this segmentation of the market by race and ethnicity may reflect objective differences in borrowers’ preferences or differences in credit-risk indicators, such as credit scores, that are not included in the HMDA data. Yet the segmentation may have more troubling causes, at least in part. Segmentation may stem from borrowers being steered to lenders that charge higher prices than what is warranted by the credit characteristics of these borrowers. Borrowers may also have different levels of financial literacy, or their knowledge of the mortgage lending process may be uneven--for example, they may not understand the importance of shopping and negotiating for the best loan terms. Additional research is needed to explore all of these, and perhaps other, hypotheses.The Board will continue to conduct and promote research that explores the racial and ethnic differences in the incidence of higher-priced lending. In June and July, the Board is conducting hearings on the home equity lending market. These hearings, which I am chairing, are intended to gather information about, among other things, how consumers select their lenders and loans. The Board’s 2007 biennial community development research conference will also provide a forum for research that may help explain differences in the incidence of higher-priced lending.The Federal Reserve’s Promotion of Community Development and Financial LiteracyI have discussed the Federal Reserve’s roles in regulation, supervision, and research. Now I will turn to its role in promoting community development and financial literacy. The Federal Reserve System uses HMDA data to help banks, community organizations, and other interested groups identify community development needs and opportunities. For example, the Federal Reserve Bank of Boston tabulates HMDA data for the New England region to help regional financial institutions, community organizations, and state and local governments access and use information about their area’s regional lending patterns. In addition, the Community Affairs Offices of the Federal Reserve System encourage and facilitate collaboration among financial institutions, governments, and community organizations to improve access to mortgage credit in traditionally underserved communities.The Federal Reserve also promotes financial literacy. Board staff provide strategic advice on developing financial literacy policies, programs, partnerships, and marketing to national initiatives, such as the Jump$tart Coalition, Operation HOPE, and the DollarWi$e Campaign of the Conference of Mayors. In a parallel effort, the Federal Reserve Banks support similar regional initiatives. The Federal Reserve also collaborates with other groups on research to develop successful financial education programs and identify the most effective way to deliver these programs to intended audiences. By these and other means, the Federal Reserve seeks to address gaps in consumers’ understanding of not only home loan transactions but also financial management more broadly. These gaps in consumer understanding may be contributing to disparities in the availability and price of home loans.In closing, I appreciate this opportunity to discuss the Federal Reserve’s regulation requiring lenders to disclose price and other data on home loans; how the Federal Reserve uses the data to improve fair lending supervision; and the Federal Reserve’s promotion of research, community development, and financial literacy.Footnotes1.Robert B. Avery, Glenn B. Canner, and Robert E. Cook (2005),"New Information Reported under HMDA and Its Application in Fair Lending Enforcement,"Federal Reserve Bulletin, vol. 91 (Summer 2005), pp. 344-394.Return to text Chairman Bachus, Representative Sanders, and members of the subcommittee, I am pleased to be here to discuss the uses and significance of the home loan data that are collected, reported, and publicly disclosed under the Home Mortgage Disclosure Act. The act, which I will refer to as HMDA, was enacted over thirty years ago. Since then, it has undergone major changes. Today, HMDA requires most home lenders, a substantial majority of the home loan market, to disclose selected information about the applications they receive and the loans they extend each year. This information can be used for at least three purposes: first, to help the public judge how well lenders are meeting the housing-credit needs of their communities; second, to facilitate efficient investment in housing and neighborhoods; and third, to enhance the enforcement of laws prohibiting discrimination in lending. HMDA promotes these goals through disclosure rather than substantive mandates or restrictions. The act does not direct lenders to make loans to any particular areas or persons. Nor does it direct lenders to make particular kinds of loans or to refrain from any particular loan terms or practices. Instead, HMDA prescribes lender disclosures that, taken together, form a public data set about lending patterns. Every reportable application for a loan occupies a unique line in the data set. In 2005, there were approximately 31 million reported loan applications. The information disclosed about each application includes the race, ethnicity, and income of the applicant, the type and amount of the loan applied for, whether the loan was originated or the application was denied, and the census tract of the property to be financed. For the public’s convenience, summary reports of the data are published by metropolitan area and by institution--for almost 9,000 depository and nondepository institutions. These summary reports are compiled by the Federal Reserve Board on behalf of the agency members of the Federal Financial Institutions Examination Council (FFIEC). The Board also processes and edits the transaction-level data, which the FFIEC makes available to members of the public, who may analyze and compile the data as they see fit. The information disclosed under HMDA constitutes a rich data set, but, of course, all data sets have their limitations. The HMDA data tell a great deal about lending patterns, but they do not tell the entire story. Nonetheless, by drawing attention to lending patterns, the data prompt discussion, investigation, analysis, and research that may deepen our understanding of why these patterns occur and allow us to increase fairness and efficiency in the home loan market. For example, in 1991, congressional amendments to HMDA resulted in the disclosure of data that, for the first time, revealed black and Hispanic applicants for mortgage loans were far more likely than non-Hispanic white applicants to have their applications denied. The publication of those data precipitated an important public discussion about the underlying causes--and about whether unlawful discrimination was one of the causes. That discussion helped bring about new initiatives for compliance and community development. Many lenders improved their lending policies and developed strong compliance and oversight programs. Lenders also expanded their outreach to underserved communities, often by strengthening ties with community-based organizations. The data also prompted supervisory and enforcement agencies to improve their fair lending oversight programs. In short, though denial disparities have persisted, HMDA’s disclosure of those disparities has helped to increase the fairness and efficiency of the home loan market. Last year we passed another HMDA milestone when the first loan-level information about mortgage loan prices was released. The public discussion that the release of these data has prompted is reminiscent of the discussion that took place after the initial release of loan-denial data fifteen years ago. Today, the focus of the discussion has shifted fromwhich consumersget home loans tothe termson which consumers get home loans--but the essential concern about the possible role of illegal discrimination is the same. I believe that the current public discussion about the new data will ultimately further the goals of fairness and efficiency in the mortgage market by prompting additional research, enhanced compliance and enforcement efforts, and more-effective investment in community development and financial literacy. The Federal Reserve has responsibilities that relate to each of these areas. In my testimony today, I will discuss four roles of the Federal Reserve that relate to the HMDA data. First, the Federal Reserve Board was entrusted by Congress to write implementing rules for HMDA. Acting in that capacity, the Board required lenders to report loan-price data. Second, as a supervisor of financial institutions, the Federal Reserve uses HMDA data, including the price data, to facilitate its supervision of institutions for compliance with laws prohibiting discrimination in home lending. Third, as a research institution, the Federal Reserve conducts and publishes analyses of the price data, and it encourages research by other parties as well. Fourth, the Federal Reserve supports efforts by other organizations to use the HMDA data to identify financial education and community development needs. The Federal Reserve also supports their efforts to respond to those needs. The Board’s Decision to Collect Price InformationAs I have said, it is a Board regulation, adopted under authority of HMDA, that requires lenders to disclose loan-price data. I will now provide some background on the Board’s decision to amend that regulation to include price data. Advances in information processing technology have expanded access to credit and homeownership opportunities for consumers. In the past, individuals seeking credit to purchase a home, or seeking to borrow for some other reason, either did or did not meet the specific underwriting criteria for a particular loan product; if they did, everyone paid about the same price for that product. Today, in part because of advances in credit scoring and underwriting technology, lenders can price loans according to risk, charging different borrowers different prices on the basis of a borrower’s estimated creditworthiness. The enhanced ability of lenders to assess credit risk gave rise to a segment of the mortgage market often referred to as subprime lending. In the subprime market, higher-risk borrowers pay higher prices. Subprime lending has grown rapidly, from less than 5 percent of all mortgage lending in 1994 to an estimated 20 percent in 2005, or over $600 billion. The wider range of loan pricing available in the subprime market helped to expand consumers’ homeownership opportunities and to increase their access to home equity. But this same price variability has raised concerns about unequal treatment of borrowers. It also has raised concerns about whether certain loan terms and lending practices are appropriate, whether consumers have the ability and knowledge to shop for the most beneficial loan terms, and whether the subprime market is sufficiently competitive. The Board responded to these concerns by amending Regulation C, the regulation that implements HMDA, to expand the available data on higher-priced lending. The data released by the FFIEC in September 2005, which covered lending activity in 2004, contained the first loan-level information on loan pricing ever available to the general public. The data contain price information for loans whose prices exceeded thresholds set by the Board. The thresholds were selected to target segments of the home loan market that have raised the most concern, taking into consideration the cost and burden of reporting. The thresholds generally correspond to an unofficial line separating the prime and subprime markets. But that line of separation is not always clear, and its correspondence with the reporting thresholds is in any event imprecise. Therefore, we call loans whose prices exceed the reporting threshold "higher-priced loans" rather than "subprime loans." This is only the second year in which price data will be publicly available under the Board’s regulation. The Board continues to monitor the effects of the regulation in an effort to understand both its benefits and costs. The Federal Reserve’s Use of HMDA Data in Fair Lending SupervisionI have spoken of the Federal Reserve’s role as the agency charged with implementing HMDA through regulations. The Federal Reserve also has a role as a supervisor of bank holding companies and state-chartered banks that are members of the Federal Reserve System. In that role, the Federal Reserve has long used HMDA data to help it supervise financial institutions’ compliance with fair lending laws. The new data on higher-priced loans are yet another "screen" to make our fair lending supervision more effective. The Federal Reserve also shared analyses of the 2004 price data with other supervisory and enforcement agencies to assist them with their oversight of the institutions they supervise. Before I discuss how the HMDA screen fits into the process of fair lending supervision, I want to describe that process more generally. Fair lending reviews are an integral part of the Federal Reserve’s supervision for consumer compliance and are performed regularly within each examination cycle. In addition, examiners may conduct targeted fair lending reviews whenever circumstances warrant. Moreover, the Federal Reserve examines institutions’ compliance with fair lending laws regardless of whether they report price data under HMDA. Indeed, the Federal Reserve was examining for potential price discrimination well before it adopted the HMDA price-reporting requirement. Although price reporting under HMDA is limited to higher-priced loans, examiners look for unlawful price discrimination at any pricing level. Furthermore, examiners seek to detect other forms of discrimination, such as underwriting discrimination (for example, denying credit on the basis of the applicant’s race) or redlining (for example, denying credit on the basis of the racial characteristics of the applicant’s neighborhood). Federal Reserve examiners use an institution’s HMDA data, including its accept-deny data for loan applications and any price data it may have reported on originations, in conjunction with other information about the institution to determine the focus of the institution’s fair lending examination. The HMDA data are incorporated into statistical management systems that produce analyses of lending patterns that aid the examination process. Starting in 2005, these analyses incorporated loan-price data. Other information that examiners use includes consumer complaints, the likely risks of an institution’s different business lines, and the adequacy of the institution’s compliance-risk management system. To gauge the risk of price discrimination, examiners consider, among other types of information, the presence of broad employee or broker discretion in pricing and the relationship, if any, between pricing and the compensation of loan officers or brokers. When examiners determine that a fair lending examination should focus on pricing, they collect additional information from the institution to evaluate whether pricing disparities can be fully attributed to legitimate factors or whether they are due, even in part, to unlawful discrimination. If unlawful discrimination is found, the institution is referred to the Department of Justice or the Department of Housing and Urban Development, as required by law. Depending on the outcome of the referral and the nature of the violation, the Federal Reserve may also take other action to fully resolve the matter. For example, the Federal Reserve may direct the institution to provide remedies to harmed parties and improve its fair lending compliance controls and policies. As the Federal Reserve has stated repeatedly, using the price and other HMDA data effectively in the supervisory process depends on a full understanding of the inherent limitations of those data. The HMDA data include valuable information, such as applicant or borrower income, loan amount, and the location of the property to be financed, but the data do not include many factors that lenders routinely consider in loan underwriting and pricing. Some of the typical credit-risk factors not included in the HMDA data are credit scores and loan-to-value ratios. Because the HMDA data lack such information, we cannot conclude from the HMDA data alone that an observed racial or ethnic difference in the prices of loans is the result of unlawful discrimination. That is why Federal Reserve examiners consider additional information about a lender, including information about its loan products and lending practices and its borrowers’ creditworthiness, before drawing conclusions about the lender’s compliance record. In addition to improving fair lending supervision and enforcement by government agencies, the new pricing data have spurred institutions to improve their own compliance. Although examiners have long considered institutions’ mortgage pricing as part of the fair lending review process, public disclosure of this pricing data appears to have given additional impetus to institutions’ compliance efforts. Many institutions have reexamined their pricing policies and procedures to ensure that they do not permit, even inadvertently, pricing differences that violate the fair lending laws. Many institutions have also reevaluated their controls to ensure that proper policies are followed. This increased attention by institutions to their own fair lending compliance is one of the principal benefits of HMDA. Research by Federal Reserve Staff and OthersSupervision for fair lending compliance deals with lending patterns at the institution level. But the HMDA data also reveal lending patterns at aggregate levels, across institutions. Disclosure of aggregate patterns can raise and focus attention on important policy questions concerning access to credit. To that end, researchers at the Federal Reserve have published numerous papers and articles. Most recently, staff published an article about patterns in the new loan-pricing data.1I will review a few of their findings. First, most home lenders make few, if any, higher-priced loans. In 2004, only about 500 out of the 8,850 reporting institutions made 100 or more higher-priced loans; the ten lenders with the largest volume of higher-priced loans accounted for about 40 percent of all such loans. (The FFIEC has not finished reviewing, processing, and editing the 2005 data, which were submitted in March of this year.) The 2004 data also show that 16 percent of borrowers took out higher-priced loans that year in the nation as a whole. This proportion may have increased from 2004 to 2005. For most loans, the Board’s regulation uses long-term interest rates to set the thresholds for reporting loan-price data, but mortgage loan rates more closely track short-term rates. Thus, a narrowing of the difference between short-term and long-term rates, such as occurred from 2004 to 2005, may increase the proportion of loans reported as higher-priced loans. The proportion of borrowers obtaining higher-priced loans is not geographically uniform but varies widely by region and by city. For example, in many of the metropolitan areas of the South and the Southwest, 30 percent to 40 percent of homebuyers taking out conventional loans in 2004 took out higher-priced loans. In other areas of the country, the proportion was much smaller. These differences may not be that surprising--other data show that credit scores tend to be lower on average in the South and the Southwest than elsewhere--but they may nonetheless warrant further analysis. Of course, public attention has focused on a notable variation in the incidence of higher-priced lending across racial and ethnic lines: blacks and Hispanics are much more likely than non-Hispanic whites to receive higher-priced loans. In 2004, 32 percent of black borrowers and 20 percent of Hispanic borrowers received higher-priced home purchase loans, but only 9 percent of non-Hispanic white borrowers did. In other words, black homebuyers received higher-priced loans more than three times as often as non-Hispanic white homebuyers, and Hispanic homebuyers received higher-priced loans more than twice as often as non-Hispanic whites. Certainly, differences of this magnitude are disturbing and raise important public policy questions. They also have led some to conclude that racial discrimination must play a role in the pricing of home loans. However, for the reasons I have explained above, we cannot use HMDA data alone to judge whether an institution has discriminated unlawfully or, therefore, whether unlawful discrimination is present in the market. Despite their limitations, the HMDA data supply a key insight into the aggregate disparities: they reflect in part a segmentation of the market by race and ethnicity. Black and Hispanic borrowers are more likely to obtain mortgage loans from institutions that tend to specialize in subprime lending. Now, at least part of this segmentation of the market by race and ethnicity may reflect objective differences in borrowers’ preferences or differences in credit-risk indicators, such as credit scores, that are not included in the HMDA data. Yet the segmentation may have more troubling causes, at least in part. Segmentation may stem from borrowers being steered to lenders that charge higher prices than what is warranted by the credit characteristics of these borrowers. Borrowers may also have different levels of financial literacy, or their knowledge of the mortgage lending process may be uneven--for example, they may not understand the importance of shopping and negotiating for the best loan terms. Additional research is needed to explore all of these, and perhaps other, hypotheses. The Board will continue to conduct and promote research that explores the racial and ethnic differences in the incidence of higher-priced lending. In June and July, the Board is conducting hearings on the home equity lending market. These hearings, which I am chairing, are intended to gather information about, among other things, how consumers select their lenders and loans. The Board’s 2007 biennial community development research conference will also provide a forum for research that may help explain differences in the incidence of higher-priced lending. The Federal Reserve’s Promotion of Community Development and Financial LiteracyI have discussed the Federal Reserve’s roles in regulation, supervision, and research. Now I will turn to its role in promoting community development and financial literacy. The Federal Reserve System uses HMDA data to help banks, community organizations, and other interested groups identify community development needs and opportunities. For example, the Federal Reserve Bank of Boston tabulates HMDA data for the New England region to help regional financial institutions, community organizations, and state and local governments access and use information about their area’s regional lending patterns. In addition, the Community Affairs Offices of the Federal Reserve System encourage and facilitate collaboration among financial institutions, governments, and community organizations to improve access to mortgage credit in traditionally underserved communities. The Federal Reserve also promotes financial literacy. Board staff provide strategic advice on developing financial literacy policies, programs, partnerships, and marketing to national initiatives, such as the Jump$tart Coalition, Operation HOPE, and the DollarWi$e Campaign of the Conference of Mayors. In a parallel effort, the Federal Reserve Banks support similar regional initiatives. The Federal Reserve also collaborates with other groups on research to develop successful financial education programs and identify the most effective way to deliver these programs to intended audiences. By these and other means, the Federal Reserve seeks to address gaps in consumers’ understanding of not only home loan transactions but also financial management more broadly. These gaps in consumer understanding may be contributing to disparities in the availability and price of home loans. In closing, I appreciate this opportunity to discuss the Federal Reserve’s regulation requiring lenders to disclose price and other data on home loans; how the Federal Reserve uses the data to improve fair lending supervision; and the Federal Reserve’s promotion of research, community development, and financial literacy. Footnotes 1.Robert B. Avery, Glenn B. Canner, and Robert E. Cook (2005),"New Information Reported under HMDA and Its Application in Fair Lending Enforcement,"Federal Reserve Bulletin, vol. 91 (Summer 2005), pp. 344-394.Return to text
Chairman Ben S. Bernanke At the Fifth Regional Issues Conference of the Fifteenth Congressional District of Texas, Washington, D.C. I am pleased to be here to discuss some strategies for helping families, particularly lower-income families, improve their economic and financial well-being. Families today face a financial marketplace that is increasingly complex, with numerous products and service providers from which to choose. Today I will touch on several approaches for helping people of modest means take advantage of these financial opportunities while managing the risks and avoiding possible pitfalls. Today’s Financial MarketplaceTechnological advances have dramatically transformed the provision of financial products and services in recent years. To cite just one example, the expanded use of computerized credit-scoring models, by reducing the costs of making loans and by increasing the range of assets that lenders can sell on the secondary market, has made possible the extension of credit to a larger group of borrowers. Indeed, we have seen an increasingly wide array of products being offered to consumers across a range of incomes, leading to what has been called the democratization of credit. Likewise, technological innovation has enhanced financial services, such as banking services, and increased the variety of financial products available to savers. The range of providers in consumer financial markets has also increased, with the number of nonbank entities offering credit and other financial services having risen particularly quickly. For example, a recent study of alternative providers of financial services found the number of nonbank check-cashing establishments doubled in the United States between 1996 and 2001.1Payday lending outlets, a source of credit that was almost non-existent a decade ago, now number more than 10,000.And data from the Survey of Consumers Finances, a triennial survey sponsored by the Federal Reserve Board, indicate that the share of households with a loan from a finance company increased from 13 percent in 1992 to 25 percent in 2004. Financial Challenges of Lower-Income FamiliesDespite the increased complexity of financial products and the wider availability of credit in many forms, U.S. households overall have been managing their personal finances well. On average, debt burdens appear to be at manageable levels, and delinquency rates on consumer loans and home mortgages have been low. Measured relative to disposable income, household net worth is at a fairly high level, although still below the peak reached earlier this decade. Families with low to moderate incomes, however, face special financial challenges. These families generally have less of a cushion to absorb unanticipated expenses or to deal with adverse circumstances, such as the loss of employment or a serious health problem. Results from the Survey of Consumer Finances show that the median net worth for households in the lowest income quintile--those whose income placed them in the bottom fifth of the population--was only $7,500 in 2004, well below the median for all survey respondents of $93,000.2The Survey data also indicate that households in the lowest quintile were significantly less likely than the average respondent to maintain a checking or savings account; almost 25 percent of those families were "unbanked," compared to less than 10 percent of families in the other income quintiles. The reasons given for not having an account varied: Some respondents said they would not write enough checks to make having an account worthwhile, but others were dissuaded by minimum balance requirements or said that they did not have enough money to justify opening an account. In some cases, a lack of knowledge about the services that banks offer or even a distrust of banks is likely a factor. The Survey also found that lower-income households are less able than others to manage their debts. A greater fraction of these households had debt-to-income ratios of 40 percent or more or had a payment past due at least sixty days. The data also reveal that only 40 percent of families in the lowest quintile own a home, compared with a homeownership rate of 69 percent among all families surveyed. Finally, the data on retirement account ownership show an even larger gap, with only 10 percent of lowest-quintile families holding a retirement account, whereas 50 percent of all families responding to the survey reported participation in some type of retirement savings plan. How can these disparities be addressed? Some general approaches to helping families of modest means build assets and improve their economic well-being include community economic development, financial education, and programs that encourage saving and investment. In the remainder of my remarks, I will discuss each of these approaches briefly and offer some insights into their effectiveness based on research and experience. Community Economic DevelopmentIn my time with the Federal Reserve, I have had a number of opportunities to meet with community economic development leaders--representatives of groups working to assist lower-income families become homeowners, start small businesses, better manage their finances, and save for the future. In fact, my first trip as a Federal Reserve Board member was to Brownsville, Texas, where I saw how a grassroots nonprofit organization is helping to build communities and to provide residents with the chance to build wealth through homeownership. The Community Development Corporation (CDC) of Brownsville works with multiple funding partners--governments at all levels, financial institutions, foundations, and corporations--to construct housing and to design innovative loan products that enable low-income families to qualify for mortgage credit. For example, because of the mix of funding sources, mortgage loans can be offered with features such as down‑payment assistance or a below-market interest rate. The CDC of Brownsville also offers a program that allows prospective homeowners to acquire "sweat equity" in a property by working on construction teams to help build their own new home and those of other participating families. As in the case of many community development organizations, the Brownsville CDC has also made financial education a critical element of its efforts to help lower-income residents improve their financial status. For example, participation in financial counseling or in an education program is typically required for a borrower to obtain a loan through the CDC or through one of its lending partners. However, the broader aim of these programs is to improve borrowers’ prospects for longer-term success in maintaining their credit and handling their overall finances. Since 1994, through this combination of leveraged financing arrangements and borrower education, the CDC of Brownsville has helped make homeownership possible for more than 2,500 low-income families. I cite the Brownsville example because of the opportunity that I had to learn about their work (and I recently had a similar opportunity to see some impressive community development efforts in the Anacostia neighborhood of the District of Columbia). But this localized approach to community development and wealth-building is playing out in neighborhoods throughout the country, in most cases through strategies tailored to the distinct needs of the particular community. Financial Education and Financial LiteracyFinancial education has not only been integral to community development but has also begun to play a larger role in the broader consumer market. Clearly, to choose wisely from the wide variety of financial products and providers available, consumers must have at least basic financial knowledge. People who understand the financial aspects of purchasing a home or starting a business, or who appreciate the importance of saving for children’s education or retirement, will almost certainly be economically better off than those without that vital information. Financial literacy can be acquired through many channels: in school, on the job, through community programs and counseling, or through self-education and experience. Studies generally find that people receiving financial education or counseling have better financial outcomes. For example, research that analyzed data on nearly 40,000 mortgage loans targeted to lower-income borrowers found that families that received individual financial counseling were less likely later to become delinquent on their mortgage payments.3Similarly, another study found that borrowers who sought and received assistance from a credit counseling agency improved their credit management, in particular, by reducing the number of credit accounts on which they carried positive balances, cutting overall debt, and reducing delinquency rates.4More broadly, the research shows that financial knowledge is correlated with good financial outcomes; for example, individuals familiar with basic financial concepts and products have been found to be more likely to balance their checkbook every month, budget for savings, and hold investment accounts.5 Studies that establish an association between financial knowledge and good financial outcomes are encouraging, but they do not necessarily prove that financial training and counseling are thecausesof the better outcomes. It could be, for example, that counseling is associated with better financial outcomes because the consumers who choose to seek counseling are the ones who are already better informed or more motivated to make good financial decisions. In medicine and other fields, researchers gain a better understanding of what causes what by doing controlled studies, in which some subjects are randomly assigned a particular treatment while others do not receive it. To translate this idea to the analysis of the effects of financial counseling, the Federal Reserve Board’s Division of Consumer and Community Affairs is collaborating with the Department of Defense to conduct a three-year study of the effects of financial education. This study will evaluate the impact of various educational programs on the financial decisions of soldiers and their families. It includes a treatment group of those receiving financial education, with the programs each family receives and when they receive it being determined randomly, and a control group of similar soldiers and their families who have not received this formal financial education. Because assignments of individuals to programs will be random, any observed changes in behavior can be more reliably attributed to the type and amount of counseling received. Among other things, the results of this study should help us better understand whether financial education leads to changes in behavior for participants in general or only for those at critical teaching moments, such as the period before making a major financial decision such as choosing a mortgage. I would like to say just a few words about the Federal Reserve’s broader role in promoting consumers’ understanding of financial products and services. Beyond conducting surveys of consumers and doing research, we work in a number of ways to support consumers in their financial decisionmaking. For example, through our consumer protection rule-writing authority, the Federal Reserve sets requirements that specify the information that must be disclosed to consumers about the terms and fees associated with credit and deposit accounts. These disclosures provide consumers with the essential information they need to assess the costs and benefits of financial services and compare products among different providers. We are currently reviewing many of our disclosures and plan to use focus groups and other methods to try to make these disclosures as clear and as user-friendly as possible. The Federal Reserve System also works to promote financial education and financial literacy through various outreach and educational activities. We provide a great deal of substantive financial information, including interactive tools for economic education, on our education websitehttp://www.federalreserveeducation.org/. The website links to a wide variety of financial education resources at the local, regional, and national levels. Additionally, the Federal Reserved Board collaborates with educational and community development organizations to support their efforts. Our national partners include the Jump$tart Coalition for Personal Financial Literacy, the Conference of Mayors’ DollarWi$e Campaign, Operation HOPE, the American Savings Education Council, and America Saves, among others. At the regional level, the twelve Federal Reserve Banks work with organizations to support financial education and financial literacy. For example, the Federal Reserve Bank of Cleveland has worked with community financial educators to form regional networks that combine resources and share best practices. The Federal Reserve Bank of Chicago sponsors "MoneySmart Week," partnering with banks, businesses, government agencies, schools, community organizations, and libraries to host activities designed to help consumers learn how to manage money. The Federal Reserve Banks of San Francisco and Minneapolis have worked with leaders in the Native American community to develop financial education materials. My recent testimony to Congress on financial literacy provided information on many other projects and programs.6The Federal Reserve will continue to make financial education a priority. Strategies to Encourage SavingEven if people know that they would be better off if they saved more or budgeted more wisely, we all know from personal experience that translating good intentions into action can be difficult. (Think about how hard it is to keep New Year’s resolutions.) The field of behavioral economics, which studies economic and financial decisions from a psychological perspective, has cast new light on consumer behavior and led to recommendations about how to improve people’s financial management. For example, studies of individual choices in 401(k) savings plans strongly suggest that workers do not pay adequate attention to their saving and investment decisions. Notably, despite the tax advantages of 401(k) contributions and, in some cases, a generous employer match, one-quarter of workers eligible for 401(k) plans do not participate. Studies have found, however, that if firms change the presentation of the plan from an "opt-in" choice to an "opt-out" choice, in which workers are automatically enrolled unless they actively choose to remain out of the plan, participation rates increase substantially.7The impact of changing from "opt-in" to "opt-out" is particularly evident for younger and lower-income workers, who may have less financial expertise. In addition, participants in savings plans evidently do not understand the various investment options that are offered. A survey by the investment management firm, The Vanguard Group, found that many plan participants cannot assess the risk inherent in different types of financial assets; for example, many did not appreciate that a diversified equity mutual fund is generally less risky than keeping most of one’s wealth in the form of the employer’s stock.8Indeed, employees appear to invest heavily in their company’s stock despite the fact that their income is already tied to the fortunes of their employer. More than one-quarter of 401(k) balances are held in company stock, and this high share arises not only from an employer match but from voluntary purchases as well.9 These insights into consumer behavior have prompted some changes in the design of retirement plans and in education programs focused on saving for retirement. More employers now feature automatic enrollment in their 401(k) plans in an effort to boost participation. Also, some have set the default investment option to a diversified portfolio that is rebalanced automatically as the worker ages or have set contribution rates to rise automatically over time in line with salary increases. However, although these changes in program design may boost saving and improve investment choices, they are not a substitute for continued financial education. Employers, including the Federal Reserve Board, offer financial education at the workplace to help their workers gain a better understanding of retirement savings options. Helping people appreciate the importance of saving and giving them the tools they need to translate that knowledge into action remain major challenges. ConclusionLet me close by observing that many factors influence consumer financial behavior. Financial education is clearly central to helping consumers make better decisions for themselves and their families, but policymakers, regulators, nonprofit organizations, and financial service providers must all help ensure that consumers have the tools and the information they need to make better decisions. Success can only come through collaborative efforts. I see much interest today in increased collaboration toward these objectives, both in Washington and around the country. Thank you for the opportunity to speak with you today. I encourage you to continue working together to help provide increased economic opportunity in your communities, and I wish you the best of luck in your efforts. Footnotes 1.Kenneth Temkin and Noah Sawyer (2004),"Analysis of Alternative Financial Service Providers (781 KB PDF),"report prepared for the Fannie Mae Foundation by the Urban Institute Metropolitan Housing and Communities Policy Center.Return to text 2.Brian K. Bucks,Arthur B. Kennickell, andKevin B. Moore(2006), "Recent Changes in U.S. Family Finances: Evidence from the 2001 and 2004 Survey of Consumer Finances (448 KB PDF),"Federal Reserve Bulletin.Return to text 3.Abdighani Hirad and Peter M. Zorn (2001),"A Little Knowledge Is a Good Thing: Empirical Evidence of the Effectiveness of Pre-Purchase Homeownership Counseling (466 KB PDF),"paper presented at "Seeds of Growth - Sustainable CommunityDevelopment: What Works, What Doesn’t and Why?"Return to text 4.Gregory Elliehausen, E. Christopher Lundquist, and Michael E. Staten (2003),"The Impact of Credit Counseling on Subsequent Borrower Credit Usage and Payment Behavior (305 KB PDF"(January), paper presented at "Seeds of Growth - Sustainable Community Development: What Works, What Doesn’t and Why?"Return to text 5.Jeanne M. Hogarth and Marianne A. Hilgert (2003),"Patterns of Financial Behaviors: Implications for Community Educators and Policymakers (1.7 MB PDF),"paper presented at "Seeds of Growth - Sustainable Community Development: What Works, What Doesn’t and Why?"Return to text 6.Chairman Ben S. Bernanke,Financial Literacy, Testimony Before the Committee on Banking, Housing, and Urban Affairs, U.S. Senate, May 23, 2006.Return to text 7.Brigitte Madrian and Dennis Shea (2001), "The Power of Suggestion: Inertia in 401(k) Participation and Savings Behavior,"Quarterly Journal of Economics,vol. 116 (November), pp. 1149-87.Return to text 8.The Vanguard Group (2002), "Expecting Lower Market Returns in the Near Term,"Vanguard Participant Monitor.Return to text 9.Jeffrey R. Brown, Nellie Liang, and Scott Weisbenner (2006), "401(k) Matching Contributions in Company Stock: Costs and Benefits for Firms and Workers,"Journal of Public Economics, vol. 90 (August), pp. 1315-46.Return to text
Mark W. Olson submitted his resignation Wednesday as a member of the Board of Governors of the Federal Reserve System, effective June 30, 2006. Olson, who has been a member of the Board since December 7, 2001, submitted his resignation to President Bush. He is leaving the Board to assume the chairmanship of the Public Company Accounting Oversight Board. He will not attend the June 28-29 meeting of the Federal Open Market Committee. "Mark’s leadership and wide experience in financial services and government were invaluable assets for the effective operation of both the Board and Federal Reserve System during his tenure," said Chairman Ben S. Bernanke. "He has been an exemplary colleague and I will miss his wise counsel. I wish him well in his new and vital role of overseeing the auditors of public companies." Olson, 63, was appointed by President Bush to fill an unexpired term on the Federal Reserve Board ending January 31, 2010. During his time on the Board, he has served as the Board’s administrative governor, as Chairman of the Board’s Committee on Consumer and Community Affairs, as a member of the Committee on Supervisory and Regulatory Affairs, and as a member of the Committee on Federal Reserve Bank Affairs. Before joining the Board, Olson served as staff director of the Securities Subcommittee of the Senate Banking, Housing, and Urban Affairs Committee. Prior to that, he was a partner with Ernst & Young LLP at its predecessor, Arthur Young & Company, and he was president and chief executive officer of Security State Bank, Fergus Falls, Minnesota. A copy of his resignation letter is attached.
The Federal Reserve Board on Tuesday released the minutes of its discount rate meetings from April 10 through May 10, 2006. The minutes are attached.
Chairman Ben S. Bernanke At the Stonier Graduate School of Banking, Washington, D.C. Good evening, and thank you for inviting me to speak to you. I am sure that, both in your academic studies and your practical experience, each of you has come to appreciate the rapid pace of change in the financial industry and the increasing complexity of that industry. My remarks will focus on an area that is evolving particularly quickly: the field of risk management. As you know, contemporary banking organizations are exposed to a diverse set of market and nonmarket risks, and the management of risk has accordingly become a core function within banks. Banks have invested in risk management for the good economic reason that their shareholders and creditors demand it. But bank supervisors, such as the Federal Reserve, also have an obvious interest in promoting strong risk management at banking organizations because a safe and sound banking system is critical to economic growth and to the stability of financial markets. Indeed, identifying, assessing, and promoting sound risk-management practices have become central elements of good supervisory practice. The evolution of risk management as a discipline has thus been driven by market forces on the one hand and developments in banking supervision on the other, each side operating with the other in complementary and mutually reinforcing ways. Banks and other market participants have made many of the key innovations in risk measurement and risk management, but supervisors have often helped to adapt and disseminate best practices to a broader array of financial institutions. And at times, supervisors have taken the lead, for example, by identifying emerging issues through examinations and comparisons of peer institutions or by establishing guidelines that codify evolving practices. The interaction between the private and public sectors in the development of risk-management techniques has been particularly extensive in the field of bank capital regulation, especially for the banking organizations that are the largest, most complex, and most internationally active. The current system of bank capital standards is the so-called Basel I framework, which was established internationally in 1988. Basel I was an important advance that resulted in higher capital levels, a more equitable international marketplace and--most relevant to my theme this evening--closer links between banks' capital holdings and the risks they take. However, as I will discuss, Basel I is becoming increasingly inadequate for our largest and most complex organizations. The activities of these organizations demand that we not only go beyond Basel I but that we continue to improve on today's most advanced methods of risk management. Thus, in the proposed new framework, known as Basel II, supervisors are seeking to draw upon industry best practice while also encouraging the industry to advance the risk-management frontier. The Evolution in Risk-Management PracticesRisk-management practices and bank supervision have both evolved over their long histories, but innovations in information technology and in financial markets have caused the pace of change to increase significantly over the past two decades. In particular, the management of market risk and credit risk has become increasingly sophisticated. Market RiskFor example, in the area of market risk, advances in data processing have enabled more analytically advanced and more comprehensive evaluations of the interest rate risks associated with individual transactions, portfolios, and even entire organizations. Institutions of all sizes now regularly apply concepts such as duration, convexity, and option-adjusted spreads in the context of analyses that ten years ago would have taxed the processing capabilities of all but a handful of large institutions. From the perspective of bank management and stockholders, the availability of advanced methods for managing interest rate risk leads to a more favorable risk-return tradeoff. For supervisors, the benefit is a greater resilience of the banking system in the face of a risk that figured prominently in some past episodes of banking problems. Other market risks are those inherent in trading and dealer activities. The management of such risks has also advanced significantly, in large part as a result of the growth and development of over-the-counter derivatives markets. Critical concepts such as value-at-risk and stress testing were pioneered and then became standard practice during the 1990s, advances that, again, were facilitated by the growth of computing power in that decade. Over the past few decades, banks' management of their capital-market risks has evolved from simple methods like the imposition of fixed position limits to increasingly sophisticated techniques that make use of extensive data analyses and a variety of new financial instruments. Supervisors have encouraged the continuous improvement of banks' systems for managing market risk by emphasizing that bankers bear responsibility for understanding and managing their risk profiles and by issuing guidance that, in some cases, includes industry advances in risk management. A case in point is the 1996 Market Risk Amendment to Basel I, in which supervisors incorporated industry innovations in the calculation of capital requirements for market risk, including the linking of capital charges to the outputs of banks' own value-at-risk models. Credit RiskThe banking industry has also made strides in managing credit risk. Until the early 1990s, the analysis of credit risk was generally limited to reviews of individual loans, and banks kept most loans on their books to maturity. Today, credit-risk management encompasses both loan reviews and portfolio analysis. Moreover, the development of new technologies for buying and selling risks has allowed many banks to move away from the traditional book-and-hold lending practice in favor of a more active strategy that seeks the best mix of assets in light of the prevailing credit environment, market conditions, and business opportunities. Much more so than in the past, banks today are able to manage and control obligor and portfolio concentrations, maturities, and loan sizes, and to address and even eliminate problem assets before they create losses. Many banks also stress-test their portfolios on a business-line basis to help inform their overall risk management. To an important degree, banks can be more active in their management of credit risks and other portfolio risks because of the increased availability of financial instruments and activities such as loan syndications, loan trading, credit derivatives, and securitization. For example, trading in credit derivatives has grown rapidly over the last decade, reaching $18 trillion (in notional terms) in 2005. The notional value of trading in credit default swaps on many well-known corporate names now exceeds the value of trading in the primary debt securities of the same obligors. Similarly, between 1990 and 2005, the market for loan syndications grew from $700 billion to more than $2.5 trillion, and loan trading grew from less than $10 billion to more than $160 billion. Asset-backed securitization has also provided a vehicle for decreasing concentrations and credit risk in bank portfolios by permitting the sale of loans in the capital markets, particularly loans on homes and commercial real estate. Risk-management principles are now ingrained in banks' day-to-day credit allocation activities. The most sophisticated banking organizations use risk-rating systems that characterize credits by both the probability of default and the expected loss given default. Consistent with the principles of the Basel II accord, the largest banks evaluate credit decisions by augmenting expert judgment with quantitative, model-based techniques. For instance, lending to individuals once relied mainly on the personal judgments of loan officers and was thus highly labor-intensive and subjective. Today, retail lending has become more routinized as banks have become increasingly adept at predicting default risk by applying statistical models to data, such as credit scores. Similarly, new analytical tools and techniques have made lending to corporate borrowers highly quantitative. Among these tools are models that estimate the risk-adjusted return on capital and thus allow lenders to price relevant risks before loan origination. Other tools include proprietary internal debt-rating models and third-party programs that use market data to analyze the risk of exposures to corporate borrowers that issue stock. Banks have also come to appreciate the importance of independent controls within the credit review and rating process. Innovations in technology have facilitated significant improvements in bank information systems, a development that the Basel II proposal also has encouraged. These systems increase the ability of bank management to identify, measure, and control key characteristics of portfolio risk.Evolution of Banking Supervision and Capital RegulationTo help fulfill their mandate to monitor and protect the safety and soundness of the financial sector, bank supervisors have consistently encouraged the development of risk management. Through guidance and the supervisory process, they have highlighted advances in sound risk-management practices and encouraged the industry to implement them broadly and consistently. Indeed, the four key elements of sound risk management that are widely accepted today were articulated more than a decade ago by Federal Reserve supervisors in guidance on managing derivatives activities and interest-rate risk. Those four elements are, first, good corporate governance--that is, active oversight by the board and senior management; second, the consistent application of policies, procedures, and limits; third, the use of appropriate risk-measurement techniques and reporting; and, fourth, the adoption of comprehensive internal controls. Since the mid-1990s, Federal Reserve supervisors have rated banks' risk-management capability as well as their financial condition as part of the examination process. Last year the Federal Reserve introduced a revised rating system for bank holding companies, under which each company receives a rating specifically for the quality of its risk management. This rating includes the four key elements of sound risk management that I just mentioned. The increasing supervisory focus on risk-management practices has also had a large influence on the practice of bank supervision. Traditional supervision consisted primarily of periodic assessments of loan quality. In the early 1990s, bank supervisors began to concentrate more on the forward-looking issues of risk and whether the bank has the infrastructure to manage risks. Under this approach, examiners focus their on-site reviews on those activities that appear to pose the greatest risk to the banking organization. The objective is to address weaknesses in management and internal controlsbeforefinancial performance suffers rather than being satisfied with identifying what went wrong after the fact. At the heart of the modern bank examination is an assessment of the quality of a bank's procedures for evaluating, monitoring, and managing risk, and of the bank's internal models for determining economic capital. These models link capital to risk-taking and help banking organizations compare risks and returns across diverse business lines and locations. Both robust risk management and strong capital positions are critical to ensure that individual banking organizations operate in a safe and sound manner that enhances the stability of the financial system. More generally, strong capital helps banks absorb unexpected shocks and reduces the moral hazard associated with the federal safety net. Why Basel II?In introducing the concept of risk-based capital ratios, Basel I established the important principle that regulatory capital requirements should be related to risk. At various times, of course, supervisors have also made important adjustments to the Basel I framework, such as the Market Risk Amendment mentioned earlier. Nonetheless, advances in risk management and the increasing complexity of financial activities have prompted international supervisors to review the appropriateness of regulatory capital standards under Basel I, particularly for the largest and most complex banking organizations. The supervisory organizations have agreed that Basel I, with its broad-brush system for setting the risk weights on various classes of bank assets, is increasingly inadequate for measuring risk and the appropriate level of capital for such firms. For example, under Basel I, a bank's regulatory capital requirement takes no account of the specific risk profile of its commercial loan portfolio, deterioration in asset quality, the risks of certain off-balance-sheet transactions or fee-based activities, and actions banks may take to mitigate balance sheet risks. Supervisors recognize that some of the largest and most complex banking organizations have already moved well beyond Basel I in the sophistication of their risk management and internal capital models. As risk-management practices continue to evolve, the gulf between the determinants of minimum regulatory capital under Basel I and what these banks actually do to manage risk will widen. Most important, if the regulatory capital required of these organizations does not adequately reflect the risks they are actually taking, the safety and soundness of the U.S. banking system may be jeopardized. The U.S. banking agencies have proposed the adoption of the Basel II accord because it links the risk-taking of large banking organizations to their regulatory capital in a more meaningful way than does Basel I and encourages further progress in risk management. It does this by building on the risk-measurement and risk-management practices of the most sophisticated banking organizations and providing incentives for further improvements. Moreover, by providing a framework to be applied consistently across banks, Basel II will make it easier for supervisors to identify banks whose capital is not commensurate with their risk levels and to evaluate emerging risks in the banking system as a whole. Broadly, the Basel II framework encompasses three pillars. Pillar 1 is risk-focused minimum regulatory capital requirements, pillar 2 is supervisory review, and pillar 3 is market discipline. Under pillar 1, the risk sensitivity of minimum risk-based capital requirements would be much greater than under the current accord. This greater sensitivity would be achieved by linking each banking organization's capital requirement to empirically based measures of credit and operational risk; these measures would be determined in part by risk parameters estimated by the banks, such as a loan's probability of default and its expected loss given default. The methods used to construct these estimates would be subject to regulatory requirements and supervisory guidance and review, including a requirement that the risk parameters used for pillar 1 be consistent with risk assessments actually used by the bank for its internal risk management. The pillar 1 treatment of credit risk also reflects more accurately the risk-reducing effects of guarantees, credit derivatives, and securitization, thus improving regulatory capital incentives for banks to hedge credit risks. The incorporation of operational risk in pillar 1 is based on the recognition that, indeed, operational failures are a potentially important risk that banks should seek to minimize. Pillar 2 of the new accord provides a consistent framework for improving supervisory assessments of capital adequacy and risk management. Under pillar 2, a bank would be required to maintain capital in excess of the regulatory minimums to capture the full set of risks to which the bank is exposed. These include liquidity risk, interest rate risk, and concentration risk, none of which are reflected in pillar 1. Currently, U.S. banking regulators assess a bank's overall capital adequacy as a normal part of the examination process. But the overall quality of assessments of capital adequacy, both by supervisor and by each bank, should improve greatly under Basel II because of the expanded information that will be available from pillar 1, from supervisory reviews under pillar 2, and from the bank's own analyses. Under pillar 3, banks will be required to disclose to the public the new risk-based capital ratios and more-extensive information about the credit quality of their portfolios and their practices in measuring and managing risk. Such disclosures should make banks more transparent to financial markets and thereby improve market discipline. Taken together, these three pillars provide a broad and coherent framework for linking regulatory capital to risk, for improving internal risk measurement and management, and for enhancing supervisory and market discipline at large, complex, internationally active banks. The three pillars build on the risk-management approaches of well-managed banks and better align regulatory and supervisory practices with the way the best-run banks are actually managed. As a result, Basel II will be better able than the current system to adapt over time to innovations in banking and markets. In addition, Basel II sets standards for the measurement and management of risk and for related disclosures that will give banks ongoing incentives to improve their practices in these areas. Although the Basel II framework provides the basis for modernizing the supervision of large, internationally active banks, I emphasize that it remains in many ways a work in progress.1Important details remain to be worked out, and much work remains to be done by both banks and supervisors to ensure that the system works as intended. The Federal Reserve Board has only recently approved a notice of proposed rulemaking, which invites comments from interested parties on all aspects of the proposed rules. The Federal Reserve and the other bank supervisors will review these comments carefully and will continue to consult widely. Under current plans, the transition to the new system will be gradual--no U.S. bank will have its capital requirement determined unconditionally by Basel II before 2012--and implementation will be subject to a number of safeguards. The supervisory agencies are also committed to continued review and adjustment of the system as experience accumulates. Proposals to Amend Basel IMany of you here today have also been following discussions about possible changes to the existing Basel I framework, proposals known collectively as "Basel IA." Only the very largest banking organizations will be required (or will choose) to adopt the Basel II framework. The vast majority of U.S. banks would be able to continue operating safely under Basel I as amended through the rulemaking process. The Basel I framework has already been amended more than twenty-five times in response to changes in the banking environment. The agencies believe that now is another appropriate time to amend the Basel I rules. Last fall, the U.S. banking agencies issued preliminary proposals that outline suggested changes to Basel I. In part, these proposed changes are meant to address concerns about the potential adverse competitive effects of Basel II. The Federal Reserve takes concerns about competitive effects seriously and has conducted substantial research on the topic. During the process to amend Basel I, we sought input from the industry and other interested parties. In view of those concerns, regulators have proposed changes to enhance the risk sensitivity of U.S. Basel I rules; we also remain vigilant about identifying potential competitive distortions that might be created with the introduction of Basel II. We are also mindful that amendments to Basel I should not be too complex or too burdensome for the multitude of smaller banks to which the revised rules would apply. That is, in amending Basel I for these institutions, we are trying to find the right balance between added risk sensitivity and regulatory burden. That balance is not necessarily easy to find. For example, one way to tie regulatory capital more closely to risk under Basel I would be to expand the number of factors used to determine risk weights--for example, to include credit scores or external credit ratings. The tradeoff is that incorporating additional risk measures is likely to increase the burden of calculating regulatory capital. The comments received suggest that institutions differ on how best to make this tradeoff. We will continue to evaluate this tradeoff and solicit further comments on how to proceed. ConclusionWe expect that risk management and banking supervision will continue to develop along parallel tracks. The Basel II framework represents an important effort by supervisors to integrate leading-edge risk management practices with the calculation of regulatory capital requirements. The ongoing work on this framework has already led large, complex banking organizations to improve their systems for identifying, measuring, and managing their risks. Indeed, banking organizations of all sizes have made substantial strides over the past two decades in their ability to measure and manage risks. The banking agencies will continue to promote supervisory approaches that complement and support banks' own efforts to enhance their risk-management capabilities. Footnotes 1.I addressed this theme in more detail in my recent speechBasel II: Its Promise and Its Challenges.Return to text
Governor Donald L. Kohn Before the Committee on Banking, Housing, and Urban Affairs, U.S. Senate Chairman Shelby, Senator Sarbanes, and members of the Committee, I am honored to have been nominated by President Bush to be the Vice Chairman of the Board of Governors of the Federal Reserve System and grateful to this Committee for scheduling this hearing so expeditiously. I have enjoyed a long and productive relationship with the Banking Committee and its staff over the years, working together to determine how the Federal Reserve can best contribute to the economic well-being of our citizens. As a governor and, if you confirm me, as Vice Chairman, I look forward to continuing to be a part of the shared pursuit of that goal. The Board's Vice Chairman has a very limited role under the Federal Reserve Act--to preside over the Board in the absence of the Chairman. By tradition and practice, however, the Vice Chairman has played a leadership role within the System. He or she has acted as the Chairman's deputy or alternate in important international groups, has headed ad hoc committees within the Board, System, or Federal Open Market Committee to help develop policy alternatives for consideration by the larger group, has helped the Chairman to lead the Board, and has worked closely with the Chairman in a variety of circumstances, including when responding to disturbances in the financial sector that had the potential of affecting the broader economy. The Federal Reserve faces considerable challenges today in meeting the responsibilities that you have given us: for fostering price stability and maximum employment at a time of rapid change in the U.S. and global economies; for helping maintain a safe and sound banking system and stable and efficient payments and financial systems in the face of innovations in financial instruments and institutions; and for protecting and educating consumers as they take advantage of the greater variety and sophistication of financial instruments available to them. I believe that my long and wide experience within the Federal Reserve--at a Reserve Bank and at the Board, on staff and as governor--along with my close working relationship with Chairman Bernanke will enable me to make even greater contributions to the work of the Federal Reserve as the Board's Vice Chairman should you choose to confirm me to this position.
The Federal Reserve Board on Friday announced the issuance of a consent Order of Assessment of a Civil Money Penalty against Bank of Tazewell County, Tazewell, Virginia, a state member bank. Bank of Tazewell County, without admitting to any allegations, consented to the issuance of the Order in connection with its alleged violations of the Board's Regulations implementing the National Flood Insurance Act. The Order requires Bank of Tazewell County to pay a civil money penalty of $4,000, which will be remitted to the Federal Emergency Management Agency for deposit into the National Flood Mitigation Fund. A copy of the Order is attached.
The Federal Reserve Board on Wednesday announced the issuance of an Order of Prohibition against Trampas B. Riggs, formerly a loan officer at an Orlando, Florida branch of Regions Bank, Birmingham, Alabama. Mr. Riggs, without admitting to any allegations, consented to the issuance of the Order based on his alleged participation in violations of law, unsafe or unsound practices, and breaches of fiduciary duty in connection with the falsification of bank books and records and false statements to bank officials relating to (a) a mortgage he obtained from the bank; and (b) his alleged use of the mortgage proceeds to fraudulently purchase, without the knowledge or consent of either the buyer or the seller, real property that a bank mortgage applicant had an option to purchase. A copy of the Order is attached.
The Federal Reserve Board, on Thursday, announced the issuance of a consent Order to Cease and Desist and Assessment of Civil Money Penalties against First Baird Bancshares, Inc., Bedford, Texas, a registered bank holding company, and its president and chairman of the board of directors, Joe E. Sharp. The order was issued to address respondents’ alleged violation of section 3 (a)(3) of the Bank Holding Company Act, 12 U.S.C. §1842(a)(3). The respondents, without admitting to any allegations, agreed to a cease and desist order and to each pay civil money penalties in the amount of $87,500. A copy of the Order is attached.
Chairman Ben S. Bernanke At the International Monetary Conference, Washington, D.C. I am pleased to be here this afternoon to participate in the International Monetary Conference. In my remarks, I will provide a brief update of the economic outlook for the United States and discuss the implications of that outlook for monetary policy. It is reasonably clear that the U.S. economy is entering a period of transition. For the past three years or so, economic growth in the United States has been robust, reflecting both the ongoing re-employment of underutilized resources as well as the expansion of the economy’s underlying productive potential, as determined by factors such as productivity trends and the growth of the labor force. Although we cannot ascertain the precise rates of resource utilization that the economy can sustain, we can have little doubt that, after three years of above-trend growth, slack has been substantially reduced. As a consequence, a sustainable, non-inflationary expansion is likely to involve some moderation in the growth of economic activity to a rate more consistent with the expansion of the nation’s underlying productive capacity. It bears emphasizing that productivity growth seems likely to remain strong, supported by the diffusion of new technologies, capital investment, and the creative energies of businesses and workers. Thus, productive capacity should continue to expand over the next few years at a rate consistent with solid growth of real output. Real gross domestic product grew rapidly in the first quarter of this year, but the anticipated moderation of economic growth seems now to be under way. Consumer spending, which makes up more than two-thirds of total spending, has decelerated noticeably in recent months. One source of this deceleration is higher energy prices, which have had an adverse impact on real household incomes and weighed on consumer attitudes. As had been expected, recent readings also indicate that the housing market is cooling, partly in response to increases in mortgage rates. To be sure, the data on home sales and construction have been somewhat erratic from month to month, reflecting weather conditions, statistical noise, and other factors. However, overall, housing activity has softened relative to the high levels of last summer, and the rate of house-price appreciation appears to have lessened. A slowing of the real estate market will likely have the effect of restraining other forms of household spending as well, as homeowners no longer experience increases in the equity value of their homes at the rapid pace seen in recent years. Gains in payroll employment in recent months have been smaller than their average of the past couple of years, and initial claims for unemployment insurance have edged up. These developments are consistent with the softening in the pace of overall economic activity that seems to be under way. That said, going forward, relatively low unemployment and rising disposable incomes may counter to some extent the factors tending to restrain household spending. Although spending by the household sector is showing signs of moderation, other sectors of the economy retain considerable momentum. According to the available data, business investment appears to have risen briskly, on net, so far this year. In particular, investment in nonresidential structures, which had been weak since 2001, seems to have picked up appreciably, raising the possibility that increased nonresidential construction may absorb some of the resources released by the slowing housing sector. Spending on equipment and software is also on a strong upward trend, and backlogs of orders for capital goods are still rising. Business investment is being supported by high rates of profitability and capacity utilization. Credit conditions for businesses are favorable: Although market participants appear to have become more attuned to risks in recent weeks, corporate bond spreads remain low, and banks are well capitalized and willing to lend. Globally, output growth appears poised to exceed 4 percent for the fourth consecutive year--a strong performance that will support the U.S. economy by continuing to stimulate our exports of goods and services. The buoyant global economy does present some challenges, however. In particular, the increased world demand for crude oil and other primary commodities, together with the limited ability of suppliers to expand capacity in the short run, has led to substantial increases in the global prices of those goods. Those price increases are a partial offset to the forces supporting global growth and are also a source of inflationary pressure. Longstanding concerns about global imbalances remain with us as well. Along with greater national saving in the United States, increased domestic demand in countries with current account surpluses and a greater flexibility of exchange rates more broadly would help to reduce those imbalances over time. Should U.S. economic growth moderate as expected, sustaining the global expansion will require a greater reliance by our trading partners on their own domestic spending as a source of growth. Consumer price inflation has been elevated so far this year, due in large part to increases in energy prices. Core inflation readings--that is, measures excluding the prices of food and energy--have also been higher in recent months. While monthly inflation data are volatile, core inflation measured over the past three to six months has reached a level that, if sustained, would be at or above the upper end of the range that many economists, including myself, would consider consistent with price stability and the promotion of maximum long-run growth. For example, at annual rates, core inflation as measured by the consumer price index excluding food and energy prices was 3.2 percent over the past three months and 2.8 percent over the past six months. For core inflation based on the price index for personal consumption expenditures, the corresponding three-month and six-month figures are 3.0 percent and 2.3 percent. These are unwelcome developments. Although the rate of pass-through from the higher prices of energy and other commodities to core consumer price inflation appears to have remained relatively low, the cumulative increases in energy and commodity prices have been large enough that they could account for some of the recent pickup in core inflation. Despite recent increases in spot oil prices, futures markets imply that oil prices are not expected to continue rising. The realization of that outcome would reduce one source of upward pressure on inflation. However, the volatility of these and other commodity prices is such that possible future increases in these prices remain a risk to the inflation outlook. Subdued growth in most broad measures of nominal labor compensation and the ongoing expansion of labor productivity have held down the rise in unit labor costs, the largest component of business costs. Anecdotal reports suggest, however, that the labor market is tight in some industries and occupations and that employers are having difficulty attracting certain types of skilled workers. Finally, some survey-based measures of longer-term inflation expectations have edged up, on net, in recent months, as has the compensation for inflation and inflation risk implied by yields on nominal and inflation-indexed government debt. As yet, these expectations measures have remained within the ranges in which they have fluctuated in recent years, but these developments bear watching. With the economy now evidently in a period of transition, monetary policy must be conducted with great care and with close attention to the evolution of the economic outlook as implied by incoming information. Given recent developments, the medium-term outlook for inflation will receive particular scrutiny. There is a strong consensus among the members of the Federal Open Market Committee that maintaining low and stable inflation is essential for achieving both parts of the dual mandate assigned to the Federal Reserve by the Congress. In particular, the evidence of recent decades, both from the United States and other countries, supports the conclusion that an environment of price stability promotes maximum sustainable growth in employment and output and a more stable real economy. Therefore, the Committee will be vigilant to ensure that the recent pattern of elevated monthly core inflation readings is not sustained. Toward this end, and taking full account of the lags with which monetary policy affects the economy, the Committee will seek a trajectory for the economy that aligns economic activity with underlying productive capacity. Achieving this balance will foster sustainable growth and help to forestall one potential source of inflation pressure. In addition, the Committee must continue to resist any tendency for increases in energy and commodity prices to become permanently embedded in core inflation. The best way to prevent increases in energy and commodity prices from leading to persistently higher rates of inflation is by anchoring the public’s long-term inflation expectations. Achieving this requires, first, a strong commitment of policymakers to maintaining price stability, which my colleagues and I share, and, second, a consistent pattern of policy responses to emerging developments as needed to accomplish that objective. Our economy has reaped ample rewards in recent years from the achievement and maintenance of price stability. Although challenges confront us, as they always do, I am confident that we will be able to preserve those hard-won benefits while promoting sustainable economic growth.
The Federal Reserve Board, jointly with the Department of the Treasury’s Financial Crimes Enforcement Network (FinCEN), on Friday issued an advance notice of proposed rulemaking (ANPR) that seeks information on the potential benefit and burden of lowering or eliminating the $3,000 threshold in the recordkeeping rule for funds transfers and transmittals of funds by financial institutions. The ANPR requests public comment on the potential benefit of a lower threshold to law enforcement and the potential burden of a lower threshold to the financial system. In addition, the ANPR seeks input from the general public on the potential impact that a lower threshold might have on their funds transfer or transmittal of funds practices. The Board concurs with FinCEN that this is an appropriate time to reassess the threshold in the recordkeeping rule in light of developments since adoption of the original rule in 1995. Specifically, the Financial Action Task Force, the international anti-money laundering and terrorist financing standard setter, recommends a de minimis threshold no higher than $1,000 (or €1000). In addition, advances in information technology may have reduced the burden to financial institutions of the recordkeeping requirement since adoption of the original rule. The Board and FinCEN request that comments on the ANPR be submitted within sixty days of publication in the Federal Register, which is expected shortly. The ANPR is attached. Attachment (63 KB PDF)
The Federal Reserve Board on Thursday requested comment on proposed revisions to Part I of its Policy on Payments System Risk (PSR policy), which addresses risk management in payments and settlement systems. The proposed revisions update and revise the policy in several ways. First, the Board is proposing to incorporate into its PSR policy the international risk management standards for central counterparties recently developed by the Committee on Payment and Settlement Systems (CPSS) of the central banks of the Group of Ten countries and the Technical Committee of the International Organization of Securities Commissions (IOSCO). These standards, published by the Bank for International Settlements in a report titledRecommendations for Central Counterparties(Recommendations for CCP), will serve as the Board's minimum standards for central counterparties identified as systemically important and subject to the Board's authority. This proposed change is consistent with past revisions that incorporated into the PSR policy theCore Principles for Systemically Important Payment Systems(Core Principles) andRecommendations for Securities Settlement Systems(Recommendations for SSS), developed by the CPSS and CPSS-IOSCO, respectively. In support of incorporating the Recommendations for CCP, the Board is proposing revisions to the scope of Part I of the PSR policy with regard to central counterparties. As revised, a central counterparty would be included as one of several types of systems that fall under the term "settlement system" as defined in the revised policy. The Board is also proposing revisions to the purposes of Part I of the policy to clarify its views on risk management for payments and settlement systems generally and its expectations for systems subject to its authority. Finally, the Board is proposing revisions that would establish an expectation that systemically important systems disclose publicly self-assessments against the principles or minimum standards incorporated in the PSR policy. Specifically, systemically important systems subject to the Board's authority will be expected to complete and disclose publicly self-assessments against the Core Principles, Recommendations for SSS, or Recommendations for CCP, as appropriate, and demonstrate the extent to which the system meets the principles or minimum standards. The Board is proposing several guidelines to assist a system operator in developing a self-assessment consistent with the Board's expectations. The Board is also making other technical changes to its PSR policy. Comments are requested by September 22, 2006. The Board's notice is attached.
The Federal Reserve Board on Thursday requested public comment on a consultation paper that is intended to help the Board obtain broader information on intraday liquidity management issues and to lay the groundwork for discussions about the long-term evolution of its Payment System Risk (PSR) Policy. The consultation paper seeks information from the financial industry and other interested parties on their experience in managing intraday liquidity, credit, and operational risks associated with Fedwire funds transfers and associated transactions. In particular, the paper requests views on potential changes in market practices, depository institution and Federal Reserve Bank operations, and the Board's PSR Policy that could reduce one or more of these risks, while maintaining or improving the efficiency of the payments system over the long run. The consultation paper includes a brief list of possible changes that might further assist depository institutions, financial markets, and the Federal Reserve Banks in managing intraday risks. Items on the list should be regarded as preliminary and intended for further study. The consultation paper stems from the Federal Reserve's ongoing review of the long-term effects of market, operational, and policy changes by the financial industry and the Federal Reserve on intraday liquidity and risks in the financial markets and the payments system, including account overdrafts at the Reserve Banks. Comment is requested by December 15, 2006. The Board's consultation paper is attached.
Statement by Chairman Ben S. Bernanke on the retirement of Jack Guynn, President of the Federal Reserve Bank of Atlanta:"Jack Guynn's forty-two-year career at the Federal Reserve Bank of Atlanta, including more than a decade as President, is an outstanding example of dedicated public service. Jack worked tirelessly for the betterment of the Federal Reserve System. I will miss his friendship as well as his valued insights at the Federal Open Market Committee table."
The Federal Reserve Board on Monday announced the termination of the enforcement action listed below. Terminations of enforcement actions are listed on the Federal Reserve's public web site,www.federalreserve.gov/boarddocs/enforcement, as they occur. Citigroup Inc., New York, New York andCitiFinancial Credit Company, Baltimore, MarylandCease and Desist Order dated May 27, 2004Terminated June 22, 2006
Governor Donald L. Kohn At the Federal Reserve Bank of Boston's 51st Economic Conference, Chatham, Massachusetts Thank you for the opportunity to participate in this conference on global imbalances, a topic of growing importance. Although I will touch on global imbalances, I would like to focus on globalization’s potential influence on inflation and the associated implications for monetary policy. It seems a natural focus for a policymaker at a central bank, and, indeed, several of my colleagues on the Federal Open Market Committee (FOMC) have also addressed this issue in recent months.1As you would see from reading their remarks, no consensus has yet emerged about how globalization has been influencing recent inflation developments, and part of my intention today is to illustrate some of the considerable challenges that are involved in attempting to identify the extent to which the recent pickup in the pace of global economic integration has influenced inflation dynamics in the United States.2 Of course, the trend toward greater international integration of product and financial markets has been established for quite a while; the share of U.S. economic activity involved in international trade (measured by nominal exports plus imports as a share of nominal gross domestic product) has been rising since the early 1970s. However, this trend has accelerated markedly over the past fifteen years or so. In particular, the economies of eastern Europe became more integrated into the global economy, and China, India, and some other East Asian market economies have emerged as important players in the global trading system. Although inflation is ultimately a monetary phenomenon, it seems natural to expect, as others have argued, that these developments would have exerted some downward pressure on inflation in the United States. The opening up of China and India, in particular, represents a potentially huge increase in the global supply of mainly lower-skilled workers. And it is clear that the low cost of production in these and other emerging economies has led to a geographic shift in production toward them--not just from the United States but also from other formerly low-cost producers such as Mexico, Korea, Singapore, and Taiwan.3Trade surpluses in China and in other East Asian countries have increased sharply over the past decade, and from a U.S. perspective, the ratio of imported goods to domestically produced goods has accelerated noticeably in recent years. However, the extent of the disinflationary effect of this shift in the pace of globalization is less obvious. Many U.S. goods and most services are still produced domestically with little competition from abroad. In addition, the significant expansion of production in China and elsewhere has put substantial upward pressure on the prices of oil and other commodities, many of which are imported for use as inputs to production in the United States. Indeed, the effects of globalization on domestic inflation need not even be negative, especially in today’s environment of strong global growth. One challenge in assessing the effect of increased globalization is the lack of research on this issue. At a research conference on modeling inflation held at the Federal Reserve Board last fall, none of the papers even touched on issues related to globalization. And, although some new and interesting research is emerging from places like the International Monetary Fund and the Bank for International Settlements, much of this work is still quite preliminary.4Nevertheless, the existing research does highlight several channels through which globalization might have helped to hold down domestic inflation in recent years. These channels include the direct and indirect effects on domestic inflation of lower import prices, a heightened sensitivity of domestic inflation to foreign demand conditions (and perhaps less sensitivity to domestic demand conditions), downward pressure on domestic wage growth, and upward pressure on domestic productivity growth.5 In trying to clarify my own thinking about the likely magnitude of these effects, I find that a useful starting point is a simple reduced-form equation that attempts to explain movements in inflation and then to ask whether and how the statistical relationships embedded in this equation have been affected by globalization. The equation is a standard one in use at the Board and elsewhere. It relates core consumer price inflation--using, say, the index for core personal consumption expenditures (PCE) or the core consumer price index (CPI)--to resource utilization, lagged inflation, changes in relative prices of food and energy, and changes in relative import prices. Using this framework, we can look for the effect of globalization in several ways. First, we can look for influences that are directly controlled for in the model--notably the influence on domestic inflation of changes in import prices. Second, we can look for evidence of globalization-related structural change in the model by examining the stability of the parameter estimates. Third, we can see whether we have omitted from the standard model any variables that might be interpreted as representing changes in globalization. And, finally, we can look for evidence of model errors that would be consistent with the hypothesis that globalization has been restraining inflation. I will focus in particular on the past five years or so, which, judging from the data on U.S. trade shares, is when the pace of globalization appears to have picked up. I will start with the import price channel--the hypothesis that increased globalization has depressed import prices and thus domestic inflation. Importantly, the estimated strength of this channel should capture not only the direct effects of import prices on the cost of living in the United States but, also, at least a portion of the indirect effects of actual and potential import competition on the prices of goods produced domestically. In the reduced-form model that I’ve just described, the effects of import prices on inflation show up quite clearly; furthermore, the estimated effects appear to have increased over time, with the increase apparently stemming primarily from the upward trend in the share of imported consumer goods in household spending.6 We can use the model to get a rough idea of how relative changes in import prices have influenced domestic inflation by simulating how core consumer prices would have behaved if relative import prices had instead remained constant. In particular, the increase in core import prices since the mid-1990s has averaged about 1-1/2 percentage points less per year than the increase in core consumer prices. According to the model simulation, which also builds in the associated reduction in inflation expectations, the direct and indirect effects of this decline in the relative price of imports held down core inflation by between 1/2 and 1 percentage point per year over this period, an estimated effect that is substantially larger than it would have been in earlier decades. However, much of the decline in import prices during this period was probably driven by movements in exchange rates and the effects of technological change on goods prices rather than by the growing integration of world markets.7 In addition, import prices have risen at about the same average pace as core consumer prices over the past several years and thus no longer appear to be acting as a significant restraint on inflation in the United States. This step-up in the rate of change of import prices obviously reflects, to some extent, recent movements in the dollar, especially its depreciation in 2004. However, it also reflects large increases in the prices of a number of imported commodities, which have been attributed in part to the rapid expansion of activity in China and other Asian countries. A second hypothesis is that increases in global capacity have held down U.S. inflation in recent years by limiting the ability of U.S. producers to raise prices in response to increases in the domestic costs of production. At a basic level, the elevated profit margins of U.S. producers over the past few years seem inconsistent with this hypothesis. But it does raise a broader issue about the determinants of inflation--that is, whether U.S. inflation is now less sensitive to domestic demand pressures and more sensitive to foreign demand conditions than it was earlier. In the context of the inflation model, we can examine this issue in two ways. First, we can look for evidence that the coefficients on the domestic output or unemployment gaps have fallen over time. Second, we can add a measure of foreign excess demand to the model to see whether it helps to explain domestic inflation in recent years. With regard to the first test, we do find evidence that the coefficient on the unemployment gap has fallen in the United States. In particular, the coefficient from a model estimated over the past twenty years appears to be about one-third lower than when the model is run over a forty-year period. Of course, globalization is not the only potential explanation for this result, and numerous other researchers have cited persistently low inflation and the improved credibility of monetary policy as having played a more important role. In fact, in rolling regressions, the timing of the decline in the sensitivity of inflation to the unemployment gap appears to be too early to be associated with the more recent acceleration in the pace of globalization. This aspect of the globalization hypothesis would be bolstered if the decline in the sensitivity of inflation to domestic demand was accompanied by an increased sensitivity to foreign demand. Efforts to find such a link have met with mixed results, with some researchers having found large effects and others having found no effect.8Our own analysis of this issue indicates that these results are sensitive to how the foreign output gap is defined and to how the inflation model is specified, suggesting that any effect may not be especially strong. Similarly, the evidence that globalization has helped to restrain unit labor costs in recent years is mixed. One hypothesis is that the increase in the supply of low-skilled workers associated with the emergence of China and other East Asian countries as low-cost centers of production has put downward pressure on the growth of nominal wages in the United States. However, a model of changes in aggregate labor compensation that is similar in structure to the price-inflation model that I described earlier does not detect a stable relationship between measures of globalization (for example, import price changes or the BIS estimates of the foreign output gap) and aggregate wage dynamics in the United States. That said, the recent changes in some, though not all, measures of aggregate compensation seem to have been somewhat lower than such models would have predicted. Of course, several purely domestic factors could help to account for any shortfall, such as the aftereffects of the unusually sluggish recovery in job growth early in this expansion or a possible downward drift in the nonaccelerating-inflation rate of unemployment. But it also is a pattern that would be consistent with downward pressures from an expansion in global labor supply. In support of this link, some cross-section studies have found a relationship between industry wage growth and import penetration, while the research on wage inequality tends to relate some of the relative decline in wages of low-skilled workers to trade, although in both types of studies the effects are generally relatively small.9Similarly, research from the Federal Reserve Bank of New York shows a modest relationship between exchange rate fluctuations and wage growth, with larger effects evident for the wages of lower-skilled workers.10 A second possibility is that globalization has restrained unit labor costs by raising productivity. Increasing volumes of trade should bolster productivity as economies concentrate their resources in those sectors in which they are relatively more efficient. But I have seen little direct evidence on the extent to which globalization may have boosted aggregate productivity growth in the United States in recent years. Nevertheless, research at the Board finds that multinational corporations, which may have the greater opportunities to realize efficiencies by shifting production locations, accounted for a disproportionate share of aggregate productivity growth in the late 1990s.11And some microeconomic studies have found a relationship between global engagement and productivity at the firm level.12Thus, it seems possible that the persistently high growth rates of multifactor productivity in recent years may partly be due to the productivity-enhancing effects of globalization. In this regard, I would note that a potential shortcoming of my approach to assessing the effects of globalization on inflation is that these effects may be too recent to be captured adequately by the data. That is, it may be too soon for globalization to have generated statistically observable changes in the parameter estimates or structure of the standard inflation model. Nonetheless, if the influence of globalization on inflation is as substantial as many claim, we might have expected the standard model to have had difficulty in predicting recent inflation trends. For example, if recent increases in world labor supply are restraining domestic unit labor costs to a significant degree or if there are other important influences on inflation that are related to globalization but difficult to quantify in the context of the standard model, we would expect to have seen sizable model errors over the past several years. Again, the evidence points to some limited influence of globalization on U.S. inflation. If we use out-of-sample dynamic simulations of a model for core PCE price inflation estimated from 1985 through the end of 2001, we find that, although the model overpredicts inflation over the past several years, the errors average only 0.1 to 0.2 percentage point per year, considerably less than one might have expected given the anecdotes in the popular press. In contrast, the forecast errors from a model of core CPI inflation are larger (averaging roughly 1/2 to 1 percentage point per year since mid-2001), perhaps suggestive of some influence from globalization. What do I conclude from all of this evidence? My own assessment is that, quite naturally, the greater integration of the U.S. economy into a rapidly evolving world economy has affected the dynamics of inflation determination. Unfortunately, huge gaps and puzzles remain in our analysis and empirical testing of various hypotheses related to these effects. But, for the most part, the evidence seems to suggest that to date the effects have been gradual and limited: a greater role for the direct and indirect effects of import prices; possibly some damping of unit labor costs, though less so for prices from this channel judging from high profit margins; and potentially a smaller effect of the domestic output gap and a greater effect of foreign output gaps, but here too the evidence is far from conclusive. In particular, the entry of China, India, and others into the global trading system probably has exerted a modest disinflationary force on prices in the United States in recent years. Moreover, we should recognize that these disinflationary effects could dissipate or even be reversed in coming years. They reflect, at least in part, the global imbalances that are the subject of this conference, rather than just the integration of emerging-market economies into the global trading system. For example, the fact that China and some other emerging-market economies have resisted upward pressure on their exchange rates and are running trade surpluses has undoubtedly contributed to their disinflationary effects on the rest of the world. The prices of their exports are lower than they would be if market forces were given greater scope in foreign exchange markets, and they are supplying more goods and services to the rest of the world than they themselves are demanding. These imbalances are not likely to be sustained indefinitely. The elevated rates of national saving in these economies--and, in some, relatively restrained rates of investment--are not likely to persist in the face of ongoing improvements in the functioning of their financial markets, increases in the depth of their product markets, and fuller development of economic safety nets. As individuals in these countries are increasingly drawn to investing at home and consuming more of their wealth and as their real wages catch up to past productivity gains, the upward pressures on their currencies will intensify, their demand will come into better alignment with their capacity to produce, cost advantages will decline, and these economies will exert less, if any, downward pressure on inflation in the United States. This observation brings me to my final point, which is about monetary policy. Clearly, the greater integration of the world’s economies does leave the United States more open to influences from abroad. In one sense, a more open economy may be more forgiving as shortfalls or excesses in demand are partly absorbed by other countries through adjustments of our imports and exports. And, to the extent that the United States can draw upon world capacity, the inflationary effect of an increase in aggregate demand might be damped for a time. But we are also subject to inflationary forces from abroad, including those that might accompany a shift to a more sustainable pattern of global spending and production, or those that might emanate from rising cost and price pressures. Moreover, a smaller response of inflation to domestic demand also implies that reducing inflation once it rose could be difficult and costly. And, from another perspective, integrated financial markets can exert powerful feedback, which may be less forgiving of any perceived policy error. For example, if financial market participants thought that the FOMC was not dedicated to maintaining long-run price stability--a notion that I can assure you is not correct--they would be less willing to hold dollar-denominated assets, and the resulting decline in the dollar would tend to add to inflationary pressures. Clearly, policymakers need to factor into their decisions the implications of globalization for the dynamics of the determination of inflation and output. In the end, however, policymakers here and abroad cannot lose sight of a fundamental truth: In a world of separate currencies that can fluctuate against each other over time, each country’s central bank determines its inflation rate. If the FOMC were to allow the U.S. economy to run beyond its sustainable potential for some time, inflation would eventually rise. And, this pickup would become self-perpetuating if it became embedded in inflation expectations. Thus, while a better understanding of the implications of globalization will aid in our understanding of inflation dynamics, it is also clear that such developments do not relieve central banks of their responsibility for maintaining price and economic stability. Footnotes 1.For example, Richard W. Fisher (2005), "Globalization and Monetary Policy," Warren and Anita Marshall Lecture in American Foreign Policy, Harvard University, November 3; and Janet L. Yellen (2006), "Monetary Policy in a Global Environment," speech delivered at The Euro and the Dollar in a Globalized Economy Conference, University of California at Santa Cruz, May 27.Return to text 2.Deb Lindner and William Wascher, of the Board’s staff, contributed to these remarks. The views expressed are my own and are not necessarily shared by my colleagues on the Board or the FOMC.Return to text 3.See, for example, International Monetary Fund (2005), "Mexico: Staff Report for the 2005 Article IV Consultation," October 2005; and Alan G. Ahearne, John G. Fernald, Prakash Loungani, and John W. Schindler (2003), "China and Emerging Asia: Comrades or Competitors?" International Finance Discussion Paper 2003-789 (Washington: Board of Governors of the Federal Reserve System, December).Return to text 4.Thomas Helbling, Florence Jaumotte, and Martin Sommer (2006), "How Has Globalization Affected Inflation?"IMF World Economic Outlook(Washington: IMF, April), chapter 3; Claudio Borio and Andrew Filardo (2006), "Globalization and Inflation: New Cross-Country Evidence on the Global Determinants of Domestic Inflation," unpublished paper, Bank for International Settlements, March.Return to text 5.Ken Rogoff also argues that globalization has increased the incentives for central banks to keep inflation low (Kenneth S. Rogoff, 2003, "Globalization and Global Disinflation," inMonetary Policy and Uncertainty: Adapting to a Changing Economy," a symposium sponsored by the Federal Reserve Bank of Kansas City, pp. 77-112.)Return to text 6.As is standard in such models, we use a price measure for "core" imports, defined as imports of goods excluding energy, computers, and semiconductors. When the change in relative import prices is weighted by the import share, the coefficient in the model is fairly stable.Return to text 7.Research at the Board examined the direct effects of Chinese exports on global import prices from the mid-1990s to 2002 and found only a modest effect of U.S. import prices. Of course, it is possible that China’s influence on import prices has grown in recent years as its trade share has expanded. Refer to Steven B. Kamin, Mario Marazzi, and John W. Schindler (2004), "Is China ‘Exporting Deflation’?" International Finance Discussion Paper 2004-791 (Washington: Board of Governors of the Federal Reserve System, January).Return to text 8.Borio and Filardo (2006) and Gamber and Hung (2001) found that foreign resource utilization had sizable effects on U.S. inflation, while Tootell (1998) found little to no effect. Refer to Borio and Filardo, "Globalization and Inflation"; Edward N. Gamber and Juann H. Hung (2001), "Has the Rise in Globalization Reduced U.S. Inflation in the 1990s?"Economic Inquiry,vol. 39 (January), pp. 58-73; and Geoffrey M. B. Tootell (1998), "Globalization and U.S. Inflation," Federal Reserve Bank of Boston,New EnglandEconomic Review(July/August), pp. 21-33.Return to text 9.See, for example, Helbling, Jaumotte, and Sommer, "How Has Globalization Affected Inflation?"; and William R. Cline (1997),Trade and Income Distribution(Washington: Institute for International Economics).Return to text 10.Linda Goldberg and Joseph Tracy (2003), "Exchange Rates and Wages," unpublished paper, Federal Reserve Bank of New York.Return to text 11.Carol Corrado, Paul Lengermann, and Larry Slifman (2005), "The Contribution of MNCs to U.S. Productivity Growth, 1977-2000," unpublished paper, Board of Governors of the Federal Reserve System.Return to text 12.For example, Mark E. Doms and J. Bradford Jensen (1998), "Productivity, Skill, and Wage Effects of Multinational Corporations in the United States," in D. Woodward and D. Nigh, eds.,Foreign Ownership and the Consequences of Direct Investment in the United States: Beyond Us and Them(Westport, Conn.: Quorum Books), pp. 49-68.Return to text
Governor Mark W. Olson At the American Bankers Association's Regulatory Compliance Conference, Orlando, Florida Thank you for the invitation to speak today on an issue of great interest to many of us, that is, compliance-risk management and supervisory expectations. Over the last few years, legal and regulatory compliance breakdowns have attracted increased attention across the financial industry. Fortunately, most of you have responded to your evolving compliance risks by investing in effective compliance-risk management programs. However, now and then, headline-grabbing incidents of noncompliance continue to capture public attention, especially when they involve such sensitive areas as fair lending and the Bank Secrecy Act (BSA). Conferences such as this are valuable opportunities for you, as compliance experts, to share experiences and successful approaches to controlling compliance risk. To assist you in your efforts to fine-tune your compliance-risk management programs, I'd like to give you a sense of what Federal Reserve examiners look for when they conduct examinations. I will also take a few minutes to address our more focused work in two particularly important areas of regulatory compliance: compliance with BSA requirements and Home Mortgage Disclosure Act (HMDA) data reporting requirements. Otherwise, I will not focus on examinations that look solely at the level of compliance with specific laws and regulations but will focus on how examiners assess the adequacy of a compliance-risk management program and its ability to manage the organization's compliance risk. Compliance-Risk ManagementOverall, a banking organization's compliance-risk management program should enable it to adequately identify, measure, monitor, and control the compliance risks involved in its various products and lines of business. These are fundamental principles not only for compliance-risk management, but also for sound management of credit, market, liquidity, and operational risk. It's worth taking a moment to definecompliance risk. It is the risk of legal or regulatory sanctions, financial loss, or damage to reputation and franchise value that may arise when an organization fails to comply with laws, regulations, or standards or codes of conduct of self-regulatory organizations applicable to the business activities and functions of the banking organization. While all banking organizations should have a program in place to effectively manage compliance risk, these programs can vary considerably, depending on the size, complexity, and geographic reach of the banking organization and the inherent risks of its activities. As with other types of risk, large multinational organizations will require more elaborate and formal compliance-risk management systems to address their broader and typically more complex range of financial activities and to provide senior managers and directors with the information they need to monitor and direct activities. Therefore, our supervisory expectations regarding an organization's risk-management program, and more specifically the scope of an examination, will vary according to the organization's size and complexity. Assessing the Adequacy of Compliance-Risk Management ProgramsThe Federal Reserve's supervisory approach in the area of compliance-risk management is consistent with our long-standing focus on the adequacy of banking organizations' overall management of risk. To this end, Federal Reserve examiners assess the quality of a banking organization's systems for identifying, measuring, and containing its risks. While historically there has been a greater emphasis on risk management in the areas of credit, market, operational, and liquidity risk, because of the growing complexity of banking operations and their regulatory frameworks the Federal Reserve is taking a greater interest in banking organizations' ability to manage their compliance risk. Scoping the ExaminationGenerally, a Federal Reserve examination team begins by defining the scope of the examination; this is when examiners determine the areas of focus and level of scrutiny. The scope of the examination will vary depending on the nature and circumstances of the banking organization. For example, as part of the scoping exercise, examiners will consider previous examination and audit findings to determine whether the organization has a satisfactory history of compliance or whether there have been previous concerns about its compliance-risk management program. The examination team will also review the organization's compliance-risk assessment. Depending on its quality, the risk assessment can also help direct the resources of the examination team. Altogether, the information gleaned from examination and audit findings and a current risk assessment will directly affect the scope of the examination, including the level and area of transaction testing required to assess the adequacy of the compliance-risk management program. At institutions with a less satisfactory record, a more extensive review will be necessary. Federal Reserve examinations for compliance-risk management are not designed to be gotcha games in which examiners look for one-time breaches of specific regulations or laws. Rather, these examinations are designed to assess the adequacy of the structure and processes the institution uses for managing compliance risk. Examiners are expected to look for the bigger picture and to look at the effectiveness of the program (including policies and processes) for managing the organization's compliance risk. We want to understand whether you have the controls in place to manage the risk ofyourorganization. As with all areas of risk management, our expectations--and therefore the scope of many examinations in this area--are framed by an emphasis on I'll give you a sense of some of the key components that examiners are likely to look for when assessing these fundamental areas. Board and Senior Management OversightA successful compliance-risk management program starts at the top of the organization. It is essential that the board of directors takes the lead by requiring a top-to-bottom compliance culture that is incorporated into the organization's day-to-day operations and is well communicated by senior management so that all staff members understand their compliance responsibilities and their roles in implementing the enterprise-wide program. Examiners will look to understand the board and senior management's roles in setting and communicating the compliance culture within the organization. Examiners will also look to see that roles and responsibilities are clearly defined and communicated throughout the organization and that senior management and staff understand their compliance obligations. In order for the board and senior management to carry out their responsibilities, they need to understand the organization'scurrentcompliance risks. We have seen organizations that have experienced challenges as a result of a lack of clarity in this area as they grow and diversify. Examiners will determine whether the organization has an effective risk assessment that accurately identifies its compliance risks and whether material risks are communicated to the board. Effective risk assessment measures the risk presented by clients, products and services, and geographic exposure within specific business lines or activities and aggregates these risks across the organization. Risk assessment is critical not only to ensure that the board and senior management is well informed. It also serves as the foundation for risk-based policies, procedures, and internal controls. Examiners will look to understand the organization's risk-assessment process. For example, they will look to see the degree to which the business lines are involved, how frequently the risk assessment is updated, and how it incorporates new products, services, or legal entities. Human and financial resources are, of course, critical to effective performance.Consequently, examiners will assess whether senior management ensures that the compliance program has sufficient financial resources and a sufficient number of qualified and well-trained staff to carry out its responsibilities effectively. Policies and ProceduresPolicies and procedures essentially define and communicate the key goals and processes of an organization's compliance program. Examiners will look to see whether policies and procedures provide for adequate risk identification, assessment, measurement, and control. As I mentioned a few moments ago, clearly communicated roles and responsibilities are a characteristic of an effective compliance program. Toward that end, examiners will also look to determine whether policies clearly delineate accountability and lines of authority across the organization's activities. Examiners also expect to see a well-defined process for ensuring that when compliance risks or potential breaches are identified they are elevated to the appropriate level, in keeping with the risk to the organization. Procedures for doing so should be well-communicated to staff throughout the organization. Overall, policies and procedures must be kept current, and, as with the risk assessment, examiners will look to see whether information gleaned from the compliance program operations is used to further tailor compliance policies, procedures, and controls to specifically address the inherent environment as it evolves. Internal ControlsInternal controls are a particularly crucial element of a compliance-risk management program. Examiners will verify whether the organization has established and implemented an effective system of internal controls, including appropriate reporting lines and separation of duties, as well as positive and negative incentives. An essential part of the internal control framework is periodic testing to determine how well the framework is operating, so that any required remedial actions can be taken. The frequency of testing should be risk-based and should involve, as appropriate, sample transaction testing, the sample size being determined by volume and the degree of risk of the activity. Examiners will carefully assess the scope and quality of the testing of the compliance program. Part of this assessment will include determining whether the testing was performed with appropriate independence. Examiners will also look to understand the specific delineations of responsibilities between the internal audit, compliance, and other independent functions or third parties. These delineations will vary by organization, but all roles should be clearly defined and communicated. Examiners will also look at how well compliance-testing exceptions are reported to senior management and resolved by business-line management. They will assess methods for tracking exceptions until the exceptions are resolved; this assessment will include examining the organization's provisions for escalating unresolved exceptions to higher levels in the organization, including the board of directors. Independence and separation of duties are also issues of importance beyond compliance testing. For example, in the case of large complex banking organizations that may have a corporate compliance function, examiners will be interested in understanding how the compliance function maintains its independence from the business lines it advises on compliance requirements and the implementation of required controls. In cases in which the compliance function has responsibility for monitoring and testing, examiners will assess whether procedures are established to ensure an adequate degree of independence and objectivity. Monitoring and ReportingAs I mentioned, the fundamental purpose of compliance-risk management programs is to identify, monitor, and manage compliance risk more effectively. Monitoring involves identifying and communicating compliance concerns to the appropriate parties within the organization. Monitoring and reporting enable senior management and the board to effectively carry out their respective responsibilities. We have seen organizations silo critical compliance information rather than share it with all levels of the organization, which can handicap an organization's ability to identify systemic risks. As a result, examiners are interested in whether a compliance program is designed to monitor and report compliance concerns. The level of sophistication of banking organizations' monitoring activities generally varies according to the size and complexity of the organization, and examiners' expectations will vary accordingly. For example, large complex banking organizations are typically supported by information systems that provide management with timely reports related to compliance with laws and regulations at the transaction level. Examiners will look to see whether these reports generally address monitoring and testing activities, actual or potential material compliance deficiencies or breaches, and new or changing compliance requirements. They will also assess whether reports are designed to ensure that information on compliance is communicated to the appropriate levels within the organization. TrainingTraining on policies, procedures, and associated controls is a component of compliance-risk management that should not be overlooked. Examiners will determine whether the banking organization's training program ensures that compliance policies, procedures, and controls are well understood and appropriately communicated throughout the organization. While the depth and breadth of training that an employee receives depends on that employee's role and responsibilities, examiners generally assess whether staff at all levels understand the organization's compliance culture, general compliance-risk issues, and high-level compliance policies and procedures. Supervisory Consistency and the Bank Secrecy ActAs banking organizations become more complex, consistency in the agencies' supervisory approach has become even more critical. The Federal Reserve views supervisory consistency as a means of enhancing supervision and reducing burden. This is particularly essential in the area of regulatory compliance, and specifically with regard to compliance with the Bank Secrecy Act and its regulations. The Federal Reserve includes a review of BSA compliance within every full-scope safety-and-soundness examination. For larger banking organizations that are subject to continuous supervision, the Federal Reserve conducts a series of targeted BSA reviews over the course of the supervisory cycle. This, combined with off-site monitoring, allows the Federal Reserve to maintain a current understanding of BSA compliance within the organizations that are subject to its supervision. On-site examinations are essential to ensure that the BSA program is operating effectively. Because of the complexity of banking organizations today, a number of institutions may be subject to the supervision of an increasing number of regulators. A consistent examination approach among regulators is critical in order to achieve a consolidated view of risk management within an organization, and also to reduce burden on banking organizations. Our work with the Federal Financial Institutions Examination Council to develop theBank Secrecy Act/Anti-Money Laundering Examination Manual, which was released last summer, marked an important step forward in our effort to ensure consistent supervision in the area of BSA compliance. Through the manual, the agencies have emphasized a banking organization's responsibility to establish and implement risk-based policies, procedures, and processes to comply with the BSA and safeguard its operations from money laundering and terrorist financing. The agencies are currently updating the manual and plan to release the revised version this summer. I have been told that the revised manual will include not only updates reflecting changes in regulations and supervisory guidance over the course of the past year, but also, among other things, additional guidance on developing a BSA/AML risk assessment, which is the foundation of effective risk-based controls. HMDA Data and Fair Lending ExaminationsExaminations to evaluate a banking organization's adherence to fair lending laws and regulations are also a routine component of consumer compliance examinations conducted by the Federal Reserve. HMDA data play an important role in examinations of those banking organizations that are required to report the data. Examiners probe that data to understand how the bank is responding to credit needs and serving its community. The data are rich in many respects. They contain information about applicants' and borrowers' race or ethnicity, sex, income level, and property location. And, since 2004, the HMDA data have also included price information about certain loans with prices that exceed thresholds set by the Board. The HMDA data help examiners better focus the fair lending examination. Particularly for banks with larger portfolios, the data, including any available pricing data, are incorporated into statistical management systems that analyze lending patterns and help direct the examination process to aspects of the bank's program that may warrant a closer look. Even in smaller banks where a statistical analysis cannot be performed, the HMDA data can be used to start the fair lending review. However, as we know, HMDA data have limitations. For example, the data do not include credit-risk factors such as credit scores and loan-to-value ratios. Because of these limitations, the examination process looks at additional information about a lender's practices, and about particular loans, before any conclusions are drawn. Examiners consider--together with HMDA data--information derived from consumer complaints, risks apparent from various business lines, and the adequacy of the institution's compliance-risk management program. Since examiners will be looking at the data, it would be advisable for a bank to make a review of the data a component of a comprehensive fair lending compliance program and Community Reinvestment Act strategy. In fact, examiners will look carefully at analyses of HMDA data performed by a bank and talk with the bank to understand the reasons for any disparities in lending patterns. The bank is probably in the best position to understand what the HMDA data suggest about its ability to reach prospective borrowers. Consequently, its own assessment is useful to an examiner establishing the fair lending examination scope. Examiners want to know how banks have addressed any disparities and how the bank's analysis has led to any changes in controls that were made to ensure that policies are followed. I want to emphasize that, as with compliance-risk management programs, the breadth of a banking organization's program and system review should be commensurate with the size and complexity of its operations, the range of its products, and the demographics of its markets. Beyond this review of HMDA data, examiners evaluate whether an organization's fair lending compliance framework makes it possible to identify, monitor, and effectively control risks. Examiners are looking for a clear articulation by the board of directors of the institution's lending strategy, including defined risk parameters and the execution of appropriate risk-measurement and risk-mitigation initiatives. Examiners will evaluate the extent to which management controls reflect the risk associated with the institution's lending strategy. As with the broader area of compliance-risk management, examiners will look closely at how the compliance culture established at the top of the organization filters down into the everyday responsibilities of business-line managers and how those managers are held accountable for compliance. ConclusionBecause of the growing complexity of banking organizations, the Federal Reserve is currently considering whether more-tailored guidance in the area of enterprise-wide compliance-risk management is warranted. In the coming months, we will continue to engage with you to better understand your successful approaches to identifying, monitoring, and managing risk across your organizations. Thank you.
Governor Randall S. Kroszner At the Bankers' Association for Finance and Trade, New York, New York Governor Randall S. Kroszner presented identical remarks at the Institute of International Bankers, New York, New York, on June 16, 2006 Today I want to talk about some new and exciting developments in bond markets around the world. The motivation for my discussion is the current puzzling situation of a relatively flat yield curve combined with relatively low real and nominal long-term interest rates, which has occurred both in developed economies and in emerging markets. I will explore some possible explanations for the pattern and will focus on changes in the prospects for and risks to the long-term inflation outlook, particularly in emerging-market economies. In particular, I will highlight how financial innovations and international competitive pressures, combined with a better public understanding of the costs of inflation and changes in the institutions of central banking, have helped improve the credibility of central banks and inflation outcomes in many emerging markets. Until recently, many emerging-market countries simply did not have a yield curve because there was effectively no market for debt issued in domestic currency beyond a very short horizon. The credibility of central banks has been crucial to this deepening of the domestic capital market, which is typically associated with higher economic growth. I am optimistic that these developments will continue, as I believe that the move toward low inflation rates reflects important technological and institutional factors that are likely to persist. Nevertheless, there are still risks, which underscore the importance of continuing to reap the benefits of improved central bank behavior and credibility in emerging markets and around the world. Global Developments in the Bond MarketIn February 2005, former Federal Reserve Board Chairman Alan Greenspan noted a puzzle in the U.S. economy related to the slope of the yield curve and the level of the long-term interest rate.1Long-term interest rates had remained low and stable despite a solid economic recovery and a sustained period of monetary policy tightening during which the target federal funds rate went from 1 percent to 2-1/2 percent. When he first publicly noted this "conundrum," as he called it, the ten-year Treasury yield was just over 4 percent. Today, despite an additional 250 basis points of increase in the target federal funds rate, the nominal ten-year Treasury yield is roughly 5 percent, still very low by historical standards, compared to an average of more than 7-1/2 percent since 1980. The combination of a rising short rate and a relatively stable long rate has led to a very flat yield curve. During the last quarter-century, for example, the difference between the yield on the ten-year Treasury note and the yield on the three-month Treasury bill has been roughly 1-3/4 percent (or, to be exact, 179 basis points from 1980 to the present). During the last year, that difference has been less than 50 basis points and is currently less than half of that. Thus, this essentially flat slope is atypical in U.S. experience. I am sure that you are all familiar with the simple relationship between short-term and long-term interest rates. The yield on a ten-year bond, for instance, can be thought of as a series of consecutive forward rates. If you could borrow and lend at the same rate as the U.S. Treasury, then you could lock in a three-month loan ten years from now by borrowing for ten years and three months and simultaneously lending the same principal for ten years. The difference between the interest you pay and the interest you earn on this transaction determines the implied forward rate ten years from today.2The forward rate reflects not only the market expectation of the future short-term interest rate but also a "term premium" to compensate for the risk in committing to extend credit so far in the future, including the risk of future inflation.3 At any point in time, then, we can calculate the short-term forward rate ten years ahead based on the yield curve of U.S. Treasury coupon securities.4This "far forward" rate makes the conundrum even more puzzling because it reached historically low levels of almost 4-1/4 percent last year, more than 200 basis points below its average since 1990, and has rebounded only somewhat this year. In real terms, the far forward rate calculated from inflation-indexed securities is similarly below its long run average. The U.S. bond market conundrum has occurred in parallel with similar developments in foreign bond markets. In major industrial countries, bond yields have trended down, in some cases reaching historical lows recently. Yields are also low in real terms, as measured by inflation-indexed bonds. Far-forward short rates in recent years have also reached unusually low levels in many industrial countries. The most interesting and, I believe, perhaps least studied recent developments in the bond markets concern the changes in emerging markets. While it is well known that the yield spreads on dollar-denominated bonds of emerging-market governments included in the EMBI+ index are near all time lows (even taking into account the recent rise), two phenomena in emerging markets have received less attention. One is the development of markets for longer-dated fixed-coupon bonds issued in local currencies. This phenomenon is, from my perspective, quite remarkableand belies the assertion that the "original sins" of bad policy from the past have doomed the development of domestic currency bond markets in many emerging markets. The recent lengthening of maturities of domestic-currency debt markets has, in many cases, not only extended a yield curve but effectively created a local currency yield curve that simply did not exist earlier. Since 2000, ten-year nominal fixed-coupon bonds in local currency have been introduced in Brazil, Colombia, Indonesia, Mexico, and Russia, while Korea issued a ten-year fixed coupon bond in 1995. To illustrate in more detail, the governments of Mexico and Korea have been able extend the average maturity of their local-currency debt significantly in just the past few years. The Mexican government issued ten-year maturities in 2001 and then 20-year maturities in 2003. The proportion of local-currency debt in Mexico maturing within one year was nearly 90 percent in 2002 and is now below 75 percent. (I have included floating rate debt in the one-year maturity category.) The Korean government continues to increase the proportion of its domestic currency debt in longer maturities, with the one-year-and-under segment falling from roughly one-half in 1999 to one-quarter by the end of last year. Two, bond yields inlocalcurrencies of emerging-market countries have also declined. It is perhaps not surprising that, given their high rates of saving and generally high level of economic development, the governments of Hong Kong and Korea can borrow at close to industrial-country levels. More notable, however, is that the Mexican government can borrow in pesos at a ten-year maturity at rates that have averaged roughly 9 percent. And Mexico is not unique in this regard. Other middle-income emerging markets with ten-year local-currency fixed rate bond yields in the single digits include Chile, Malaysia, Russia, and Thailand, to name but a few. For countries with longer maturities, implied short-term interest rates five years ahead also have been declining and have reached very low levels, although there have been some increases in the past few months. What is driving these changes? There are a number of complementary, not alternative, explanations. Explanations for the Low Real Bond YieldsChairman Bernanke has suggested that an excess of ex ante global savings relative to global investment, sometimes referred to as a global savings glut, has held down real interest rates around the world and encouraged capital inflows to the United States.5Some of the factors behind this savings glut include the surge in revenues of oil and commodity exporters, a reduction in fiscal deficits in some Latin American countries, and a retreat in Asian investment demand from the boom that preceded the late 1990s financial crises while saving rates stayed high in Asia. The savings glut story helps to explain the real component of low bond yields as well as the pattern of global capital flows, which was Chairman Bernanke’s focus. Another factor behind declining real yields in some emerging markets is that their improved fiscal situation not only increases national saving but also calms fears about the ability of governments to service their debt. However, there is also a nominal aspect of low global bond yields. In the rest of my talk, I would like to emphasize the worldwide decline of inflation and perceived inflation risk as a key contributor to low nominal bond yields. Explanations for the Low Nominal Bond YieldsInflation rates in major industrial and developing regions have trended down over the past twenty-five years. Compared with the period 1980 to 1999, median inflation rates from 2000 to 2004 fell from 5 percent to 2 percent in industrialized countries and from 14 percent to 4-1/2 percent in emerging markets, according to the most recent statistics from the International Monetary Fund. Not long ago, annual inflation rates in Brazil and Mexico at times exceeded 100 percent. But during the past decade, Brazilian and Mexican inflation rates have remained low. In particular, inflation in Brazil did not spike up after its financial crises and sharp currency depreciations in the late 1990s. Given Brazil’s history of hyperinflation, this stability is especially remarkable. Brazil did experience a small spike of inflation around its presidential election in 2002, but even this was minor by historical standards. The pattern of low inflation is seen across many countries, large and small. A few years ago I did some research that showed how inflation rates around the world have fallen significantly since the 1970s and 1980s, both in terms of averages and medians.6Indeed, the IMF’s April 2006World Economic Outlooknotes that average inflation rates in both the industrial countries and the developing countries in recent years are at their lowest levels since at least the early 1970s. More important, I found that the worst inflation performers (specifically the 10 percent of the countries of the world experiencing the highest inflation) had much lower inflation rates than the worst performers from the 1970s, 1980s, and 1990s. Thus, the worst behavior is not as bad as it once was. Do markets expect low inflation to persist in the long run? To answer this question, we can look at measures of expected inflation. Consensus Economics surveys hundreds of professional forecasters in numerous countries each April. The surveys allow us to examine forecasts of inflation around the world six to ten years ahead beginning in 1996. The latest observation, in April 2006, for example, is the forecast of a given country’s average consumer price inflation rate from 2012 through 2016. For both a representative sample of industrial economies (Euro area, Japan, the United States, and the United Kingdom) and emerging-market economies (Brazil, China, Korea, and Mexico), we observe substantial declines from the late 1990s to today. These forecasts have been low and stable in both industrial and many important developing countries in recent years. The surveys thus provide one indication that markets do expect low inflation to persist. The volatility of inflation has also declined notably, suggesting that perceived inflation risk may have declined as well. For the industrial countries, inflation volatility (measured as a twenty-quarter rolling standard deviation of consumer price inflation) has declined from the 1980s to the 1990s to the period since 2000. Although it has since drifted up just a bit due to volatility in oil prices, it remains at or near its lowest level in the last quarter-century. For the emerging markets, the decline in volatility is even more dramatic. Brazil, in particular, was off the chart much of the time before the late 1990s. Volatility of inflation in China, Korea, and Mexico is now at levels similar to those of the industrial countries, and volatility in Brazil is not much higher. Overall, the combination of lower and less volatile inflation around the world has led to a reduction in inflation expectations and lower perceived inflation risk, hence a lower inflation uncertainty premium in long rates. I believe that these factors have been important contributors to the lower long-term yields and the flattening of yield curves, particularly in emerging markets. The existence of markets for long-term nominal government and corporate debt is powerful evidence of the faith that investors place in a future environment of price stability. Factors Behind the Global Move to Price StabilityFour broad factors lie behind the move to price stability, especially in emerging markets, and these factors tend to reinforce each other. Each factor affects the cost-benefit tradeoff of pursuing a high-inflation policy. The first factor, which gets surprisingly little attention in my view, is financial innovation that alters the ability and incentive of a government to pursue a high-inflation policy.7I put the innovations into two main categories, developments in information technology and physical dollarization, both of which effectively increase potential competition among currencies. Financial innovations make it easier for citizens to move their assets out of the local currency should their government resort to an inflation tax. The dollarizations that followed the high-inflation episodes in Latin America and the former Soviet Union, for example, significantly reduced the costs of switching away from a local currency for small-value transactions. The specific channels by which financial innovations could have affected competition among currencies are many: Given these innovations, a government that pressures a central bank to pursue an inflationary policy gets much less benefit for each unit increase in inflation because people can more easily switch out of the local currency. In other words, the inflation tax becomes much more difficult and costly to levy because citizens can more easily avoid the tax by using an alternative money. The second and closely related factor behind disinflation is deregulation and competition in a globalized marketplace. The collapse of the centrally-planned economies has led many countries to turn increasingly to private markets to deliver growth and progress and reduce the role of government. Technology has helped to increase global competition by shrinking the barriers of time and distance. Again, there are several channels by which globalization and competition may have affected the cost-benefit tradeoff in pursing inflation: The third factor is that economists and the public have learned from painful experience about the costs of inflation.9The end of the Bretton Woods gold standard in the early 1970s was associated with the first global and sustained peacetime inflation in history. Although the specific experiences differed across countries, public opinion eventually turned strongly against allowing inflation to continue, and policymakers responded to this pressure by taking stronger measures to achieve price stability. This learning process helped to drive some of the financial innovations that I discussed earlier, which, in turn, helped households and businesses to economize on holding inflationary assets. Economists and central bankers also devoted great attention to understanding the causes and consequences of inflation, providing the intellectual underpinning to policies oriented toward price stability. The fourth factor I wish to mention relates to changes in the institutions of central banking that may have increased the costs of pursuing high-inflation policies. The most notable change is the increased independence of many central banks and the corresponding reduced control of the fiscal authorities over monetary policy. Central bank independence reduces the ability of a government to "raid the cookie jar" through a surprise inflation tax. In most cases, central bank independence can be reversed by a majority vote of parliament. But having to resort to such a vote is a greater obstacle to inflationary finance than previous arrangements allowed, especially given the public’s increased sensitivity and aversion to inflation. Central bank independence has typically been granted in conjunction with an explicit mandate that makes achieving low and stable inflation one of the goals of monetary policy. Central bank independence with a mandate that includes price stability increases the credibility of monetary policy with regard to achieving low inflation. Policy is credible because the central bank’s objectives are clear to the public and the central bank can be held accountable for failing to achieve its objectives. When citizens are more aware of the costs of inflation and when governments would reap lower benefits from a high-inflation policy, institutional reforms that will make central banks more credible and independent may be more likely to be adopted and sustained.10The fundamental forces I mentioned earlier--financial innovation, deregulation, globalization, and public understanding about the costs of inflation--provided the impetus for fighting inflation and opened the political path to institutional reforms, such as central bank independence, that enhance central bank credibility. Once in place, these reforms made further progress against inflation easier and raised the costs of backsliding. As the benefits of stable prices accrue and as financial markets deepen and become more sophisticated, the benefits of sound economic policies will help to create support for institutional reforms that make returning to inflation harder for future governments. Benefits of Price StabilityWhile it is well known that low and stable inflation improves the environment for investment planning and avoids many costs and disruptions associated with frequent price adjustments, I want to focus on a few of the many benefits that are particularly relevant for emerging markets. Price stability boosts growth through deepening financial markets. With stable prices, savers and investors have more confidence about the ultimate value of their deposits and loans. Stable prices encourage the growth of financial intermediaries and financial markets. As noted above, many emerging markets have recently experienced a deepening of their local financial markets with greater issuance of longer-dated paper. According to numerous studies, there is a strong link between financial market development and economic growth. Thus, the greater credibility of central banks that permits more development of the local markets can have an economic benefit beyond the financial sector.11 The development of long-term local-currency bond markets may also help governments and firms plan long-term infrastructure and investment projects that boost economic development. Although such debt markets are only one of many factors that can lower the costs of long-term planning and enhance the ability to undertake long-term investments, the development of these markets, particularly when accompanied by lower real rates, help to support longer-horizon projects and reduce the effect of foreign exchange movements on such activities. A better fiscal outlook, which might arise from higher and more stable growth as well as better long-term planning, also increases financial market confidence and development and thus further boosts growth and reinforces prospects for continued price stability. This virtuous cycle appears to be happening in key emerging markets that were long plagued with poor fiscal situations, such as Brazil and Mexico. In the 1980s and early 1990s, for example, public sector deficits in these countries often exceeded 10 percent of GDP. Since the late 1990s, deficits have been diminished. Maintaining this ProgressAlthough I am an optimist, I would be remiss if I did not point out some risks to this otherwise rosy scenario. The difficulty of reaching agreement in the Doha Round of trade negotiations highlights the risk of renewed protectionism. Trade barriers reduce both domestic and international competition, one of the key factors behind low inflation, and make all countries poorer. Barriers to free flow of goods, services, and capital would also diminish the force of other factors outlined above that help to reduce inflationary pressures. We must not forget the examples of high inflation and hyperinflation from the past: They hold important lessons about the costs of not maintaining price stability. That sound policies are the basis for solid economic growth should not be forgotten. Footnotes 1.Alan Greenspan (2005), statement before the Senate Committee on Banking, Housing, and Urban Affairs, presenting the Federal Reserve Board’s "Monetary Policy Report to the Congress," February 16.Return to text 2.Strictly speaking, this calculation requires the use of zero-coupon bonds, but it can be approximated using coupon securities.Return to text 3.Don H. Kim and Jonathan H. Wright (2005), "An Arbitrage-Free Three-Factor Term Structure Model and the Recent Behavior of Long-Term Yields and Distant-Horizon Forward Rates," Finance and Economics Discussion Series 2005-33 (Washington: Board of Governors of the Federal Reserve System, August).Return to text 4.Typically we calculate an "instantaneous" forward rate, which is the limiting value of a sequence of forward rates with maturities declining toward zero.Return to text 5.Ben S. Bernanke (2005), "The Global Saving Glut and the U.S. Current Account Deficit," Sandridge Lecture at the Virginia Association of Economists, March 10.Return to text 6.Randall S. Kroszner (2003), "Currency Competition in the Digital Age," in David E. Altig and Bruce D. Smith, eds.,Evolution and Procedures in Central Banking(New York: Cambridge University Press), pp. 275–99.Return to text 7.I discussed aspects of this factor in my presentation at a May 2001 conference at the Federal Reserve Bank of Cleveland, cited above.Return to text 8.Kenneth S. Rogoff (2003), "Globalization and Global Disinflation," inMonetary Policy and Uncertainty: Adapting to a Changing Economy: A Symposium(Federal Reserve Bank of Kansas City, Aug. 28–30), pp. 77–112.Return to text 9.This hypothesis was raised in the discussion of Rogoff (2003). See Guillermo Ortíz, chair, "General Discussion: Globalization and Global Disinflation," inMonetary Policy and Uncertainty: Adapting to a Changing Economy: A Symposium(Federal Reserve Bank of Kansas City, Aug. 28–30), pp. 119–130. For evidence that voters in Latin America have punished politicians for bad inflation outcomes in recent years, see Eduardo Lora and Mauricio Oliveira (2005), "The Electoral Consequences of the Washington Consensus,"Economía,vol. 5 (Spring), pp. 1–61.Return to text 10.In a paper with Douglas Irwin, I documented a similar dynamic at work in the gradual reversal of protectionist policies in the United States in the 1930s and 1940s. See Douglas A. Irwin and Randall S. Kroszner (1999), "Interests, Institutions, and Ideology in Securing Policy Change: The Republican Conversion to Trade Liberalization after Smoot-Hawley,"Journal of Law and Economics,vol. 42 (October), pp. 643–73.Return to text 11.See Ross Levine (2005), "Finance and Growth: Theory and Evidence," Philippe Aghion and Steven Durlauf, eds.,Handbook of Economic Growth(New York: Elsevier); and Randall S. Kroszner and Philip E. Strahan (2006), "Regulation and Deregulation of the U.S. Banking Industry: Causes, Consequences, and Implications of the Future," unpublished paper.Return to text
Governor Randall S. Kroszner At the Institute of International Bankers, New York, New York Governor Randall S. Kroszner presented identical remarks at the Bankers' Association for Finance and Trade, New York, New York, on June 15, 2006 Today I want to talk about some new and exciting developments in bond markets around the world. The motivation for my discussion is the current puzzling situation of a relatively flat yield curve combined with relatively low real and nominal long-term interest rates, which has occurred both in developed economies and in emerging markets. I will explore some possible explanations for the pattern and will focus on changes in the prospects for and risks to the long-term inflation outlook, particularly in emerging-market economies. In particular, I will highlight how financial innovations and international competitive pressures, combined with a better public understanding of the costs of inflation and changes in the institutions of central banking, have helped improve the credibility of central banks and inflation outcomes in many emerging markets. Until recently, many emerging-market countries simply did not have a yield curve because there was effectively no market for debt issued in domestic currency beyond a very short horizon. The credibility of central banks has been crucial to this deepening of the domestic capital market, which is typically associated with higher economic growth. I am optimistic that these developments will continue, as I believe that the move toward low inflation rates reflects important technological and institutional factors that are likely to persist. Nevertheless, there are still risks, which underscore the importance of continuing to reap the benefits of improved central bank behavior and credibility in emerging markets and around the world. Global Developments in the Bond MarketIn February 2005, former Federal Reserve Board Chairman Alan Greenspan noted a puzzle in the U.S. economy related to the slope of the yield curve and the level of the long-term interest rate.1Long-term interest rates had remained low and stable despite a solid economic recovery and a sustained period of monetary policy tightening during which the target federal funds rate went from 1 percent to 2-1/2 percent. When he first publicly noted this "conundrum," as he called it, the ten-year Treasury yield was just over 4 percent. Today, despite an additional 250 basis points of increase in the target federal funds rate, the nominal ten-year Treasury yield is roughly 5 percent, still very low by historical standards, compared to an average of more than 7-1/2 percent since 1980. The combination of a rising short rate and a relatively stable long rate has led to a very flat yield curve. During the last quarter-century, for example, the difference between the yield on the ten-year Treasury note and the yield on the three-month Treasury bill has been roughly 1-3/4 percent (or, to be exact, 179 basis points from 1980 to the present). During the last year, that difference has been less than 50 basis points and is currently less than half of that. Thus, this essentially flat slope is atypical in U.S. experience. I am sure that you are all familiar with the simple relationship between short-term and long-term interest rates. The yield on a ten-year bond, for instance, can be thought of as a series of consecutive forward rates. If you could borrow and lend at the same rate as the U.S. Treasury, then you could lock in a three-month loan ten years from now by borrowing for ten years and three months and simultaneously lending the same principal for ten years. The difference between the interest you pay and the interest you earn on this transaction determines the implied forward rate ten years from today.2The forward rate reflects not only the market expectation of the future short-term interest rate but also a "term premium" to compensate for the risk in committing to extend credit so far in the future, including the risk of future inflation.3 At any point in time, then, we can calculate the short-term forward rate ten years ahead based on the yield curve of U.S. Treasury coupon securities.4This "far forward" rate makes the conundrum even more puzzling because it reached historically low levels of almost 4-1/4 percent last year, more than 200 basis points below its average since 1990, and has rebounded only somewhat this year. In real terms, the far forward rate calculated from inflation-indexed securities is similarly below its long run average. The U.S. bond market conundrum has occurred in parallel with similar developments in foreign bond markets. In major industrial countries, bond yields have trended down, in some cases reaching historical lows recently. Yields are also low in real terms, as measured by inflation-indexed bonds. Far-forward short rates in recent years have also reached unusually low levels in many industrial countries. The most interesting and, I believe, perhaps least studied recent developments in the bond markets concern the changes in emerging markets. While it is well known that the yield spreads on dollar-denominated bonds of emerging-market governments included in the EMBI+ index are near all time lows (even taking into account the recent rise), two phenomena in emerging markets have received less attention. One is the development of markets for longer-dated fixed-coupon bonds issued in local currencies. This phenomenon is, from my perspective, quite remarkableand belies the assertion that the "original sins" of bad policy from the past have doomed the development of domestic currency bond markets in many emerging markets. The recent lengthening of maturities of domestic-currency debt markets has, in many cases, not only extended a yield curve but effectively created a local currency yield curve that simply did not exist earlier. Since 2000, ten-year nominal fixed-coupon bonds in local currency have been introduced in Brazil, Colombia, Indonesia, Mexico, and Russia, while Korea issued a ten-year fixed coupon bond in 1995. To illustrate in more detail, the governments of Mexico and Korea have been able extend the average maturity of their local-currency debt significantly in just the past few years. The Mexican government issued ten-year maturities in 2001 and then 20-year maturities in 2003. The proportion of local-currency debt in Mexico maturing within one year was nearly 90 percent in 2002 and is now below 75 percent. (I have included floating rate debt in the one-year maturity category.) The Korean government continues to increase the proportion of its domestic currency debt in longer maturities, with the one-year-and-under segment falling from roughly one-half in 1999 to one-quarter by the end of last year. Two, bond yields inlocalcurrencies of emerging-market countries have also declined. It is perhaps not surprising that, given their high rates of saving and generally high level of economic development, the governments of Hong Kong and Korea can borrow at close to industrial-country levels. More notable, however, is that the Mexican government can borrow in pesos at a ten-year maturity at rates that have averaged roughly 9 percent. And Mexico is not unique in this regard. Other middle-income emerging markets with ten-year local-currency fixed rate bond yields in the single digits include Chile, Malaysia, Russia, and Thailand, to name but a few. For countries with longer maturities, implied short-term interest rates five years ahead also have been declining and have reached very low levels, although there have been some increases in the past few months. What is driving these changes? There are a number of complementary, not alternative, explanations. Explanations for the Low Real Bond YieldsChairman Bernanke has suggested that an excess of ex ante global savings relative to global investment, sometimes referred to as a global savings glut, has held down real interest rates around the world and encouraged capital inflows to the United States.5Some of the factors behind this savings glut include the surge in revenues of oil and commodity exporters, a reduction in fiscal deficits in some Latin American countries, and a retreat in Asian investment demand from the boom that preceded the late 1990s financial crises while saving rates stayed high in Asia. The savings glut story helps to explain the real component of low bond yields as well as the pattern of global capital flows, which was Chairman Bernanke’s focus. Another factor behind declining real yields in some emerging markets is that their improved fiscal situation not only increases national saving but also calms fears about the ability of governments to service their debt. However, there is also a nominal aspect of low global bond yields. In the rest of my talk, I would like to emphasize the worldwide decline of inflation and perceived inflation risk as a key contributor to low nominal bond yields. Explanations for the Low Nominal Bond YieldsInflation rates in major industrial and developing regions have trended down over the past twenty-five years. Compared with the period 1980 to 1999, median inflation rates from 2000 to 2004 fell from 5 percent to 2 percent in industrialized countries and from 14 percent to 4-1/2 percent in emerging markets, according to the most recent statistics from the International Monetary Fund. Not long ago, annual inflation rates in Brazil and Mexico at times exceeded 100 percent. But during the past decade, Brazilian and Mexican inflation rates have remained low. In particular, inflation in Brazil did not spike up after its financial crises and sharp currency depreciations in the late 1990s. Given Brazil’s history of hyperinflation, this stability is especially remarkable. Brazil did experience a small spike of inflation around its presidential election in 2002, but even this was minor by historical standards. The pattern of low inflation is seen across many countries, large and small. A few years ago I did some research that showed how inflation rates around the world have fallen significantly since the 1970s and 1980s, both in terms of averages and medians.6Indeed, the IMF’s April 2006World Economic Outlooknotes that average inflation rates in both the industrial countries and the developing countries in recent years are at their lowest levels since at least the early 1970s. More important, I found that the worst inflation performers (specifically the 10 percent of the countries of the world experiencing the highest inflation) had much lower inflation rates than the worst performers from the 1970s, 1980s, and 1990s. Thus, the worst behavior is not as bad as it once was. Do markets expect low inflation to persist in the long run? To answer this question, we can look at measures of expected inflation. Consensus Economics surveys hundreds of professional forecasters in numerous countries each April. The surveys allow us to examine forecasts of inflation around the world six to ten years ahead beginning in 1996. The latest observation, in April 2006, for example, is the forecast of a given country’s average consumer price inflation rate from 2012 through 2016. For both a representative sample of industrial economies (Euro area, Japan, the United States, and the United Kingdom) and emerging-market economies (Brazil, China, Korea, and Mexico), we observe substantial declines from the late 1990s to today. These forecasts have been low and stable in both industrial and many important developing countries in recent years. The surveys thus provide one indication that markets do expect low inflation to persist. The volatility of inflation has also declined notably, suggesting that perceived inflation risk may have declined as well. For the industrial countries, inflation volatility (measured as a twenty-quarter rolling standard deviation of consumer price inflation) has declined from the 1980s to the 1990s to the period since 2000. Although it has since drifted up just a bit due to volatility in oil prices, it remains at or near its lowest level in the last quarter-century. For the emerging markets, the decline in volatility is even more dramatic. Brazil, in particular, was off the chart much of the time before the late 1990s. Volatility of inflation in China, Korea, and Mexico is now at levels similar to those of the industrial countries, and volatility in Brazil is not much higher. Overall, the combination of lower and less volatile inflation around the world has led to a reduction in inflation expectations and lower perceived inflation risk, hence a lower inflation uncertainty premium in long rates. I believe that these factors have been important contributors to the lower long-term yields and the flattening of yield curves, particularly in emerging markets. The existence of markets for long-term nominal government and corporate debt is powerful evidence of the faith that investors place in a future environment of price stability. Factors Behind the Global Move to Price StabilityFour broad factors lie behind the move to price stability, especially in emerging markets, and these factors tend to reinforce each other. Each factor affects the cost-benefit tradeoff of pursuing a high-inflation policy. The first factor, which gets surprisingly little attention in my view, is financial innovation that alters the ability and incentive of a government to pursue a high-inflation policy.7I put the innovations into two main categories, developments in information technology and physical dollarization, both of which effectively increase potential competition among currencies. Financial innovations make it easier for citizens to move their assets out of the local currency should their government resort to an inflation tax. The dollarizations that followed the high-inflation episodes in Latin America and the former Soviet Union, for example, significantly reduced the costs of switching away from a local currency for small-value transactions. The specific channels by which financial innovations could have affected competition among currencies are many: Given these innovations, a government that pressures a central bank to pursue an inflationary policy gets much less benefit for each unit increase in inflation because people can more easily switch out of the local currency. In other words, the inflation tax becomes much more difficult and costly to levy because citizens can more easily avoid the tax by using an alternative money. The second and closely related factor behind disinflation is deregulation and competition in a globalized marketplace. The collapse of the centrally-planned economies has led many countries to turn increasingly to private markets to deliver growth and progress and reduce the role of government. Technology has helped to increase global competition by shrinking the barriers of time and distance. Again, there are several channels by which globalization and competition may have affected the cost-benefit tradeoff in pursing inflation: The third factor is that economists and the public have learned from painful experience about the costs of inflation.9The end of the Bretton Woods gold standard in the early 1970s was associated with the first global and sustained peacetime inflation in history. Although the specific experiences differed across countries, public opinion eventually turned strongly against allowing inflation to continue, and policymakers responded to this pressure by taking stronger measures to achieve price stability. This learning process helped to drive some of the financial innovations that I discussed earlier, which, in turn, helped households and businesses to economize on holding inflationary assets. Economists and central bankers also devoted great attention to understanding the causes and consequences of inflation, providing the intellectual underpinning to policies oriented toward price stability. The fourth factor I wish to mention relates to changes in the institutions of central banking that may have increased the costs of pursuing high-inflation policies. The most notable change is the increased independence of many central banks and the corresponding reduced control of the fiscal authorities over monetary policy. Central bank independence reduces the ability of a government to "raid the cookie jar" through a surprise inflation tax. In most cases, central bank independence can be reversed by a majority vote of parliament. But having to resort to such a vote is a greater obstacle to inflationary finance than previous arrangements allowed, especially given the public’s increased sensitivity and aversion to inflation. Central bank independence has typically been granted in conjunction with an explicit mandate that makes achieving low and stable inflation one of the goals of monetary policy. Central bank independence with a mandate that includes price stability increases the credibility of monetary policy with regard to achieving low inflation. Policy is credible because the central bank’s objectives are clear to the public and the central bank can be held accountable for failing to achieve its objectives. When citizens are more aware of the costs of inflation and when governments would reap lower benefits from a high-inflation policy, institutional reforms that will make central banks more credible and independent may be more likely to be adopted and sustained.10The fundamental forces I mentioned earlier--financial innovation, deregulation, globalization, and public understanding about the costs of inflation--provided the impetus for fighting inflation and opened the political path to institutional reforms, such as central bank independence, that enhance central bank credibility. Once in place, these reforms made further progress against inflation easier and raised the costs of backsliding. As the benefits of stable prices accrue and as financial markets deepen and become more sophisticated, the benefits of sound economic policies will help to create support for institutional reforms that make returning to inflation harder for future governments. Benefits of Price StabilityWhile it is well known that low and stable inflation improves the environment for investment planning and avoids many costs and disruptions associated with frequent price adjustments, I want to focus on a few of the many benefits that are particularly relevant for emerging markets. Price stability boosts growth through deepening financial markets. With stable prices, savers and investors have more confidence about the ultimate value of their deposits and loans. Stable prices encourage the growth of financial intermediaries and financial markets. As noted above, many emerging markets have recently experienced a deepening of their local financial markets with greater issuance of longer-dated paper. According to numerous studies, there is a strong link between financial market development and economic growth. Thus, the greater credibility of central banks that permits more development of the local markets can have an economic benefit beyond the financial sector.11 The development of long-term local-currency bond markets may also help governments and firms plan long-term infrastructure and investment projects that boost economic development. Although such debt markets are only one of many factors that can lower the costs of long-term planning and enhance the ability to undertake long-term investments, the development of these markets, particularly when accompanied by lower real rates, help to support longer-horizon projects and reduce the effect of foreign exchange movements on such activities. A better fiscal outlook, which might arise from higher and more stable growth as well as better long-term planning, also increases financial market confidence and development and thus further boosts growth and reinforces prospects for continued price stability. This virtuous cycle appears to be happening in key emerging markets that were long plagued with poor fiscal situations, such as Brazil and Mexico. In the 1980s and early 1990s, for example, public sector deficits in these countries often exceeded 10 percent of GDP. Since the late 1990s, deficits have been diminished. Maintaining this ProgressAlthough I am an optimist, I would be remiss if I did not point out some risks to this otherwise rosy scenario. The difficulty of reaching agreement in the Doha Round of trade negotiations highlights the risk of renewed protectionism. Trade barriers reduce both domestic and international competition, one of the key factors behind low inflation, and make all countries poorer. Barriers to free flow of goods, services, and capital would also diminish the force of other factors outlined above that help to reduce inflationary pressures. We must not forget the examples of high inflation and hyperinflation from the past: They hold important lessons about the costs of not maintaining price stability. That sound policies are the basis for solid economic growth should not be forgotten. Footnotes 1.Alan Greenspan (2005), statement before the Senate Committee on Banking, Housing, and Urban Affairs, presenting the Federal Reserve Board’s "Monetary Policy Report to the Congress," February 16.Return to text 2.Strictly speaking, this calculation requires the use of zero-coupon bonds, but it can be approximated using coupon securities.Return to text 3.Don H. Kim and Jonathan H. Wright (2005), "An Arbitrage-Free Three-Factor Term Structure Model and the Recent Behavior of Long-Term Yields and Distant-Horizon Forward Rates," Finance and Economics Discussion Series 2005-33 (Washington: Board of Governors of the Federal Reserve System, August).Return to text 4.Typically we calculate an "instantaneous" forward rate, which is the limiting value of a sequence of forward rates with maturities declining toward zero.Return to text 5.Ben S. Bernanke (2005), "The Global Saving Glut and the U.S. Current Account Deficit," Sandridge Lecture at the Virginia Association of Economists, March 10.Return to text 6.Randall S. Kroszner (2003), "Currency Competition in the Digital Age," in David E. Altig and Bruce D. Smith, eds.,Evolution and Procedures in Central Banking(New York: Cambridge University Press), pp. 275–99.Return to text 7.I discussed aspects of this factor in my presentation at a May 2001 conference at the Federal Reserve Bank of Cleveland, cited above.Return to text 8.Kenneth S. Rogoff (2003), "Globalization and Global Disinflation," inMonetary Policy and Uncertainty: Adapting to a Changing Economy: A Symposium(Federal Reserve Bank of Kansas City, Aug. 28–30), pp. 77–112.Return to text 9.This hypothesis was raised in the discussion of Rogoff (2003). See Guillermo Ortíz, chair, "General Discussion: Globalization and Global Disinflation," inMonetary Policy and Uncertainty: Adapting to a Changing Economy: A Symposium(Federal Reserve Bank of Kansas City, Aug. 28–30), pp. 119–130. For evidence that voters in Latin America have punished politicians for bad inflation outcomes in recent years, see Eduardo Lora and Mauricio Oliveira (2005), "The Electoral Consequences of the Washington Consensus,"Economía,vol. 5 (Spring), pp. 1–61.Return to text 10.In a paper with Douglas Irwin, I documented a similar dynamic at work in the gradual reversal of protectionist policies in the United States in the 1930s and 1940s. See Douglas A. Irwin and Randall S. Kroszner (1999), "Interests, Institutions, and Ideology in Securing Policy Change: The Republican Conversion to Trade Liberalization after Smoot-Hawley,"Journal of Law and Economics,vol. 42 (October), pp. 643–73.Return to text 11.See Ross Levine (2005), "Finance and Growth: Theory and Evidence," Philippe Aghion and Steven Durlauf, eds.,Handbook of Economic Growth(New York: Elsevier); and Randall S. Kroszner and Philip E. Strahan (2006), "Regulation and Deregulation of the U.S. Banking Industry: Causes, Consequences, and Implications of the Future," unpublished paper.Return to text