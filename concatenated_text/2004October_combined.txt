Remarks by Governor Ben S. Bernanke At the Institute of International Bankers' Annual Breakfast Dialogue, Washington, D.C. October 4, 2004 The Implementation of Basel II: Some Issues for Cross-Border Banking
Remarks by Chairman Alan Greenspan Banking At the American Bankers Association Annual Convention, New York, New York October 5, 2004 It is a pleasure to join you once again at the annual convention of the American Bankers Association.ï¿½By any measure, banking in the United States today is strong, vibrant, and profitable.ï¿½ However, a number of times in the past half-century, many informed observers questioned the long-term viability of commercial banking.ï¿½ U.S. commercial banks, which began the post-World War II period as the dominant financial institution, soon faced intense competition from thrifts, from new forms of mutual funds, from customer direct financing in the securities markets, from foreign banks, and from a wide range of nondepository lenders.ï¿½ As the competition intensified, banks found their ability to respond increasingly constrained by rules and regulations established in the far different environment of the Great Depression of the 1930s.ï¿½ And banking, just like other businesses, faced the implications of immense changes in technology and of the rapid growth in globalization, which created new risks as well as new opportunities.ï¿½ Under the circumstances, the present health of banking is a dramatic testament to both the management skills of bankers and the ability of regulators and legislators to adapt, albeit slowly, to change. This morning, I would like to review some of the major innovations and changes that have propelled banks to their present state and have allowed them successfully to navigate through a rapidly changing economic and technical environment. A further word of prologue, however, is necessary to understand todayï¿½s banking markets.ï¿½ What turned out to be bad credit judgments, especially in real estate, energy, and foreign credit markets, coupled with high interest rates and a deep recession, led to the assisted acquisitions of almost 120 banks and the actual demise of about 1,250 of them between 1985 and 1992.ï¿½ Many more had a near-death experience, and survivors recapitalized by raising $176 billion of new long-term capital, including $13 billion of equity, from 1991 to 1995.ï¿½ The managers of these surviving organizations had deeply impressed upon them anew the need to manage risks, to control costs, to build capital and reserves, and generally to focus on the lessons of banking history.ï¿½ The passage of time no doubt has caused the experience to fade for those banks that looked into an abyss, but survived; nevertheless the systems and procedures that were put into place by many institutions remains one of the hallmarks of todayï¿½s banking industry. To Fund or Not to Fund The first response to the changing environment after World War II occurred in the early 1960s, with banksï¿½ decision to actively compete on a price basis to buy money to fund operations--the development of the negotiable certificate of deposit (CD).ï¿½ For years preceding the 1960s, banks had no reason to aggressively seek deposits.ï¿½ During the Great Depression, credit demands on banks, of course, were unusually low, and during and immediately after World War II banks were extremely liquid owing to heavy accumulations of U.S. government securities, an aftermath of war-time financing.ï¿½ The decision to compete on a price basis using instruments such as the negotiable CD seems quaint today, but in the early 1960s it represented a sea change in the way managers thought about the business of banking.ï¿½ And its implications turned out to be far reaching.ï¿½ It was a modest step forward to the whole range of nondeposit and price-sensitive borrowing, from the repurchase agreement to the subordinated debenture, not to mention the NOW account and the range of retail time deposits that banks routinely tap by adjusting offering rates when additional funding is needed.ï¿½ Many of these instruments, including the large-denomination, market-rate-based deposit, that was once thought to be only for large banks, are now used, with great success, by community banks when their core deposits fall short of their funding needs. Indeed, banks of all sizes will never again be the passive deposit takers that they were at the beginning of the 1960s.ï¿½ To be sure, the whole range of services and characteristics of bank claims are important, but banks now both can and do look at the cheapest source first and pay at the margin what is necessary to obtain the needed funding. When deposit rate ceilings--Regulation Q--first constrained the ability of banks to pay the market rate on CDs in the mid-1960s, banks shifted to a source that was then unconstrained, the Eurodollar market.ï¿½ This step not only underlined the increasing importance of globalization but also finally required legislators and regulators to consider the efficacy and policy implications of deposit rate ceilings.ï¿½ Only the inability of thrifts to sustain deposit inflows with the high rates of the mid-1960s and the late 1970s, an important cause of the later thrift crisis, kept the eroding deposit rate ceilings from being eliminated until the 1980s.ï¿½ But the principle slowly began to be established that regulations that are inconsistent with market realities cannot be sustained indefinitely, although vestiges may remain long beyond the regulationsï¿½ perceived usefulness. The pricing of liabilities was not the only response of banks to the new competition.ï¿½ Another was the securitization of consumer and residential mortgage loans--the conversion of a pool of credits into a security--that others not necessarily other banks, could hold.ï¿½ Securitization also allowed the creating bank to remove the underlying loans from its books.ï¿½ The bank, or an affiliate, might provide limited recourse or take an equity position in the pool to provide a credit enhancement, but the concept was clearly to eliminate the need for funding while profiting from fees or rate spread.ï¿½ The syndicated commercial loan soon followed the initial securitizations, with the managing bank acting more like the lead underwriter on behalf of a syndicate, a syndicate that, I might add, increasingly is composed of nonbank financial institutions. Some observers at the time, projecting these developments, concluded that the bank of the future would hold virtually no assets, would require virtually no funding, and would have no branches.ï¿½ The vision that the bank of the future would be essentially an underwriter of diverse credits has not come to pass, despite the continued growth of securitization and syndication, because taking credit risk, the historic core of banking, remains profitable for those that know how to manage it effectively.ï¿½ In addition, with better pricing, deposits have been restored as a more-resilient funding source.ï¿½ Moreover, the market test has clearly underlined the customer desire for branches at most types of banking organizations. Pricing and Managing Risk One of the more painful lessons learned in the 1970s and 1980s is that accepting narrow or nonexistent spreads in order to retain market share is a losing strategy.ï¿½ This lesson seems clear enough, but many banks were nevertheless reluctant to see traditional customers shift to other markets, let alone other banks, and matched loan rates despite the resultant lackluster returns on equity.ï¿½ Competition in the loan market can still be intense, as it is today.ï¿½ Nonetheless, even with narrowing margins most recently, loan pricing is now generally linked to careful assessment of economic returns that often includes an assessment of the profitability of the credit and the overall relationship. Loan officers, if left to their own devices, might be more interested in booking loans than in evaluating risk and pricing loans commensurately.ï¿½ But, pricing, credit decisions, and risk measurement and management at those banking organizations displaying best practices have increasingly been based on systems and procedures that impose a quantifiable discipline.ï¿½ That discipline, in turn, has given the credit-risk manager the ability to make the case for absolute and relative risk, enabling the bank to choose its risk profile rather than having it imposed by events.ï¿½ Quantification of risk has contributed to a changing balance of power between loan officers and credit-risk managers. We have already begun to see the benefits of this new balance.ï¿½ The tightening of lending standards by banks has historically occurred at, or most often after, cyclical peaks, accentuating the decline in economic activity.ï¿½ Before our most recent recession, however, banks began to be more selective lenders in response to the data indicating cumulating deterioration in borrower balance sheets.ï¿½ The volatility of interest rates in 1998 associated with the Asian crisis and the Russian default, as well as cautions from the regulatory community, also provided a useful early warning, and the memory of the painful losses of the late 1980s and early 1990s contributed importantly to the response of bank management.ï¿½ But, in my judgment, better risk measurement and risk management were noticeably important in moderating overall credit losses during the most recent recession and in establishing the higher credit standards that have been so important in the most recent years. The supervisory authorities are seeking, as you know, to build on these best practices of banks in developing the new capital rules, Basel II.ï¿½ The improving bank practices, coupled with the new rules, hold out the hope of a safer and stronger banking system contributing to a more stable economy.ï¿½ We anticipate that the best practices and procedures will spread beyond the largest banks, even to those entities that are not required to adopt the new capital rules. No discussion of better risk management would be complete without mentioning derivatives and the technologies that spawned them and so many other changes in banking and finance.ï¿½ Derivatives have permitted financial risks to be unbundled in ways that have facilitated both their measurement and their management.ï¿½ Because risks can be unbundled, individual financial instruments can now be analyzed in terms of their common underlying risk factors, and risks can be managed on a portfolio basis.ï¿½ Concentrations of risk are more readily identified, and when such concentrations exceed the risk appetites of intermediaries, derivatives and other credit and interest rate risk instruments can be employed to transfer the underlying risks to other entities.ï¿½ As a result, not only have individual financial institutions become less vulnerable to shocks from underlying risk factors, but also the financial system as a whole has become more resilient. Derivatives have been used effectively by many banks to shift interest rate risks.ï¿½ In addition, while credit risks are transferred among financial intermediaries based on their ability and willingness to absorb such risk, increasingly credit risk has been transferred from highly leveraged financial institutions to those with much larger equity coverage.ï¿½ For example, not only has a significant part of the credit risks of an admittedly few large U.S. banks been shifted to other U.S. and foreign banks and to insurance and reinsurance firms here and abroad, but such risks also have been shifted to pension funds, to hedge funds, and to other organizations with diffuse long-term liabilities or no liabilities at all.ï¿½ Most of the credit-risk transfers were made early in the credit-granting process; but in the late 1990s and early in this decade, significant exposures to telecommunication firms were laid off through credit default swaps, collateralized debt obligations, and other financial instruments.ï¿½ Other risk transfers reflected later sales at discount prices as specific credits became riskier and banks rebalanced their portfolios.ï¿½ Some of these sales were at substantial concessions to entice buyers to accept substantial risk.ï¿½ Whether done as part of the original credit decision or in response to changing conditions, these transactions represent a new paradigm of active credit management and are a major part of the explanation of the banking system's strength during the most recent period of stress.ï¿½ Even the largest corporate defaults in history (WorldCom and Enron) and the largest sovereign default in history (Argentina) have not significantly impaired the capital of any major U.S. financial intermediary. Technology Technology, as I have noted, has been among the most significant factors permitting banks to adjust to the new competitive environment in making credit decisions, in measuring and managing risk, and in creating and using new instruments.ï¿½ Technology of course, is a two-edged sword.ï¿½ The technology that banks use so profitably in risk measurement and management and in their dealing and underwriting activities is the same that their rivals and their customers used to deprive banks of the traditional lending business with their best customers.ï¿½ However, technology has also allowed banks to assess the credit and other risks of customers previously deemed too risky and, then, to extend credit profitably to such borrowers. Some investment in bank technology has been largely defensive, with the gains captured mainly by customers who would otherwise have shifted to competing institutions.ï¿½ Retail internet banking and, for some smaller banks, ATMs, are examples.ï¿½ But the use of even these defensive investments has often yielded benefits for banks from greater fees and from lower costs resulting from reduced check processing. I would be remiss not to note the more-direct contributions of technology to increased productivity in banking, the same kind of improvements that have occurred throughout our economy.ï¿½ Such gains are notoriously hard to measure in banking, but have visibly contributed to the improved profitability of banking.ï¿½ Not all such gains have been cost reducing:ï¿½ Some have increased cost, but have raised revenue even more by improving the variety and quality of banking services in ways for which customers are willing to pay.ï¿½ The increase in banksï¿½ fee income is not unrelated to improvements in technology. Bank Consolidation Technology has also facilitated consolidation in banking by making it more efficient at the margin--or perhaps less inefficient--for firms to become larger, more geographically dispersed, and better able to manage multiple business lines.ï¿½ Research at the Federal Reserve and elsewhere is consistent with other indications in the past decade or so of cost scale economies, or fewer diseconomies, and improved control by multibank holding companies over their bank subsidiaries.ï¿½ Improvement in the ability of these organizations to make small business loans over a wider geographical area is striking.ï¿½ Some of the consolidation of the past decade would not have been possible if the Congress, led by the states, had not removed prohibitions on interstate banking and branching.ï¿½ The combination of the resultant geographical diversification with the product line diversification facilitated by technology and the removal of out-dated legal prohibitions, has, in my view, greatly strengthened the stability of our financial system.ï¿½ Diversified banking organizations in most recent years have been able to absorb substantial losses in some lines or weak demand for some products without significant hits to capital or, in some cases, even to earnings.ï¿½ Banking history as recently as the 1980s and early 1990s would have been quite different had our banking structure then been more similar to that of today. The recent consolidation of the banking system has been dramatic.ï¿½ Excluding intra-bank holding company mergers, and including the approximate 100 announced but not yet completed mergers, about 2,400 banking organizations have been absorbed by other banking entities since 1995.ï¿½ If all the mergers that have been announced are completed, the ten largest banking organizations in the United States will account for about 51 percent of all domestic banking assets, almost double their share in 1995.ï¿½ Consolidation has not been a phenomenon involving only large banks.ï¿½ Roughly 45 percent of the mergers involved an acquirer and a target each of which had less than one billion dollars in assets.ï¿½ I must emphasize that, despite these merger trends, market and other pressures have kept measures of local market banking concentration virtually unchanged. ï¿½An important factor has been the almost 1,400 new commercial bank formations since 1995. It would be a mistake to conclude from these comments that the only way to succeed in banking is through ever-greater size and diversity.ï¿½ Indeed, better risk management may be the only truly necessary element of success in banking.ï¿½ The variety in scale, strategy, and approach among quite profitable and well-capitalized banks in this country is striking.ï¿½ A handful of organizations operate diversified, multi-line, financial service businesses nationally or globally or both.ï¿½ Others deliver services throughout a multistate region.ï¿½ Some specialize in credit cards or mortgage finance.ï¿½ Some operate an alliance of smaller, independent organizations through multibank holding companies, seeking local investors and management.ï¿½ Some insurance, securities, or investment management firms have become affiliated with banks with the intention of broadening their product lines.ï¿½ Some banks have large branch systems whereas others have business plans with no branches, using mail and ATMs as alternatives.ï¿½ A very few are trying to operate without brick and mortar, only through the Internet.ï¿½ And, by number, our structure is still dominated, as it will continue to be, by the community banks that offer local services through local management, using specialized local information.ï¿½ The potential for new entrants, we should not forget, is always there and will keep the existing entities on this non-exhaustive list on their toes. Conclusion The factors that have contributed to the strength, resilience, and profitability of the U.S. banking system, which I have described, should continue to guide the industry in the years ahead.ï¿½ We have, in short, every reason to believe that banks of all sizes and types will continue to successfully compete in an ever-changing market environment.ï¿½ Nonetheless, as time passes, more and more bank managers will not have the first-hand memories of times of banking stress.ï¿½ That is why we must endeavor to build into bank and regulatory systems the product of the earlier experiences in order not only to retain and consolidate the gains made, but also to rapidly incorporate more widely the future advances that best-practice banks will continue to make.
No content found
Remarks by Vice Chairman Roger W. Ferguson, Jr. To the National Bankers Association, Nashville, Tennessee October 6, 2004 Questions and Reflections on the Personal Saving Rate I am delighted to be here today to offer my thoughts on an issue that I believe is important to all of us: the long-standing decline in household saving. Since the early 1980s, the personal saving rate has fallen steadily; on average, a household today saves only about 1-1/2 percent of its disposable income, compared with about 11 percent in 1984. The fall in the personal saving rate could have important implications for the ability of the country to finance investment in plant and equipment, for future growth in productivity and real incomes, and for our growing economic dependence on other countries to finance our spending patterns. Although my remarks today concentrate on the behavior of household saving and overall national saving, I also want to spend some time on a related issue: What is the evidence on the saving of minority households? Much has been written about the adequacy of retirement saving for many American households and the wealth accumulation of different income cohorts. But what do we know about the saving of minority households, and does it differ from the saving of low-income households, where minorities are disproportionately concentrated? Let me turn first to the bigger picture. Personal saving, as measured by the Commerce Department's Bureau of Economic Analysis, is essentially the amount of after-tax income left after household bills are paid. From the end of the Second World War until the early 1980s, the personal saving rate--personal saving expressed as a percentage of disposable income--gradually trended up. To be sure, the saving rate showed considerable volatility from year to year, and in some periods, such as the second half of the 1970s, its upward drift stalled for a time. But overall, the picture was that of a fairly steady rise in the personal saving rate, from about 7-1/2 percent in the early 1950s to around 10-1/2 percent in the early 1980s. Since that time, however, the household saving rate has declined precipitously and, in the last couple of years, it has averaged only about 1-1/2 percent. As is often the case with statistics, the figures I've just given are not the only word on this subject because the government publishes additional measures of household saving. One such measure, produced by the Federal Reserve, uses different source data to estimate the same concept of savings. The Fed measure suggests that households have been putting away about 3 to 4 percent of their income in recent years, a little more than estimated by the Commerce Department. But, importantly, it also shows the same precipitous decline since the early 1980s in the personal saving rate. Interestingly, the Fed's study of this issue shows that the decline in the saving rate of households at the top 20 percent of the income distribution accounts for virtually all of the decline in the aggregate personal saving rate since 1989, the first year for which estimates on saving by income quintile are available. That is, the saving rates of the bottom 80 percent of the income distribution have fluctuated in a relatively narrow range and importantly have shown no secular decline since 1989. Should we worry about the fall in the personal saving rate? Do we need to worry about the fall in the personal saving rate? Taking a big-picture point of view and asking whether the low rate signals that adjustments are needed for the future for the U.S. economy, the answer is a conditional "yes"; but the period over which those adjustments will occur is very unclear. In the aggregate, an economy needs to generate savings for two basic purposes--to invest in new plant and equipment with the aim of raising future consumption growth and to expand the residential housing stock, thereby boosting the flow of housing services over time. Thus, the act of saving is essentially about the allocation of an economy's resources: Some sector of the economy must be willing to consume less than its current income to free resources for the purchase of capital. Intuitively, we often think of saving in financial terms: Rather than spending our entire paycheck, we put money aside into savings accounts or certificates of deposits, and the bank lends this money to business; or we lend directly to firms by buying corporate bonds or stocks. Similarly, corporations save by not paying out all their profits to their stockholders. But underlying all these financial transactions is the reallocation of resources away from the immediate consumption of goods and services and toward the purchase of capital goods--goods that are not consumed directly but are instead used to produce future goods and services for consumption. How much should an economy save and invest? The answer comes down to a decision about what combination of capital and labor inputs minimizes the cost of producing goods and services. The cost-minimizing mix will depend on the relative prices and relative productivity of capital and labor and on the rate of interest. If saving is inadequate to meet these investment needs, then interest rates rise, increasing the return to saving and perhaps boosting saving to some extent but also making it worthwhile for firms to reorganize their production methods to use less capital per worker. It is this consequence--operating at a lower ratio of capital to labor--that drives the concern about adequate savings in the economy. Over time, reducing the ratio of capital to labor in production reduces the productive capacity of the economy. And critically for the average worker, reducing the amount of capital per worker reduces a worker's marginal productivity, his or her real wage rate, and of course, the sustainable amount of his or her consumption. To get some idea about the importance of saving and investment for future productivity growth, we can look to the past. Since the mid-1990s, productivity growth in the nonfarm business sector has averaged a bit more than 3 percent, roughly double its average from 1973 through 1995. Estimates produced by the Bureau of Labor Statistics, augmented by analysis carried out at the Federal Reserve and elsewhere, suggest that about one-third of the step-up in productivity growth is attributable directly to increases in the amount of capital per worker used in production. This so-called capital deepening has in turn come about because of the sharp decline in the relative price of capital: For example, the price of new high-tech capital equipment has fallen 70 percent relative to the price of business output since the end of 1995, so that increasing the capital intensity of production has become cost efficient. But this estimate may well understate the total contribution from investment to labor productivity growth because of synergies that are difficult to quantify but are significant nonetheless. For example, newer vintages of capital may embody more-advanced technology than older vintages and thus, even without any increase in capital intensity, productivity would rise as new capital replaces old capital in production. So if capital investment is a critical factor behind productivity growth, why have I hedged on the issue of whether the decline in the personal saving rate is something about which we should be concerned? The reason is that, in a country with a well-developed capital market, investment needs of one sector can be met by savings of another sector. In principle, the burden of saving need not fall exclusively or even primarily on the household sector, and indeed, the contribution of the various sectors to aggregate saving has varied considerably over the past fifty years. For the most part, government saving has been negative over this period; consolidating the savings of the federal, state, and local governments indicates that, since about 1960, except for a few years during the late 1990s, the government has spent more each year than it has collected in tax revenues. It is the federal government that accounts for nearly all of the negative saving; state and local governments have generally balanced their operating budgets because most of them face constitutional or statutory requirements to do so. Although the Treasury ran a surplus as recently as 2001, the prospects for its doing so again anytime soon are not high. Both Social Security and Medicare face running deficits in the near future because of factors such as the retirement of the baby-boom generation, rapidly increasing health costs, and a slowdown in the growth rate of the labor force. Tax cuts enacted over the past three years, although undoubtedly supporting the economy during its recent period of recession, have also added to the prospects for federal government deficits. In this regard, let me just say that I fully support the goal of fiscal prudence for the federal government: To the extent that the federal government is soaking up funds that might otherwise be used for private domestic investment, the United States is getting smaller productivity gains than we could be getting. Foreigners are another source of saving, and they have played an increasingly important role over the past twenty years in financing our domestic investment. Foreign saving is identified with our current account balance: When we import more than we export in dollar terms, we borrow from foreigners. Between 1950 and the early 1980s, our current account balance stayed close to zero--sometimes we borrowed from foreigners, and other times we lent, but for many years we remained a net global creditor. Since then we have become increasingly reliant on the willingness of foreigners to fund our investment needs; the current account deficit now stands at almost 6 percent of gross domestic product, and foreigners today fund about 30 percent of our domestic investment. In some respects, this foreign borrowing is not problematic--the rest of the world supports investment in plant and machinery while we maintain our consumption. But two considerations weigh against foreign funding being a sustainable long-run solution. First, continued borrowing from abroad means that foreigners have an ever-growing claim on the nation's capital assets. Thus, a growing share of the output produced by those assets is not ours to spend but instead goes to foreigners in the form of dividends and interest payments. So, if the goal of saving is to raise the capital stock in order to increase our own future production and consumption possibilities, sending increasingly larger amounts of additional income abroad lowers the gain from investment. Certainly, we are still better off than we would be had the investment not occurred: Labor productivity is increased regardless of who owns the capital stock, and as a result, both real wage growth and future consumption growth are greater than they would otherwise be. A second reason we should be vigilant about our growing foreign indebtedness is that, should global investors decide to rebalance their own portfolio so as to reduce the amount of their lending to the United States, the economy could face some significant adjustments in numerous economic variables, including interest rates, the composition of consumption, and the level of investment. Of course, dynamic economies are used to seeing such changes, and for the United States, these changes have historically been orderly. But there is always some risk, however remote, that future changes could be less orderly than has been our experience historically. So, if depending in the long run on government saving and foreign saving to finance private domestic investment raises serious concerns, where does that leave us? The answer is that the private domestic sector, households and businesses, ultimately must generate the bulk of saving. Business saving is, and has always been, greater than household saving because corporations set aside a large volume of income to replace aging equipment. Thus, the precipitous drop in the share of income that households save does not translate into a proportional drop in total private-sector savings. But, we have no evidence that business saving has moved over time to significantly offset the downward trend in household saving. Indeed, the ratio of gross business saving to GDP has risen only about 1 percentage point since the mid-1980s, whereas the decline in personal saving--again relative to GDP--has been about 7 percentage points. Realistically, the key to ensuring adequate saving in the future appears to rest on reversing or at least containing the decline in the personal saving rate. The prospects for doing so depend on why the personal saving rate has fallen. Why has the personal saving rate fallen? Economists, as you might expect, are not in complete agreement about the causes of the decline. Perhaps the most popular explanation is that large capital gains on equity holdings and residential real estate have sharply raised the net worth of many households, assuring them that they are well positioned to meet goals for precautionary or retirement savings even while they save less of their current income. This explanation suggests that for many households the operative concept of saving is not the portion of current income that they do not spend but rather the change in their net worth. The former measures only the acquisition cost of new household assets whereas the latter measures the change in the market value of assets, which is the acquisition cost of new assets plus the capital gain or loss on existing assets. The latter measure of saving does indeed paint a far more positive picture of household saving behavior: The ratio of the change in net worth to disposable income, although more volatile over the past decade than previously, has been essentially trendless over the past two decades. Whether or not we should take comfort from this alternative picture of the saving rate is a complicated issue, one that is inextricably tied to our confidence that the price of corporate equity accurately reflects the underlying productivity of corporate assets. One would expect that capital gains on financial or real capital assets reflect a positive reassessment of the productivity of some physical asset and, therefore, an increase in the potential for greater future consumption. To this extent, capital gains serve the same function as saving out of current income. But, it is hard to believe that all the movements in asset prices witnessed in recent years are well-rooted in changes to the underlying productivity of those assets. A telling reason for skepticism is the behavior of stock prices since the late 1990s. What information on productivity or productivity growth can account for, first, the near-tripling of share prices during the late 1990s and, then, the retrenchment of prices in 2000 and 2001? It would appear that a portion of past swings in net worth has reflected behavior based on something other than well-founded assessments of changes in the underlying productive potential of existing capital. Nevertheless, on the issue of why the personal saving rate has fallen, empirical evidence linking the stock of wealth to consumption spending supports the view that capital gains on corporate equities and residential real estate have been important factors. Another explanation for the decline in the personal saving rate relates to possible upward revisions to households' expectations for their long-run or permanent income. Many studies of household consumption and saving behavior link current consumption to both current income and expected future income as households appear to smooth spending in response to fluctuations in income. One consequence of this behavior is that the ratio of consumption to current income will be higher--and hence the personal saving rate will be lower--the higher is the expected growth rate of future income. So to the extent that households have taken note of the step-up in productivity growth over the past decade and have assumed that it means more rapid increases in future income, their saving rate would fall. This belief in "better economic times ahead" increases the confidence of households about their future income prospects and encourages them to be less thrifty today. Another commonly referenced argument for the decline in the personal saving rate emphasizes the growing importance of Social Security, Medicare, and other government transfer payments in overall household income. These programs have the effect of shifting income toward those portions of the population that, at least in theory, have a relatively high propensity to spend. Moreover, by providing some insurance against future financial hazards, the very existence of the programs has probably reduced the incentive of even those currently not receiving such transfers to save for retirement and other emergencies. Many other theories have been put forth dissecting the fall in personal savings. One involves financial market innovation. Since the 1980s, households have had easier access to credit markets. Credit card usage has grown exponentially over the past two decades, and the ratio of consumer credit to income has increased 50 percent. Mortgage credit has also become less costly to obtain, and along with the tremendous run-up in real estate prices since the mid-1990s, it has encouraged frequent refinancings with many households tapping into their home equity for consumption needs. Another theory attributes the fall in the personal savings rate to the generally low level of real interest rates in recent years. This particular theory has both supporters and detractors in the economics profession. Whether raising the rate of return on savings raises or reduces savings propensities remains an open question. On the one hand, the higher return to saving should make saving more attractive; on the other hand, a higher return means that less saving is required to achieve any given level of wealth. The weight of empirical evidence favors a positive relationship between interest rates and the saving rate, although the confidence intervals around such estimates are quite large. Will the personal saving rate rebound? Suffice it to say, theories on the decline in the personal saving rate are abundant. Empirical research suggests that multiple factors played into the decline in the rate, and the relative contributions of the factors have fluctuated over time. Taking all the factors into account, what are the odds of a rebound in the personal saving rate to the average level of the 1950s through the 1980s? First, current levels of personal saving are insufficient to maintain the current ratio of wealth to income, without significant capital gains in the future. A decline in the ratio of wealth to income would, by itself, tend to raise the future saving rate. To the extent that a decline in net worth relative to income turns out to be the precipitating factor for a future rebound in the personal saving rate, it is reasonable to expect that the saving rate of the top quintile of the income distribution will do the bulk of the rebounding. As I noted earlier, the saving rate of this quintile accounted for virtually all of the decline in the aggregate personal saving rate. Because households in this income quintile own about 65 percent of aggregate net worth, any revaluation of assets will be felt strongly in this group and consequently their saving behavior should most clearly reflect this influence. Second, productivity growth, or households' perceptions of such growth, could fall back from rates experienced in the past few years, again raising personal saving rates. Once again, this might most noticeably affect the saving rate of the top quintile of the income distribution, at least in the short run. Why? While changes in trend productivity growth should ultimately feed through to changes in wage growth, the passthrough of productivity gains to wages generally is not instantaneous. Instead, changes to productivity growth are felt first in capital income--profits and rents and dividends--so any drop back in future productivity growth would likely be felt first in capital income. Capital income is of course more frequently found in the income of the top quintile than in the lower quintiles of the income distribution. A third factor that could influence the saving rate is that market-determined interest rates may rise from their low levels at present and thus may raise the incentive to save a bit. Such a rise in interest rates might also tend to slow the increase in the value of real estate and equities, eliminating some of the cushion that households currently might count on from past high rates of capital gains and reducing the impetus to consumption spending that mortgage refinancings have in recent years permitted. On the other hand, government transfer payments are unlikely to fall, and financial innovation is not going to reverse itself. Although it is difficult to predict with any precision the course of asset values, or productivity growth, or federal entitlement programs, or even interest rates, all told I would not expect the personal saving rate to return in the near term to the peaks seen twenty years ago, and I would be surprised even by a return anytime soon to the average rate that prevailed between the 1950s and the 1980s. At the same time, I want to note that we likely will not need quite so high a national saving rate in the future because, as the growth rate of the labor force slows with the retirement of the baby boom generation, less investment will be required to equip each worker with the same amount of capital. Thus the shortfall in national savings relative to private domestic investment might be a bit less than we would assess by looking only at national savings. But the problem of inadequate national savings is still there. Saving and minority households Let me now turn away from the issue of whether the country saves and invests enough and focus on the issue of what we know about the wealth accumulation of minority households. A fair number of studies exist on this subject, but two stand out. Both find that, after controlling for differences in income and in demographic factors, black families have lower wealth than white families. Thus, even if policies designed to reduce racial differences in income were completely successful, the bulk of the wealth differential would remain, and the ratio of net worth to income would be lower for black families . Three principal factors can account for this. First, black families may receive lower inheritances or other intergenerational transfers; second, black families may have lower propensities to save out of income; and third, black families may experience lower rates of return on their savings. The two studies that I cited disagree to some extent on which of these factors is most important. One study stresses the importance of intergenerational transfers, whereas the other stresses differences in savings behavior. But both argue that differential rates of return are important. Black families are less inclined at most income levels to invest in stocks, and black families are less likely to be owners of small business. Although it is difficult to draw precise inferences regarding the key factors that have limited minority wealth accumulation, one endeavor should pay off in terms of greater saving by and higher net worth of minority households: increased efforts in financial education. We at the Federal Reserve have embarked on a program to raise the level of financial literacy in our country, and I believe that similar programs offered by private financial institutions will also yield a high return. Thus, I encourage all of you to work to increase the knowledge of your depositors about financial issues. Conclusion Let me briefly conclude by restating my main points. Probably nothing is more critical to the long-run well-being of the U.S. economy than ensuring high rates of productivity growth. Productivity growth requires adequate levels of investment. While foreign saving is currently a feasible source of investable resources, it would be more economically advantageous in the longer run if we could raise the amount of household and government savings and close the gap between domestic investment and national savings. Within the household sector, the accumulated saving of minority households, relative to their income, appears to be lower than that of nonminority households. In this regard, increased efforts at financial literacy programs can have a positive payoff, especially since at least one source of the minority-nonminority differential is apparently due to lower rates of return earned by minority households. Footnotes For estimates of productivity growth and the contribution of capital deepening through 2001, see the Bureau of Labor Statistics release . For more recent years, I use Federal Reserve estimates. The so-called wealth effect has a long history in the economics profession. Among the earliest and most frequently cited references is the work of Albert Ando and Franco Modigliani (1963), "The 'Life Cycle' Hypothesis of Saving: Aggregate Implications and Test," American Economic Review , vol. 53 (March), pp. 55-84. A review of the effect that of the late 1990s gains in equity prices had on consumption is available in James M. Poterba (2000), "Stock Market Wealth and Consumption," Journal of Economic Perspectives , vol. 14 (Spring), pp. 99-118. This alternative concept of the personal saving rate has, in fact, shown a slight positive trend since the early 1950s. The influence of permanent income on consumption also has a long history in the economics literature, and the work by Milton Friedman is among the best known of the early papers. See, for example, Milton Friedman (1957), A Theory of the Consumption Function , (Princeton: Princeton University Press. For another early and fundamental study, see Franco Modigliani and Richard Brumberg (1954), "Utility Analysis and the Consumption Function: An Interpretation of Cross-section Data," in Kenneth K. Kurihara (ed.), Post-Keynesian Economics , (Rutgers, N.J.: Rutgers University Press), pp.338-436. For a more recent study on this issue, see John Y. Campbell (1987), "Does Saving Anticipate Declining Labor Income? An Alternative Test of the Permanent Income Hypothesis," Econometrica , vol. 55 (November), pp. 1249-73. The classic paper on the effect of government transfer payments on household spending is by Martin Feldstein (1974), "Social Security, Induced Retirement, and Aggregate Capital Accumulation," Journal of Political Economy , vol. 82 (September/October), pp. 905-26. For a commonly cited paper on the relationship between precautionary saving and government entitlement programs, see Lawrence H. Summers and Christopher D. Carroll (1987), "Why is U.S. National Savings So Low ?" Brookings Papers on Economic Activity, 2:1987 , pp. 607-36. Francine D. Blau and John W. Graham (1990), "Black-White Differences in Wealth and Asset Composition," Quarterly Journal of Economics , vol. 105, pp. 321-39. See also Joseph G. Altonji, Ulrich Doraszelski, and Lewis Segal, (2000), "Black/White Differences in Wealth," Federal Reserve Bank of Chicago, Economic Perspectives , vol. 24 (1st quarter), pp.38-50.
Remarks by Vice Chairman Roger W. Ferguson, Jr. At the Conference on Trade and the Future of American Workers, Washington, D.C. October 7, 2004 Free Trade: What Do Economists Really Know? The role of trade in the U.S. economy has moved well into the spotlight in recent years, and I am pleased to be here today to share my thoughts on this important topic with such distinguished and knowledgeable colleagues. Over the course of this day, you will be hearing from leading analysts, policymakers, and commentators about recent developments in the U.S. economy, past and prospective trends in job creation, the role of sourcing (both out- and in-), and the implications of trade for the coming elections. In my remarks this morning, I would like to put these issues into the broader context of the debate over free trade and its implications for the American economy. Though my focus will be on free trade, we must remember that prospects for the average American depend on many other factors as well, including technological progress, the education required to exploit this progress, a dynamic market-oriented economy, a framework of limited but effective regulation, healthy and well-governed financial institutions, and a stable macroeconomic environment. And free trade is not necessarily the most important item on this list. Even so, it has been a focus of interest and aspiration for economists dating back to Adam Smith and David Ricardo. As you know, finding overwhelming agreement on issues is difficult among economists, but free trade is an exception. The supporters of free trade have not been ignored. In the past half-century, global trade has become freer and has expanded rapidly. The ratio of trade (exports plus imports) to worldwide gross domestic product rose from only 16 percent in 1960 to 40 percent by 2001. In 1960, the United States, Germany, and Japan had average tariff rates of around 7 percent; these rates were more than halved by 1993. The number of members of the World Trade Organization (WTO), or its predecessor, the General Agreement on Tariffs and Trade, rose from 18 in 1948 to 146 in 2003, and the number of regional trade agreements in the world ballooned from only 1 in 1958 to 161 in 2003. Although most economists welcome these trends, the public at large has been much more ambivalent about international trade. Attitudes toward free trade in principle remain generally positive, but a substantial--and, perhaps, growing--minority of Americans hold more negative views. According to a poll completed around the beginning of this year, 41 percent of respondents viewed the process of increasing international trade through reduction of barriers as proceeding too quickly; this number was up from 30 percent in 1999. And 43 percent of respondents believed that the government should try to slow or reverse the expansion of international trade, up from 39 percent in 1999. What accounts for the apparent deterioration in public support for free trade over the past five years? The widening of the U.S. trade deficit may have exacerbated concerns about the country's international competitiveness. More important, some have blamed overseas competition for the job losses associated with the economic slowdown earlier in this decade. Without solid public support for free trade, achieving continued progress in reducing protectionist barriers, both at home and abroad, may become more difficult. In the remainder of my remarks, I'd like to review the arguments for and against free trade, explore why it has been difficult to muster more widespread public support for this goal, and address some of the consequences of trade protection as it has been implemented in practice. Arguments for Free Trade International trade contributes to prosperity and growth through several channels. These channels are not especially subtle or esoteric, and I would argue that the public at large understands them reasonably well. At the same time, however, quantifying the contributions of trade to national welfare is by no means straightforward. First, and most obviously, trade increases the variety of goods available to consumers. Trade provides some products that otherwise would be beyond the reach of most American households, such as roses for Valentine's Day, or peaches and nectarines during the winter. More generally, international trade allows us to choose from a wider array of goods than would otherwise be available: Japanese and German cars in addition to American, Chilean apples as well as Washington state, French and Australian wine as well as Californian. It is difficult to put a dollar figure on the value of this increased variety to the consumer, but estimates range as high as nearly 3 percent of GDP. A second benefit of international trade is its role in reducing the cost of goods and hence in raising our standard of living. To anyone who has walked into a large discount store and surveyed the range of low-priced items produced in any number of distant economies, this benefit is abundantly clear. However, actually measuring the extent to which trade holds down consumer costs is tricky. Between 1990 and 2003, for example, the overall consumer price index rose 41 percent, whereas prices declined for many highly traded goods, including toys (whose prices fell 26 percent), televisions (53 percent), and clocks and lamps (15 percent); in just the past five years, the price of telephones, calculators, and other such items has fallen 42 percent. Yet, we do not know how much of the decline in these prices can be attributed to trade, as most traded products are manufactures and are subject to greater productivity growth (and hence steeper declines in costs) than nontraded products such as services. A more fruitful approach may be to compare the prices of goods that are protected from international competition with what they would be in the absence of such barriers. A recent study by the U.S. International Trade Commission indicates that sectoral trade liberalization would lower the price of sugar for U.S. consumers by 8 percent, of apparel by 5 percent, and of footwear and leather products by 4 percent. Clearly, if international trade were curtailed for a much broader range of goods, the cost of living for American workers would be higher and the standard of living correspondingly lower. A third key benefit of free trade is that it allows economies to specialize in the activities they do best. This notion was at the core of the classical economists' defense of free trade. By allowing England to specialize in cloth production and Portugal in wine, for example, international commerce leads to a higher income for both countries than if each tried to produce both goods for themselves. By the same token, no American today would object to trade between Massachusetts and Montana, or between Alaska and Alabama--the various U.S. states obviously have their own comparative advantages in producing a variety of different products, and trade among them makes such specialization possible. Extending the example of trade among states to trade among countries is not much of a stretch. Can we measure the extent to which the specialization associated with free trade may boost incomes and welfare? Such an estimate is obviously no simple thing to calculate. Economists frequently use so-called computable general equilibrium models, often consisting of hundreds of equations, to address this issue. A recent analysis of the effects of past trade liberalizations on the U.S. economy puts the gains to U.S. welfare at about 1/2 percent of GDP. A separate analysis of a hypothetical 33 percent reduction in trade barriers around the world suggests it would raise welfare by 1-1/2 percent of global GDP. In addition to promoting specialization, trade boosts productivity through a fourth channel of influence: opening the economy to heightened competition. This effect could occur either as firms are spurred by foreign competitors to become more efficient, or as the least productive firms are forced to close, thus raising the average level of productivity for the economy as a whole. Again, most Americans likely recognize the importance of competition in boosting performance--the ascendancy of Japanese automobiles, for example, has been cited as a factor that has spurred Detroit to greater innovation and better quality. By heightening competitive forces and thus incentives for productivity and innovation, international trade has likely accelerated the process of "creative destruction" by which outdated and less productive activities are replaced by new technologies and more dynamic enterprises. Academic research supports the view that import competition has led U.S. manufacturing firms to become more capital intensive; trade liberalization apparently has enhanced productivity in some import-competing firms in foreign countries as well. Producing for export markets may also yield dividends: Research suggests that exporters are more productive than non-exporters in the same industry and that they grow more rapidly as well. Finally, many studies suggest that countries that are more open to international trade have enjoyed higher rates of economic growth. Our sad experience after adoption of the Smoot-Hawley tariff of 1930, as well as the record of Latin America, India, and other regions that experimented with "import-substituting industrialization," point to the deterioration in economic performance that occurs when countries erect barriers to trade. Arguments against Free Trade If the benefits conferred by international trade are reasonably straightforward, how can we explain the apparent ambivalence toward trade picked up by recent surveys? Clearly, many people view the benefits of free trade as being outweighed by its perceived costs. One concern about free trade may be that it has given rise to large trade and current account deficits, thereby adding to the nation's debt and putting future prosperity at risk. Now at more than 5 percent of GDP, the current account deficit is in record territory, it is growing, and it cannot be sustained indefinitely. We cannot foresee when the deficit will stop growing and return to more-sustainable levels, through what mechanisms this adjustment will occur, or whether this adjustment will be smooth or disruptive for financial markets and the economy more generally. No matter how a correction of the external imbalance proceeds, however, it will involve a range of adjustments to investment, saving, and asset prices, both for the U.S. economy and for our trading partners. Research suggests that past corrections of large external imbalances in industrial countries generally have occurred without crisis. Whether or not this will remain the case, I am confident that protectionism is not the appropriate response to our growing current account deficit. The amount of current account adjustment that would be gained from a given tightening of import controls is questionable. Yet, it is certain that such actions would impose costs on the economy that would persist long after concerns about the deficit dissipated. A second concern about free trade that is frequently voiced, and probably a more important one to many people, is that trade destroys American jobs and creates unemployment. The same survey I mentioned earlier, showing a deterioration in general attitudes toward trade, also indicated that 40 percent of respondents believed that trade barriers should be maintained because of the threat to U.S. jobs, up from 31 percent in 1999. It is worth distinguishing among several variants of the concern about trade and jobs. The first variant holds that the rise in imports lowers employment and raises the unemployment rate by shifting jobs overseas. This claim is strongly contradicted both by theory and by experience. Make no mistake: Import competition clearly has cost some American workers their jobs and has caused them considerable hardship as a result. However, economywide equilibrating forces, including monetary policy, ensure that over time such employment losses are offset by gains elsewhere in the economy, so that the nationwide unemployment rate averages around its equilibrium level. In fact, the inflow of foreign capital that finances our trade deficit provides the funding for investment projects that employ U.S. workers just as surely as does any other productive activity in the economy. Between 1960 and 2003, the trade balance moved from a slight surplus to a deficit of 4-1/2 percent of GDP, and nominal imports rose from about 4 percent of GDP to 14 percent--yet, the current unemployment rate of about 5-1/2 percent is little changed from its 1960 level, while nonfarm private employment has grown by more than 60 million jobs. It has also been suggested that import competition has caused a significant portion of the decline in employment since the recession of 2001. Yet, the ratio of the nominal trade deficit to GDP widened less than 1 percentage point between 2000 and 2003. Moreover, this deterioration came entirely from a decline in the ratio of exports to GDP, from 11.2 percent in 2000 to 9.5 percent in 2003; the ratio of imports to GDP actually declined about 1 percentage point over this period. A second variant of the concern over trade and jobs is certainly valid: Import competition can be highly disruptive and cause considerable pain for those who lose their jobs. One study of worker displacement indicates that only about two-thirds of displaced workers found another job within three years, and even when they were successful in finding full-time work, the earnings of these workers on average declined 8 percent. Another study found that job losers in industries facing heavy import competition were slightly less likely to be reemployed, and suffered greater earnings losses, than workers who lost their jobs in industries facing less import competition. We cannot and should not minimize the hardships of workers displaced by imports. However, we must also keep in mind that their numbers are relatively small compared with either the total labor force or even the total number of jobs lost in the United States. Estimates of the gross number of jobs lost to imports vary, but one representative estimate puts them at a bit more than 300,000 per year during the 1980s and 1990s. This number, while hardly negligible, is dwarfed by the roughly 15 million job losses estimated to occur each year in the United States. As our dynamic market economy evolves, it generates substantial churning in labor markets as jobs are gained in some sectors and lost in others; jobs gained and lost because of trade are only a small part of that process. It is understandable that concerns about job losses from import competition may extend far beyond their actual incidence in the labor market, given more general anxieties about employment security among American workers. However, to echo a point that has been made before, the proper response to the disruptions associated with trade is not to reduce trade, but rather to ameliorate the pain associated with those disruptions through enhanced assistance and retraining for displaced workers. A final concern about trade that I would like to discuss is that import competition, whether or not it affects the number of jobs, shifts the employment mix from high-quality jobs to low-quality jobs. For example, critics have long held that international trade pushes workers out of manufacturing jobs and into less desirable service-sector jobs. However, no conclusive evidence has shown that, over the long haul, the service jobs being created pay less or are otherwise less desirable than manufactured jobs being displaced. Moreover, the declining share of manufacturing in U.S. employment most likely stems less from import competition than it does from the rapid pace of productivity growth in manufacturing; this growth outpaced the productivity growth of the overall economy by about 1-1/4 percentage points annually from 1973 to 1994 and by 1-1/2 percentage points from 1994 to 2000. The higher rate of productivity growth in manufacturing has restrained both price increases and employment in the sector, thus leading the services area of the economy to expand its share of spending and jobs. This phenomenon is hardly unique to the United States--the share of manufacturing has declined in most of our major foreign trading partners as well. More recently, the outsourcing of service jobs to developing countries has come under the spotlight. The increasing use of computer programming talent in India and other low-wage countries has, understandably, struck a chord of anxiety among American workers. For years, the response of pro-trade advocates to the loss of low-wage jobs in manufacturing has been that they are being made up by the creation of higher-paid, higher-skilled jobs in the service sector. The loss of highly paid programming jobs to lower-paid workers abroad now appears to suggest that there is no place where American workers can hold their own. Yet, as in the case of import competition more generally, we must not exaggerate the importance of outsourcing to the nation's overall employment picture. There are no conclusive data, but a prominent study puts the number of jobs displaced through services outsourcing over the next decade or so at fewer than 300,000 annually, or less than 2 percent of the 15 million in total gross job losses I noted earlier. Moreover, only a fraction of those jobs represent high-skilled, high-wage jobs; these numbers are quite difficult to pin down, but one study puts the number of software jobs lost to India since 2000 at fewer than 50,000 annually. Finally, we should remember that the United States gains jobs through what is often referred to as "insourcing," that is, performing service jobs for other countries. In fact, the United States has consistently run a surplus in those categories of the balance-of-payments associated with trade in business services. Turning from the sectoral job mix to the impact of import competition on wages, the evidence is particularly unclear. Some studies have suggested that import competition from low-wage countries has depressed wages for low-skilled workers relative to those for higher-skilled workers in recent decades. However, other studies have argued that the rise in skill premiums is attributable to technological developments that have raised relative demands for educated workers. Focusing on the past few years, we see no consensus on how the mix of low- and high-wage jobs in the economy has evolved; estimates are extremely sensitive to the definition of job classes, the source of data, the time period, and method of calculation. In any event, it is doubtful that changes in the pattern of wages in the U.S. economy can be explained by any single factor--trends in trade, in population and immigration, in unionization and labor market competition, in minimum wage policy, in the skill mix of the labor force, and in technology all play a role. Drawbacks of Protectionism To sum up the discussion so far, the public likely has a reasonably good grasp of the benefits of free trade. It is the perceived drawbacks to international trade that probably account for the ambivalence indicated in opinion surveys. Some of these fears may be overstated--for example, the claim that imports lower aggregate employment. But other concerns cannot be dismissed out of hand--especially the claim that trade leads to disruptions for some workers. Balancing the pain for a few against the lasting gains for the economy as a whole, economists generally view the latter as outweighing the former, but it is admittedly difficult for many individuals in American society to share this assessment. Rather than arguing the merits of international trade in the abstract, advocates of free trade might gain more traction by arguing against concrete examples of protectionism. Each year brings new actions by the U.S. government to protect individual sectors from imports. Antidumping duties are imposed when domestic industry is believed to be injured by the sale of imported goods at less than "fair value." Countervailing duties are intended to counteract subsidies to foreign producers. Safeguard actions are intended to protect a domestic industry that has been seriously injured by a surge in imports. As of August 2004, 359 antidumping and countervailing duty orders were in place in the United States against imports from 51 countries. By discouraging unfair commercial practices, such actions, in principle, promote a more stable and competitive environment for international trade. In practice, identifying anticompetitive practices is a murky process. For example, in antidumping cases, determining the "fair value" of a good may involve a degree of discretion, thereby complicating the assessment of whether foreign goods are being sold below their appropriate price. Domestic producers have a strong incentive to lobby for trade actions regardless of whether such actions are merited. Because they inhibit free trade, protectionist actions have an array of adverse consequences that one would expect: They reduce variety and raise costs for consumers; they distort the allocation of resources in the economy by encouraging excessive resources to flow into protected sectors; and they foster inefficiency by reducing the extent of competition. Perhaps more important in the eyes of the public, however, may be several related and highly egregious consequences of protectionist actions. First, by raising the cost of goods that are inputs for other producers, import barriers may destroy more jobs in so-called "downstream" sectors than they save in protected sectors. According to one study, the 2002 steel safeguard program contributed to higher steel prices that eliminated about 200,000 jobs in steel- using industries, whereas only 187,500 workers were employed by U.S. steel- producers in December 2002. Second, trade protection may lead to very large payouts to a small number of producers and hence is often inequitable. Any time a product receives import protection, of course, a relatively small number of domestic producers receive benefits--through higher prices--at the cost of all domestic consumers in the economy. On top of this, a disproportionately small number of sectors, and often a disproportionately small number of firms within a sector, tend to enjoy the gains from protection. For example, more than one-half of the antidumping and countervailing duty orders in place as of August were on iron and steel-related products alone; by contrast, less than one-half of 1 percent of total private nonfarm employment is accounted for by iron and steel producers. As another example, according to a 1993 General Accounting Office study, 42 percent of the benefits to growers from sugar protection went to just 1 percent of growers. Although Americans favor policies designed to help the small farmer, much larger enterprises are also benefiting from agricultural trade protection. This disturbingly inequitable distribution of the benefits of protectionism is exacerbated under current law by provisions allowing antidumping and countervailing duties to be disbursed to the companies that petitioned for the duties. These provisions, which have been ruled illegal by the WTO, lead to protected producers being rewarded twice: Once through the higher prices stemming from the trade protection and again through the disbursal of the higher duties paid by importers. The distribution of these payouts has been extremely skewed: For fiscal year 2003, a single firm received more than one-fourth of the $190 million in countervailing and antidumping duties that were distributed to U.S. firms. Import quotas (as opposed to tariffs) raise a third concern about trade protection. By restricting the supply of certain types of imports within the United States, quotas may benefit those foreign producers who retain the right to sell to U.S. markets by raising the prices of their goods. For example, one study found that, of the $8.6 billion in net welfare costs induced by the Multi-Fiber Agreement, which restricts textile and apparel imports, about $6 billion accrued to those foreign producers who were allotted shares of the import quotas. Surely, many Americans would cease to support certain types of import protections if they knew that such actions were serving to prop up the profits of foreign producers. Finally, we must not forget that trade actions, while sometimes protecting some American workers in import-competing industries, often invite the threat of foreign retaliation that would hurt American workers in export industries. For example, after the imposition of steel safeguard duties in March 2002, eight of our trading partners initiated safeguard investigations of their own on steel imports. Given the importance of export markets to the most dynamic areas of U.S. manufacturing, we cannot afford to jeopardize them by inviting foreign barriers to our products. Conclusion In conclusion, I think it unlikely that we will see a marked global reversal of trade liberalization on the order of the restrictions enacted in the 1930s. Policymakers have generally learned the lessons of that destructive episode. Nevertheless, it is not inconceivable that progress in dismantling trade barriers could stall. Many of the easiest negotiations--such as on lowering tariffs--have already taken place. More ambitious and intrusive trade liberalizations, which often involve dismantling barriers to internal competition or cherished systems of domestic subsidies, may not have the necessary public support. It is also possible that a multiplicity of narrow, targeted trade actions--such as antidumping or safeguard actions--could lead to a de facto rollback in the overall degree of free trade even without a concerted shift in national policies. Thus, it is crucial to maintain public pressure for free trade. First, it is important to continue to educate the public and create a political environment supportive of free trade. In this respect, targeted criticisms of protectionist actions may be more effective than general paeans to free trade. In a recent speech, my colleague, William Poole, urged journalists describing trade restrictions to ask who gains, who loses, and what is the net gain or loss for the economy as a whole? I very much support that sentiment. Second, it is crucial to implement policies that foster stability and economic growth. Reducing unemployment and diminishing economic insecurity will likely be more effective against protectionism than a thousand speeches like this one. Toward that end, the Federal Reserve will do its part by working to promote stable financial conditions and sustainable, noninflationary growth. Footnotes Ninety-three percent of economists surveyed agreed, to a least a limited degree, with the statement that "tariffs and import quotas usually reduce general economic welfare." Richard M. Alston, J.R. Kearl, and Michael B. Vaughan (1992), "Is There a Consensus Among Economists in the 1990s?" American Economic Review , vol. 82 (May, Papers and Proceedings, 1991), pp. 203‑09. Steven Kull and others (2004), "Americans on Globalization, Trade, and Farm Subsidies," The American Public on International Issues , the PIPA/Knowledge Networks Poll (Program on International Policy Attitudes, University of Maryland, January 22), Christian Broda and David E. Weinstein (2004), "Globalization and the Gains from Variety," NBER Working Paper Series 10314 (Cambridge, Mass.: National Bureau of Economic Research, February). U.S. International Trade Commission (2004), The Economic Effects of Significant U.S. Import Restraints: Fourth Update, Investigation 332‑325, Publication 3701 (Washington: ITC, June). U.S. International Trade Commission (2003), The Impact of Trade Agreements: Effect of the Tokyo Round, U.S.-Israel FTA, U.S.-Canada FTA, NAFTA, and the Uruguay Round on the U.S. Economy, Investigation TA-2111-1, Publication 3621 (Washington: ITC, August). Drusilla K. Brown, Alan V. Deardorff, and Robert M. Stern (2002), "Computational Analysis of Multilateral Trade Liberalization in the Uruguay Round and Doha Development Round," Discussion Paper 489, Research Seminar in International Economics, Gerald R. Ford School of Public Policy (Ann Arbor: University of Michigan). Andrew B. Bernard, J. Bradford Jensen, and Peter K. Schott (2002), "Survival of the Best Fit: Competition from Low Wage Countries and the (Uneven) Growth of U.S. Manufacturing Plants," NBER Working Paper Series 9170 (Cambridge, Mass.: National Bureau of Economic Research, September). Petia Topalova (2004), "Trade Liberalization and Firm Productivity: The Case of India," IMF Working Paper WP/04/28 (Washington: International Monetary Fund, February); Nina Pavcnik (2002), "Trade Liberalization, Exit, and Productivity Improvements: Evidence from Chilean Plants," Review of Economic Studies, vol. 69 (January), pp. 245-76. Andrew B. Bernard and J. Bradford Jensen (1995), "Exporters, Jobs, and Wages in U.S. Manufacturing, 1976-1987," Brookings Papers on Economic Activity: Microeconomics, 1995 , pp. 69-119. David Dollar and Aart Kraay (2001), "Trade, Growth, and Poverty," unpublished paper, World Bank, June; Sebastian Edwards (1998), "Openness, Productivity and Growth: What Do We Really Know?" Economic Journal , vol. 108 (March), pp. 383-98. Alan M. Taylor (1994), "Three Phases of Argentine Economic Growth," NBER Historical Paper 60 (Cambridge, Mass.: National Bureau of Economic Research, September); Jagdish Bhagwati (1993), India in Transition: Freeing the Economy (New York: Oxford University Press); Douglas A. Irwin (2002), Free Trade Under Fire (Princeton: Princeton University Press); Mario J. Crucini and James Kahn (1996), "Tariffs and Aggregate Economic Activity: Lessons from the Great Depression," Journal of Monetary Economics , vol. 38 (December), pp. 427-67. Caroline Freund (2000), International Finance Discussion Paper 2000-692 (Washington: Board of Governors of the Federal Reserve System, December). Kull and others (2004), "Americans on Globalization, Trade, and Farm Subsidies." My colleague, Ben Bernanke, has discussed many of the issues linking trade and jobs in a speech earlier this year ( at the Fuqua School of Business, Duke University, March 30, 2004). Henry Farber (2003), "Job Loss in the United States, 1981-2001," Industrial Relations Section Working Paper 471, (Princeton: Princeton University, January). This study covers workers displaced for any reason, including import competition. Lori G. Kletzer (2001), Job Loss from Imports: Measuring the Costs (Washington: Institute for International Economics). Kletzer, Job Loss from Imports, estimates that 6.4 million workers were displaced from import-competing industries from 1979 to 1999. This is based on widely cited results from the technology research firm Forrester, which predicts that 3.4 million U.S. service jobs will have been moved offshore by 2015. Martin Neil Baily and Robert Z, Lawrence (2004), "What Happened to the Great U.S. Job Machine? The Role of Trade and Offshoring," paper prepared for the Brookings Panel on Economic Activity, September 9-10. Their rough estimate of nearly 45,000 software jobs relocated annually to India is consistent with an estimate by Charles L. Shultze that "the number of workers employed in producing computer and related services relocated from the United States to India could have increased by roughly 185,000 over the past four years" (Charles L. Schultze, "Offshoring, Import Competition, and the Jobless Recovery," Policy Brief 136, Washington: The Brookings Institution, August). See World Trade Organization, ; U.S. International Trade Commission (1998), Summary of Statutory Provisions Related to Import Relief, Publication 3125 (Washington: ITC, August). U.S. International Trade Commission (2004), Five-Year (Sunset) Reviews, General Information, item 7: AD and CVD orders in place. Bruce A. Blonigen (2003), "Evolving Discretionary Practices of U.S. Antidumping Activity," NBER Working Paper Series 9625 (Cambridge, Mass.: National Bureau of Economic Research, April). Joseph Francois and Laura M. Baughman (2003), "The Unintended Consequences of U.S. Steel Import Tariffs: A Quantification of the Impact During 2002," CITAC Job Studies (Washington: Consuming Industries Trade Action Coalition). "U.S. International Trade Commission, Antidumping and Countervailing Duty Orders in Place as of August 9, 2004, by Product Group." U.S. General Accounting Office (1993), "Sugar Program: Changing Domestic and International Conditions Require Program Changes," GAO/RCED-93-84 (Washington: GAO, April). As of March 2004. U.S. Customs and Border Protection (2004), Continued Dumping and Subsidy Offset Act FY 2003 Annual Report (Washington: CBP). Gary Clyde Hufbauer and Kimberly Ann Elliot (1994), Measuring the Costs of Protection in the United States (Washington: Institute for International Economics). William Poole (2004), Speech prepared for the Trade, Globalization, and Outsourcing Conference, Reuters America, Inc., New York, June 15.
Joint Press Release Board of Governors of the Federal Reserve System New York State Banking Department For Immediate Release October 8, 2004 The Federal Reserve Board and the New York State Banking Department on Friday announced the execution of a Written Agreement by and among Standard Chartered plc, London, United Kingdom, its subsidiary bank, Standard Chartered Bank, London, United Kingdom, the bank's New York branch, the Federal Reserve Bank of New York, and the New York State Banking Department. The Written Agreement addresses Bank Secrecy Act and anti-money-laundering compliance at Standard Chartered Bank's New York branch, including policies and practices relating to the provision of correspondent banking services. A copy of the Written Agreement is attached. The Federal Reserve Board and the New York State Banking Department on Friday announced the execution of a Written Agreement by and among Standard Chartered plc, London, United Kingdom, its subsidiary bank, Standard Chartered Bank, London, United Kingdom, the bank's New York branch, the Federal Reserve Bank of New York, and the New York State Banking Department. The Written Agreement addresses Bank Secrecy Act and anti-money-laundering compliance at Standard Chartered Bank's New York branch, including policies and practices relating to the provision of correspondent banking services. A copy of the Written Agreement is attached.
Remarks by Governor Ben S. Bernanke To the Conference on Reflections on Monetary Policy 25 Years after October 1979, Federal Reserve Bank of St. Louis, St. Louis, Missouri October 8, 2004 Panel discussion: What Have We Learned Since October 1979? The question asked of this panel is, "What have we learned since October 1979?" The evidence suggests that we have learned quite a bit. Most notably, monetary policy-makers, political leaders, and the public have been persuaded by two decades of experience that low and stable inflation has very substantial economic benefits. This consensus marks a considerable change from the views held by many economists at the time that Paul Volcker became Fed Chairman. In 1979, most economists would have agreed that, in principle, low inflation promotes economic growth and efficiency in the long run. However, many also believed that, in the range of inflation rates typically experienced by industrial countries, the benefits of low inflation are probably small--particularly when set against the short-run costs of a major disinflation, as the United States faced at that time. Indeed, some economists would have held that low-inflation policies would likely prove counterproductive even in the long run, if an increased focus on inflation inhibited monetary policy-makers from responding adequately to fluctuations in economic activity and employment. As it turned out, the low-inflation era of the past two decades has seen not only significant improvements in economic growth and productivity but also a marked reduction in economic volatility, both in the United States and abroad, a phenomenon that has been dubbed "the Great Moderation." Recessions have become less frequent and milder, and quarter-to-quarter volatility in output and employment has declined significantly as well. The sources of the Great Moderation remain somewhat controversial, but as I have argued elsewhere, there is evidence for the view that improved control of inflation has contributed in important measure to this welcome change in the economy (Bernanke, 2004). Paul Volcker and his colleagues on the Federal Open Market Committee deserve enormous credit both for recognizing the crucial importance of achieving low and stable inflation and for the courage and perseverance with which they tackled America's critical inflation problem. I could say much more about Volcker's achievement and its lasting benefits, but I am sure that many other speakers will cover that ground. Instead, in my remaining time, I will focus on some lessons that economists have drawn from the Volcker regime regarding the importance of credibility in central banking and how that credibility can be obtained. As usual, the views I will express are my own and are not necessarily shared by my colleagues in the Federal Reserve System. Volcker could not have accomplished what he did, of course, had he not been appointed to the chairmanship by President Jimmy Carter. In retrospect, however, Carter's appointment decision seems at least a bit incongruous. Why would the President appoint as head of the central bank an individual whose economic views and policy goals (not to mention personal style) seemed, at least on the surface, quite different from his own? However, not long into Volcker's term, a staff economist at the Board of Governors produced a paper that explained why Carter's decision may in fact have been quite sensible from the President's, and indeed the society's, point of view. Although the question seems a narrow one, the insights of the paper had far broader application; indeed, this research has substantially advanced our understanding of the links among central bank credibility, central bank structure, and the effectiveness of monetary policy. Insiders will have already guessed that the Board economist to whom I refer is Kenneth Rogoff, currently a professor of economics at Harvard, and that the paper in question is Ken's 1985 article, "The Optimal Degree of Commitment to an Intermediate Monetary Target" (Rogoff, 1985). The insights of the Rogoff paper are well worth recalling today. Rather than considering the paper in isolation, however, I will place it in the context of two other classic papers on credibility and central bank design, an earlier work by Finn Kydland and Edward Prescott and a later piece by Carl Walsh. As I proceed, I will note what I see to be the important lessons and the practical implications of this line of research. Central bankers have long recognized at some level that the credibility of their pronouncements matters. I think it is fair to say, however, that in the late 1960s and 1970s, as the U.S. inflation crisis was building, economists and policymakers did not fully understand or appreciate the determinants of credibility and its link to policy outcomes. In 1977, however, Finn Kydland and Edward Prescott published a classic paper, entitled "Rules Rather than Discretion: The Inconsistency of Optimal Plans" (Kydland and Prescott, 1977), that provided the first modern analysis of these issues. Specifically, Kydland and Prescott demonstrated why, in many situations, economic outcomes will be better if policymakers are able to make credible commitments, or promises, about certain aspects of the policies they will follow in the future. "Credible" in this context means that the public believes that the policymakers will keep their promises, even if they face incentives to renege. In particular, as one of Kydland and Prescott's examples illustrates, monetary policy-makers will generally find it advantageous to commit publicly to following policies that will produce low inflation. If the policymakers' statements are believed (that is, if they are credible), then the public will expect inflation to be low, and demands for wage and price increases should accordingly be moderate. In a virtuous circle, this cooperative behavior by the public makes the central bank's commitment to low inflation easier to fulfill. In contrast, if the public is skeptical of the central bank's commitment to low inflation (for example, if it believes that the central bank may give in to the temptation to overstimulate the economy for the sake of short-term employment gains), then the public's inflation expectations will be higher than they otherwise would be. Expectations of high inflation lead to more-aggressive wage and price demands, which make achieving and maintaining low inflation more difficult and costly (in terms of lost output and employment) for the central bank. Providing a clear explanation of why credibility is important for effective policymaking, as Kydland and Prescott did, was an important step. However, these authors largely left open the critical issue of how a central bank is supposed to obtain credibility in the first place. Here is where Rogoff's seminal article took up the thread. Motivated by the example of Carter and Volcker, Rogoff's paper showed analytically why even a president who is not particularly averse to inflation, or at least no more so than the average member of the general public, might find it in his interest to appoint a well-known "inflation hawk" to head the central bank. The benefit of appointing a hawkish central banker is the increased inflation-fighting credibility that such an appointment brings. The public is certainly more likely to believe an inflation hawk when he promises to contain inflation because they understand that, as someone who is intrinsically averse to inflation, he is unlikely to renege on his commitment. As increased credibility allows the central bank to achieve low inflation at a smaller cost than a non-credible central bank can, the president may well find, somewhat paradoxically, that he prefers the economic outcomes achieved under the hawkish central banker to those that could have been obtained under a central banker with views closer to his own and those of the public. Appointing an inflation hawk to head the central bank may not be enough to ensure credibility for monetary policy, however. As Rogoff noted in his article, for this strategy to confer significant credibility benefits, the central bank must be perceived by the public as being sufficiently independent from the rest of the government to be immune to short-term political pressures. Thus Rogoff's proposed strategy was really two-pronged: The appointment of inflation-averse central bankers must be combined with measures to ensure central bank independence. These ideas, supported by a great deal of empirical work, have proven highly influential. Indeed, the credibility benefits of central bank autonomy have been widely recognized in the past twenty years, not only in the academic literature but, far more consequentially, in the real-world design of central banking institutions. For example, in the United Kingdom, the euro area, Japan, and numerous other places, recent legislation or other government action has palpably strengthened the independence of the central banks. Rogoff's proposed solution to the credibility problems of central banks does have some limitations, however, as Ken recognized both in his paper and in subsequent work. First, although an inflation-averse central banker enhances credibility and delivers lower inflation on average, he may not respond to shocks to the economy in the socially desirable way. For example, faced with an aggregate supply shock (such as a sharp rise in oil prices), an inflation-averse central banker will tend to react too aggressively (from society's point of view) to contain the inflationary impact of the shock, with insufficient attention to the consequences of his policy for output and employment. Second, contrary to an assumption of Rogoff's paper, in practice the policy preferences of a newly appointed central banker will not be precisely known by the public but must be inferred from policy actions. (Certainly the public's perceptions of Chairman Volcker's views and objectives evolved over time.) Knowing that the public must make such inferences might tempt a central banker to misrepresent the state of the economy (Canzoneri, 1985) or even to take suboptimal policy decisions; for example, the central banker may feel compelled to tighten policy more aggressively than is warranted in order to convince the public of his determination to fight inflation. The public's need to infer the central banker's policy preferences may even generate increased economic instability, as has been shown in a lively recent literature on the macroeconomic consequences of learning. The third pathbreaking paper I will mention today, a 1995 article by Carl Walsh entitled "Optimal Contracts for Central Bankers," was an attempt to address both of these issues. To do so, Walsh conducted a thought experiment. He asked his readers to imagine that the government or society could offer the head of the central bank a performance contract, one that includes explicit monetary rewards or penalties that depend on the economic outcomes that occur under his watch. Remarkably, Walsh showed that, in principle, a relatively simple contract between the government and the central bank would lead to the implementation of monetary policies that would be both credible and fully optimal. Under this contract, the government provides the central banker with a base level of compensation but then applies a penalty that depends on the realized rate of inflation--the higher the observed inflation rate, the greater the penalty. If the public understands the nature of the contract, and if the penalty assessed for permitting inflation is large enough to affect central bank behavior, the existence of the contract would give credence to central bank promises to keep the inflation rate low (that is, the contract would provide credibility). Walsh's contract has in common with Rogoff's approach the idea that, in a world of imperfect credibility, giving the central banker an objective function that differs from the true objectives of society may be useful. However, Walsh also shows that the contracting approach ameliorates the two problems associated with Rogoff's approach. First, under the Walsh contract, the central banker has incentives not only to achieve the target rate of inflation but also to respond in the socially optimal manner to supply shocks. Second, as the inflation objective and the central banker's incentive scheme are made explicit by the contract, the public's problem of inferring the central banker's policy preferences is significantly reduced. There have been a few attempts in the real world to implement an incentive contract for central bankers--most famously a plan proposed to the New Zealand legislature, though never adopted, which provided for firing the governor of the central bank if the inflation rate deviated too far from the government's inflation objective. But Walsh's contracts are best treated as a metaphor rather than as a literal proposal for central bank reform. Although the pay of central bankers is unlikely ever to depend directly on the realized rate of inflation, central bankers, like most people, care about many other aspects of their jobs, including their professional reputations, the prestige of the institutions in which they serve, and the probability that they will be reappointed. Walsh's analysis and many subsequent refinements by other authors suggest that central bank performance might be improved if the government set explicit performance standards for the central bank (perhaps as part of the institution's charter or enabling legislation) and regularly compared objectives and outcomes. Alternatively, because central banks may possess the greater expertise in determining what economic outcomes are both feasible and most desirable, macroeconomic goals might be set through a joint exercise of the government and the central bank. Many countries have established targets for inflation, for example, and central bankers in those countries evidently make strong efforts to attain those targets. The Federal Reserve Act does not set quantitative goals for the U.S. central bank, but it does specify the objectives of price stability and maximum sustainable employment and requires the central bank to present semi-annual reports to the Congress on monetary policy and the state of the economy. Accountability to the public as well as to the legislature is also important; for this reason, the central bank should explain regularly what it is trying to achieve and why. In sum, Walsh's paper can be read as providing theoretical support for an explicit, well-designed, and transparent framework for monetary policy, one which sets forth the objectives of policy and holds central bankers accountable for reaching those objectives (or, at least, for providing a detailed and plausible explanation of why the objectives were missed). In the simple model that Walsh analyzes, the optimal contract provides all the incentives needed to induce the best possible monetary policy, so that appointing a hawkish central banker is no longer beneficial. However, in practice--because Walsh's optimal contracts can be roughly approximated at best, because both the incentives and the policy decisions faced by central bankers are far more complex than can be captured by simple models, and because the appointment of an inflation-averse central banker may provide additional assurance to the public that the government and the central bank will keep their promises--the Walsh approach and the Rogoff approach are almost certainly complementary. That is, a clear, well-articulated monetary policy framework; inflation-averse central bankers; and autonomy for central banks in the execution of policy are all likely to contribute to increased central bank credibility and hence better policy outcomes. Of course, other factors that I could not cover in this short review, such as the central bank's reputation for veracity as established over time, may also strengthen its credibility (Barro and Gordon, 1983b; Backus and Driffill, 1985). Let me end where I began, with reference to Paul Volcker and his contributions. I have discussed today how Volcker's personality and performance inspired one seminal piece of research about the determinants of central bank credibility. In focusing on a few pieces of academic research, however, I have greatly understated the impact of the Volcker era on views about central banking. The Volcker disinflation (and analogous episodes in the United Kingdom, Canada, and elsewhere) was undoubtedly a major catalyst for an explosion of fresh thinking by economists and policymakers about central bank credibility, how it is obtained, and its benefits for monetary policy-making. Over the past two decades, this new thinking has contributed to a wave of changes in central banking, particularly with respect to the institutional design of central banks and the establishment of new frameworks for the making of monetary policy. Ironically, the applicability of the ideas stimulated by the Volcker chairmanship to the experience of the U.S. economy under his stewardship remains unclear. Though the appointment of Volcker undoubtedly increased the credibility of the Federal Reserve, the Volcker disinflation was far from a costless affair, being associated with a minor recession in 1980 and a deep recession in 1981-82. Evidently, Volcker's personal credibility notwithstanding, Americans' memories of the inflationary 1970s were too fresh for their inflation expectations to change quickly. It is difficult to know whether alternative tactics would have helped; for example, the announcement of explicit inflation objectives (which would certainly have been a radical idea at the time) might have helped guide inflation expectations downward more quickly, but they might also have created a political backlash that would have doomed the entire effort. Perhaps no policy approach or set of institutional arrangements could have eliminated the 1970s inflation at a lower cost than was actually incurred. If so, then the significance of Paul Volcker's appointment was not its immediate effect on expectations or credibility but rather the fact that he was one of the rare individuals tough enough and with sufficient foresight to do what had to be done. By doing what was necessary to achieve price stability, the Volcker Fed laid the groundwork for two decades, so far, of strong economic performance. REFERENCES Backus, David, and John Driffill (1985). "Inflation and Reputation," American Economic Review (75), June, pp. 530-8. Barro, Robert, and David Gordon (1983a). "A Positive Theory of Monetary Policy in a Natural Rate Model," Journal of Political Economy (91), pp. 589-610. Barro, Robert, and David Gordon (1983b). "Rules, Discretion, and Reputation in a Model of Monetary Policy," Journal of Monetary Economics (12), pp. 101-21. Bernanke, Ben (2004). remarks before the Eastern Economic Association, Washington, D.C., February 20. Calvo, Guillermo (1978). "On the Time Consistency of the Optimal Policy in a Monetary Economy," Econometrica (46), November, pp. 1411-28. Canzoneri, Matthew (1985). "Monetary Policy Games and the Role of Private Information," American Economic Review (75), September, pp. 547-64. Erceg, Christopher, and Andrew Levin (2001). Board of Governors of the Federal Reserve System, Finance and Economics Discussion Series, 2001-45 (October). Evans, George, and Seppo Honkopohja (2001). Learning and Expectations in Macroeconomics. Princeton, N. J.: Princeton University Press. Herrendorf, Berthold, and Ben Lockwood (1997). "Rogoff's 'Conservative' Central Banker Restored," Journal of Money, Credit, and Banking (29), November, pp. 476-95. Kydland, Finn, and Edward Prescott (1977). "Rules Rather than Discretion: The Inconsistency of Optimal Plans," Journal of Political Economy (85), June, pp. 473-92. Lohmann, Suzanne (1992). "Optimal Commitment in Monetary Policy: Credibility versus Flexibility," American Economic Review (82), March, pp. 273-86. Orphanides, Athanasios, and John C. Williams (forthcoming). "Imperfect Knowledge, Inflation Expectations, and Monetary Policy," in B. Bernanke and M. Woodford, eds., The Inflation Targeting Debate . Chicago, Ill.: University of Chicago Press for NBER. Persson, Torsten, and Guido Tabellini (1993). "Designing Institutions for Monetary Stability," Carnegie-Rochester Conference Series on Public Policy (39), pp. 53-84. Rogoff, Kenneth (1985). "The Optimal Degree of Commitment to an Intermediate Monetary Target," Quarterly Journal of Economics (100), November, pp. 1169-89. Rogoff, Kenneth (1987). "Reputational Constraints on Monetary Policy," Carnegie Rochester Conference Series on Public Policy (26), pp. 141-82. Svensson, Lars (1997). "Optimal Inflation Contracts, 'Conservative' Central Banks, and Linear Inflation Contracts," American Economic Review (87), March, pp. 98-114. Walsh, Carl (1995). "Optimal Contracts for Central Bankers," American Economic Review (85), March, pp. 150-67. Walsh, Carl (2003). Monetary Theory and Policy , 2nd ed. Cambridge, Mass: MIT Press. Footnotes Rogoff's paper was widely circulated in 1982, a sad commentary on publication lags in economics. In focusing on three landmark papers I necessarily ignore what has become an enormous literature on credibility and monetary policy. Walsh (2003, chap. 8) provides an excellent overview. Rogoff (1987) was an important early survey of the "first generation" of models of credibility in the context of central banking. In another noteworthy paper, Calvo (1978) made a number of points similar to those developed by Kydland and Prescott. The extension of the Kydland-Prescott "inflation bias" by Barro and Gordon (1983a) has proved highly influential. Rogoff was my graduate school classmate at M.I.T., and I recently asked him for his recollections about the origins of the conservative central banker. Here (from a personal e-mail) is part of his response: [T]he paper was mainly written at the Board in 1982 . . . It came out as an IMF working paper in February 1983 (I was visiting there), and then the same version came out as an International Finance Discussion paper [at the Board of Governors] in September 1983 . . . The original version of the paper . . . featured inflation targeting. Much like the published paper, I suggested that having an independent central bank can be a solution to the time consistency [that is, credibility] problem if we give the bank an intermediate target and some (unspecified) incentive to hit the target . . . I had the conservative central banker idea in there as well, as one practical way to ensure the central bank placed a high weight on inflation. Larry Summers, my editor at the [ Quarterly Journal of Economics ], urged me to move that idea up to the front section and place inflation targeting second. This, of course, is how the paper ended up. [Regarding the Fed], Dale Henderson and Matt Canzoneri liked the paper very much . . . many other researchers gave me feedback on my paper (including Peter Tinsley, Ed Offenbacher, Bob Flood, Jo Anna Gray, and many others) . . . Last but perhaps most important, there is absolutely no doubt that the paper was inspired by my experience watching the Volcker Fed at close range. I never would have written it had I not . . . ended up as an economist at the Board. Walsh (2003, section 8.5) reviews empirical research on the correlations of central bank independence and economic outcomes. A consistent finding is that more-independent central banks produce lower inflation without any increase in output volatility. The benefits of central bank independence should not lead us to ignore its downside, which is that the very distance from the political process that increases the central bank's policy credibility by necessity also risks isolating the central bank and making it less democratically accountable. For this reason, central bankers should make communication with the public and their elected representatives a high priority. Moreover, central bank independence does not imply that central banks should never coordinate with other parts of the government, under the appropriate circumstances. Lohmann (1992) shows that this problem can be ameliorated if the government limits the central bank's independence, stepping in to override the central bank's decisions when the supply shock becomes too large. However, to preserve the central bank's independence in normal situations, this approach would involve stating clearly in advance the conditions under which the government would intercede, which may not be practicable. Evans and Honkopohja (2001) is the standard reference on learning in macroeconomics. Recent papers that apply models of learning to the analysis of U.S. monetary policy include Erceg and Levin (2001) and Orphanides and Williams (forthcoming). Persson and Tabellini (1993) provided an influential analysis of the contracting approach that extended and developed many of the points made by Walsh (1995). An objection to this conclusion is that, although the central bank's incentives are made clear by the contract, the public might worry that the government might renege on its commitment to low inflation by changing the contract. Those who discount this concern argue that changing the contract in midstream would be costly for the government, because laws once enacted are difficult to modify and because changing an established framework for policy in an opportunistic way would be politically embarrassing. A key assumption underlying this result is that the central banker cares about the state of the economy as well as about the income provided by his incentive contract. In personal communication, Walsh reports to me that he was visiting a research institute in New Zealand at the time of these discussions. Walshs reflection on the New Zealand proposals helped to inspire his paper. Several authors have shown this point in models in which the inflation bias arising from non-credible policies differs across states of nature; see, for example, Herrendorf and Lockwood (1997) and Svensson (1997). But see Rogoff (1987) for a critique of models of central bank reputation. Evidence on the behavior of inflation expectations after 1979 supports the view that the public came to appreciate only very gradually that Volcker's policies represented a break from the immediate past (Erceg and Levin, 2001).
Joint Press Release Board of Governors of the Federal Reserve System Financial Crimes Enforcement Network For Immediate Release October 12 , 2004 Civil money penalty against AmSouth Bank of Birmingham The Financial Crimes Enforcement Network (FinCEN) and the Board of Governors of the Federal Reserve System announced today that they have jointly assessed a $10 million civil money penalty against AmSouth Bank of Birmingham, Alabama for its violations of the Bank Secrecy Act. In addition, the Federal Reserve Board and the Alabama Superintendent of Banks concurrently issued a Cease and Desist Order requiring AmSouth Bank and its parent bank holding company, AmSouth Bancorporation, to take certain corrective actions. AmSouth, without admitting or denying any allegations, consented to the payment of the civil money penalty and issuance of the Orders by FinCEN, the Board, and the State. FinCEN and the Federal Reserve Board based their assessment on the failure of the banking organization to establish an adequate anti-money-laundering program and the failure to file accurate, complete, and timely Suspicious Activity Reports (SARs). The agencies found systemic defects in AmSouthï¿½s program with respect to internal controls, employee training, and independent review that resulted in failures to identify, analyze and report suspicious activity occurring at the bank. William D. Langford, Jr., Associate Director of FinCENï¿½s Regulatory Policy and Programs Division, stated, ï¿½Comprehensive Bank Secrecy Act compliance programs that enable financial institutions to identify and report suspicious activities are the foundation of our efforts to combat money laundering and protect our financial system. As this case reflects, if a financial institution fails to establish and implement effectively such programs, we will take appropriate action to ensure compliance.ï¿½ The Orders are part of coordinated actions with the Office of the U.S. Attorney for the Southern District of Mississippi and the Internal Revenue Service, Criminal Investigation, who are today announcing the execution of a Deferred Prosecution Agreement with AmSouth in connection with charges the bank violated the Bank Secrecy Act relating to the filing of inaccurate, incomplete, or late SARs. The Federal Reserve Board and FinCEN provided assistance to, and cooperation with, law enforcement authorities during the course of their investigation. ï¿½These actions demonstrate how coordination among the agencies responsible for enforcement of the Bank Secrecy Act can address the effectiveness of banksï¿½ anti-money-laundering programs and internal compliance reviews,ï¿½ said Herbert A. Biern, Senior Associate Director of the Boardï¿½s Division of Banking Supervision and Regulation. The Cease and Desist Order issued by the Federal Reserve Board requires improvements in the banking organizationï¿½s Bank Secrecy Act compliance and suspicious activity monitoring and reporting programs, a review of prior transactions to ensure that all SARs have been filed, as required, and enhancements to internal controls and management oversight. Copies of the agenciesï¿½ enforcement actions are attached. Civil money penalty against AmSouth Bank of Birmingham The Financial Crimes Enforcement Network (FinCEN) and the Board of Governors of the Federal Reserve System announced today that they have jointly assessed a $10 million civil money penalty against AmSouth Bank of Birmingham, Alabama for its violations of the Bank Secrecy Act. In addition, the Federal Reserve Board and the Alabama Superintendent of Banks concurrently issued a Cease and Desist Order requiring AmSouth Bank and its parent bank holding company, AmSouth Bancorporation, to take certain corrective actions. AmSouth, without admitting or denying any allegations, consented to the payment of the civil money penalty and issuance of the Orders by FinCEN, the Board, and the State. FinCEN and the Federal Reserve Board based their assessment on the failure of the banking organization to establish an adequate anti-money-laundering program and the failure to file accurate, complete, and timely Suspicious Activity Reports (SARs). The agencies found systemic defects in AmSouthï¿½s program with respect to internal controls, employee training, and independent review that resulted in failures to identify, analyze and report suspicious activity occurring at the bank. William D. Langford, Jr., Associate Director of FinCENï¿½s Regulatory Policy and Programs Division, stated, ï¿½Comprehensive Bank Secrecy Act compliance programs that enable financial institutions to identify and report suspicious activities are the foundation of our efforts to combat money laundering and protect our financial system. As this case reflects, if a financial institution fails to establish and implement effectively such programs, we will take appropriate action to ensure compliance.ï¿½ The Orders are part of coordinated actions with the Office of the U.S. Attorney for the Southern District of Mississippi and the Internal Revenue Service, Criminal Investigation, who are today announcing the execution of a Deferred Prosecution Agreement with AmSouth in connection with charges the bank violated the Bank Secrecy Act relating to the filing of inaccurate, incomplete, or late SARs. The Federal Reserve Board and FinCEN provided assistance to, and cooperation with, law enforcement authorities during the course of their investigation. ï¿½These actions demonstrate how coordination among the agencies responsible for enforcement of the Bank Secrecy Act can address the effectiveness of banksï¿½ anti-money-laundering programs and internal compliance reviews,ï¿½ said Herbert A. Biern, Senior Associate Director of the Boardï¿½s Division of Banking Supervision and Regulation. The Cease and Desist Order issued by the Federal Reserve Board requires improvements in the banking organizationï¿½s Bank Secrecy Act compliance and suspicious activity monitoring and reporting programs, a review of prior transactions to ensure that all SARs have been filed, as required, and enhancements to internal controls and management oversight. Copies of the agenciesï¿½ enforcement actions are attached.
Joint Press Release Board of Governors of the Federal Reserve System Federal Deposit Insurance Corporation National Credit Union Administration Office of the Comptroller of the Currency Office of Thrift Supervision For Immediate Release October 14 , 2004 Contacts: Federal Reserve Susan Stawick (202) 452-2955 FDIC David Barr (202) 898-6992 NCUA Cherie Umbel (703) 518-6330 OCC Dean DeBuck (202) 874-5770 OTS Erin Hickman (202) 906-6677
Remarks by Governor Ben S. Bernanke At the Cato Institute 22nd Annual Monetary Conference, Washington, D.C. October 14, 2004 International Monetary Reform and Capital Freedom The free movement of capital across borders has created, and will certainly continue to create, enormous economic benefits. Capital flows afford developing countries and other regions the means to exploit promising investment opportunities, while providing savers around the globe the means both to earn higher returns and to reduce risk through international portfolio diversification. Access to international capital markets also permits nations to accumulate foreign assets in good times and to deplete those assets or to borrow in bad times, mitigating the effects on living standards of shocks to domestic income and production. In recent years, global capital flows have attained record highs relative to global income, reflecting both the powerful tendency of capital to seek the highest return and a concerted international effort to dismantle political and regulatory barriers to capital mobility. The issue I would like to address today is the role of monetary policy, and in particular the choice of the exchange rate regime, in enabling economies to take the maximum advantage of the increasing openness and depth of international capital markets. I should begin by noting that the views I will express today are my responsibility and are not necessarily shared by my colleagues at the Federal Reserve. The discussion of monetary policy and capital flows almost inevitably begins with the well-known "trilemma,ï¿½ the observation that a country can choose no more than two of the following three features of its policy regime: (1) free capital mobility across borders, (2) a fixed exchange rate, and (3) an independent monetary policy. Various combinations of these features have dominated world monetary arrangements in different eras. Under the classical gold standard of the nineteenth century, the major trading countries chose the benefits of free capital flows and the perceived stability of a fixed relation of their currency to gold; of necessity, then, they largely abjured independent monetary policies. Under the Bretton Woods system created at the end of World War II, many countries renounced capital mobility in an attempt to maintain both fixed exchange rates and monetary independence. Currently, among the major industrial regions at least, we have collectively chosen a regime that gives up fixed exchange rates in favor of the other two elements. Is the international monetary regime that is in place today the best one for the world? For the economically advanced nations that use the worldï¿½s three key currencies--the euro, the yen, and the dollar--I believe that the benefits of independent monetary policies and capital mobility greatly exceed whatever costs may result from a regime of floating exchange rates. My view is widely--though not universally--shared among economists and policymakers. In particular, what was once viewed as the principal objection to floating exchange rates, that their adoption would leave the system bereft of a nominal anchor, has proven to be unfounded. Most countries today, including many emerging-market and developing nations as well as the advanced industrial countries, have succeeded in establishing a commitment to keeping domestic inflation low and stable, a commitment that has served effectively as a nominal anchor. A newer critique of floating exchange rates contends that exchange rates are more volatile than can be explained by the macroeconomic fundamentals and, moreover, that this excess volatility has in some cases inhibited international trade (Flood and Rose, 1995; Rose, 2000; Klein and Shambaugh, 2004). Like other asset prices, floating exchange rates do indeed exhibit a great deal of volatility in the very short term, responding to many types of economic news and, sometimes it seems, to no news at all. Whether this very short-term volatility is excessive relative to fundamentals (which are inherently difficult to observe and measure) is debatable. In any case, this short-term volatility seems unlikely to have substantial effects on trade or capital flows, as short-term fluctuations in exchange rates are easily hedged. Exchange rates also exhibit long-horizon volatility, of course; but, although the swings in the exchange value of the dollar over the past thirty years have been large, so have been the changes in the global macroeconomic environment. As key components of the international adjustment mechanism, fluctuations in exchange rates and the associated financial flows have often played an important stabilizing role. For example, the sharp rise in the dollar in the late 1990s reflected to an important degree a surge in U.S. productivity growth, which raised perceived rates of return and attracted significant inflows of capital. The capital inflows, the stronger dollar, and the associated rise in imports worked together to permit increased capital investment in the United States during that period, enabling production and incomes to grow without overheating the economy or requiring a sustained rise in interest rates. The value of floating exchange rates as shock absorbers might make their adoption worthwhile even if their volatility did have a chilling effect on trade. However, the sharp rise in trade volumes relative to world gross domestic product in recent decades suggests to me that, at least for the world as a whole, any such chilling effect has likely been minor. The presumption in favor of allowing the market to determine the exchange rates among the major currencies is strengthened by the fact that a consensus about the appropriate levels at which to peg these currencies would be difficult to obtain. A poor choice of the rates at which currencies would trade could condemn one or more regions to unwanted inflation and the other regions to economic stagnation for a transition period that could easily last several years. The United Kingdom suffered the consequences of a poor choice of peg when it returned to the gold standard after World War I, as an overvalued pound reduced British exports and significantly worsened the countryï¿½s unemployment problem. The United Kingdom faced analogous problems sixty-five years later, when it entered the European exchange rate mechanism (ERM) in 1990 at a parity that again disadvantaged British exports and contributed to Great Britainï¿½s worst recession in the past twenty years. Nor were these macroeconomic costs compensated for by greater external stability; in both episodes, doubts about the sustainability of the peg generated speculative attacks that ultimately forced the pound off its fixed rate. Overall, the case for floating exchange rates among the United States, Japan, and the euro zone seems to me to be compelling. For smaller industrial countries, the case for floating rates may in some instances be less clear-cut, for example, when the bulk of a countryï¿½s trade is with a single, large trading partner. Generally, though, my sense is that the benefits of floating exchange rates exceed the costs for these countries as well. Much more controversial is the question of how developing and emerging-market countries should resolve the trilemma. Some might argue against these countriesï¿½ choosing to allow free capital mobility on the grounds that rapid reversals in international capital flows have induced balance of payments crises and difficult domestic adjustments for them in the past. But even those most concerned about potential instability in international capital flows would have to admit that comprehensive capital controls, if applied for any extended period, might solve one problem at the cost of creating a more serious one--namely, the inhibition of growth and development that occurs when nations lack access to international capital markets. At best, then, restrictions on capital mobility should be viewed as a temporary expedient, a second-best or third-best solution to the problems presented by flawed or immature institutions in a nation at early or intermediate stages of development. In the medium run, the better approach--admittedly, one not always so easy to implement--is to commit to making the nationï¿½s legal, regulatory, and fiscal framework stronger and more transparent. If foreign investors are thus reassured that their capital will be employed efficiently and its returns repatriated smoothly, the risks of capital flow reversals under a regime of free capital mobility should be much reduced. If we agree that every country should set a goal of achieving at least some degree of capital mobility, then the trilemma for developing countries ultimately boils down to the choice between flexible exchange rates (and the associated independence of monetary policy) and fixed rates (which do not allow monetary independence). For the remainder of my remarks I will focus on that choice. I should acknowledge immediately that to state the choice as one of "fixed versus floatingï¿½ is to oversimplify. Both types of regime are actually broad categories, each of which contains a number of variants. Fixed exchange rates are almost never irrevocably fixed, for example: Crawling pegs allow the rate to be adjusted in a controlled manner, while some putatively fixed rates are actually re-set at frequent intervals, either as an instrument of policy or under external pressure. So-called hard pegs, including currency boards and dollarization, may draw credibility from various institutional impediments to changing the rate; but even full dollarization can be reversed, as Liberia proved in 1982. Floating exchange rates cover an even wider range of policy behavior than fixed rates--from full reliance on the foreign exchange market for the determination of the exchange rate to a carefully managed float. So what should developing countries do about the exchange rate? Theory suggests that any group of countries whose economic structures and trade linkages satisfy the requirements of an optimum currency area, in the sense of Mundell (1961), would be well served by fixing the exchange rates among their currencies or, even better, by forming a currency union. However, in practice, empirical analyses have generally been unsuccessful at identifying multi-country regions of any size that meet the criteria for an optimum currency area. Indeed, some studies have concluded that even the United States and the European Union, the largest currency unions, are themselves not optimum currency areas. Plausibly, political rather than economic considerations--namely, the desire to form a more perfect union--underlay the decisions of each of these entities to adopt a common currency. , Besides countries well-suited for a currency union, a second group of countries that might conceivably be better off with a fixed exchange rate, at least for a time, are the very poorest and least developed countries, which may lack the institutional infrastructure to effectively operate an independent monetary policy. In these countries, a hard peg or even the adoption of the currency of a major trading partner--sometimes known as dollarization, although the term also refers to cases in which the currency adopted is one other than the dollar--may be policy options worth considering. (I want to be clear that I am speaking generally and am not advocating that other countries adopt the U.S. currency.) Although dollarization has the advantage of making monetary policy essentially automatic and should be an effective device for controlling inflation, one is struck by the fact that so few countries have chosen this approach. Costs of dollarization include the loss of revenue from money creation and the reduced ability of the central bank to serve as a lender of last resort. But perhaps the most important impediment to dollarization is that, in giving up their own currency, the countryï¿½s citizens may feel that they are losing an important symbol of the nationï¿½s sovereignty and pride. For other developing and emerging-market countries, I would argue that the best course is generally to let the exchange rate float freely and to make low and stable inflation a principal focus of monetary policy. As I have already suggested, this approach makes the targeted inflation rate, and not the exchange rate or some other variable, the nominal anchor of the system. An important reason for making the inflation rate (more precisely, the price level) the nominal anchor is that the general price level is more directly linked to economic welfare than is the exchange rate. Domestic price stability improves the operation of markets, reduces the costs associated with economizing on money holdings and with changing prices, lessens distortions associated with imperfect indexing of the tax system and the accounting system, and aids long-term planning. As I have also already noted, concerns about the feasibility of this approach have been put to rest by the experience of the past decade or so. Central banks in many countries, with either an explicit or an implicit inflation target, have demonstrated the capacity to keep inflation low and stable. Indeed, recent research suggests that the combination of an inflation target, central bank independence, and a market-determined exchange rate tends to reduce variability in both inflation and output, even in small open economies such as Finland and New Zealand (Truman, 2003). To be clear, a focus on domestic inflation does not imply that policymakers must entirely ignore the exchange rate; particularly in small open economies, stabilization of the domestic price level may entail some "leaning against the windï¿½ with respect to exchange rate movements, because of their influence on domestic prices. This behavior does not imply that exchange rate stabilization is an independent objective, however; and should price stability and exchange rate stability come into conflict, it is the latter that should be jettisoned. In contrast to floating rates, fixed exchange rates--rather than being a mechanism for reducing macroeconomic instability--have often been a source of instability. Historically, governments have often defended their fixed parity even after the overvaluation of the exchange rate became obvious, leading to losses of foreign exchange reserves, a balance of payments crisis, and difficult domestic adjustments. Some observers have suggested that the solution to this problem is to tie the governmentï¿½s hands even more forcefully by imposing a harder peg, by means of a currency board or dollarization for example. But market participants know that promises to maintain a fixed rate are almost never irrevocable, and so a speculative attack is always possible (as Argentina recently learned, for example). Another strategy for deterring speculative attacks on a fixed exchange rate is to build a "war chestï¿½ of foreign-currency reserves. To be effective in todayï¿½s world of highly mobile capital, the war chest may have to be sizable indeed; and for countries with large government debts and high domestic interest rates, holding great quantities of low-yielding reserves can have serious fiscal consequences. In any case, strategies to increase the defensibility of the peg ignore the broader issue of the role of the exchange rate in macroeconomic adjustment. For an individual country, forcing adjustment to a mis-valued exchange rate through domestic price changes is likely to be far more difficult and costly than an adjustment occurring through exchange rate depreciation or appreciation. For the world as a whole, macroeconomic adjustment may likewise be impeded if economically important countries attempt to maintain pegs at levels that differ from those dictated by fundamentals. If fixed exchange rates bear such risks, what explains their continued existence? One traditional argument in favor of fixed exchange rates for developing countries focuses on their usefulness in so-called heterodox programs for overcoming high inflation. According to this view, the advantage of fixing the exchange rate as one element of an anti-inflation program (along with fiscal reforms and other policy changes) is that fixing the rate is more visible, more credible, and easier to explain than a commitment to stabilizing prices directly. Even if we grant a role for a fixed exchange rate in combating high inflation, however, this argument provides no rationale for fixing the rate indefinitely. If the program is successful and the inflationary psychology is broken, nothing prevents a transition from targeting the exchange rate to targeting inflation. Two countries with chronic inflation problems, Argentina and Brazil, did not experience a sustained resurgence of high inflation when they abandoned fixed rates in recent years. Brazil now targets inflation, and by some reports Argentina has considered the option. Israel broke the back of its hyperinflation in the mid-1980s with the aid of a fixed exchange rate but then made a gradual and successful transition to inflation targeting. And, of course, this argument provides no rationale for the use of fixed exchange rates by countries, such as the East Asian emerging-market countries, that have not experienced episodes of high inflation. An interesting recent explanation for the continued existence of fixed exchange rates is the so-called fear-of-floating phenomenon (Calvo and Reinhart, 2000). According to this view, the poor credibility of policymakers in some countries implies that the exchange rate, if left unmanaged, would prove excessively volatile. High exchange rate volatility could prove very harmful in these countries, for at least two reasons. First, the openness of these economies to trade, coupled with the fact that the exchange rate may serve as a focal point for inflation expectations, may imply that exchange rate volatility translates quickly into instability in consumer prices. Second, because firms and households in these countries often borrow in foreign currencies but receive revenues and incomes in the domestic currency, swings in the exchange rate have major effects on the net worth of these borrowers. In particular, a sharp devaluation, by raising the value of foreign liabilities relative to domestic assets, might bankrupt large segments of the economy, with severe financial and economic implications. According to the fear-of-floating hypothesis, the severe consequences of exchange rate volatility in these countries may lead policymakers to manage their currencies quite closely to damp volatility, no matter what the putative exchange rate regime. If we assume that the fear-of-floating hypothesis accurately describes behavior, what are the implications? Some have argued that, given the unwillingness to float, countries would be better off dollarizing or taking other measures to achieve a hard peg. This approach would have the benefits (the argument goes) of making explicit the countryï¿½s implicit policy, making a disruptive devaluation less likely, and consequently, possibly reducing the risk premium that borrowers in the country must pay to borrow abroad. I have already expressed reservations about so-called hard pegs for developing countries: Though less so than conventional pegs, they remain subject to speculative attacks, and they may make domestic macroeconomic adjustment more difficult. They also constrain the central bankï¿½s ability to act as a lender of last resort in the event of a banking crisis. Moreover, the small amount of available evidence does not favor the view that a hard peg will significantly reduce the risk premium a country must pay on international loans; for example, the dollarized nations of El Salvador and Panama do not appear to be paying lower interest rate premiums on their debt than other similarly situated countries. Furthermore, to the extent that a hard peg encourages foreign-currency borrowing, the costs of devaluation, should it come, may be greatly increased. One may also question whether the fear of floating is a permanent and irremediable condition. An important underpinning of the fear-of-floating argument is the idea that borrowing and lending in international capital markets must take place only in a few key currencies, condemning most countries to borrow in a currency other than their own and exposing them to heavy losses in the event of a devaluation (Eichengreen and Hausman, 1999). In addition, because of creditor mistrust, the borrowing that does take place must be mostly in short-maturity instruments, greatly increasing the risk of a liquidity crisis. Continuing the tradition of colorful nomenclature in international economics, this hypothesis has been labeled "original sin,ï¿½ because the need to borrow in foreign currencies and in short-maturity instruments supposedly constrains all but the largest and wealthiest countries regardless of economic policies and performance. However, recent developments in international capital markets challenge the inevitability of "original sinï¿½ (Eichengreen, Hausman, and Panizza, 2003; Burger and Warnock, 2004). First, some small countries have in fact been able to sell domestic-currency debt to foreigners (examples include New Zealand, Poland, and South Africa). Second, some developing countries have been able to establish active domestic credit markets in which borrowing may take place in long-term, fixed-rate debt, providing a partial substitute for foreign-currency borrowing (examples include Chile, India, and Korea). In both situations, the quality of the countryï¿½s macroeconomic policies as well as the strength and transparency of its institutional framework have been critically important for improving the access of borrowers to capital. Redemption from "original sinï¿½ through good works may thus be possible. These experiences suggest that, whatever interim arrangements they adopt regarding exchange rates and capital mobility, developing countries would do well to shift their focus to the task of building institutions, protecting property rights, and establishing a sound fiscal and monetary framework, with the ultimate goal of making free capital flows and a floating exchange rate feasible. In the wake of the Asian crisis, the conventional wisdom asserted that a country should eschew fixed exchange rates in favor of either of the two extremes: a floating rate or a currency union. I agree with this "bipolar viewï¿½ insofar as I think that a garden-variety fixed exchange rate is, in most instances, the worst of all worlds. Notably, fixed exchange rates often result in irresistible one-way bets for speculators, with crisis and painful economic adjustment the likely result. Large holdings of foreign exchange reserves reduce this risk but create other costs. Currency unions are considerably less prone to speculative attack and may reduce uncertainty and transactions costs in international trade and finance. But as I have indicated today, I believe that floating exchange rates are generally to be preferred either to fixed exchange rates or--except in those relatively rare cases in which the criteria for an optimum currency area are met--to currency unions. This view seems to be spreading. According to the International Monetary Fund (2004), for example, inflation-targeting countries are becoming more numerous as countries that fix the exchange rate become fewer. Consistent with this observation, average inflation rates in both industrial and developing countries are near their lowest levels in four decades, reflecting the new emphasis in policy. Politicians and policymakers around the world are being converted to the idea that monetary policy should focus on delivering low and stable inflation, with the determination of exchange rates left to free markets. The most consequential exception to the general trend toward inflation stabilization, free capital markets, and floating exchange rates is, of course, China. China currently has relatively strict--though not absolutely impermeable--barriers to capital flows, as well as an exchange rate that is effectively pegged to the U.S. dollar. The governments of the United States and the other G-7 countries have urged China to make the transition to a market-determined exchange rate, in the interest of promoting global macroeconomic adjustment. I will add here only that moving toward exchange rate flexibility is in the interest of China as well as the rest of the world. As a large, increasingly wealthy, and increasingly market-oriented economy, China will benefit from the shock-absorber properties of an independent monetary policy and a floating exchange rate. Because it needs capital to fuel its rapid growth and because its citizens would benefit greatly from the opportunity to invest their own savings abroad, China will likewise benefit from increased capital freedom. Finally, the institutional developments needed to support ever-more-open capital markets, including a strengthened legal and regulatory framework, an increased capacity of its banks to allocate capital to the most productive uses, and a reduced role of the government in investment decisions, are themselves necessary and important steps in Chinaï¿½s economic modernization. The United States will also benefit as China and other East Asian countries make the transition to floating exchange rates and freer capital flows. More-open capital accounts and market-determined exchange rates will likely engender greater stability and improved resource allocation in Asia, setting the stage for sustained future growth. The development of the Asian economies will expand export markets for U.S. producers, particularly as independent monetary policies and institutional reform provide scope for stimulating demand by Asian households and firms. Some observers have expressed concern about the effects of reduced reserve accumulation by Asian central banks on U.S. bond markets; however, the U.S. bond market is extremely deep and has shown a remarkable capacity to handle transitions smoothly, particularly when they occur in a gradual and predictable manner. Moreover, under a regime of free capital mobility, private savers in China and the rest of East Asia may well wish to diversify into U.S. assets, including U.S. bonds. In summary, I have argued today for an international system based on the principles of flexible exchange rates, free capital mobility, and independent monetary policies, at least within the great majority of countries. Important complementary elements include free trade (though I have not discussed it today) and the further development of the "softï¿½ infrastructure--the legal, regulatory, fiscal, and financial frameworks that characterize advanced economies. The fundamental virtue of this system is its flexibility and adaptability, qualities that will become increasingly essential in a complex and interdependent world. REFERENCES Bayoumi, Tamim, and Barry Eichengreen (1993).ï¿½ ï¿½Shocking Aspects of European Monetary Integration,ï¿½ in G. Torres and F. Giavazzi, eds., Adjustment and Growth in European Monetary Union , Cambridge, U.K.: Cambridge University Press. Burger, John, and Francis Warnock (2004). Board of Governors of the Federal Reserve System, International Finance Discussion Paper 794. Calvo, Guillermo, and Carmen Reinhart (2000).ï¿½ National Bureau of Economic Research, working paper no. 7993. Dornbusch, Rudiger, and Andrew Warner (1994).ï¿½ ï¿½Mexico: Stabilization, Reform, and No Growth,ï¿½ Brookings Papers on Economic Activity , 1, pp. 253-315. Eichengreen, Barry, and Ricardo Hausman (1999). in Federal Reserve Bank of Kansas City, New Challenges for Monetary Policy . Eichengreen, Barry, Ricardo Hausman, and Ugo Panizza (2003). National Bureau of Economic Research, working paper no. 10036. Flood, Robert, and Andrew Rose (1995). ï¿½Fixing Exchange Rates: A Virtual Quest for Fundamentals,ï¿½ Journal of Monetary Economics , vol. 36, pp. 3-37. Frankel, Jeffrey, and Andrew Rose (2002).ï¿½ ï¿½An Estimate of the Effect of Common Currencies on Trade and Growth,ï¿½ Quarterly Journal of Economics , vol. 117, pp. 437-66. Ghosh, Atish, and Holger Wolf (1994).ï¿½ National Bureau of Economic Research, working paper no. 4805. International Monetary Fund (2004). World Economic Outlook , October. Klein, Michael, and Jay Shambaugh (2004). ï¿½Fixed Exchange Rates and Trade,ï¿½ manuscript, Tufts University. Mundell, Robert (1961). ï¿½A Theory of Optimum Currency Areas,ï¿½ American Economic Review , vol. 51, pp. 657-665. Obstfeld, Maurice, Jay Shambaugh, and Alan Taylor (2004).ï¿½ National Bureau of Economic Research, working paper 10396. Reinhart, Carmen, and Kenneth Rogoff (2002).ï¿½ National Bureau of Economic Research, working paper no. 8963. Rose, Andrew (2000).ï¿½ ï¿½One Money, One Market: Estimating the Effect of Common Currencies on Trade,ï¿½ Economic Policy , vol. 30, pp. 7-46. Sargent, Thomas (1982).ï¿½ ï¿½The Ends of Four Big Inflations,ï¿½ in Robert Hall, ed., Inflation: Causes and Effects , Chicago, Ill.: University of Chicago Press. Truman, Edwin (2003).ï¿½ Inflation Targeting , Washington, D.C.: Institute for International Economics. Vegh, Carlos (1992).ï¿½ ï¿½Stopping High Inflation: An Analytical Overview,ï¿½ IMF Staff Papers 39, pp. 626-95. Footnotes I would like to thank Board staff members Joseph Gagnon and Steven Kamin for excellent assistance in the preparation of these remarks. Obstfeld, Shambaugh, and Taylor (2004) provide historical evidence that supports the empirical relevance of the trilemma. When the parity is nominally fixed but can be varied, and if capital flows are less than perfectly free, monetary policy under a fixed exchange rate may have a degree of independence; thus, the resolution of the trilemma may not be a stark choice of two of the three elements but a partial adoption of each. An optimum currency area is a region in which labor and capital are internally mobile and sub-regions tend to be affected by similar shocks. As Mundell (1961) first argued, in this situation the shock-absorbing benefits of flexible exchange rates are outweighed by the reduction in transactions costs and in uncertainty provided by fixed exchange rates or a common currency. See, for example, Bayoumi and Eichengreen (1993) and Ghosh and Wolf (1994). European economic integration has been motivated to a significant degree by a desire to make a repeat of the destructive conflicts of the twentieth century impossible. In the fledgling United States, the desire to strengthen the central government was a principal reason behind Alexander Hamiltonï¿½s advocacy of a common currency and common national debt. On the other hand, recent research has pointed out the interesting possibility that the formation of a currency union, by promoting trade and economic integration among its members, may lead the criteria for an optimum currency area among the participating countries to be satisfied after the fact even if not before (Frankel and Rose, 2002). Of course, to justify a currency union on this basis requires the ability to forecast how linkages among the participants will evolve under the common currency, a difficult undertaking indeed. Sargent (1982) notes the role of exchange rate stabilization in ending the European hyperinflations of the 1920s. Analysts of more recent stabilization programs in developing countries have observed that even if exchange rate-based policies succeed in reducing inflation initially, fixing the exchange rate may lead to subsequent problems (Vegh, 1992; Dornbusch and Warner, 1994). Reinhart and Rogoff (2002) argue that the move away from pegs is less pronounced in terms of actual policy behavior than in terms of official classifications. Their point is an important one. However, they do not dispute the direction of the change, and as their analysis compares 1991-2001 to earlier periods they miss a very recent acceleration toward floating exchange rates and inflation-focused monetary policies.
For immediate release The Federal Reserve Board on Friday announced its approval of the proposal filed by BNP Paribas, Paris, France, and BancWest Corporation, Honolulu, Hawaii, to acquire USDB Bancorp, Stockton, California. Attached is the Board's Order relating to this action.
Remarks by Governor Donald L. Kohn At the European Central Bank Conference on Monetary Policy and Imperfect Knowledge, Würzburg, Germany October 15, 2004 How Should Policymakers Deal with Low-Probability, High-Impact Events? Considering how to deal with low-probability, high-impact events has always been an important aspect of central banking. Central banks and other government agencies use various policies, including supervisory vigilance and access to discount window credit, to make such situations less likely to occur and less costly when they do. Even so, from time to time monetary policy settings have been influenced by the perception of a potential for serious economic and financial dislocation. Before going further, I should say the views I will express today are my own and not necessarily those of other members of the Board of Governors or its staff. Adjusting monetary policy in such circumstances is an example of a more general phenomenon. When central banks are not tightly focused on achieving a specific objective for an exchange rate, a monetary aggregate, or an inflation rate, policymakers may be granted a degree of discretion and can take account of the entire distribution of potential economic outcomes and their effects on societal welfare. I used the words ï¿½may be grantedï¿½ in that sentence quite deliberately. Discretion has gotten a bad reputation in the economics profession, in part because of a too-literal interpretation of the contributions of the two newest Nobel laureates. The effective use of discretion--the ability to deviate from the programmatic pursuit of a fixed goal--is only granted to central bankers when the public is confident that the opportunity will not be misused. As I reflect on my observation of central banking over the years, my impression is that policymakers these days are taking account of a broader array of potential outcomes than in the past. Policy seems more frequently to be deviating a bit from a stance that is calculated only to maximize the odds of achieving a specific, numerical, economic goal. More countries have recognized the benefits of allowing exchange rates to fluctuate freely, and the inflation-targeting regimes that have replaced exchange rate anchors in many countries have become more flexible over time. This evolution has not only allowed policymakers greater scope to weigh more than one short-run objective in the pursuit of long-term price stability, but it has also permitted them to pay greater attention to the consequences of potential economic outcomes with relatively low probabilities. Such possible outcomes tend naturally to get some weight when policymakers perceive that events are not necessarily a product of linear relationships among variables and that welfare is not always defined by the linear quadratic utility function that theorists find convenient to use. In Chairman Greenspanï¿½s risk-management paradigm, low-probability, high-impact events are always factors in the calculus of monetary policy. This approach recognizes that ï¿½impactï¿½ is the product of two separate distributions--one for expected economic outcomes and one for the effect of those outcomes on welfare--that may be nonlinear. The two are closely related but not identical, and their relationship may well depend on the situation. In large part, central banks have been able to shift their attention more toward events in the tails of the probability distributions of possible outcomes because the centers of the distributions of key macroeconomic variables have been so much better behaved than they were a few decades ago. Inflation has been low and stable in most economies, expectations that inflation will remain contained are much better anchored, and output fluctuations have been damped. This favorable economic climate has reduced the risk that temporarily aiming somewhat away from hitting objectives dead on will engender behaviors, like rising inflation expectations, that could have seriously adverse and destabilizing consequences for the economy. In effect, the cost of ï¿½buying insuranceï¿½ against events in the tail has been greatly reduced. Buying insurance may also have appeared more attractive in recent years because the impact of tail events, especially those associated with financial markets, may have increased, even if their probability remains low. As wealth rises relative to income and more of the populace owns significant quantities of assets, wealth becomes an increasingly important factor in shaping spending decisions. In addition, the secular decline in the cost of financial transactions has facilitated balance sheet adjustments by businesses and households, potentially heightening their responses to financial market developments. Although a whole range of possible events with varying probabilities and effects can be taken into account by monetary policymakers, the influence of possible low-probability events is most evident when serious instability is a much greater threat than usual. It is in these circumstances that the distribution of possible outcomes is skewed noticeably, and the effect of a given outcome itself may also be especially large. Guarding against such a low-probability, high-impact event can in turn significantly skew policy temporarily away from the rate setting most likely to achieve longer-run objectives for inflation or output. I will illustrate the rationale for making such choices and their possible implications by relating some of the episodes in which the Federal Reserve has given unusual weight to possible tail events--in reaction to the financial market events of 1987 and 1998 and in response to the threat of deflation in 2001 through 2003. The Federal Reserve reacted strongly to both the stock market crash of 1987 and the ï¿½seizing upï¿½ of financial markets in the fall of 1998 after the Russian debt default and failure of Long Term Capital Management. In each of these situations, we were dealing with the aftermath of one low-probability, high-impact event--the market meltdown--in a manner also designed to limit another such event--snowballing disruptions to intermediation and spending. In both instances, developments in financial markets caused forecasts of economic activity and inflation to be marked down. The 1987 stock market crash reduced wealth and raised the cost of capital, which seemed likely to trim both consumption and investment in 1988. The market disruptions of 1998 severely impaired the liquidity and functioning of a number of financial markets for a time, in effect closing them to many borrowers; even after more normal trading patterns were restored, many private firms--especially the riskiest borrowers--found that their cost of credit had risen, with negative implications for spending incentives. But concerns went beyond the direct macroeconomic fallout from the initial movement in asset prices, and in both cases the Federal Reserve, therefore, eased more than probably would have been justified by the change in the center of gravity of the forecast itself. Importantly, the potential effects of these events on confidence--on the psychology of market participants and of savers and spenders more generally--raised the specter of continuing flights to liquidity and safety that could disrupt the financial markets and economic activity even more severely. Such an outcome was unlikely--it would have been a nonlinear and unusual reaction to the prevailing economic circumstances and outside the ambit of standard models--but it was not unheard of in history. The policy actions were designed in part to build confidence; by demonstrating that the Federal Reserve was taking steps to deal with the downside risks, it intended to lower the probability that the very events that concerned us would occur. In addition, lower interest rates--taking some chances temporarily on the side of stronger activity--should help to limit upward pressures on private interest rates and restore market liquidity. Such outsized policy actions have not been taken uniquely in response to shocks emanating from financial markets. We eased aggressively in early 2001 as the economy weakened. This easing was perhaps quicker than might have been anticipated from our past behavior, but it was not out of line with our perception of the center of gravity of the evolving economic situation. However, from late 2001 through the first half of 2003, as the lack of vigor of the economic rebound gradually became evident, we eased further, bringing the policy rate to an especially low level, whether viewed in nominal or in real terms. The extent of these latter actions was influenced by the accumulation of evidence that the economy was not responding to policy stimulus as much as might have been anticipated, creating the remote possibility that a persistent, if not a widening, output gap would cause deflation, which in turn could further undermine economic performance. In these circumstances, the zero bound on nominal interest rates could potentially constrain conventional policy easing, further adding to the potential for nonlinear responses in the economy. Policy rates were already quite low, the economy had been weak for some time, and inflation had settled into the zone of price stability. Although other types of monetary policy actions likely would be effective at the zero bound, they had not been tried. We did not see a high probability of deflation, but in those circumstances the most prudent course appeared to be to ease aggressively--by more than the central economic outlook might call for--in order to raise the odds of forestalling what could have become a very disruptive and costly economic situation. I judge our policy in these cases to have been successful--though the record for the most recent episode is still being written. One can never know the counterfactual--what would have happened if the reaction of the Federal Reserve had been more in line with a standard response to a changing central tendency forecast, rather than the more forceful actions we took. And some believe that our easings contributed to difficulties that emerged subsequently--a subject to which I will return later. However, in 1987 and 1998 financial markets stabilized and we did not see the continuing disruptions to intermediation and spending that concerned us after the initial market shock had taken place. And in the last year or so economic growth has strengthened and the possibility of destabilizing deflation receded. Omitted from my list of examples of low-probability, high-impact events that the Federal Reserve has addressed with monetary policy are episodes in which a possible substantial deviation of key asset prices from fundamentals threatens future disruption when those prices correct. The reason for the omission is that I know of no such episodes in the past few decades. Our monetary policy certainly takes into account the effects of asset prices on the likely course of the economy and prices. But we have not attempted to damp fluctuations in asset prices by tightening or easing policy more than the medium-term macroeconomic outlook implies. In concept, a significant deviation of important asset prices from fundamental values raises the risk of a future reversal that would add to economic volatility, representing a low-probability event that, like many others, could be given some weight in the stance of policy. But we have been deterred by a number of uncertainties about dealing with this possibility and a consequent lack of confidence that the benefits of policy action in these circumstances would outweigh the costs. Among other things, we are uncertain (a) about any judgment that the level of a particular class of asset prices is moving far enough away from fundamentals to make a correction inevitable and disruptive; (b) about the timing of a reversal of those prices, so that a step to truncate a movement, say by raising rates in response to a perception that the prices of some assets were becoming unsustainably high, does not increase economic instability by hitting the economy and asset prices just as the reversal occurs; and (c) about the response of asset prices, possibly driven by self-fulfilling optimism for a time, to a change in rates. As a result of this last unknown, one has difficulty assessing whether a change in policy large enough to prevent asset-price disequilibrium would have a greater adverse effect over time on economic performance than would allowing asset prices to evolve. Moreover, we have also recognized that much of the extra damage that rapidly changing asset prices may inflict occurs through weakening the financial system enough to cause a constriction in credit flows that restrains spending. This potential problem can be addressed, in part, through the supervisory process and attention to the vulnerabilities of key intermediaries. From the vantage point of, say, 1999, when price-earnings ratios were at lofty levels and forecasts of annual-earnings growth over the longer term were in the high teens, an asset-price correction did not seem like a low-probability event. Although such a correction would result in considerable losses for those holding the assets when their prices fell and would damp demand for a time, its macroeconomic effect did not seem likely to be unusually large. Banks were well capitalized, and financial institutions more sophisticated in their risk-taking, so that the scope for significant knock-on effects appeared limited. Thus the risks seem higher than with many other possible low-probability events that the balance of costs and benefits will turn out to be adverse when monetary policy is aimed away from fundamental objectives to influence asset prices. Given these uncertainties, we have chosen to react to the asset-price correction when it occurs rather than to try to head it off. Monetary policymakers giving significant weight to low-probability events face several challenges. One serious potential pitfall is paying so much attention to the tails of the distributions of possible outcomes that the central tendencies veer well away from objectives for economic and price stability--in effect paying too much for insurance. A key issue in this regard is judging when to begin reversing the extra easing or tightening put in place to take account of the possible high-impact event. The policy actions we have been addressing are importantly based on concerns about the effects of nonlinearities, and it may be difficult to judge when the threat of those nonlinearities has diminished sufficiently to make unwinding the action--reducing or dropping the insurance policy--advisable. The difficulty is compounded because the reasons for the behavior that leads to heightened potential impact of a low-probability event often are not fully understood--for example, why the markets cracked or why the economy has not responded more strongly to previous stimulus. Moreover, when the threat of the low-probability event recedes into the past, policy may need to compensate over time in the other direction to preserve economic and price stability--to achieve the appropriate policy stance on average--a consideration that further complicates the policy decision in these circumstances. Another issue raised by some critics in connection with central bank efforts to guard against financial instability and other low-probability, high-impact developments is that such actions encourage undue risk-taking in financial markets and the economy. However, to the extent that the conduct of policy actually reduces the potential for high-impact events or more generally damps fluctuations in output and prices, risks are genuinely lower, and that situation should be reflected in the behavior of private agents. To me, this criticism is similar to asserting that mandating seat belts in cars has led to more traffic accidents because they give drivers a sense of security. And it is probably true when looked at narrowly. Policies should be judged from a general equilibrium perspective, however. Damped fluctuations in economic activity and the containment of financial crises has made the populace, at large, better off. That some view this security as reason to be less cautious does not seem especially damaging to welfare. To be sure, adverse consequences for resource allocation, and perhaps even for the stability of output and prices, will occur if private agents overestimate the ability or willingness of central banks to damp volatility in asset prices or the economy. In the context of the sorts of decisions we are discussing on this panel, the question is whether the tendency of a risk-managing central bank to lean particularly hard against the consequences of asset-price declines might not give market participants a false sense of security. However, experience should have taught market participants that risk management by central banks does not prevent sharp movements in asset prices. Policy actions in 1987, 1998, and 2001-03 cushioned the economy, but they did not stop major declines in the prices of risky credits in 1998 or equities in 1987 or 2001. Any asymmetries in central bank reactions were aimed at stabilizing the economy, not achieving particular asset-price configurations. The small effects of monetary policy asymmetries on the asset prices have been overwhelmed by the fundamentals of shifting perceptions of risk and future earnings. In gauging the effects of policy on asset prices, market participants should not be making systematic errors that distort resource allocation. In my view, these potential difficulties should not deter central banks from taking account of low-probability, high-impact events in judging the appropriate stance of monetary policy. To be sure, any such actions cannot be allowed to compromise the primary long-run policy goal of preserving price stability. And policymakers, through their words as well as their deeds, must remind market participants that monetary policy is but one of many influences on asset prices and that the level of those prices is not an objective of policy. But when inflation expectations are firmly anchored at price stability, policy has the flexibility to consider a range of outcomes and judicious use of this flexibility can improve economic welfare. Footnotes Vincent Reinhart provided valuable ideas and comments. Alan Greenspan (2004), “Risk and Uncertainty in Monetary Policy,” The American Economic Review, vol. 94 (May), pp. 33-40. As an aside, the issue here is the appropriate setting of the policy rate, not the quantity of reserves or money. Central bankers recognize that it is necessary to accommodate increased demands for liquidity at times of stress in financial markets. To do otherwise would permit the increased demand for liquidity to put upward pressure on short-term rates and effectively tighten policy..
Release Date: October 19, 2004 For immediate release The Federal Reserve Board on Tuesday announced the execution of a Written Agreement by and between the Union Bank of California International, New York, New York and the Federal Reserve Bank of New York. The Written Agreement addresses Bank Secrecy Act and anti-money-laundering compliance at the Union Bank of California International, including policies and practices relating to the provision of correspondent banking services. A copy of the Written Agreement is attached.
Remarks by Chairman Alan Greenspan The mortgage market and consumer debt At Americas Community Bankers Annual Convention, Washington, D.C. October 19, 2004
Release Date: October 21, 2004 For immediate release The Federal Reserve Board on Thursday announced the execution of a Written Agreement by and among The Community State Bank, Poteau, Oklahoma; the Oklahoma State Banking Department, Oklahoma City, Oklahoma; and the Federal Reserve Bank of Kansas City. A copy of the Written Agreement is attached.
Remarks by Governor Ben S. Bernanke At the Distinguished Lecture Series, Darton College, Albany, Georgia October 21, 2004 Oil and the Economy If you have regular occasion to fill your car's tank with gas, you know that the price of gasoline has recently been both high and volatile--a consequence, for the most part, of similar movements in the price of crude oil. The weekly average price for a barrel of West Texas intermediate, a standard grade of crude oil, hovered around $30 during the second half of 2003 but began to rise around the turn of the year. The price per barrel reached $37 in March and nearly $41 in May. Oil prices have continued to rise erratically since the spring, even as other commodity prices have generally stabilized and overall inflation has been low. As of last week, the price of a barrel of West Texas intermediate stood at about $55. Some perspective is in order. Oil prices are at record levels when measured in nominal terms, but when adjusted for inflation the price of oil still remains well below its historical peak, reached in 1981. Measured in today's dollars, crude oil prices in 1981 were about $80 per barrel, and the price of gasoline at the pump was nearly $3 per gallon. Moreover, energy costs at that time were a larger share both of consumers' budgets and of the cost of producing goods and services than they are today. Clearly, the surges in oil prices of the 1970s and early 1980s had much more pronounced economic effects than the more recent increases have had or are likely to have, barring a substantial further rise. All that being said, prices of oil and oil products in the United States today are quite high relative to recent experience. During most of the 1990s, oil prices were roughly $20 per barrel, and for a short period in 1998 (remembered without fondness by oil explorers and producers) the price of a barrel of crude fell to just above $10. As I mentioned, only a year ago the price of oil was about $30 per barrel. The recent rise in oil prices has thus been large enough to constitute a significant shock to the economic system. The runup in oil prices raises a number of important questions for economists and policymakers. Why have oil prices risen by so much and why do they continue to fluctuate so erratically? What is the outlook for oil supplies and oil prices in the medium term and in the long term? What implications does the behavior of oil prices have for the ongoing economic expansion? And how should monetary policy respond to these developments? I will touch briefly on each of these questions today. Before doing so, I should note that the opinions I express today are my own and are not to be attributed to my colleagues in the Federal Reserve System. Recent and Prospective Developments in Oil Markets To assess recent developments in the oil market, it would be useful to know whether the high price of oil we observe today is a temporary spike or is instead the beginning of an era of higher prices. Although no one can know for sure how oil prices will evolve, financial markets are one useful place to learn about informed opinion. Contracts for future deliveries of oil, as for many other commodities, are traded continuously on an active market by people who have every incentive to monitor the energy situation quite closely. Derivative financial instruments, such as options to buy or sell oil at some future date, are also actively traded. The prices observed in these markets can be used to obtain useful information about what traders expect for the future course of oil prices, as well as the degree of uncertainty they feel in predicting the future. One inference we can draw from recent developments in the oil market, in particular from the pricing of derivative instruments, is that traders in that market are unusually uncertain about how the price of oil will evolve over the next year or so. For example, as of last week, traders assigned about a two-thirds probability that the price of crude oil as of next June would be between $38 and $60 per barrel. Or, to say the same thing another way, traders perceived a one-third chance that the price of oil would fall outside the wide $38-$60 range. That well-informed traders would be so uncertain about what the price of oil will be only eight months in the future is striking, to say the least. Uncertainty can in itself be a negative factor for the economy; for example, I would not rule out the possibility that uncertainty about future energy costs has made companies a bit more cautious about making new capital investments. However, probably more economically significant than near-term uncertainty about oil prices is the fact that traders appear to expect tight conditions in the oil market to continue for some years, with at best only a modest decline in prices. This belief on the part of traders can be seen in the prices of oil futures contracts. Throughout most of the 1990s, market prices of oil for delivery at dates up to six years in the future fluctuated around $20 per barrel, suggesting that traders expected oil prices to remain at about that level well into the future. Today, futures markets place the expected price of a barrel of oil in the long run closer to $39, a near doubling. Thus, although traders expect the price of oil to decline somewhat from recent highs, they also believe that a significant part of the recent increase in prices will be long lived. What accounts for the behavior of the current and expected future price of oil? The writer George Bernard Shaw once said that, to obtain an economist, it was only necessary to teach a parrot to repeat endlessly the phrase "supply and demand." Well, as an economist, I have to agree with the parrot. For the most part, high oil prices reflect high and growing demand for oil and limited (and uncertain) supplies. On the demand side, the International Energy Agency (IEA), perhaps the most reliable source of data on world oil production and consumption, has continued to revise upward its projections of global oil usage. To illustrate, world oil consumption for the second quarter of this year, the latest quarter for which we have complete data, is now estimated to have been about 3.7 million barrels per day higher than the IEA projected in July 2003. (For reference, total global oil consumption this year has averaged about 81 million barrels per day). A significant part of this unexpected increase in oil consumption, about 2.2 million barrels per day, reflected quickly growing oil demands in East Asia, notably China. However, an ongoing economic expansion across both the industrialized and the emerging-market economies has also contributed to the world's growing appetite for oil. On the supply side, the production of oil has been constrained by the available capacity and by geopolitical developments. With oil consumption and prices rising briskly, Saudi Arabia and other members of the Organization of Petroleum Exporting Countries (OPEC) have promised to pump more oil. However, the relatively limited increases in production delivered so far by OPEC members, together with non-OPEC production that has fallen a bit below projections, have raised concerns that the spare production capacity available in the near term may be severely limited, perhaps below 1 million barrels per day. Interacting with the limits on capacity, and contributing to the exceptional volatility in oil prices of recent months, are uncertainties about the reliability and security of oil supplies. Of course, the oil-rich Middle East remains especially volatile. But political risks to the oil supply have emerged in nations outside the Middle East as well, including Russia, Venezuela, and Nigeria. Weather also has taken a toll, as recent hurricanes affected the production and distribution of oil on the U.S. Gulf Coast. Because neither the demand for nor the supply of oil responds very much to price changes in the short run, the recent unexpected rise in oil consumption together with disruptions to supply can plausibly account for much of the increase in prices. However, the sharp increases and extreme volatility of oil prices have led observers to suggest that some part of the rise in prices reflects a speculative component arising from the activities of traders in the oil markets. How might speculation raise the price of oil? Simplifying greatly, speculative traders who expect oil to be in increasingly short supply and oil prices to rise in the future can back their hunches with their money by purchasing oil futures contracts on the commodity exchange. Oil futures contracts represent claims to oil to be delivered at a specified price and at a specified date and location in the future. If the price of oil rises as the traders expect--more precisely, if the future oil price rises above the price specified in the contract--they will be able to re-sell their claims to oil at a profit. If many speculators share the view that oil shortages will worsen and prices will rise, then their demand for oil futures will be high and, consequently, the price of oil for future delivery will rise. Higher oil futures prices in turn affect the incentives faced by oil producers. Seeing the high price of oil for future delivery, oil producers will hold oil back from today's market, adding it to inventory for anticipated future sale. This reduction in the amount of oil available for current use will in turn cause today's price of oil to rise, an increase that can be interpreted as the speculative premium in the oil price. Many people take a dim view of speculation in general, and in some instances this view is justified. In many situations, however, informed speculation is good for society. In the case of oil, speculative activity tends to ensure that a portion of the oil that is currently produced is put aside to guard against the possibility of disruptions or shortages in the future. True, speculation may raise the current price of oil, but that increase is useful in stimulating current production and reducing current demand, thereby freeing up more oil to be held in reserve against emergencies. Speculative traders have no altruistic motives, of course; their objective is only to buy low and sell high. But speculators' profits depend on their ability to induce a shift in oil use from periods when prices are relatively low (that is, when oil is relatively plentiful) to periods when prices are relatively high (when oil is scarce). Social welfare is likely increased by informed speculation in oil markets because speculative activities make oil relatively more available at the times when it is most needed. This discussion suggests three indicators to help us detect the influence of speculative activity on current oil prices. First, if speculative activity is an important source of the rise in oil prices, we would expect today's oil price to react strongly to news bearing on future conditions of oil supply and demand. Second, we should see speculative traders holding claims to large amounts of oil for future delivery, in the hope of enjoying a profit by re-selling the oil should prices rise. Finally, corresponding to the speculative positions held by traders, we would expect to see significant increases in the physical inventories of oil being held for future use. The first indicator, rapid swings of oil prices in response to news about the prospective supplies and usage of oil, does appear to be present and to suggest a speculative element in pricing. It is thus somewhat puzzling that the other two indicators of speculative activity do not appear to be present: Our best-available measure of speculative traders' holdings of contracts for future delivery of crude oil and petroleum products has decreased from earlier in the year and is not unusually high by historical standards. And official data imply that physical inventories of crude oil and petroleum products, at least within the industrial countries for which we have good data, have not risen to any significant degree and at times have even been below seasonal norms. Perhaps the official data overlook important accumulations of crude oil stocks--in China and other emerging-market economies, for example--but that remains (if you will excuse the expression) speculation. My tentative conclusion is that speculative activity may help to account for part of the recent volatility in oil prices. However, the available evidence does not provide clear support for the view that speculative activity has made oil prices during the past year much higher on average than they otherwise would have been. A rather different explanation of the recent increase in oil prices holds that the rise is in large part a symptom of inflationary monetary policies. An extensive literature exists on this topic. The general idea is that, if most prices adjust slowly, the effects of an excessively easy monetary policy will show up first as a sharp increase in those prices that are able to adjust most quickly, such as the prices of commodities (including oil). If this idea were valid, then commodity price movements could be used as a guide for setting monetary policy. However, the consensus that emerges from this literature is that the relationship between commodity price movements and monetary policy is tenuous and unreliable at best. Moreover, applied to the recent experience, economic models that support the use of oil prices as a leading indicator of monetary policy make a number of other predictions that are strongly contradicted by the facts. These predictions include (1) that all commodity prices should move proportionally in response to changes in monetary policy (in fact, oil prices have risen sharply since the spring as other commodity prices have generally stabilized); (2) that the dollar should have rapidly depreciated as the oil price rose (in fact, the dollar has been broadly stable during 2004); (3) that inflation expectations should have increased substantially (but long-term nominal interest rates, the level of inflation compensation implicit in inflation-indexed bond yields, and survey measures of inflation expectations concur in showing no such rise); and (4) that general inflation, though lagging commodity-price inflation, should also rise over time (but inflation excluding energy prices remains quite low). Models of commodity-price "overshooting" also imply that the current surge in oil prices will be almost entirely temporary, a prediction strongly at variance with market expectations as revealed in the futures markets. I conclude that an increasingly tight supply-demand balance, rather than speculation or easy monetary policies, probably accounts for most of the recent run-up in oil prices. I have focused on near-term developments in the oil markets. What about the longer term? In that regard, we can safely assume that world economic growth, together with the rapid pace of industrialization in China, India, and other emerging-market economies, will generate increasing demands for oil and other forms of energy. If we are lucky, growth in the demand for energy will be moderated by continued improvements in energy efficiency that will be stimulated by higher prices and concerns about the security of oil supplies. Such improvements are certainly possible, even without new technological breakthroughs. For example, Japan is an advanced industrial nation that uses only about one-third as much energy to produce each dollar of real output as the United States does. Industrializing nations such as China appear to be quite inefficient in their energy use; for example, the underdeveloped electricity grid in China has induced heavy use of inefficient diesel-powered generators. As these countries modernize, their energy efficiency will presumably improve. Still, if the global economic expansion continues, substantial growth in the use of oil and other energy sources appears to be inevitable. The supply side of the oil market is even more difficult to predict. In a physical sense, the world is not in imminent danger of running out of oil. At the end of 2003, the world's proved reserves of oil--that is, oil in the ground that is viewed as recoverable using existing technologies and under current economic conditions--reached more than 1.15 trillion barrels, 12 percent more than the world's proved reserves a decade earlier and equal to about forty years of global consumption at current rates (BP , 2004, p. 4). Of course, global oil consumption will not remain at current rates; it will grow. But, on the other hand, today's proved reserve figures ignore not only the potential for new discoveries but also the likelihood that improved technology and higher oil prices will increase the amount of oil that can be economically recovered. The oil is there, but whether substantial new production sources can be made available over the next five years or so is in some doubt. Some important fields are in locations that are technically difficult and time-consuming to develop, such as deep-water fields off West Africa, in the Gulf of Mexico, or off the east coast of South America. In many cases, the development of new fields also faces the challenge of recovering the oil without damaging delicate ecosystems, if indeed the political process allows exploitation of ecologically sensitive fields at all. I have already noted the uncertainties generated by geopolitical instability; perhaps it is sufficient here to note that, despite the opening of fields in a number of new regions in the past decade, about 63 percent of known oil reserves today are in the Middle East. Oil producers are also aware from painful experience that oil prices can fall as quickly as they rise; hence, exploration projects launched when prices are high may come to fruition when prices are much lower. These risks help to explain why major oil companies have not rushed to increase exploration activities during this recent period of high prices. Thus, the supply-demand fundamentals seem consistent with the view now taken by oil-market participants that the days of persistently cheap oil are over. The good news is that, in the longer run, we have options. I have already noted the scope for improvements in energy efficiency and increased conservation. Considerable potential exists as well for substituting other energy sources for oil, including natural gas, coal, nuclear energy, and renewable sources such as wind and hydroelectric power. For example, the world has vast supplies of natural gas that, pending additional infrastructure development, might be transported in liquefied form to the United States, Europe, Asia, and elsewhere at BTU-equivalent prices below those expected for crude oil. Given enough time, market mechanisms (most obviously, higher prices) are likely to increase energy supplies, including alternative energy sources, while simultaneously encouraging conservation and substitution away from oil to other types of energy. These adjustments will not occur rapidly, however. Hence the next few years may be stressful ones for energy consumers, as stretched and uncertain supplies of oil and other conventional energy sources face the growing demands of a rapidly expanding world economy. Economic and Policy Implications of Increased Oil Prices What are the economic implications of the recent increase in oil prices? In the long run, higher oil prices are likely to reduce somewhat the productive capacity of the U.S. economy. That outcome would occur, for example, if high energy costs make businesses less willing to invest in new capital or causes some existing capital to become economically obsolescent. Lower productivity in turn implies that wages and profits will be lower than they otherwise would have been. Also, the higher cost of imported oil is likely to adversely affect our terms of trade; that is, Americans will have to sell more goods and services abroad to pay for a given quantity of oil and other imports. The increase in the prices of our imports relative to the prices of our exports will impose a further burden on U.S. households and firms. Under the assumption that oil prices do not spike sharply higher from their already high levels, these long-run effects, though negative, should be manageable. As I have already discussed, conservation and the development of alternative energy sources will, over the long term, take some of the sting out of higher oil prices. Moreover, productivity gains from diverse sources, including technological improvements and a more highly educated workforce, are likely to exceed by a significant margin the productivity losses created by high oil prices. In the short run, sharply higher oil prices create a rather different and, in some ways, a more difficult set of economic challenges. Indeed, a significant increase in oil prices can simultaneously slow economic growth while stoking inflation, posing hard choices for monetary policy makers. An increase in oil prices slows economic growth in the short run primarily through its effects on spending, or aggregate demand. Because the United States imports most of its oil, an increase in oil prices is, as many economists have noted, broadly analogous to the imposition of a tax on U.S. residents, with the revenue from the tax going to oil producers abroad. Since the beginning of the year, the cost of oil imported into the United States has increased by about $75 billion (at an annual rate), or about 3/4 percent of the gross domestic product (GDP). Add to this the effects of the rise in natural gas prices, and the total increase in imported energy costs over a full year--the increase in the "tax" being paid to foreign energy producers--comes to almost $85 billion. The impact of this decline in net income on the U.S. GDP depends in large part on how the increase in the energy "tax" affects the spending of households and firms. For a number of reasons, an increase of $85 billion in payments to foreign energy producers is likely to reduce domestic spending by something less than that amount. For example, in the short run, people may be reluctant to cut non-energy spending below accustomed levels, leading them to reduce saving rather than spending. Because high energy costs lower firms' profits, they normally reduce the willingness of firms to purchase new capital goods; however, if the increase in energy prices looks to be permanent, firms might decide that it makes sense for them to invest in more energy-efficient buildings and machines, moderating the decline in their capital spending. If higher energy prices reflect in part more rapid economic growth abroad--which seems to be the case in the recent episode--or if foreign energy producers spend part of their increased income on U.S. goods and services, then the demand for U.S. exports may be stronger than it would have been otherwise. With these and many other qualifications taken into account, a reasonable estimate is that the increased cost of imported energy has reduced the growth in U.S. aggregate spending and real output this year by something between half and three-quarters of a percentage point. At the same time that higher oil prices slow economic growth, they also create inflationary pressures. Higher prices for crude are passed through, with only a very short lag, to increased prices for oil products used by consumers, such as gasoline and heating oil. When oil prices rise, people may try to substitute other forms of energy, such as natural gas, leading to price increases in those alternatives as well. The rise in energy costs faced by households represents, of course, an increase in the cost of living, or inflation. This direct effect of higher energy prices on the cost of living is sometimes called the first-round effect on inflation. In addition, higher energy costs may have indirect effects on the inflation rate--if, for example, firms pass on their increased costs of production in the form of higher consumer prices for non-energy goods or services, or if workers respond to the increase in the cost of living by demanding higher wages. These indirect effects of higher energy prices on the overall rate of inflation are called second-round effects . The overall inflation rate reflects both first-round and second-round effects, of course. Economists and policymakers also pay attention to the so-called core inflation rate, which excludes the direct effects of increases in the prices of energy (as well as of food). By stripping out the first-round inflation effects, core inflation provides a useful indicator of the second-round effects of increases in the price of energy. In the past, notably during the 1970s and early 1980s, both the first-round and second-round effects of oil-price increases on inflation tended to be large, as firms freely passed rising energy costs on to consumers, and workers reacted to the surging cost of living by ratcheting up their wage demands. This situation made monetary policy making extremely difficult, because oil-price increases threatened to raise the overall inflation rate significantly. The Federal Reserve attempted to contain the inflationary effects of the oil-price shocks by engineering sharp increases in interest rates, actions which had the unfortunate side effect of sharply slowing growth and raising unemployment, as in the recessions that began in 1973 and 1981. Since about 1980, the Federal Reserve and most other central banks have worked hard to bring inflation down, and in recent years, inflation in the United States and other industrial countries has been both low and stable. An important benefit of these efforts is that the second-round inflation effect of a given increase in energy prices has been much reduced (Hooker, 1999). Because households and business owners are now confident that the Fed will keep inflation low, firms have both less incentive and less ability to pass on increased energy costs in the form of higher prices, and likewise workers have less need and less capacity to demand compensating increases in wages. Thus, increases in energy prices, though they temporarily raise overall inflation, tend to have modest and transient effects on core inflation; that is, currently, the second-round effects appear to be relatively small. Although the difficulties posed by increases in oil prices are less than in the past, the economic consequences are nevertheless unpleasant, as higher oil prices still tend to induce both slower growth and higher inflation. How then should monetary policy react? Unfortunately, monetary policy cannot offset the recessionary and inflationary effects of increased oil prices at the same time. If the central bank lowers interest rates in an effort to stimulate growth, it risks adding to inflationary pressure; but if it raises rates enough to choke off the inflationary effect of the increase in oil prices, it may exacerbate the slowdown in economic growth. In conformance with the Fed's dual mandate to promote both high employment and price stability, Federal Reserve policy makers would ideally respond in some measure to both the recessionary and inflationary effects of increased oil prices. Because these two factors tend to pull policy in opposite directions, however, whether monetary policy eases or tightens following an increase in energy prices ultimately depends on how policymakers balance the risks they perceive to their employment and price-stability objectives. An important qualification must be added, however. The relatively small effects of higher oil prices on the underlying inflation rate that we have seen in recent years are a consequence of the public's confidence that the Fed will maintain inflation at a low level in the medium term. As I have discussed, the public's expectation that inflation will remain low minimizes the second-round effects of oil price increases, which (in a virtuous circle) helps to limit the ultimate effect on inflation. Moreover, well-anchored inflation expectations have been shown to enhance the stability of output and employment. Maintaining the public's confidence in its policies should thus be among the central bank's highest priorities. For this reason, I would argue that the Fed's response to the inflationary effects of an increase in oil prices should depend to some extent on the economy's starting point. If inflation has recently been on the low side of the desirable range, and the available evidence suggests that inflation expectations are likewise low and firmly anchored, then less urgency is required in responding to the inflation threat posed by higher oil prices. In this case, monetary policy need not tighten and could conceivably ease in the wake of an oil-price shock. However, if inflation has been near the high end of the acceptable range, and policymakers perceive a significant risk that inflation and inflation expectations may rise further, then stronger action, in the form of a tighter monetary policy, may well prove necessary. In directing its policy toward stabilizing the public's inflation expectations, the Fed would be making an important investment in future economic stability. I will close by briefly linking this discussion to recent Federal Reserve policy. As a professor and textbook author, I was accustomed to discussing the effects of a particular phenomenon, such as rising oil prices, with all other factors held equal. However, as policymakers know, everything else is never held equal. The increases in oil prices this year did not take place in isolation. Along with the rise in oil prices, increases in the prices of other important commodities, such as steel and lumber, as well as higher import prices resulting from the earlier decline in the dollar, provided supply-side pressure on inflation in early 2004. Meanwhile, an economic expansion that took hold in the middle of 2003 resulted in strong output growth but, as of early this year, limited progress in creating new jobs. As a final complication, the beginning of the year also saw the Fed's policy interest rate, the federal funds rate, at the historically low level of 1 percent, the result of the efforts of the Federal Open Market Committee (FOMC) to spark faster growth and minimize deflation risks in 2003. In January, with inflation low and the job market still weak, the FOMC indicated that it would be "patient" in removing the policy accommodation implied by the low value of the federal funds rate. The increase in inflation that occurred last spring posed a choice for the FOMC. Should the Committee remain "patient" in the face of this development, or should it move more aggressively to meet an emerging inflation threat? The answer, I would argue, properly depended on both the source of the inflation and the state of inflation expectations. In particular, if the pickup in inflation had largely resulted from an overheating economy and a consequent increase in pricing power and wage demands, a more-aggressive policy would have been appropriate. The FOMC's analysis of the situation, however, was well described by the statement issued after its June meeting. In that statement, the Committee suggested that the increase in inflation was due at least in part to "transitory factors"--a heading under which I include the increases in oil prices, commodity prices, and import prices--and indicated as well that "underlying inflation" would likely remain low, which I interpret as saying that, with medium-term inflation expectations well contained, second-round effects appeared likely to be small. The implication of this analysis was that the FOMC could remain "patient." Thus far at least, the FOMC's diagnosis appears to have been correct, as both headline and core inflation have receded from the levels of last spring. Looking forward, I am sure that the Committee will continue to watch the oil situation carefully. However, future monetary-policy choices will not be closely linked to the behavior of oil prices per se . Rather, they will depend on what the incoming data, taken as a whole, say about prospects for inflation and the strength of the expansion. Generally, I expect those data to suggest that the removal of policy accommodation can proceed at a "measured" pace. However, as always, the actual course of policy will depend on the evidence, including, of course, what we learn about how oil prices are affecting the economy. As the FOMC evaluates its policy options, retaining public confidence in the Federal Reserve's commitment to price stability will continue to be essential. If the public were not fully assured of that commitment, the FOMC would find achieving its objectives of price stability and maximum sustainable employment to be difficult if not impossible. For that reason, I fully endorse the sentiment in the last few FOMC statements that "the Committee will respond to changes in economic prospects as needed to fulfill its obligation to maintain price stability." References BP (2004).ï¿½ London: BP, June. Chinn, Menzie, Michael LeBlanc, and Olivier Coibion (2001). unpublished paper, University of California, Santa Cruz. Gramlich, Edward M. (2004).ï¿½ speech delivered at the Annual Economic Luncheon, Federal Reserve Bank of Kansas City, September 16. Hooker, Mark A. (1999).ï¿½ Finance and Economics Discussion Series 1999-65.ï¿½ Washington: Board of Governors of the Federal Reserve System. Pindyck, Robert S. (2001).ï¿½ "The Dynamics of Commodity Spot and Futures Markets: A Primer," Energy Journal , vol. 22, no. 3, pp. 1-29. Weiner, Robert J. (2002).ï¿½ "Sheep in Wolvesï¿½ Clothing?ï¿½ Speculators and Price Volatility in Petroleum Futures," Quarterly Review of Economics and Finance , vol. 42, no. 2, pp. 391-400. Footnotes Although gasoline prices generally rise and fall with the price of crude oil, in the short run the linkage can be relatively loose. One reason that oil and gasoline prices do not march in lockstep is that the margins that refiners and distributors of gasoline can command may vary significantly over time, depending on such factors as the availability of refinery capacity, seasonal variations in the demand for gasoline, and regional imbalances in gasoline supply. The price of West Texas intermediate (WTI) is often cited in the media, which is why I have used it as an example here. For consistency, in the remainder of the talk, when I refer to oil prices I mean the price of WTI. However, as a particularly desirable grade of "light, sweet" oil, WTI commands a premium price. The average price of crude oil imported into the United States is currently about $40 per barrel, about $15 less than the price of WTI. I thank William Helkie and Charles Struckmeyer, of the Board's staff, for their excellent assistance. Oil futures and other oil-related derivatives are traded on the New York Mercantile Exchange (NYMEX) and the International Petroleum Exchange (IPE) as well as over the counter. I should acknowledge that oil futures prices have a less-than-stellar record in forecasting oil price developments, but they are probably the best guide that we have. Chinn, LeBlanc, and Coibion (2001) find that futures quotes are unbiased predictors of future spot prices, though not very accurate ones. Saudi Arabia and other OPEC members, like the IEA and most participants in the oil markets, did not anticipate the surge in consumption we have seen this year either. OPEC actually reduced its production targets in 2003 and again in early 2004 out of concern that weak oil demand would cause price declines. For example, we know of historical examples of speculators "cornering" a market, leading to wild price fluctuations unjustified by fundamentals. In addition to helping ensure that oil is used at the socially most valuable time, speculation also reduces risks for producers and consumers of oil. For example, an oil producer who sells oil for future delivery receives a guaranteed price today and does not have to bear the risk that the price will drop sharply before the oil delivery date. The measure used here is net long futures positions of noncommercial traders (that is, traders who do not have a direct hedging need). These data, available from the Commodity Futures Trading Commission, do not perfectly measure speculative activity, as they do not cover all trading in oil futures, nor do they necessarily cleanly distinguish speculators from other traders. Oil market data for the United States, including inventories data, are released weekly by the Energy Information Administration, part of the U.S. Department of Energy. Each month, the International Energy Agency releases analogous information covering the thirty member countries of the Organisation for Economic Co-operation and Development (OECD). Weiner (2002) surveys the academic literature and concludes that, over the long term, speculative activity has not much affected the average price of oil. The apparently strong effect on oil prices of recent hurricanes in the Gulf of Mexico, which led to short-term reductions in production, is a bit of evidence that high prices reflect a tight supply-demand balance rather than speculative hoarding. If inventories or spare production capacity had been available, the shortfalls created by hurricanes could have been replaced, and the price effect would have been more muted. A somewhat different question is whether future prices for oil contain a significant risk premium. The finding of Chinn, LeBlanc, and Coibion (2001) that futures prices are unbiased predictors of future spot prices argues against a large risk premium. Estimates by the Board's staff, based on the methods of Pindyck (2001), indicate that the risk premium in oil futures was no more than $2 or so even during the recent spikes in prices. Japan may set an unreasonably high standard: That country's small area reduces the use of energy for transportation, and the low average size of homes on these densely populated islands reduces heating and cooling costs. Japan also produces a different mix of goods and services than the United States, a mix that may be less energy-intensive. On the other hand, not even Japan has made full use of the energy conservation potential of existing technologies, such as hybrid autos for example. As discussed earlier, higher energy prices may also lower the economy's productive capacity, by reducing investment and making a portion of the capital stock un-economical to operate. This decline in potential output puts additional upward pressure on the inflation rate. As my colleague Edward Gramlich put it in his recent remarks on oil price shocks and monetary policy, "The worst possible outcome is for monetary policy makers to let inflation come loose from its moorings" (Gramlich, 2004).
No content found
Remarks by Governor Susan Schmidt Bies At the American Association of Individual Investors Washington Chapter Meeting, Arlington, Virginia October 23, 2004 The Federal Reserve System and the Economy Good morning. I'm certainly pleased to be here with you. The programs of the American Association of Individual Investors play an important role in advancing the financial education of its members. Folks like you--individual investors--are important participants in our economic system. As financial services firms and their products continue to evolve, people are continually challenged to improve their ability to evaluate alternative consumer and investor services. The great strength of our financial markets is that they efficiently weigh and sort the judgments of literally millions of investors, large and small, as economic conditions evolve, channeling investment dollars, at least ideally, to where they can best be used. Programs such as this morning's event doubtless help keep your members informed about where they may seek the highest risk-adjusted returns on their investments. I know that because you have a Federal Reserve policymaker here, you will want to hear how my own views of where our economy stands compare with yours. I'll get to that. But first, let me offer the customary caution that the views I'll express are my own and don't necessarily reflect those of other policymakers or staff members of the Federal Reserve. And second, I want to spend some time offering you a broader perspective on the Federal Reserve's purposes and functions, of which monetary policy is just one part, albeit a very important part, of the larger whole. At the Board, we sometimes nickname this topic "Fed 101." In fact, the Fed has a wonderful website with just that name. You can find it at . The Federal Reserve System is generically described as the central bank of the United States. It represents our nation's third, and I trust final, attempt to establish a central bank. You may well recall learning in school that, in the late eighteenth and early nineteenth centuries, the Congress chartered the First Bank of the United States and the Second Bank of the United States, but neither institution lasted more than twenty years. The Banks' very existence was controversial and went to the heart of the great national debate, which continues to this day, over which responsibilities and powers should be handled at the federal level and which should be left to the states. Suffice it to say that, after the charter of the Second Bank of the United States expired in 1836, we went without a central bank for nearly eighty years. A series of financial panics in the late nineteenth and early twentieth centuries, most notably the Panic of 1907, revived the idea of creating a central bank to provide the nation with a safer, more flexible, and more stable monetary and financial system. But suspicion of centralized power remained at the core of the American psyche, and so the institution that the Federal Reserve Act established in 1913 was a central bank that assigned significant responsibilities for monetary-policy-making to regional Federal Reserve Banks. The System that resulted consists of a governmental agency--the Board of Governors--in Washington and, in twelve major cities, the regional Federal Reserve Banks, which combine public and private elements. The role of the Board vis-a-vis the regional Banks was elevated in the aftermath of the stock market crash of 1929 and in the early years of the Great Depression, but the combination of centralized and regional responsibilities remains an important strength of the the Federal Reserve System, as I'll explain shortly when I discuss the formulation of monetary policy. The role that the Fed's founders envisioned for the central bank was narrower, and more passive, than the role that the Fed plays today. The emphasis was on providing currency and reserves to meet seasonal demands and on assisting banks in accommodating the credit needs of commerce and business. Indeed, until the 1920s, it wasn't clearly understood that the Reserve Banks' purchases and sales of government securities influenced the supply of money and credit in the economy. Today, the Federal Reserve's duties fall into four general areas--some that would have been familiar to the central bankers in the Fed's early years and some that would have been unfamiliar: maintaining the stability of the financial system and containing systemic risk that may arise in financial markets supervising and regulating banking organizations to ensure the safety and soundness of the nation's banking and financial system and to protect consumers from harm in their use of credit and banking services playing a major role in operating and overseeing the nation's payment system, including providing certain financial services to financial institutions, the U.S. government, and foreign official institutions conducting monetary policy in pursuit of stable prices and maximum sustainable employment We have an all-too-recent example of the Fed as a source of financial stability in its response to the financial aftermath of the terrorist attacks of September 11, 2001, which occurred just before I joined the Board in December 2001. As a commercial bank executive, I was impressed with the speed at which the Fed responded when the normal settlement and information systems in check and securities markets were interrupted. The Fed worked immediately through discount window lending, open market operations, and other means to provide the financial and banking systems with sufficient liquidity. It worked with public- and private-sector participants to keep markets open or, if circumstances forced markets to close, to return them quickly to normal operations. As the operator and overseer of key payment systems, it had to ensure that its own systems, as well as those of the private sector, were operational. And on the Monday after September 11, it lowered the target federal funds rate to help cushion the economic fallout of the blow to consumers' and businesses' confidence. Because the Fed worked so effectively, bankers throughout the country could serve their consumer and business customers and thereby help to minimize the economic effect of the terrorist attacks. The Fed's role as the supervisor of banking organizations--both as the federal supervisor of the roughly one thousand state-chartered banks that have joined the Federal Reserve System and as the umbrella overseer of financial and bank holding companies--gives the Fed's staff and policymakers the kind of hands-on experience and knowledge that is essential for a central bank during a financial crisis. The Fed's examiners and supervisors seek to ensure not only the safety and soundness of the banking system but also the strength of banking organizations, systems for complying with anti-money-laundering, consumer-protection, and other laws. In fact, the Congress charged the Federal Reserve Board with writing the rules that implement consumer protection laws such as the Truth in Savings Act and the Truth in Lending Act, though each of the various federal banking agencies enforces the regulations for the institutions within its purview. Given all the attention paid to the Board and its Chairman, you may be surprised to learn that more than 21,000 of the Federal Reserve System's roughly 23,000 employees work not in Washington but at the twelve regional Federal Reserve Banks. A substantial portion of these employees work in vital but often unsung jobs, keeping the payment system operating smoothly. The System's employees handle the distribution of U.S. currency and coin throughout the nation and the world. They also clear and process checks and electronic payments, such as the direct deposit of paychecks and they facilitate the electronic transfer of huge sums between large financial institutions. But it is monetary policy--and the Fed's principal monetary lever, the federal funds rate, which is the interest rate on overnight loans of reserves between depository institutions--that earns the Federal Reserve all that ink and airtime. Deciding on the appropriate policy from among the various options keeps nineteen policymakers and a staff of more than four hundred Ph.D. economists at the Board and the Reserve Banks quite busy. The chief monetary-policy-making body within the Federal Reserve is the Federal Open Market Committee, or FOMC. It meets eight times a year but can confer by telephone more often if necessary, as it did in 2001 as it responded to incoming economic information as well as economic shocks from terrorism, and as it did again in 2003 as policymakers sought to understand the economic effect of the war in Iraq. The FOMC has nineteen members. Although all members actively participate in discussions at the meetings, only twelve have votes at any one time on the Committee. Each of the seven members of the Board wields a vote, as does the president of the Federal Reserve Bank of New York by virtue of that Bank's unique responsibility for implementing monetary policy decisions through the open market operations of its Domestic Trading Desk. The responsibility for casting the remaining four votes alternates among the remaining eleven Reserve Bank presidents: Two vote every other year, and the other nine vote every third year. But the important point to remember is that, in a consensus-driven body such as the FOMC, the identity of a member who casts a vote in any given year is less significant than the fact that each member of the FOMC participates fully in the deliberations. The presidents, in particular, bring to the table analyses of economic and business conditions in their districts. The boards of the Reserve Banks also contribute a wealth of anecdotal information to supplement the torrent of hard economic data the Fed analyzes. Moreover, they make recommendations to the Board on the discount rate, the rate the Fed charges on its own loans to financial institutions. The information from the Reserve Bank boards, along with other economic intelligence, is summarized in a report known as the Beige Book, which is publicly released about two weeks before each FOMC meeting. The FOMC also consults other books of other colors. But I'm getting ahead of myself. Let me describe the routine at a typical FOMC meeting. After seating ourselves around the twenty-seven-foot-long, polished mahogany-and-black-granite Board table, we begin punctually at nine o'clock. After approving the minutes of the previous meeting, our first order of business is a report from the Manager of the System Open Market Account at the New York Fed, who focuses on conditions in domestic and international financial markets. That report is followed by a presentation from the directors of the Board's Divisions of Research and Statistics and International Finance, who deliver the Board staffs' economic forecast as represented in the Greenbook, which FOMC members have usually had the weekend to study. The Greenbook contains the staffs' summary of recent economic information, a baseline economic forecast, which is the staff's best estimate, and scenarios based on possible alternative future events. Then comes the first "go-round," in which every member of the Committee offers his or her assessment of current economic conditions. We may usefully digress here to consider how the Board staff arrives at its forecast and to describe what role the forecast plays in policymakers' deliberations. An important, perhaps obvious, point to make is that it is not--I repeat, not--the FOMC's forecast. The economic staff of each Reserve Bank independently advises its president. And the economic staffs of the Reserve Banks and the individual members of the FOMC may or may not agree with elements of the Board staff's forecast. Indeed, FOMC members sometimes couch the presentation of their economic views in terms of where those views coincide with and diverge from the Greenbook's forecast. That description, in and of itself, gives you some sense of the staff's influence of the forecast. It sets the parameters of the discussion. So what kind of forecast is it? It is a forecast based on human judgment. But this judgmental forecast is informed by sophisticated econometric models. The staff's core, large-scale structural model has been dubbed FRB/US--pronounced "ferbus." But that model is not the only one the staff uses. Indeed, the staff uses its suite of smaller-scale models to probe the vulnerabilities of the core model. But as seductive as modeling is to us economists, we must remember that no model can fully capture a dynamic, ever-evolving economy such as ours. Thus, the staff's forecast, and I'm sure the individual forecasts of each FOMC member, are in the end judgmental assessments. After the Greenbook session, the director of the Board's Division of Monetary Affairs briefs the committee on the Bluebook, a document that presents policy options, usually two or three, for the Committee's consideration and that offers arguments for and against each course of action. Not a recommendation from the staff, the briefing is instead a vehicle against which FOMC members can test their own thinking. Finally, after hours of discussion and analysis, the Chairman speaks on the policy choice for the first time. Until this point, his participation in the meeting has usually been limited to questions and to comments aimed at keeping the meeting moving. After the Chairman makes his recommendation, FOMC members react in the second go-round. Then we vote, and by then it is usually about one o'clock and time for lunch. About an hour later, at around quarter after two, a statement publicly announces our decision. As currently formulated, the announcement has four parts: the first states the target for the federal funds rate; the second briefly explains the Committee's analysis of current economic conditions; the third provides the Committee's assessment of the risks to price stability and economic growth; and the last provides Committee members' votes. The statement is a relatively recent innovation; it is about a decade old and, over that period, it has evolved from a quite terse missive to the almost loquacious form it takes today. Before the advent of FOMC statements, market observers had to infer shifts in monetary policy by watching the New York Fed's open market operations. The FOMC statement, as well as more-detailed minutes released about six to seven weeks after each meeting, twice-a-year reports to the Congress on monetary policy, and audits by outside auditors and the Government Accountability Office (formerly the General Accounting Office), are all important elements of the transparency necessary for an independent central bank to function within a democracy. As I mentioned, our goals--price stability and maximum sustainable employment--are set by law, but we are afforded the political independence to make the sometimes unpopular decisions required to achieve those goals. Appropriate transparency and accountability offer a necessary counterbalance to that independence. Now, as promised, let me turn to the state of the economy and the prospects ahead. The Economic Outlook As you know, real gross domestic product grew at an annual rate of 3.3 percent in the second quarter, building on larger increases since the middle of 2003. After having moderated a bit in late spring, partly in response to a substantial rise in energy prices, aggregate demand appears to have regained some traction. Consumer spending has begun expanding at a faster pace and housing activity remains strong. Business outlays for capital equipment also appear to be on an upward trend, continuing to rebound from their weakness of the past several years. And with financial conditions still accommodative, I expect that economic activity will continue to expand at a solid pace for the remainder of the year. Despite the continued expansion of output, the pace of job creation has been disappointing in recent months. Nonfarm payrolls have grown an average of only 101,000 jobs per month from June through September, after growing at nearly triple that pace in the prior three months. At the same time, despite the recent volatility in oil markets, inflation, on balance, remains subdued. The core consumer price index, which excludes food and energy, edged up only 0.1 percent in each of the three months from June through August and rose at a faster 0.3 percent in September. Last month's increases occurred in varying sectors, including used cars and lodging. We will continue to monitor the pass through effect from energy and import prices on inflation, but I expect underlying inflation to remain relatively low. In my view, under these circumstances the Federal Reserve can remove its policy accommodation at a measured pace, consistent with its commitment to maintain price stability as a necessary condition for maximum sustainable economic growth. Household Financial Conditions Continued vigorous expansion depends importantly on consumer spending, so let me spend a few minutes on the financial condition of the household sector. Some commentators have expressed concern about the rapid growth in household debt in recent years. They fear that households have become overextended and will need to rein in their spending to keep their debt burdens under control. My view is considerably more sanguine. Although there are pockets of financial stress among households, the sector as a whole appears to be in good shape. Households have taken on quite a bit of debt over the past several years. According to the latest available data, total household debt grew at an annual rate of about 10 percent between the end of 1999 and the second quarter of 2004; in comparison, after-tax household income increased at a rate of about 5 percent. But looking below the aggregate data, we must understand that the rapid growth in household debt reflects largely a surge in mortgage borrowing, which has been fueled by historically low mortgage interest rates and strong growth in house prices. Indeed, many homeowners have taken advantage of low interest rates to refinance their mortgages, and some have done so several times over the past couple of years. Survey data suggest that homeowners took out cash in more than one-half of these "refis," often to pay down loans having higher interest rates. On net, the resulting drop in the average interest rate on household borrowings, combined with the lengthening maturity of their total debt, has damped the monthly payments made by homeowners on their growing stock of outstanding debt. The Federal Reserve publishes two data series that quantify the burden of household obligations. The first series, the debt service ratio, measures the required payments on mortgage and consumer debt as a share of after-tax personal income. The second series, the financial obligations ratio, is a broader version of the debt service ratio that includes required household payments on rent, auto leases, homeowners insurance, and property taxes. Both ratios rose during the 1990s, and both reached a peak in late 2001. Since then, however, they have receded slightly on net, an indication that households, in the aggregate, have been keeping an eye on repayment burdens. Moreover, delinquency rates for a wide range of household loans have continued to drift down this year and lie below recent highs in 2001. To be sure, mortgage rates and other consumer loan rates have come off the lows reached early this year, and concerns have been heightened about interest payment burdens for households. Although some households will be pressured by the higher rates, I believe the concerns can be overstated. First, most household debt--mortgage and consumer debt combined--carries a fixed interest rate, which slows the adjustment of interest costs to rising rates. Second, although interest rates on some variable-rate loans will rise quickly, the adjustment for a large number of variable-rate loans could be a good deal slower. For example, many adjustable-rate mortgages start off with a fixed rate for several years, providing households with some protection from rising rates. This relatively upbeat assessment of household credit quality seems to be shared by lenders and by investors in securities backed by consumer debt. According to the Federal Reserve's survey of senior loan officers, the number of banks tightening their standards on consumer loans has fallen over the past year. Moreover, credit spreads on securities backed by auto loans and credit card receivables have narrowed in recent months. These indicators do not point to much concern about household loan performance. Thus far, I have focused on the liability side of the household balance sheet. Favorable developments have occurred on the asset side as well. Equity prices rallied strongly last year and have held their ground this year; as a result, they have reversed a good portion of the losses sustained over the previous three years. In addition, home prices have appreciated sharply since 1997. All told, the ratio of household net worth to disposable income--a useful summary of the sector's financial position--has climbed in the past couple of years and currently stands at a high level relative to the past decade. Financial Conditions of Businesses Businesses are also in good financial shape, having experienced a dramatic improvement in recent years. Indeed, starting last year, many firms found themselves in the unusual position of being able to finance a pickup in spending entirely out of rapidly rising cash flow, and those that turned to external markets generally found the financing environment to be quite accommodative. This improvement in financial conditions reflects a number of factors, namely low interest rates, a widespread restructuring of corporate liabilities, and significant cost-cutting and productivity gains that boosted profitability. In my view, even with an expected rise in interest rates and some moderation in profit growth, the financial condition of the business sector should remain strong and able to support continued expansion. I will address each factor in turn. First, firms are continuing to benefit from the accommodative stance of monetary policy. Even with the recent increase by the FOMC in the target funds rate to 1.75 percent, short-term borrowing costs remain low. For longer-term debt, the combination of low yields on benchmark Treasury securities and sharply reduced risk spreads from those of a couple of years ago has kept borrowing costs quite attractive. The reduced risk spreads reflect the improved financial positions and more positive investor sentiment, perhaps as accounting and corporate governance scandals have receded. Second, in response to low long-term rates and to investors' concerns arising from some high-profile, unanticipated meltdowns, firms have greatly strengthened their balance sheets. Many firms have refinanced high-cost debt, a move that has reduced the average interest rate on the debt of nonfinancial corporations by about 1 percentage point on net since the end of 2000. Businesses have also substituted long-term debt for short-maturity debt to improve their balance sheet liquidity and to reduce the risk of rolling over funds. In addition, many firms--especially in the most troubled industries--have retired debt through equity offerings and asset sales, while others have used their growing profits to retire debt. As a result, the growth of nonfinancial corporate debt in the past two and a half years has been limited to its slowest pace since the early 1990s. These repairs to balance sheets have also reduced the exposure of many firms to rising interest rates, especially in the near term. In particular, the replacement of short-term debt by long-term bonds means that less debt will have to be rolled over in the near term at higher rates. In addition, because much of the long-term debt has a fixed rate, interest payments typically are unaffected over the life of the bond. Moreover, research by the Board's staff suggests that firms that are more likely to rely on floating-rate debt, and for that reason might be more vulnerable to rising rates, have tended to use derivatives in recent years to hedge their exposure to interest rate risk. Thus, for many firms, the effect of rising interest rates will be mitigated and stretched out over time. In addition, a lesson we can take from the episode of policy tightening in 1994 is that rising interest rates have little detrimental effect on the financial health of the corporate sector when the rate increases occur in the context of an expanding economy. Specifically, corporate credit quality improved on balance after 1994 with the pickup in economic activity and corporate profits. Third, the improvement in financial conditions among businesses is due partly to some significant belt-tightening by many firms. Over the past few years, the drive to cut costs and boost efficiency has generated rapid productivity gains. Fuller utilization of the capabilities of capital already in place, ongoing improvements in inventory management, and streamlined production processes requiring fewer workers, to name but a few examples of efficiency enhancements, have boosted corporate profitability even when revenue growth was tepid. With the pickup in revenue growth in the second half of last year, companies were able to leverage the productivity gains and produce a dramatic recovery in overall corporate profitability. The profits of nonfinancial corporations as a share of sector output rose to almost 11 percent in the second quarter of this year. This share lies above its long-run average over the past few decades and well above the cyclical trough of 7 percent in 2001. To be sure, the profit share will likely slip a bit from its high level as the expansion gains steam and businesses are less able to keep a lid on their labor costs. Moreover, because cyclical factors likely contributed to the recent dramatic advances in productivity, we should expect productivity gains to moderate. But these developments and the decline in profit share are to be expected and will not, in my view, lead to a meaningful impairment of the financial health of companies. The improvements that businesses have made to their financial strength and profitability have been substantial and should help to support sustained, solid growth of the U.S. economy. Footnotes These remarks draw from the following sources: Laurence H. Meyer (1998), ," speech delivered at Willamette University, April 2; Mark W. Olson (2004), " speech delivered at the Twenty-sixth Conference of the American Council on Gift Annuities, May 5; and David J. Stockton (2002), "What Makes a Good Model for the Central Bank to Use?" speech delivered at the Federal Reserve Bank of San Francisco, March 2. Covitz, Daniel and Steven A. Sharpe, "Which Firms use Interest Rate Derivatives to Hedge? An Analysis of Debt Structure and Derivative Positions at Nonfinancial Corporations," Working paper, July 2004.
Remarks by Vice Chairman Roger W. Ferguson, Jr. At the Greater Issues Series, The Citadel, Charleston, South Carolina October 26, 2004 Factors Influencing Business Investment Thank you for inviting me to speak today as part of the Citadel's Greater Issues Series. I will speak about one of the forces likely to shape developments in the U.S. economy. In past speeches, I have addressed the so-called jobless recovery, trade, global imbalances, and national saving. Today, I round out this series on fundamental issues by reviewing business capital investment--that is, spending by businesses on such things as machines, computers, and new buildings. Although it makes up only about 10 percent of gross domestic product, business investment is a vital element of the U.S. economy, with important implications for a variety of broader economic issues. Investment has a large influence on the year-to-year fluctuations in economic activity. During the past six recessions, the drop in domestic investment has generally accounted for most of the decline in GDP. Business investment was a major factor in both the 1990s economic expansion and the subsequent recession. In fact, the decline in business outlays on investment goods in 2001 was even larger than the downturn in the overall economy. Although overall GDP edged down at an average annual rate of only 0.2 percent in the first three quarters of 2001, the decline in business investment subtracted nearly 2 percentage points from GDP growth over that period. Clearly, some insight into investment swings would enable us to better understand the economic cycles of recessions and expansions, which in turn have such a big effect on job creation, the budget deficit, and a host of other important issues. Business investment also affects the broader economy through labor productivity--or output per hour of work. Over the past fifty years, the average hourly output of American workers has increased nearly 200 percent. According to the Bureau of Labor Statistics, more than one-third of this improved efficiency likely reflects increases in the use of capital goods. Over the past decade, efficiency gains due to increased capital expenditures have been especially pronounced. Because rising productivity is the primary means through which standards of living increase, capital investment is clearly an important part of the economic engine. Accordingly, an understanding of investment is critical for insight into both cyclical and longer-run economic developments. In my discussion today, I want to address the outlook for the three categories of business investment: equipment and software, structures, and inventories. Forecasting business investment is complicated, however. Despite the importance of this subject, the policymakers, academics, and business economists who study it have limited knowledge regarding its behavior and the factors determining that behavior. By highlighting some of the thorny issues that need to be considered, I hope to provide a backdrop to help elucidate the likely performance of business investment in the quarters to come. Although forecasting involves considerable uncertainty, I think that the prospects for business investment over the next few quarters are, on balance, relatively positive. I should note, of course, that the comments that I make today reflect only my own views; they should not be taken to represent the views of my colleagues on the Board of Governors or in the Federal Reserve System. Equipment and Software The largest component of business investment is expenditures on new equipment and software. This category includes computers, routers and switches, machinery, aircraft, trucks, software, and a wide variety of other types of equipment that are used to produce goods and services. Decisions of business people regarding equipment and software investment are based on their assessment of business prospects, the nature of the capital goods themselves, and financing conditions. In short, potential purchasers of business equipment will need to assess a plethora of variables that are at best known only imperfectly. For economists who forecast investment, the task is even harder: Not only must we form opinions about all these variables, we must try to discern the business community's response to them. Currently, demand for business products and services appears to be rising. In addition, interest rates remain low, and the business sector has ample cash on hand. Historically, such conditions have been associated with increasing real business spending on equipment and software. At the moment, however, at least four additional factors are clouding our view. First, after the trough of the last recession, businesses seemed more hesitant than usual to expand their productive capabilities. Concerns about terrorism, war, and corporate governance scandals may have made it harder for firms to have confidence that a robust and durable recovery was under way. With heightened uncertainty, many firms may have been reluctant to increase capital spending. The issue we face now, nearly three years since the trough, is whether this reluctance has abated. The evidence we have for ongoing business hesitancy is suggestive but far from conclusive. One piece of evidence is found in the state of the "financing gap"--the difference between a firm's capital expenditures and its cash flow, or internal funds. In the past, the financing gap for nonfinancial corporations was almost always positive--that is, capital spending was larger than internal funds. Between 1991 and 2000, the financing gap rose from less than $35 billion to a peak of more than $300 billion. The rapid rise largely reflected sharp increases in capital expenditures in the telecommunications, high-tech, and transportation industries that greatly outstripped the increases in internally-generated funds. However, the financing gap fell abruptly in 2001 and 2002, turned negative last year, and has stayed below zero since then. This negative financing gap, which is widespread across industries, indicates that the business sector as a whole is generating enough cash to purchase capital expenditures without borrowing. In fact, because it has been negative for a while, the gap has contributed to the accumulation of a large cushion of liquid assets. Over 2003 and the first half of 2004, liquid assets in the nonfinancial corporate sector rose $244 billion, or more than 20 percent, to $1.3 trillion. This news is good because it means that business balance sheets are in good shape and financial conditions are not holding back business investment. But the news is also troubling. Given the current low interest rates, the preference for holding financial assets over expanding operations suggests that businesses lack confidence in the future profitability of their potential ventures. The negative financing gap could very well be a sign that businesses remain cautious about the outlook--a condition that, unfortunately, can become a self-fulfilling prophesy. A second factor that complicates the outlook for investment is the state of the computer sector. About 12 percent of business spending on equipment and software is for computer gear. Some of that spending is to equip new plants and new employees, but a large share of it is to replace old machines and outdated technology. Over the past few decades, we have seen technology advance rapidly, and businesses have purchased a large amount of high-tech equipment. More recently, the growth rate of business spending on computers has slowed--from about 40 percent last year to less than half that pace, on average, in the first two quarters of this year. One possible explanation is that we are seeing a deceleration in the pace of technical advancement. Technological progress affects business investment in primarily two ways. First, it changes how businesses organize their operations. Second, even innovations that do not spur an entirely new way of doing business can encourage equipment spending because some firms will choose to retire obsolete equipment more rapidly than they otherwise would. Accordingly, if the pace of progress slows, increases in business investment, particularly of high-tech goods, may also slow. Of course, we cannot directly measure the pace of technological progress, but we can look at some indicators to help us judge. One indicator that economists often look at is prices, particularly "quality-adjusted prices" compiled by the Bureau of Labor Statistics and used by the Bureau of Economic Analysis to deflate nominal computer expenditures. Over time, these quality-adjusted prices tend to fall, as computers and related equipment become more and more powerful. Between 1992 and 2002, the quality-adjusted price of new computers fell at an annual rate of 18 percent. The speed at which these prices fall reflects mainly the pace of technological progress. Unfortunately, over the past several quarters, the rate of price decline slowed from that experienced during the preceding decade: Computer equipment prices fell just 9 percent at an annual rate in 2003 and the first half of 2004. Although we cannot be certain, at least some of this deceleration may represent some slowing in the rapid pace of technological improvement. Indeed, detailed data that we use in putting together the industrial production data suggest that the number of new PC models introduced this year has fallen markedly from the pace posted in the preceding few years, suggesting that the pace of innovation, at least in this one market, has slowed. A third factor for economists considering the outlook for the business sector is the question of whether the existing stock of business equipment is too high. As the high-tech boom of the nineties was ending, many observers claimed that companies had been overly optimistic and had purchased too many PCs and peripherals and laid too much fiber optic cable, resulting in an actual capital stock that exceeded the desired level for business. When such a "capital overhang" emerges, new investment spending tends to be curtailed for a while. Indeed, in 2001 and 2002, real outlays for equipment and software fell at an annual rate of nearly 6 percent. Determining whether a capital overhang exists is difficult, and estimates of the size of overhangs are subject to considerable error. First, capital stocks are hard to measure; although we know the amount of new capital goods purchased, we can only roughly estimate the rate of economic depreciation and obsolescence. Consequently, we cannot know with certainty the level of the existing capital that is still available to be used. Second, we do not know how much capital firms would ideally like to employ because their expectations and production processes are always changing. Of course, we can estimate both actual and desired capital stocks, but these estimates are quite dependent on our assumptions, especially our assumptions about technological change. Based on the depreciation rates used by the Bureau of Economic Analysis, we estimate that the growth rate of the capital stock of equipment and software slowed from around 7 percent in 1999 and 2000 to about 2-1/2 percent in 2002, a slowdown large enough to substantially shrink most estimates of the capital overhang. The final factor that complicates the outlook for equipment and software spending stems from the tax code. Currently, the partial-expensing provision in the tax law allows a firm to subtract a large fraction of the cost of new capital equipment from profits right away, rather than depreciating the cost over time, and thereby to lower its taxes. The partial-expensing provision, which provides an incentive to invest in new capital goods, will expire at the end of this year. The impending expiration is probably boosting investment spending in the second half of this year as firms rush to take the tax advantage before it disappears; however, at this point the evidence is not conclusive. The anecdotal evidence on whether firms are responding to the partial-expensing provision is sparse and somewhat contradictory. According to a summary of commentary on current economic conditions prepared by the San Francisco Fed in September, a number of contacted firms planned increases in capital spending, yet there was no mention of partial expensing. In contrast, a recent special question in the Philadelphia Fed's Business Outlook Survey showed that about one-quarter of respondents thought that the tax provision was likely to boost their spending this year. The statistical evidence for a tax response is also inconclusive. Shipments of long-lived equipment (which should be more favorably affected than demand for short-lived equipment) have increased more than overall capital spending since the passage of the most recent version of the partial-expensing law--the pattern we would expect to see if businesses were taking advantage of the tax incentive. However, other explanations for this pattern are possible, and the difference between the long-lived and the short-lived categories is neither statistically significant nor terribly robust. The evidence that partial expensing is having an effect is not clear-cut, but my view is that capital spending is probably being influenced by the tax law and that its expiration in January will probably damp outlays in the early part of next year. Nonresidential Structures Besides spending on equipment and software, businesses also build and purchase nonresidential structures. Although this category--which includes factories, warehouses, shopping malls, oil wells, cell phone towers, fiber optic cable tunnels, office parks, and more--is only about 10 percent as large as the equipment and software category, it too can contribute to swings in GDP. In 2001 and 2002, expenditures for new business structures declined more than $75 billion, subtracting nearly 1/2 percentage point from annual GDP growth on average in those two years. After having flattened out last year, spending in this sector appears to have turned up recently. Business outlays on structures rose 7 percent in the second quarter, and construction data indicate that the sector expanded further in both July and August. Still, nonresidential structures are notoriously difficult to project with any certainty. Many sectors of the economy wax and wane along with the overall business cycle, but the structures sector tends to follow long cycles of its own. Although a weak economy is generally detrimental to spending in this category, expenditures often continue to increase well into an economic downturn, making forecasting difficult. In addition, the nonresidential structures category includes a diverse set of buildings, and forecasting this sector requires keeping tabs on a wide variety of indicators. Purchases of one of the largest components, commercial buildings, tend to be associated with conditions in the retail sector. Retail rents rose 3.2 percent in the four quarters that ended in the second quarter, the fastest pace in four years, and the vacancy rate remains below 6 percent. Likewise, indicators for spending on drilling and mining wells, which usually rise after a jump in oil and natural gas prices, look quite strong. However, the outlook for outlays on office buildings, which tend to be correlated with activity and hiring in the business services sectors as well as in the finance and insurance industries, is less upbeat: Office rents have continued to fall, and the vacancy rate, at 15 percent, remains elevated. The vacancy rate for industrial buildings, a sector that generally keeps pace with manufacturing activity, has flattened out around 10 percent over the past six quarters after having risen markedly for the preceding three years. Thus, at the moment, the various indicators are giving fairly mixed signals. However, the mixed signals are still an improvement over the almost uniformly negative tone of the markets for nonresidential structures a year or two ago. To me, they suggest that the nascent upturn in this sector is likely to continue. Inventory Investment So far I have discussed business fixed investment. Another important part of capital expenditures, however, is inventory investment. There are three types of inventory investment: materials and supplies, work in progress, and finished goods. In dollar terms, inventory investment is not large: From 1994 to 2003, it averaged about $37 billion--less than 1 percent of GDP. However, because it can swing from a sizable positive as firms stockpile goods in one quarter to a pronounced negative when they clear out the warehouses in the next quarter, the change in business inventories is generally considered to be one of the most important categories for understanding business-cycle volatility. The reasons that firms need to hold inventory stocks, unlike their reasons for investing in capital equipment and buildings, are not always obvious. For manufacturers, more than half of all inventories are held in the form of materials and supplies or as work in progress. These inventories are necessary, of course, to facilitate production. However, even inventories of finished goods are important. Businesses need to weigh the cost of running out of an item--perhaps forcing a customer to turn to a competitor--against the storage costs of carrying inventories from quarter to quarter. And, particularly in the retail sector, inventories of some goods--like clothing and cars--can spur sales because customers have the chance to try out different sizes or option packages before buying. With so many reasons for holding inventories, inventory investment may appear about as difficult to predict as investment in equipment or structures. It is probably even more difficult. So far I have mentioned only the reasons for which businesses intentionally change their inventory holdings. But inventory swings are often the result of miscalculations on the part of business owners. If a particular product is unexpectedly popular, inventories get drawn down; if the product is unpopular, inventories pile up. The situation is complicated for economists who are trying to draw inferences from flows into and out of inventories. We need not only to figure out how much inventory businesses have wanted to hold but also to discern when they have been surprised by sales. The difficulty of this task can be illustrated by the most recent period. In the second quarter of this year, businesses accumulated inventory stocks at a rapid pace, after having kept inventories relatively lean for several years. This acceleration in the pace of accumulation could mean that inventories had finally gotten too lean and that firms wanted to re-stock, or it could mean only that businesses were startled by the unexpectedly weak pace of demand for their products and that inventories piled up unintentionally. Answering this question is important for determining what is likely to happen to inventory building for the rest of the year. How do we begin to gauge whether businesses wanted to rebuild inventories in the second quarter? One way is to look at the ratio of inventories to sales. In the nonfarm sector, this ratio has fallen nearly 25 percent in the past fifteen years, from 2.59 months' supply to 1.97 months' supply. Most likely this secular decline represents improvements in inventory management, possibly related to better technology. In 2003, the inventory-sales ratio fell especially sharply, dropping from 2.02 to 1.94, or about 4 percent. Part of the decline likely reflected improvements in inventory-management techniques. However, unless the pace of technological change has improved markedly, the drop in the inventory-sales ratio probably also reflected sales outstripping the cautious expectations of businesses. The implication is that inventories may have been a bit on the lean side in the first part of this year. If so, then some of the inventory accumulation in the second quarter may have been an intentional re-stocking of inventories that had become too lean. Survey results from the Institute of Supply Management support this conjecture. For several years, a majority of respondents had said that their customers' inventories were too low. The most recent data, however, suggest that many supply managers have reassessed that view, and the mix of those who think customers' inventories are lean has moved more in line with those who think stocks are excessive. Thus, the recent upturn in inventory investment does not seem to be pointing toward another problematic inventory cycle, with its accompanying need to drastically reduce production to eliminate unwanted stocks. At the same time, the bulk of stock rebuilding appears to be behind us so that inventories are unlikely to be a major spur to GDP growth in the near future. Conclusions Today, I have highlighted some of the issues that continue to challenge economists in evaluating the outlook for business investment, an extremely important element in determining the outlook for the economy more broadly. With respect to investment in equipment and software, although we do not know with certainty just how rapidly technology is changing and how much businesses are expecting to sell and produce in the future, a number of indicators can help explain recent trends and likely developments. At this point, although there is uncertainty, these indicators on balance suggest that the outlook in this sector is relatively positive. Regarding nonresidential structures, the mixed indicators are a distinct improvement over the negative outlook of a few years ago. And, regarding business inventories, the recent upturn in inventory investment does not appear to be problematic, but it seems unlikely that further inventory investment will impart significant forward momentum to the economy. In short, although the economy may not experience the outsized growth rates of high-tech equipment spending or other business investment seen in the late 1990s, the fundamental features of the current U.S. economy argue for solid increases in the capital expenditures needed to produce and facilitate sales. With steady contributions from business investment, GDP growth is likely to continue expanding at a good pace, leading to further job gains and increases in family incomes. And in the longer run, the expansion of the capital stock can be expected to continue improving the efficiency of the American worker and thus to lead to additional increases in the standard of living.
No content found
No content found
Release Date: October 29, 2004 For immediate release The Federal Reserve Board on Friday announced the execution of a Written Agreement by and between the County Bank, Merced, California and the Federal Reserve Bank of San Francisco. A copy of the Written Agreement is attached.
Remarks by Vice Chairman Roger W. Ferguson, Jr. To the University of Connecticut School of Business Graduate Learning Center and the SS&C Technologies Financial Accelerator, Hartford, Connecticut October 29, 2004 Equilibrium Real Interest Rate: Theory and Application I want to thank the University of Connecticut for providing me this opportunity to comment on the important and challenging concept of the equilibrium real interest rate and its relevance to monetary policy. I will use this occasion to discuss the role that estimates of the equilibrium real federal funds rate can play in thinking about the desired degree of policy accommodation. Those views, I should add, are my own and are not necessarily shared by anyone else in the Federal Reserve System. I hope that at the end of this talk you will conclude, as I do, that while the concept of the equilibrium real rate is a useful aid in thinking about setting monetary policy, it is not measured and observed with such precision as to provide a practical guide to the appropriate stance of policy. Current Situation As the most recent statement of the Federal Open Market Committee (FOMC) made clear, the U.S. economy appears to have moved out of the soft patch that characterized the second quarter. Supported by ongoing advances in productivity and the attendant increases in real incomes, household spending has picked up. Businesses, for their part, seem to have shaken off at least some of their hesitancy to spend, although the subdued pace of hiring may signal that they still retain a wary attitude toward making important commitments. But the strengthened balance sheets of the business sector, along with buoyant cash flow, should provide firms with the wherewithal to fund a healthy expansion of the capital stock in coming quarters. No doubt the recent run-up in energy prices poses some challenges, but the evidence indicates that, without some further material shock, aggregate demand is on a track consistent with sustained economic growth. That should gradually return the economy to full utilization of its resources, while inflation remains subdued. The FOMC was confident enough about its assessment of the vigor of spending to indicate in its most recent statement that it continues to believe that policy accommodation can be removed at a pace that is likely to be measured. That begs the question, of course, of how the Committee can be sure that policy is currently accommodative. I find it instructive to first consider how not to measure policy accommodation. In particular, the fact that the nominal federal funds rate remains quite low does not, by itself and without context, signal that policy is loose. After all, spending decisions should depend on real, not nominal, determinants, including the real federal funds rate, which is the nominal federal funds rate less prevailing inflation expectations. Although backward-looking measures of inflation--such as the four-quarter growth in core personal consumption expenditure (PCE) prices--imply that the FOMC's cumulative 75 basis points of tightening so far this year has moved the real federal funds rate into positive territory for the first time in almost three years, that observation is not sufficient to calibrate the stance of policy. For example, the U.S. economy expanded at about the same average pace from 1981 to 1990 and from 1991 to 2000. In the earlier period, however, the real short-term rate averaged 4-3/4 percent whereas in the more recent one the real rate was 2 percentage points lower. Clearly, prevailing conditions matter in determining the degree of policy accommodation. It is only against a backdrop of an economy that seems poised to maintain sustained and solid economic growth, even as the funds rate rises, that the FOMC can determine that current policy is accommodative. The Equilibrium Rate in Theory What is needed is a benchmark summarizing the economic circumstances--including, among other variables, the underlying strength of aggregate demand, the level of aggregate wealth, and economic developments in our trading partners--combining to shape the expansion of activity and the extent of pressures on inflation. One way of providing that benchmark is to consider what level of the real federal funds rate, if allowed to prevail for several years, would place economic activity at its potential and keep inflation low and stable. If the actual real rate is below that benchmark level, policy can be viewed as accommodative, in that if that stance were maintained, ultimately pressures on resources would build. If the actual real rate is kept above that benchmark level, policy would seem to be contractionary. This definition makes clear that the most relevant aid in policymaking is an intermediate-run measure, in that there may be forces at work in the shorter run that push spending away from potential output even if the real rate were pegged at this benchmark rate. It also makes clear that the concept involves a good amount of judgment--indeed, the same judgment that goes into making any economic forecast--about the determinants of spending, the trend of productivity, and the forces affecting inflation in the intermediate term. Economists famously cannot agree on much. In this case, we cannot even agree on the name of the benchmark concept that I have just described. The real interest rate consistent with the eventual full utilization of resources has been called the equilibrium real federal funds rate, the natural rate of interest, and the neutral real rate. I prefer the first name, the equilibrium real federal funds rate, because, by using the word "equilibrium," it reminds us that it is a concept related to the clearing of markets. Even if economists settled on a name, however, we are not likely to agree on a single model to describe a system as richly complicated as the U.S. economy. Thus, there are as many ways of estimating the equilibrium real federal funds rate as there are different economic models. There is, however, one way of estimating the equilibrium real rate that I do not find especially convincing. Some economists derive point estimates of the equilibrium real rate by taking averages of the actual real rate over long periods of time. True, over a long-enough sample period, resource slack probably averages near zero, which suggests that the sample average of the real interest equals the equilibrium real rate. But decisions about the sample period--whether to include low-real-rate stretches, such as the 1950s, or high-rate periods, such as the early 1980s--have material bearing on the estimate. This indicates to me that there can be significant and persistent deviations in the equilibrium real rate from the observed long-run average measured over decades. The average interest rate that seems to have brought aggregate demand and aggregate supply into rough balance in the past may not be the same rate required in every conjunctural setting. Our inability to equate the long-run average interest rate to the equilibrium real interest rate that is relevant for setting policy is not surprising given the manner in which economic behavior, technology, and government policy can change over time. Put another way, an estimate derived from long-run observations may not be relevant for policy for two reasons. First, economic conditions during the policy-relevant period might differ from the average conditions during the observation period. Second, the economy changes in ways that tend to limit the relevance of historical observations for policymaking. That said, policymakers do strive to understand what the equilibrium real interest rate will be over the long run, but that is a forward-looking notion that depends on our sense of how the forces of productivity and thrift will evolve over time as measured in decades. An understanding of a likely long-run level of the equilibrium real rate is useful, even though the level is not directly observable, because it provides a general sense of the level that would, over that longer period, allow aggregate supply and demand to move into balance, given the evaluation of secular forces such as productivity and population growth. Such an understanding of the longer-term prospects for the real interest rate aids in identifying variations in the concept over the intermediate run that is relevant for setting monetary policy--a period of several years, when cyclical forces dominate. Critically, such deviations in the intermediate run can be especially important for policy choice. For example, an unusual hesitancy on the part of businesses to hire and spend emerged in 2001 after the collapse of equity prices and was subsequently reinforced by corporate-governance concerns; this hesitancy could be thought of as pulling the equilibrium real federal funds rate down temporarily below its longer-run value. In addition, other forces may also have weighed on growth, making it appropriate to move the real funds rate below the intermediate-run equilibrium for a time. From that perspective, the FOMC's reduction in the actual nominal federal funds rate over this period from the level of 6-1/2 percent that prevailed at the beginning of 2001 to the forty-five-year low of 1 percent by mid-2003 had three components: (1) A reduction to match the decline in inflation expectations so as to prevent the real funds rate from rising inappropriately, (2) an effort to chase a downwardly moving equilibrium real rate given the pressures on aggregate demand, and (3) an effort to bring the actual real rate below its apparently lowered equilibrium to provide sufficient stimulus to cope with transitory adverse factors and to speed the recovery in production and employment. So while the real federal funds rate ultimately was pushed below zero, the extent of policy accommodation was less exceptional, in that many estimates of the equilibrium real rate had also fallen significantly. This is a tangible recent example of the need both to judge how the equilibrium real interest rate that is relevant for policy might have changed from a perceived long-run level and to set policy against the background of such an understanding. Indeed, in my judgment, the lingering hesitancy of businesses to make commitments, the restraint imposed on domestic consumers from an increase in the cost of energy, and the drag on domestic production from the excess of imports over exports all represent forces pulling the equilibrium real federal funds rate below its perceived longer-term level. And, in the context of well-contained inflation, the evidence of remaining underused resources gives us a good reason to hold the real rate below even the intermediate-run notion of its equilibrium to allow the economy to be firmly set on a path that will shrink the pool of these underused resources over a reasonable period. But as the expansion regains its footing and resource slack is worked down, we should expect both that the equilibrium real rate will move toward its longer-run level and that policymakers will no longer find it appropriate to keep the actual rate below its equilibrium. That is, the FOMC will likely be removing its policy accommodation over time. The Pace of Return to Equilibrium I have thus far argued that the equilibrium rate that is relevant for actual policy determination can only be judged in the context of forces influencing economic developments. Several aspects of the current outlook lead me to suspect that the return of the equilibrium real rate from its currently somewhat depressed level to its long-run value might plausibly be expected to be gradual and attenuated compared with historical experience. Let me highlight just three of these aspects. I have already mentioned the role of business hesitancy in determining the past trajectory of monetary policy. Clearly, if evidence of that hesitancy remains--for example, if the labor market were to remain sluggish--that might be one indication that the return of the equilibrium rate to its longer-run level is likely to be relatively gradual. Secondly, the household saving rate has fallen to less than 1 percent, quite low in its range of historical variation. If households, on net, take steps to return the saving rate closer to the middle of that range (which, I might add, would provide welcome support to capital accumulation), then a sustained period in which consumption grows more slowly than income would result. Third, given government budgetary trends, some fiscal restraint is in order, and one might expect that those responsible for fiscal policy will move that policy to a more-balanced position (another development I would welcome), thereby removing some fiscal impetus. I believe that the combined force of these three factors restraining aggregate demand, plus others that I have not mentioned, would require a lower real rate than otherwise to avoid economic slack. Let me add, however, that there is a powerful force tending to make the equilibrium real rate higher than it would otherwise be. The rapid expansion of labor productivity has raised the growth of economic potential, increased permanent income and wealth, and created an important inducement to add to the capital stock. All else equal, a higher growth rate of productivity will be associated with a more elevated equilibrium real rate. As long as productivity grows steadily at its recent pace, however, there is no reason to suspect that it will produce a change in the equilibrium real rate. In addition, the factors that I mentioned above might not unfold as hypothesized. Business hesitancy might lift abruptly and would be evidenced by large increases in business demand for capital and labor resources; households might maintain a very low savings rate; and government policy might not return quickly to a more-balanced posture. Any of these factors might imply that the equilibrium rate relevant for policy returns more quickly to, or even moves above, its long-run level as fewer forces weigh on aggregate demand. Recognizing the uncertainty regarding these various forces and the interplay among them, I believe it important that the FOMC calibrate the return of policy to the equilibrium real rate so that the process is neither hasty nor overly attenuated. Clearly, incoming data and the implications for the outlook should play a particularly important role in policy determination at this juncture. However, theory and practice both indicate that policy works with long and variable lags. Therefore, the actual stance of policy will have to approximate more closely the equilibrium real rate before the pool of underutilized resources is fully exhausted. Otherwise, we risk a buildup of inflationary pressures. Clearly the execution of policy will require careful evaluation as the FOMC attempts to judge both the equilibrium rate that is relevant and the pace of removal of accommodation that is appropriate. Estimating the Equilibrium Rate in Practice So much for the generality of theory. Economists have taken a variety of tacks to arrive at measures of the equilibrium real federal funds rate. I will touch on two techniques in particular. The first can be thought of as a mechanical attempt to implement my definition--the level of the real federal funds rate that, if allowed to prevail for a couple of years, would place economic activity at its potential--in models of the U.S. economy. For instance, we can use the many equations of a large-scale macroeconomic representation of the U.S. economy, such as the Federal Reserve Board's staff model, FRB/US, to calculate at any point in time the level of the real rate that would eliminate economic slack in a reasonable period of time. Or we can rely on a reduced-form description of the economy that measures the output gap in terms of the actual real short rate. The value of the real rate that will move that gap to zero can be thought of as the equilibrium real rate. Besides the assumptions undergirding the construction of either model, such a calculation will require judgment in determining what is a "reasonable" period of time and how to cope with the run of prediction errors that are inevitable when trying to explain economic data. An attempt to employ a large model to calculate the equilibrium nominal federal funds rate can be found in an article by Antulio Bomfim. Using the MPS model, the predecessor to the Board staff's current model, Bomfim found that the equilibrium nominal funds rate varied in a range from 2 percent to 14 percent over the period from 1965 to 1994, implying that his estimate of the equilibrium real rate turned negative at times. Laubach and Williams opted for the single-equation approach and estimated that the equilibrium real funds rate was around 3 percent in mid-2002 but that it varied from as low as 1 percent in the early 1990s to as high as 5 percent in the late 1960s. In addition to exhibiting large swings, the Laubach-Williams point estimate of the equilibrium rate is a very uncertain statistic. The confidence interval around the estimate is such that there was a 70 percent probability that the actual value of the equilibrium real rate was between 0.5 percent and 5.5 percent. Clearly, this estimate is not measured sufficiently precisely to be a useful guide to policy. An alternative approach turns to financial markets to infer the market's assessment of the longer-term prospects for real interest rates. Since 1997, the U.S. Treasury has been issuing price-index-linked securities providing an assured real return. With about $250 billion of these inflation-protected securities now outstanding, we can get readings along the entire maturity structure of real interest rates. Currently, for instance, real short yields are close to zero, and longer-term rates are at about 1-5/8 percent. One could presume that the forward real rate of interest implied by yields on longer-term indexed debt--or the real return provided, say, over the period five to ten years from now--conveys a sense of market participants' view of the long-run equilibrium real interest rate. Unfortunately for such an inference, however, longer-term yields embody expectations of future interest rates, a term premium, and potentially a premium for the relative illiquidity of these instruments, so this technique will provide an overestimate of the equilibrium real rate. Conclusion This brief discussion highlights the uncertainties attending any attempt to measure the equilibrium real rate. I find these measures useful teaching tools to describe the complicated and iterative process of forecasting the path of the economy so as to arrive at the appropriate stance of policy. However, I believe it to be very important that the FOMC not go on a forced march to some point estimate of the equilibrium real federal funds rate. In my judgment, we should remove the current degree of accommodation at a pace that is importantly determined by incoming data and a changed outlook. Our knowledge of the workings of the economy is sufficiently imprecise that we could not attach much confidence to any single calculation that one might make of the equilibrium rate. Moreover, history provides a daunting record of challenges to economic forecasting associated with changes in economic behavior, the evolution of technology, and swings in governmental policy that would suggest that the equilibrium can vary over time. In such circumstances, the performance of the economy will provide feedback to assess the level of the equilibrium real federal funds rate over time. Footnotes Antulio Bomfim (1997), "The Equilibrium Fed Funds Rate and the Indicator Properties of Term-Structure Spreads," Economic Inquiry , 54(4), pp. 830-46. Thomas Laubach and John C. Williams (2003), "Measuring the Natural Rate of Interest," Review of Economic Statistics , 85(4), pp. 1063-70. See, for instance, Antulio Bomfim (2001), Finance and Economics Discussion Series 2001-53 (Washington: Board of Governors of the Federal Reserve System).