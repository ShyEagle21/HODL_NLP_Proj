Board of Governors of the Federal Reserve SystemFederal Deposit Insurance Corporation The Federal Reserve Board (Board) and the Federal Deposit Insurance Corporation (FDIC) on Monday announced the release of additional guidance, clarification and direction for the first group of institutions filing their resolutions plans pursuant to the Dodd-Frank Act. These 11 institutions filed their initial resolution plans with the Federal Reserve Board and the FDIC in 2012. Plans were required generally from U.S. bank holding companies with $250 billion or more in total nonbank assets and foreign-based bank holding companies with $250 billion or more in total U.S. nonbank assets. Following review of the initial resolution plans, the agencies have developed instructions for the firms to detail what information should be included in their 2013 resolution plan submissions. In particular, the revised instructions include requests for more detailed information on, and analysis of, obstacles to resolvability under the Bankruptcy Code including global issues, financial market utility interconnections, and funding and liquidity, as well as to provide analysis to support the strategies and assumptions contained in the firms' resolution plans. The Board and the FDIC have also granted an extension to the filing date to give the firms additional time to develop resolution plan submissions that address the agencies' instructions. Accordingly, the 2013 resolution plan filing deadline will move from July 1, 2013, to October 1, 2013. The extension does not affect resolution plan submission dates for other banking organizations. The agencies expect that the submission of increasingly comprehensive resolution plans will facilitate a more robust and effective resolution planning process. As in 2012, the Board and the FDIC will post the public sections of the resolution plans to their websites. The additional guidance can be found on the Board website at: Guidance for 2013§165(d) Annual Resolution Plan Submissions by Domestic Covered Companies that Submitted Initial Resolution Plans in 2012 (PDF)Guidance for 2013§165(d) Annual Resolution Plan Submissions by Foreign-Based Covered Companies that Submitted Initial Resolution Plans in 2012 (PDF)
Scott G. Alvarez, General Counsel Before the Committee on Financial Services, Subcommittee on Oversight and Investigations, U.S. House of Representatives, Washington, D.C. Chairman McHenry, Ranking Member Green, and other members of the Subcommittee, thank you for the opportunity to testify on the provisions of the Dodd-Frank Wall Street Reform and Consumer Protection Act (the Dodd-Frank Act) designed to address the increased risks posed by systemically important financial institutions and to ensure that no institution is "too-big-to-fail". The perception that some institutions are too-big-to-fail reduces the incentives of shareholders, creditors, and counterparties of these firms to constrain excessive risk-taking. It also produces competitive distortions by enabling firms perceived as too-big-to-fail to fund themselves more cheaply than other firms. This competitive distortion is not only unfair to smaller firms and damaging to competition, but it also spurs further growth by the largest firms and more consolidation and concentration in the financial industry. The Dodd-Frank Act contains a number of provisions that specifically address the risks posed by systemically important financial institutions. The Federal Reserve has been actively engaged in implementing these provisions. Our goal--working with other U.S. regulators and our counterparts around the world--is to produce a well-integrated set of rules and supervisory practices that substantially reduces the probability of failure of our largest, most complex financial firms and that minimizes the losses to the financial system and the economy if such a firm should fail. These steps also force large firms to internalize the costs that their failure would impose on the broader financial system, minimize the advantage these firms enjoy due to market perceptions of their systemic importance, and give the firms regulatory incentives to reduce their systemic footprint. The Federal Reserve has been working intensively for the past few years to accomplish this goal through both rulemakings and firm-by-firm supervisory efforts. Because the Federal Reserve is primarily responsible for the supervision and regulation of banks and bank holding companies, my testimony today will focus on the steps we are taking to address too-big-to-fail in the context of banking organizations. However, it is important to note that concepts like "too-big-to-fail" can also apply to nonbank financial companies. Individual nonbank financial companies posed clear risks to financial stability during the 2007â09 crisis. In these sorts of cases, the authority of the Financial Stability Oversight Council (the Council) to designate systemically important nonbank financial companies or financial activities provides another valuable tool. Moreover, the Dodd-Frank Act contains provisions designed to facilitate the orderly resolution of systemically important financial institutions. The ability to resolve a firm that is failing--regardless of size or systemic importance--is critical to making clear that no firm is too-big-to-fail. Reducing the Probability of Failure of Systemic FirmsStrong capital requirements are the cornerstone of prudential bank regulation because capital provides a buffer against losses from any source or activity. A critical way to reduce the distortions associated with too-big-to-fail is for our most systemic banking firms to have substantial capital buffers, sized to reflect their own risk profiles and the damage that would be done to the financial system were such firms to fail. Achievement of this aim requires both improvement of the traditional, firm-based approach to capital regulation, and the development of a macroprudential overlay to ensure that capital requirements applicable to the most systemic banking firms are more stringent than the requirements that apply to other firms. With respect to the traditional, firm-based approach, the Basel Committee on Banking Supervision (the Basel Committee) issued in December 2010 the Basel III package of reforms to its framework for minimum bank capital requirements, supplementing an earlier set of changes that increased capital requirements for important classes of trading assets. Last year, the Federal Reserve and the other U.S. banking agencies issued for comment a set of proposals to implement the Basel III capital standards in the United States. To help ensure that all U.S. banking firms maintain strong capital positions, the Basel III proposals would introduce a new common equity capital requirement, raise the existing tier 1 capital minimum requirement, implement a capital conservation buffer on top of the regulatory minimums, and introduce a more risk-sensitive standardized approach for calculating risk-weighted assets. Large, internationally active banking firms would also be subject to a supplementary leverage ratio and a countercyclical capital buffer, and would face higher capital requirements for derivatives and certain other capital markets exposures they hold. The U.S. banking agencies are reviewing comments on this proposal and working toward a final rule now. We are specifically focused on addressing comments that urge the agencies to reduce the burden of the proposal on community banks. In addition to this baseline approach to capital, the Federal Reserve has undertaken several initiatives to enhance the capital protection at large firms. In particular, the Federal Reserve conducts an annual supervisory stress test and Comprehensive Capital Analysis and Review (CCAR) for the largest U.S. bank holding companies. In CCAR, the Federal Reserve requires each covered firm to demonstrate that it has rigorous, forward-looking capital planning processes that effectively account for the unique risks of the firm, and maintains sufficient capital to continue to operate through times of extreme economic and financial stress. In the 2012 and 2013 CCAR exercises, the Federal Reserve applied a separate global market shock to the trading books of the six largest U.S. bank holding companies, effectively increasing the amount of capital those firms are required to hold against their trading portfolios. The 2013 CCAR exercise revealed that the aggregate tier 1 common equity ratio--which is the strongest form of loss-absorbing capital--at the 18 firms covered by this stress test has more than doubled, from 5.6 percent at the end of 2008 to 11.3 percent at the end of 2012. That reflects an increase of about $400 billion in tier 1 common equity at these firms since the crisis. The Federal Reserve is also working under section 165 of the Dodd-Frank Act to implement enhanced risk-based capital standards for large bank holding companies that would increase in stringency based on the relative systemic footprint of those companies. Consistent with this requirement, the Federal Reserve advanced proposals in the Basel Committee for substantial capital surcharges on the world's largest, most interconnected banking organizations. In December 2011, the Basel Committee reached an agreement on a global framework for such surcharges, and the Federal Reserve will be making forthcoming proposals to implement the capital surcharge framework for systemic U.S. bank holding companies. In recognition of the fact that illiquidity at some financial firms played a key role in the financial crisis, the Basel III agreements also introduced for the first time quantitative liquidity requirements for large, internationally active banking firms. One standard, the Liquidity Coverage Ratio (LCR), is designed to help ensure a banking firm's ability to withstand short-term liquidity shocks through adequate holdings of high quality, liquid assets. The other standard, the Net Stable Funding Ratio, is intended to complement the LCR by preventing significant maturity mismatches over longer-term horizons. As with capital, section 165 of the Dodd-Frank Act calls for enhanced, graduated liquidity standards for the largest bank holding companies. The Federal Reserve has already proposed a set of stricter qualitative liquidity standards pursuant to section 165, and we intend to issue a U.S. proposal to implement the LCR later this year. In addition to the enhanced capital and liquidity regulations for large bank holding companies as described earlier, the Dodd-Frank Act requires the Board to apply single-counterparty credit limits, risk management and risk committee requirements, and an early remediation framework to large bank holding companies. The Board has issued proposals to implement each of these standards for both large domestic bank holding companies and for large foreign banks operating in the United States. These standards represent a core part of the new regulatory framework for mitigating risk posed by systemically important financial firms and for offsetting benefits these firms may gain from being perceived as too-big-to-fail. Improving Resolvability of Systemic FirmsAn important goal of post-crisis financial reform has been to counter too-big-to-fail by reducing the potential damage to the financial system and the economy from the failure of a major financial firm. To this end, the Dodd-Frank Act created the Orderly Liquidation Authority (OLA), a mechanism designed to improve prospects for an orderly resolution of a systemic financial firm. Since the passage of the Dodd-Frank Act, the Federal Deposit Insurance Corporation (FDIC) has developed a single-point-of-entry preferred resolution strategy under OLA that is intended to effect a creditor-funded holding company recapitalization of the failed financial firm. Key to the ability of the FDIC to execute this approach is the availability of sufficient amounts of unsecured long-term debt at the parent holding company of the failed firm. The Federal Reserve has been working with the FDIC, both as the FDIC develops its OLA framework, and to consider the merits of a regulatory requirement that the largest, most complex U.S. banking firms maintain a minimum amount of parent-level, long-term unsecured debt that would ultimately facilitate a single-point-of-entry approach to OLA. Parent-level, long-term debt could lend greater confidence that the combination of equity owners and long-term debt holders would be sufficient to bear all losses at the consolidated firm, thereby allowing a more orderly resolution of large, complex firms, and counteract the moral hazard associated with the perception that large firms are too-big-to-fail. The Dodd-Frank Act also required all large bank holding companies to develop, and submit to supervisors, resolution plans. The Federal Reserve has been working with the FDIC to review resolution plans submitted by the largest U.S. bank holding companies and foreign banks. The largest banking firms submitted their first annual resolution plans to the Federal Reserve and the FDIC in the summer. The initial round has yielded valuable information that is being used to identify, assess, and mitigate key challenges to resolvability under the Bankruptcy Code (Title I plans) and to support development of backup resolution plans under OLA (Title II plans). We believe that, over time, these resolution plans will help firms and the supervisors identify and address structural and other issues that could be impediments to the orderly resolution of the firms. Limitations on the Size and Activities of FirmsThe Dodd-Frank Act also contains several provisions that limit the size and growth of financial firms. For example, sections 163 and 604 of the Dodd-Frank Act require various types of large financial firms to obtain regulatory approval before growing through a merger or acquisition. In each of these cases, the reviewing agency must consider the risk of the transaction to the stability of the United States banking or financial system. In addition, section 622 prohibits a firm from growing through acquisition, with very limited exceptions once the firm reaches a specified size. Finally, section 121 of the Dodd-Frank Act authorizes the Federal Reserve, with the consent of two-thirds of the voting members of the Council, to impose a variety of restrictions on large bank holding companies and designated nonbank financial companies if the Board finds that the firm poses a grave threat to the financial stability of the United States. These restrictions include limiting the ability of the company to grow through mergers or acquisitions, requiring the termination of any activity, and imposing conditions on the manner in which the company conducts its activities. In the event that the Federal Reserve determines that these types of actions are inadequate to mitigate the threat the firm poses to the financial stability of the United States, the firm may be required to sell assets. ConclusionThe Federal Reserve has made significant progress in the past few years toward the goals of making all firms, including large, systemically important firms, more resistant to failure and ensuring that no firm is too-big-to-fail, but more work remains to be done. Thank you for your attention. I would be pleased to answer any questions you might have.
Richard M. Ashton, Deputy General Counsel Before the Subcommittee on Financial Institutions and Consumer Protection, Committee on Banking, Housing, and Urban Affairs, U.S. Senate, Washington, D.C. Chairman Brown, Ranking Member Toomey, and members of the subcommittee, thank you for the opportunity to testify regarding the required use of third-party consulting firms (consultants) in Federal Reserve enforcement actions. Use of Consultants by Regulated Banking OrganizationsAt the outset, it might be helpful to point out that regulated banking organizations routinely choose to retain consultants for a variety of purposes apart from any supervisory directive by regulators to do so. Banking organizations decide to retain consultants because these firms can provide specialized expertise, familiarity with industry best practices, a more objective perspective, and staffing resources that the regulated organizations do not have internally. In this respect, reliance on consultants can significantly contribute to the overall efficient governance and management of these organizations as well as to their safe and sound operation and their compliance with supervisory expectations and legal requirements. Use of Consultants in Federal Reserve Enforcement ActionsIn the vast majority of Federal Reserve enforcement actions, the organization itself, using its own personnel and resources, is directed to take the necessary corrective and remedial action. In appropriate circumstances, the Federal Reserve has found that it can be an effective enforcement tool to require regulated organizations to retain a consultant to perform specific tasks on behalf of that organization. However, the mandatory use of a consultant has typically not been a frequent requirement in Federal Reserve enforcement actions. And, importantly, consultants are used to conduct work that ordinarily the organization itself would be required to conduct. At all times, the Federal Reserve retains authority to, and does, review and supervise the consultant's work in the same manner as if the institution conducted the work directly. In all cases, the regulated organization is itself ultimately responsible for its own safe and sound operations and compliance with legal requirements. As a general rule, our enforcement actions require the use of consultants to perform specific functions that the organization involved should do but has shown that it cannot perform itself. This may be because a particular organization lacks the necessary specialized knowledge or experience. Similarly, the organization may not have sufficient staffing resources internally. In addition, it may be necessary to have a third party undertake a particular project because a more objective viewpoint is required than would be provided by the organization's management.Over the last 10 years, for instance, there were consultant requirements in an average of less than 15 percent of all formal enforcement actions taken by the agency. In addition to formal enforcement actions, Federal Reserve examiners may informally direct organizations to retain consultants to undertake designated engagements on behalf of the organization where circumstances warrant. In our enforcement actions, we required the use of consulting firms to perform several limited, specialized types of work. In many of these enforcement actions, an expert third party must be retained to review and submit a report on a specific area of the organization's operations. These mandated reviews by consultants have often involved an evaluation of an organization's compliance program, its accounting practices, or its staffing needs and the qualifications and performance of senior management. These enforcement directives usually require the organization to incorporate the findings of the report into a plan to improve that particular area of operations. Federal Reserve regulators may also use the product of a consultant's work as a guide in developing the ongoing supervision of the organization. Another type of enforcement action where use of consultants has been required involves situations where examiners have found serious past deficiencies in an organization's systems for monitoring compliance with Bank Secrecy Act and anti-money laundering (BSA/AML) requirements. In these cases, our actions have required a consultant retained by the organization to review certain kinds of transactions that occurred at the organization over a specific past period of time and determine whether BSA/AML reports were filed as required with regard to those transactions. These reviews require the consultant to identify situations where a suspicious activity report or a currency transaction report should have been filed, rather than to perform an assessment of the organization's compliance program. After receiving the results of the consultant's review, the organization would then file all the required reports with the appropriate government agencies. Finally, in several recent enforcement actions that required organizations to identify and then compensate or otherwise remediate injured consumers, the organizations have been required to retain consultants to administer that process. In these actions, the consultants were required to make recommendations about the appropriate remediation to individual consumers or to make remediation decisions about individual consumers or review the organization's remediation decisions. Federal Reserve Oversight of Consultant PerformanceWhen enforcement actions require a regulated banking organization to use a consultant to carry out a particular function, the Federal Reserve oversees the organization's implementation of this directive. Our standard practice is to require the organization's retention of a consulting firm to be first approved by the Federal Reserve. We typically look at the particular expertise and experience of the selected consultant. The resources and capacity of the firm to carry out the particular engagement are also examined. Whether the consultant has the appropriate objectivity and separation from management is also a key factor in assessing the acceptability of the firm. To assess objectivity, we examine the extent and type of work that the consultant has done for the organization in the past. One guiding principle is that a consulting firm should not be allowed to review or evaluate work that it has previously done for the organization. How these factors are evaluated is necessarily determined on a case-by-case basis, depending on the specific type of task the consultant is being required to perform. However, the approval of particular consultants is not perfunctory; where warranted we have disapproved a consultant that has been selected by an organization under an enforcement order requirement. Additionally, our general practice is to explicitly require that the letter between the organization and the consulting firm or other documentation that describes the scope, terms, and conditions of the particular engagement be approved by the Federal Reserve. Thus, we are able to assess whether the consultant's planned work will be consistent with what was intended in the enforcement action and whether effective safeguards of objectivity will be maintained. We also oversee the consultant's performance during the course of the engagement. This oversight can involve obtaining and reviewing interim progress reports from the consultant. We also can call for periodic meetings with consultant personnel, which can be as frequently as every week. If a consultant is not meeting the required standards of performance, we will inform the organization of the needed improvements, applying the same criteria as if the organization was performing the work with its own personnel. In sum, it is important to note that consultants retained under Federal Reserve enforcement actions work for the organization that retained them, and the organization, not the consultant, is responsible for correcting the deficiencies that triggered issuance of the enforcement action and for preventing their reoccurrence. Requiring the use of consultants to assist in implementing corrective and remedial measures is just one tool available to Federal Reserve regulators in fashioning formal enforcement actions. Our experience has shown that consultants can be expected to provide the expertise, experience, and third-party perspective needed by the regulated banking organization to better meet supervisory objectives, including assisting the regulated organizations with correcting particular governance or operational deficiencies identified through the supervisory process. However, in deciding to use this tool in appropriate cases, the Federal Reserve does not cede its regulatory responsibilities or judgment to those consultants. We require that regulated organizations comply with the same basic standards of prudent practices and compliance with applicable laws and regulations, irrespective of whether an organization has relied on the assistance of a consultant or not. Use of Independent Consultants in the Independent Foreclosure ReviewAlthough it is not the specific subject of this hearing, it might be helpful to note briefly the independent foreclosure reviews required by the consent orders issued by the Office of the Comptroller of the Currency and the Federal Reserve against major mortgage servicing firms, and the role of the independent consultants required under those orders.1In those mortgage servicing orders, the servicers were required to retain independent consultants to review foreclosure files of borrowers within a two-year period to identify financial injury caused by servicer error. Recently, the regulators and 13 of the servicers subject to the foreclosure orders entered into agreements under which these servicers must make cash payments to borrowers and provide other borrower assistance. These payments and other assistance replace the independent foreclosure review by independent consultants that had been required of these servicers under the initial orders. As we have explained, the regulators accepted these agreements with the 13 servicers because the agreements provided the greatest benefit to borrowers potentially subjected to unsafe and unsound mortgage-servicing and foreclosure practices in a more timely manner than would have occurred under the review process. In practice, for these servicers, the scope of the inquiry required of the consultants to conduct the independent foreclosure review proved over time to be more expansive, time-consuming, and labor-intensive than what is typically required of consultants in Federal Reserve enforcement actions. The result was significant delays in providing funds to consumers. Accordingly, the decision to replace the review of individual foreclosure files by the consultants with agreements to pay cash and provide other assistance to borrowers was based on the specialized and unprecedented nature of the particular reviews the consultants were required to undertake. Thank you again for the invitation to appear before the subcommittee today. I would be pleased to answer any questions you might have. 1.Of the 16 servicing organizations subject to enforcement actions requiring independent foreclosure reviews, 10 are regulated by the Office of the Comptroller of the Currency, four are regulated by the Federal Reserve, and two organizations are regulated by both agencies.Return to text
Governor Sarah Bloom Raskin At the "Building a Financial Structure for a More Stable and Equitable Economy" 22nd Annual Hyman P. Minsky Conference on the State of the U.S. and World Economies, New York, New York Thank you for asking me to join you today at this conference and to be a part of your continuing inquiry into how the ideas and legacy of Hyman Minsky can inform and shape our understanding of financial markets and the economy. This speech expands on remarks I made in March to the National Community Reinvestment Coalition, in which I explored the roles that monetary and bank regulatory policy play in reducing the unemployment, economic marginalization, and financial vulnerability of millions of moderate- and low-income working Americans. Today I am interested in continuing this exploration by examining an issue of growing saliency that macroeconomic models used at central banks and by academics have not traditionally emphasized--specifically, how such economic marginalization and financial vulnerability, associated with stagnant wages and rising inequality, contributed to the run-up to the financial crisis and how such marginalization and vulnerability could be relevant in the current recovery. To isolate my proper subject here, I want to be clear that I am not engaging this afternoon with the concern that many Americans have that excessive inequality undermines American ideals and values. Nor will I be investigating the social costs associated with wide distributions of income and wealth. Rather, I want to zero in on the question of whether inequality itself is undermining our country's economic strength according to available macroeconomic indicators. Economists have documented that widening income and wealth inequality has been one of the most notable structural changes to the U.S. economy since the late 1970s. This change represents a dramatic departure from the three decades prior to that time, when Americans enjoyed broadly rising incomes and shared prosperity. Indeed, many of you in the room have shed important light on the recent trends in inequality and on the potential role of fiscal policy in addressing them. You have also explored how these trends are relevant to issues of financial stability. I won't attempt to repeat this strong line of research and analysis. Instead, my remarks today are specifically focused on adding to the conversation about how such disparities in income and wealth could be relevant for a macro understanding of the financial crisis and the recovery and the appropriate course of monetary policy today. I will argue that at the start of this recession, an unusually large number of low- and middle-income households were vulnerable to exactly the types of shocks that sparked the financial crisis. These households, which had endured 30 years of very sluggish real-wage growth, held an unusually large share of their wealth in housing, much of it financed with debt. As a result, over time, their exposure to house prices had increased dramatically. Thus, as in past recessions, suffering in the Great Recession--though widespread--was most painful and most perilous for low- and middle-income households, which were also more likely to be affected by job loss and had little wealth to fall back on. Moreover, I am persuaded that because of how hard these lower- and middle-income households were hit, the recession was worse and the recovery has been weaker. The recovery has also been hampered by a continuation of longer-term trends that have reduced employment prospects for those at the lower end of the income distribution and produced weak wage growth. Of course, it is not part of the Federal Reserve's mandate to address inequality directly, but I want to explore these issues today because the answers may have implications for the Federal Reserve's efforts to understand the recession and conduct policy in a way that contributes to a stronger pace of recovery. Traditionally, the distribution of wealth and income has not been a primary consideration in the way most macroeconomists think about business cycles. But if inequality played a role in the financial crisis, if it contributed to the severity of the recession, and if its effects create a lingering economic headwind today, then perhaps our thinking, and our macroeconomic models, should be adjusted. Despite the tentative nature of these conclusions, I do think it is vital to explore these issues, and, in the spirit of Minsky, I hope my remarks spur more inquiry and discussion. I should also note that the views I express are my own and not necessarily those of my colleagues on the Board of Governors or the Federal Open Market Committee (FOMC). Trends in Income, Wealth, and DebtIn order to "level set" our understanding, let me begin by reviewing some of the changes to the structure of income, wealth, and debt in the years leading up to the Great Recession--changes that have had significant implications for the well-being of most American households. Long before the recession--decades before, in fact--income data show only sluggish increases in real incomes for low- and middle-income American households, and more-rapid increases for high-income households, resulting in a much greater concentration of income among those at the very top of the income distribution. As just one example of the broader trend, according to the Congressional Budget Office, between 1979 and 2007, inflation-adjusted, pretax income for a household in the top 1 percent more than doubled, while, in contrast, income for a household in the middle of the income distribution increased less than 20 percent.1Over these years, the share of pretax income accruing to the top 1 percent of households also doubled, from 10 percent to 20 percent, while the share accruing to the bottom 40 percent fell from 13 percent to 10 percent. These growing disparities of total income are largely due to the increasing concentration of labor income, which, on average, accounted for more than 70 percent of all income over this period. In addition, the distribution of other sources of total income‑‑such as profits from small businesses, capital gains and dividend income, rental income, and the like--also became more concentrated over this period. Many have argued that these disparities in income are hindering economic growth through their effects on consumption. Intuitively, one might assume that the growing concentration of income at the top could lead to less consumer spending and aggregate demand, as wealthier households tend to save more of their additional income than others. However, there is no definitive research indicating that these income disparities show mixed results on the question of whether there are stable differences in the marginal propensity to consume across households with different incomes.2More generally, the evidence is equivocal as to whether there is an empirical relationship between higher income inequality and reduced aggregate demand. In my view, understanding the links between greater concentrations of income, variation in spending patterns throughout the income distribution, and the effect of that variation on aggregate consumption--and, ultimately, growth--requires more exploration.3 But since household behavior is surely driven by more than the size of the paycheck coming in the proverbial front door, the distribution of wealth--as distinct from the distribution of income--could have clearer implications for the macroeconomy. Indeed, wealth inequality is greater than income inequality in the United States, although it has widened little in recent decades. For example, according to the Survey of Consumer Finances (SCF), a survey conducted every three years by the Federal Reserve Board, the top one-fifth of families ranked by income owned 72 percent of the total wealth in the economy in 2010, whereas families in the bottom one-fifth of the income distribution together owned only 3 percent of total wealth in 2010.4 Hence, families with more-modest incomes have much less wealth to cushion themselves against income shocks, such as unemployment. For example, in 2010, the median value of financial assets was less than $1,000 for families in the lowest income quintile. Moreover, what wealth low- and middle-income families do have is typically concentrated in housing. For families in the top quintile of income, the value of residential properties accounted for about 15 percent of total wealth in 2010. For families in the middle and lower half of the income distribution, the ratio of their home values to total net worth was near 70 percent. In contrast, stock market wealth (and the value of other securities) constitutes a very small share of wealth for low- and middle-income families. Because the wealth of people at the lower end of the distribution is concentrated in housing, these households are disproportionately exposed to swings in house prices. This compositional effect was intensified during the housing boom, as the share of wealth accounted for by housing grew even faster for low- and middle-income families than for high-income families. That said, the increases in homeownership and house values during the boom were largely financed by rising mortgage debt. Thus, the direct positive effect ofrisinghouse prices on most households' net worth was largely offset by the negative effect of increased debt that households took on. On net, mortgage debt and home values moved up together. But when house prices beganfalling, the mortgage debt and repayment obligations remained. To be sure, the increase in mortgage debt prior to the recession occurred across all types of households. But it was families with modest incomes and wealth largely in their homes that were the most vulnerable to subsequent drops in home values. The question then arises as to why households with poor income prospects sought out levels of mortgage debt that would ultimately prove so problematic. Putting aside the practice, in the run-up to the crisis, of lenders steering households to mortgage debt products that were more costly than what such households may have otherwise qualified for, one reason may have been that many households in the middle and lower end of the income distribution, whose wage earnings were stagnant, did not recognize the long-run and persistent trends underlying their lack of income growth.5If households thought they were merely going through a rough patch, it would have been quite reasonable for them to borrow money to smooth through it--to make home improvements, for example, or to send a child to college.6At the same time, many people believed that the sharp increases in their home values had made them permanently richer and that house prices would never turn down, a belief that appears to have been shared by many households in the upper part of the income distribution as well. In fact, purchasing a house using debt was a profitable investment in the early 2000s. While it is hard to know with any certainty what these individual households believed at the time, it seems quite plausible to me, as others have argued, that stagnant wages and rising inequality, in combination with the relaxation of underwriting standards, led to an increase in the use of credit unsupported by greater income.7 Inequality and the Great RecessionGiven these developments, when house prices fell, household finances were struck a devastating blow. The resulting fallout magnified this initial shock, ushering in the Great Recession. Let me lay out this argument in more detail. As I mentioned earlier, low- to middle-income families held a disproportionate share of their assets in housing prior to the financial crisis and hence were very exposed to what was a historic decline in house prices. And so, while total household net worth fell 15 percent in real terms between 2007 and 2010, median net worth fell almost 40 percent. This difference reflects the amplified effect that housing had on wealth changes in the middle of the wealth distribution. The unexpected drop in house prices on its own reduced both households' wealth and their access to credit, likely leading them to pull back their spending. In particular, underwater borrowers and heavily indebted households were left with little collateral, which limited their access to additional credit and their ability to refinance at lower interest rates. Indeed, some studies have shown that spending has declined more for indebted households.8 Compounding the effect of falling house prices on household wealth and credit was the fact that these low- to middle-income households are also composed of some of the groups that have historically borne the brunt of downturns in the labor market. During recessions, the young, the less educated, and minorities are more likely to experience flat or declining wages, reduced hours, and unemployment.9While this disparity is not a new phenomenon, dealing with a loss in labor income during the most recent recession was a heightened challenge to households that had mortgage obligations and no other forms of wealth to cushion the blow. The adverse developments in the labor market added to the difficulty most households were having in repaying their existing debts and in accessing credit in the recession. These low- to middle-income households that bore the strains in both housing and labor markets, and had little wealth cushion, had more difficulty making payments on their mortgages and other consumer credit debt. For example, among the mortgages originated from 2004 to 2008, almost 25 percent of those in low-income neighborhoods were foreclosed on or in serious delinquency as of 2011, more than twice the rate of mortgages originated in higher-income neighborhoods. Higher-income households had also taken on debt and were affected by declines in asset prices. But these households entered the recession with a larger wealth buffer and higher incomes, so they generally were still able to service their debts. The sharp rise in defaults and delinquencies put extraordinary stress on most households' finances, intensified the financial crisis, and exacerbated the effect of the initial economic shocks. Indeed, a rapid downward spiral of tighter credit, declines in asset prices, rising unemployment, and falling demand caused severe distress and a pullback in spending that was ultimately widespread across households. Inequality and the RecoveryI have argued that rising inequality and stagnating wages may have led households to borrow more and to pin their hopes for economic advancement on rising home values, developments that exacerbated the severity of the financial crisis and recession. Now we are nearly four years into the recovery, which has been weak. In my view, this same confluence of factors has also contributed to the tepid recovery. If my theory about why households overextended themselves before the financial crisis is correct, then it is likely also true that households have had a rude awakening in the years since. Not only did they receive an unwelcome shock to their net current wealth, but they also undoubtedly have come to realize that house prices will not rise indefinitely and that their labor income prospects are less rosy than they had believed. As a result, they are curtailing their spending in an effort to rebuild their nest eggs and may also be trimming their budgets in order to bring their debt levels into alignment with their new economic realities. In this case, the effects of the plunge in net wealth and the jump in unemployment on subsequent spending have been long lasting and lingering. Overall debt levels remain higher than before the house price boom, and many families continue to struggle to keep up with their monthly payments. Although many households have significantly reduced their debt levels, many others probably have far to go.10It is hard to know just what the optimal debt-to-income ratio is, but, in my view, households will likely aim for something lower than before the financial crisis: Households are probably working toward lower, more-manageable debt service obligations; the heightened uncertainty in the recession may have raised the desired level of financial buffers; and, to the extent that households saw the negative shocks to house prices and income as permanent, they are reducing their spending and thus their demand for new borrowing. While the process of household deleveraging has affected the spending and borrowing of many households, there is no doubt that the process has been more acute for those that have experienced unemployment, underemployment, or slower wage gains. To make matters worse, there is also some evidence to suggest that the factors that contributed to the rise in inequality and the stagnation of wages in the bottom half of the income distribution, such as technological change that favors those with a college education and globalization, are still at play in the recovery--and perhaps may have accelerated.11About two-thirds of all job losses in the recession were in middle-wage occupations--such as manufacturing, skilled construction, and office administration jobs--but these occupations have accounted for less than one-fourth of subsequent job growth.12In contrast, the decline in lower-wage occupations--such as retail sales, food service, and other lower-paying service jobs--accounted for only one-fifth of job loss and more than one-half of total job gains in the recovery.13 It is not only the occupational and industrial distribution of the new jobs that poses challenges for workers and their families struggling to make ends meet, but also the fact that many of the jobs that have returned are part time or make use of temporary arrangements popularly known as contingent work. The flexibility of these jobs may be beneficial for workers who want or need time to address their family needs. However, workers in these jobs often receive less pay and fewer benefits than traditional full-time or "permanent" workers, are much less likely to benefit from the protections of labor and employment laws, and often have no real pathway to upward mobility in the workplace.14 Wage gains have remained more muted than is typical during a recovery. While this phenomenon likely partly reflects the trends in job creation that I have already discussed, weak wage growth also reflects the severe nature of the crisis: Typically, those who are laid off during recessions struggle to find reemployment that is of comparable quality to their previous job, and research has shown that, on average, a person's income remains depressed for decades following job loss, and that income losses over one's working life are especially severe when the job loss occurs during a recession.15 Indeed, while average wages have continued to increase (albeit slowly) on an annual basis for persons who have remained employed, the average wage for new hires has declined since 2010.16Although it is too early to state with certainty what the long-term effect of this recession will be on the earnings potential of those who lost their jobs, given the severity of the job loss and sluggishness of the recovery--with nearly 9 million jobs lost and still almost 2-1/2 million jobs below pre-recession employment levels--it is very likely that, for many households, future labor earnings will be well below what they had anticipated in the years before the recession. Implications for Our Thinking about the MacroeconomyI have focused most of my remarks on the experiences of households at the lower ends of the income and wealth distributions, those households whose incomes improved the least in the years prior to the financial crisis and that suffered disproportionately as a result of the crisis and ensuing recession. To be clear, my approach of starting with inequality and differences across households is not a feature of most analyses of the macroeconomy, and the channels I have emphasized generally do not play key roles in most macro models. The typical macroeconomic analysis focuses on the general equilibrium behavior of "representative" households and firms, thereby abstracting from the consequences of inequality and other heterogeneity across households and instead focusing on the aggregate measures of spending determinants, including current income, wealth, interest rates, credit supply, and confidence or pessimism. In certain circumstances, this abstraction might be a reasonable simplification. For example, if the changes in the distribution of income or wealth, and the implications of those changes for the overall economy, are regular features of business cycles, then even an aggregate model without an explicit focus on distributional issues would capture those historical regularities. However, the narrative I have emphasized places economic inequality and the differential experiences of American families, particularly the highly adverse experiences of those least well positioned to absorb their "realized shocks," closer to the front and center of the macroeconomic adjustment process. The effects of increasing income and wealth disparities--specifically, the stagnating wages and sharp increase in household debt in the years leading up to the crisis, combined with the rapid decline in house prices and contraction in credit that followed--may have resulted in dynamics that differ from historical experience and which are therefore not well captured by aggregate models. How these factors have interacted and the implications for the aggregate economy are subject to debate, but I have laid out some possible channels through which there could be effects and that I believe represent some particularly fruitful areas for continued research. Implications for Monetary PolicyThe arguments that I have laid out suggest that paying attention to the experiences of different types of households may be important for the way we understand and interpret the macroeconomic events of the past several years. As a consequence, these differential experiences may also have implications for the conduct of monetary policy. Arguably, the FOMC's conduct of monetary policy in recent years has in part been designed to address this particular landscape. In response to continuing low levels of resource utilization, the FOMC has kept monetary policy highly accommodative by keeping its primary policy instrument, the federal funds rate, at an exceptionally low level; by supplementing this move with forward guidance about the funds rate; and by initiating unconventional policy actions such as large-scale asset purchases. One channel through which these policies operate is by putting downward pressure on longer-term interest rates, thereby encouraging firms to invest in plants and equipment and helping enable households to purchase cars and other durable goods and also to refinance their mortgages. Lower interest rates also support the prices of homes and other assets, which can lead to additional spending. The resulting boost to demand leads firms to hire and invest further, strengthening the economy as a whole. To be sure, every household is different, and the particular mix of assets, skills, and opportunities that each has will determine how much it is able to share in the recovery. But accommodative monetary policy that lifts economic activity more generally is expected to increase the odds of good outcomes for American families. Of course, it is also relevant to consider whether the unusual circumstances--the outsized role of housing wealth in the portfolios of low- and middle-income households, the increased use of debt during the boom, and the subsequent unprecedented shocks to the housing market--may have attenuated the effectiveness of monetary policy during the depths of the recession. Households that have been through foreclosure or have underwater mortgages or are otherwise credit constrained are less able than other households to take advantage of the lower interest rates, either for homebuying or other purposes. In my view, these effects likely clogged some of the channels through which monetary policy traditionally works. As the housing market recovers, though, I think it is possible that accommodative monetary policy could be increasingly potent. As house prices rise, more and more households have enough home equity to gain renewed access to mortgage credit and the ability to refinance their homes at lower rates. The staff at the Federal Reserve Board has estimated that house price increases of 10 percent or less from current levels would be sufficient for about 40 percent of underwater homeowners to regain positive equity. It is my view that understanding the long-run trends in income and wealth across different households is important in understanding the dynamics of the macroeconomy and thus also may be relevant for setting monetary policy to best reach our goals of maximum employment and price stability. I believe that the accommodative policies of the FOMC and the concerted effort we have made to ease conditions in the mortgage markets will help the economy continue to gain traction. And the resulting expansion in employment will likely improve income levels at the bottom of the distribution. However, given the long-standing trends toward greater income and wealth inequalities, it is unlikely that cyclical improvements in the labor markets will do much to reverse these trends. ConclusionIt strikes me that macroeconomists are far from a comprehensive understanding of how wealth and income inequality may affect business cycle dynamics. My remarks today are given only in the spirit of describing how that relationship might be further explored. I have said nothing about the social costs associated with such trends, nor have I provided much detail on what is occurring at the top end of the income and wealth distribution and the effects of those trends on the recovery. Nonetheless, I believe that, given the wide income and wealth disparities in the United States, this area is ripe for more research. In recent years, the Board has increased its efforts to measure and understand differences in the economic situations faced by different types of families. A particularly strong source of data to improve our understanding of the role for inequality and heterogeneity is the SCF. The triennial SCF marks its 30th anniversary this year, as the fieldwork for the 2013 survey begins this month. The data we collect on U.S. families are a fundamental input for many different types of research projects being undertaken by Board economists, in other government agencies and research centers, and in academia. In addition, the Board, in partnership with other members of the Federal Reserve System, is engaged in a wide range of analysis and research using rich and timely data on households' use of consumer credit. And the Board continues to support direct efforts to understand differences in spending and saving behavior across households, such as studies of stimulus policies in the Thomson Reuters/University of Michigan Surveys of Consumers. There is much work to be done on understanding the ways in which income and wealth inequality and other forms of household heterogeneity affect aggregate behavior, and the implications for monetary policy. The times demand that we continue to analyze such dynamics and their implications, in partnership with academics, our Federal Reserve System colleagues, and policy analysts representing many different types of government and private-sector institutions. Thank you for your attention and the creative thought you bring to today's economic challenges. 1.See Congressional Budget Office (2011),Trends in the Distribution of Household Income between 1979 and 2007 (PDF)(Washington: CBO, October).Return to text 2.The survey article by Attanasio and Weber (2010) describes several conditions that raise a household's propensity to consume additional income, such as temporary income shocks, borrowing constraints, and low liquidity. However, existing studies do not provide clear evidence that people with permanently low income have a high marginal propensity to consume. See Orazio P. Attanasio and Guglielmo Weber (2010), "Consumption and Saving: Models of Intertemporal Allocation and Their Implications for Public Policy,"Journal of Economic Literature, vol. 48 (September), pp. 693-751.Return to text 3.One concern with rising inequality and stagnating wages is that low- and middle-income households will turn to credit and wealth extraction to maintain their consumption growth. One sign of this behavior would be consumption inequality rising much less than income inequality. Researchers--including Krueger and Perri (2006); Aguiar and Bils (2011); and Attanasio, Hurst, and Pistaferri (2012)--have produced mixed findings on this basic question, although, taken together, there is growing evidence that consumption inequality has also risen substantially over the past several decades. See Dirk Krueger and Fabrizio Perri (2006), "Does Income Inequality Lead to Consumption Inequality? Evidence and Theory,"Review of Economic Studies, vol. 73 (January), pp. 163-93; Mark A. Aguiar and Mark Bils (2011), "Has Consumption Inequality Mirrored Income Inequality?" NBER Working Paper Series 16807 (Cambridge, Mass.: National Bureau of Economic Research, February); and Orazio Attanasio, Erik Hurst, and Luigi Pistaferri (2012), "The Evolution of Income, Consumption, and Leisure Inequality in the US, 1980-2010," NBER Working Paper Series 17982 (Cambridge, Mass.: National Bureau of Economic Research, April).Return to text 4.The specific measure used to group families for these wealth calculations is the stable component of income, referred to in the SCF as "normal" or "usual" income. In the SCF, after families have reported their actual incomes for the year, they are asked whether this was a normal year. If the answer is no, they are asked what their income usually would be in a normal year. Using normal income as a classifier removes the systematic bias in average wealth that arises when, for example, normally high-income families are temporarily in the lowest income group because they had a particularly bad year.Return to text 5.In a separate line of inquiry on the social dynamics of spending, Bertrand and Morse (2013) find that moderate-income households spend more if they live in states with rapid spending growth among high-income households, which suggests another channel for inequality to increase debt. See Marianne Bertrand and Adair Morse (2013), "Trickle-Down Consumption," NBER Working Paper Series 18883 (Cambridge, Mass.: National Bureau of Economic Research, March).Return to text 6.In fact, recent research shows that these trends in annual inequality are mostly due to rising disparities in the component of a household's income that is stable over time, rather than rising disparities in the component that varies from year to year. See Jason DeBacker, Bradley Heim, Vasia Panousi, and Ivan Vidangos (2011), "Rising Inequality: Transitory or Permanent? New Evidence from a U.S. Panel of Household Income 1987-2006," Finance and Economics Discussion Series 2011-60 (Washington: Board of Governors of the Federal Reserve System, December).Return to text 7.For example, Rajan (2010) has argued that rising inequality resulted in the relaxation of credit standards, which led to the financial crisis, and Kumhof and Ranciere (2011) present a model with such features. However, Bordo and Meissner (2012) look at data from 14 advanced countries and do not find a general relationship between inequality and credit booms. Meanwhile, Bhutta (2011, 2012) finds that federal programs aimed at increasing homeownership only modestly increased the availability of mortgage credit to lower-income borrowers. See Raghuram Rajan (2010),Fault Lines: How Hidden Fractures Still Threaten the World Economy(Princeton, N.J.: Princeton University Press); Michael Kumhof and Romain Ranciere (2011), "Inequality, Leverage and Crises," CEPR Discussion Paper 8179 (London: Centre for Economic Policy Research, January); Michael D. Bordo and Christopher M. Meissner (2012), "Does Inequality Lead to a Financial Crisis?" NBER Working Paper Series 17896 (Cambridge, Mass.: National Bureau of Economic Research, March); Neil Bhutta (2011), "The Community Reinvestment Act and Mortgage Lending to Lower Income Borrowers and Neighborhoods,"Journal of Law and Economics, vol. 54 (November), pp. 953-83; and Neil Bhutta (2012), "GSE Activity and Mortgage Supply in Lower-Income and Minority Neighborhoods: The Effect of the Affordable Housing Goals,"Journal of Real Estate Finance and Economics, vol. 45 (June), pp. 238-61.Return to text 8.See Atif Mian, Kamalesh Rao, and Amir Sufi (2011), "Household Balance Sheets, Consumption, and the Economic Slump (PDF)," unpublished paper, University of Chicago, Booth School of Business, November; and Karen Dynan (2012), "Is a Household Debt Overhang Holding Back Consumption?"Brookings Papers on Economic Activity,Spring, pp. 299-358.Return to text 9.An Organisation for Economic Co-operation and Development study by Ahrend, Arnold, and Moeser (2011) documents across a wider range of countries that individuals with low incomes tend to lose the most from adverse macroeconomic shocks. See Rudiger Ahrend, Jens Arnold, and Charlotte Moeser (2011), "The Sharing of Macroeconomic Risk: Who Loses (and Gains) from Macroeconomic Shocks," OECD Economics Department Working Papers 877 (Washington: OECD Publishing, July).Return to text 10.In contrast to the decrease in overall debt, student loans have continued to rise at a solid pace. The outstanding level of student loan balances is nearly twice its level five years ago and now represents the largest component of consumer (nonmortgage) lending. The increase in student loans is likely related to broader developments in the recession and exposes the households holding these loans to new risks.Return to text 11.The poverty rate has risen sharply since the onset of the recession, after a decade of relative stability, and it now stands at 15 percent, significantly higher than the average over the past three decades. See Carmen DeNavas-Walt, Bernadette D. Proctor, and Jessica C. Smith (2012),Income, Poverty, and Health Insurance Coverage in the United States: 2011 (PDF), U.S. Census Bureau Current Population Reports P60-243 (Washington: U.S. Government Printing Office, September).Return to text 12.See National Employment Law Project (2012), "The Low-Wage Recovery and Growing Inequality,"Data Brief, report (New York: NELP, August), http://nelp.3cdn.net/8ee4a46a37c86939c0_qjm6bkhe0.pdf.Return to text 13.These patterns were also observed during the recessions of the early 1990s and early 2000s--the so-called jobless recoveries--but not prior to then. See Nir Jaimovich and Henry E. Siu (2012), "The Trend Is the Cycle: Job Polarization and Jobless Recoveries," NBER Working Paper Series 18334 (Cambridge, Mass: National Bureau of Economic Research, August); and Christopher L. Foote and Richard W. Ryan (2012), "Labor-Market Polarization over the Business Cycle," Public Policy Discussion Paper 12-8 (Boston: Federal Reserve Bank of Boston, December).Return to text 14.See U.S. Department of Labor, Commission on the Future of Worker-Management Relations (1994), "Contingent Workers," inFact Finding Report.Return to text 15.See Steven J. Davis and Till von Wachter (2011), "Recessions and the Costs of Job Loss,"Brookings Papers on Economic Activity,Fall, pp. 1-55.Return to text 16.See Jesse Rothstein (2012), "The Labor Market Four Years into the Crisis: Assessing Structural Explanations,"ILRReview, vol. 65 (July), figure 11, p. 486.Return to text
Vice Chair Janet L. Yellen At the Society of American Business Editors and Writers 50th Anniversary Conference, Washington, D.C. Thank you for inviting me here and for offering me what I consider a perfect opportunity to speak on a topic at the heart of the Federal Reserve's efforts to promote a stronger economy--the vital role and growing use of communication in monetary policy.1 Some of you cover the Federal Reserve and are familiar with how it sets monetary policy through the Federal Open Market Committee (FOMC). You know that the FOMC pays very close attention to what it says in the statements it issues after each meeting. This communication is supplemented by Chairman Bernanke's postmeeting press conferences and by providing detailed minutes of the Committee's meetings. Getting this message out to the public depends a good deal on the work you do in reporting on the FOMC, analyzing its statements and actions, and explaining its role and objectives. So let me begin by thanking you for those contributions. But let me also say why I am particularly pleased to speak to you today. As writers and editors, all of you are prodigious consumers and producers of communication. At first glance, the FOMC's communication may not seem so different from what you've heard other government agencies say about their policies or businesses say about their products. I hope to show how communication plays a distinct and special role in monetary policymaking. Let me offer a comparison that may highlight that difference. Suppose, instead of monetary policy, we were talking about an example of transportation policy--widening a road to ease traffic congestion. Whether this road project is announced at a televised press conference or in a low-key press release--or even if there is no announcement--the project is more or less the same. The benefit to drivers will come after the road is widened and won't be affected by whether drivers knew about the project years in advance. At the heart of everything I'll be explaining today is the fact that monetary policy is different. The effects of monetary policy depend critically on the public getting the message about what policy will do months or years in the future.2 To develop this idea, I will take you on a tour of past FOMC communication, the present, and what I foresee for the future. Until fairly recently, most central banks actively avoided communicating about monetary policy. Montagu Norman, governor of the Bank of England in the early 20th century, reputedly lived by the motto "never explain, never excuse," and that approach was still firmly in place at the Federal Reserve when I went to work there as a staff economist in 1977. I'll begin by discussing how a growing understanding of the importance of transparency shaped FOMC communication in the years before the financial crisis. Next, I'll relate how the financial crisis brought unprecedented challenges for monetary policy that required the use of unconventional policy tools, including some barely contemplated before the crisis. Communication was a centerpiece of these efforts. Finally, I'll look ahead. I am encouraged by recent signs that the economy is improving and healing from the trauma of the crisis, and I expect that, at some point, the FOMC will return to a more normal approach to monetary policy. At the conclusion of my remarks, I'll discuss the communication challenges the FOMC will face when it comes time to make that transition. FOMC communication has long been a topic of great interest to me, and one I have worked on more directly since 2010, when Chairman Bernanke asked me to lead a new FOMC subcommittee on communications. This is probably a good moment to remind you that, as always, I speak for myself and not the FOMC or my colleagues in the Federal Reserve System. From "Never Explain" to TransparencyRecently I used the word "revolution" to describe the change from "never explain" to the current embrace of transparency in the FOMC's communication.3That might sound surprising to an audience that knows very well what it feels like to be in the middle of a communications revolution. The speed and frequency of most communication, it seems, never stops growing, and I will admit that the FOMC's changes to the pace and form of its communication seem rather modest in comparison. I've mentioned the Chairman's quarterly postmeeting press conferences, which were initiated two years ago. While these events are televised and streamed live, the mode for most of the FOMC's communication is decidedly old-school--the printed word. The Committee's most watched piece of communication is the written statement issued after each of its meetings, which are held roughly every six weeks. It may seem quaint that my colleagues and I continue to spend many hours laboring over the few hundred words in this statement, which are then extensively analyzed only minutes after their release. The revolution in the FOMC's communication, however, isn't about technology or speed. It's a revolution in our understanding of how communication can influence the effectiveness of monetary policy. It will help if I start with some basics. The FOMC consists of the 7 members of the Federal Reserve Board in Washington and 5 of the 12 presidents of the regional Federal Reserve Banks. All 12 presidents participate in FOMC meetings but only 5 get a vote, a roster that rotates each year. The FOMC's job, assigned by the Congress, is to use monetary policy to promote maximum employment and stable prices, objectives that together are known as the Federal Reserve's dual mandate. In normal times, the Committee pursues these goals by influencing the level of a short-term interest rate called the federal funds rate, which is what banks charge each other for overnight loans. When the FOMC pushes the federal funds rate up or down, other short-term interest rates normally move in tandem. Medium- and longer-term interest rates, including auto loan rates and mortgage rates, generally adjust also, through a mechanism I will return to in a moment. By pushing the federal funds rate up or down, the FOMC seeks to influence a wide range of interest rates that matter to households and businesses. Typically, the FOMC acts to lower the federal funds rate, with the intention of reducing interest rates generally, when the economy is weakening or inflation is declining below the Committee's longer-run objective. The FOMC raises the federal funds rate when inflation threatens to rise above its objective or when economic activity appears likely to rise above sustainable levels. Raising and lowering the federal funds rate was long the primary means by which the FOMC pursued its economic objectives. It is hard to imagine now, but only two decades ago, the Federal Reserve and other central banks provided the public with very little information about such monetary policy moves--the spirit of "never explain" was very much alive. There were a number of different justifications for this approach. One view was that less disclosure would reduce the risk and tamp down suspicions that some could take advantage of disclosures more readily than others. Some believed that markets would overreact to details about monetary policy decisions. And there was a widespread belief that communicating about how the FOMC might act in the future could limit the Committee's discretion to change policy in response to future developments. In sum, the conventional wisdom among central bankers was that transparency was of little benefit for monetary policy and, in some cases, could cause problems that would make policy less effective. While communication and transparency steadily increased elsewhere in government and society, change came slowly to the FOMC. It wasn't until February 1994 that the Committee issued a postmeeting statement disclosing a change in monetary policy. Even then, it only alerted the public that the Committee had changed its policy stance, with scant explanation.4 Something bigwaschanging, however, and it would soon be the force driving major enhancements in the FOMC's communication. By the early 1990s, a growing body of research challenged widespread assumptions about the how central banks, such as the Federal Reserve, affected the economy. The reevaluation starts with a question that puzzled many of my students when I was a professor: How is it that the Federal Reserve manages to move a vast economy just by raising or lowering the interest rate on overnight loans by 1/4 of a percentage point? The question arises because significant spending decisions--expanding a business, buying a house, or choosing how much to spend on consumer goods over the year--depend on expectations of income, employment, and other economic conditions over the longer term, as well as longer-term interest rates. The crucial insight of that research was that what happens to the federal funds rate today or over the six weeks until the next FOMC meeting is relatively unimportant. Whatisimportant is the public's expectation of how the FOMC will use the federal funds rate to influence economic conditions over the next few years.5 For this reason, the Federal Reserve's ability to influence economic conditions today depends critically on its ability to shape expectations of the future, specifically by helping the public understand how it intends to conduct policy over time, and what the likely implications of those actions will be for economic conditions. To return to the example I used earlier, contrast this effect on expectations with that of a road project. Today's commute, alas, will not be improved or changed at all by the news that a road will be widened one day. But the effects of today's monetary policy actions are largely due to the effect they have on expectations about how policy will be set over the medium term. Let me further illustrate this with some history. Starting in the mid-1960s, the Federal Reserve didn't act forcefully in the face of rising inflation, and the public grew less certain of the central bank's commitment to fighting inflation. This uncertainty led expectations of future inflation to become "unanchored" and more likely to react to economic developments. In 1973, an oil price shock led to a large increase in overall inflation. Expectations of higher inflation in the future affected the public's behavior--workers demanded raises, and businesses set prices and otherwise acted in anticipation of higher costs--and this helped fuel actual inflation. The FOMC's occasional efforts to reduce inflation in the 1970s were ineffective partly due to the expectation that it ultimately wouldn't do enough. By contrast, most of you probably know about the Federal Reserve's successful inflation fighting in the early 1980s. The FOMC raised the federal funds rate very high, causing a deep recession but also convincing the public that it was committed to low and stable inflation. Anchoring inflation expectations at low levels helped ensure that jumps in commodity prices or other supply shocks would not generate persistent inflation problems. This was illustrated by the effect of another escalation in oil prices starting in 2005. Unlike in the 1970s, these price shocks did not result in a broad and lasting increase in overall inflation because the public believed the Federal Reserve would keep inflation in check. The FOMC wasn't forced to raise interest rates--which softened the blow of higher fuel costs on households and businesses--because of the credibility the Federal Reserve had built since the 1980s. If the public's expectations have always been important, you might wonder how monetary policy had any effect prior to the transparency revolution. As it turns out, with the notable exception of the late 1960s and 1970s, the FOMC usually responded in a systematic way to economic conditions. In 1993, economist John Taylor documented that FOMC policy changes since the mid-1980s had fairly reliably followed a simple rule based on inflation and output. Changes in the federal funds rate were usually made in several small steps over a number of months. In practice, the Federal Reserve's approach was "never explain, but behave predictably." A close analysis of the FOMC's past behavior was a good guide to future policy, but it had two shortcomings as a substitute for transparency: First, it gave an advantage to sophisticated players who studied the FOMC's behavior--something that is arguably inappropriate for a government institution. Second, while a policy rule such as the one developed by John Taylor explained the course of the federal funds rate much of the time, there were cases when it didn't and when even the experts failed to correctly anticipate the FOMC's actions. The trend toward greater transparency accelerated during the early 2000s. Starting in 2000, the FOMC issued information after every meeting about its economic outlook. It also provided an assessment of the balance of risks to the economy and whether it was leaning toward increasing or decreasing the federal funds rate in the future. Such information about intentions and expectations for the future, known as forward guidance, became crucial in 2003, when the Committee was faced with a stubbornly weak recovery from the 2001 recession. It had cut the federal funds rate to the very low level of 1 percent, but unemployment remained elevated, and the FOMC sought some further way to stimulate the economy. In this situation, it told the public that it intended to keep the federal funds rate low for longer than might have been expected by adding to its statement that "[i]n these circumstances, the Committee believes that policy accommodation can be maintained for a considerable period."6 Let's pause here and note what this moment represented. For the first time, the Committee was using communication--mere words--as its primary monetary policy tool. Until then, it was probably common to think of communication about future policy as something that supplemented the setting of the federal funds rate. In this case, communication was an independent and effective tool for influencing the economy. The FOMC had journeyed from "never explain" to a point where sometimes the explanationisthe policy. By the eve of the recent financial crisis, it was established that the FOMC could not simply rely on its record of systematic behavior as a substitute for communication--especially under unusual circumstances, for which history had little to teach. I think we're all fortunate that policymakers had learned this lesson, because the FOMC was about to encounter unprecedented economic conditions and policy challenges. The financial crisis and its aftermath demanded advances in FOMC communication as great as any that had come before. Monetary Policy since the Onset of the Financial CrisisThe situation in 2008 and 2009 was like nothing the Federal Reserve had faced since the 1930s. In late 2008, the FOMC cut the federal funds rate nearly to zero--essentially, as low as it could go--where it has remained. With its traditional tool for expansionary monetary policy--lowering the federal funds rate--off the table, the FOMC turned to unconventional and, in some cases, newly invented policy options to try both to help stabilize the financial system and to arrest the plunge in economic activity. The public had grown accustomed to monetary policy that focused on changes to the federal funds rate target, with occasional, and at this point fairly limited, guidance that a particular policy stance would probably last for a while. Beyond the task of describing the new policies, extensive new communication was needed to justify these unconventional policy actions and convincingly connect them to the Federal Reserve's employment and inflation objectives. The best known of these unconventional policies is large-scale asset purchases, commonly known as quantitative easing. Starting in late 2008 and continuing through today, the Federal Reserve has purchased longer-term government agency debt securities, agency-guaranteed mortgage-backed securities, and longer-term Treasury securities that have added about $2.5 trillion to its assets. These purchases were intended to, and I believe have, succeeded in significantly lowering longer-term interest rates and raising asset prices to help further the Federal Reserve's economic objectives. This is an easing of monetary policy, also known as accommodation, beyond what is provided by maintaining the federal funds rate close to zero. It is important to emphasize that the effects of asset purchases also depend on expectations. If the FOMC buys, say, $10 billion in longer-term securities today but is expected to sell them tomorrow or very shortly, there will be little effect on the economy. Current research suggests that the effects of asset purchases today depend on expectations of the total value of securities the FOMC intends to buyandon expectations of how long the FOMC intends to hold those securities. To make these asset purchases as effective as possible in adding accommodation, the FOMC, therefore, needs to communicate the intended path of Federal Reserve securities holdings years into the future. I will return in a moment to current and possible future ways in which the FOMC does and might communicate this information. The other unconventional policy designed to contribute to monetary easing was almost purely communication--enhanced forward guidance about how long the Committee expects to maintain the federal funds rate near zero. The situation in early 2009 was similar to 2003 but even more challenging, because in that earlier episode, the FOMC at least retained the option of a further reduction in the federal funds rate target. In 2009, communication about the future path of the federal funds rate was the only option. Initially, the forward guidance was simple and familiar: The FOMC statement noted that "economic conditions are likely to warrant exceptionally low levels of the federal funds rate for an extended period."7The Committee enhanced its forward guidance in August 2011, when it substituted "at least through mid-2013" for the words "an extended period."8This date was moved into the future several times, most recently last September, when it was shifted to mid-2015.9 This "calendar guidance" was an advance over the indefinite "extended period," but it suffered from an important limitation. The date failed to provide the public with a clear understanding of what conditions the FOMC was trying to achieve or the economic conditions that would warrant a continuation of the policy. As a consequence, it was hard for the public to tell whether a change in the calendar date reflected a shift in policy or a change in the Committee's economic forecast. To help provide greater clarity about the Committee's objectives, in January 2012, the FOMC adopted and released a statement of its longer-run goals and monetary policy strategy.10This statement laid out, for the first time, the rates of inflation and unemployment that the FOMC considers consistent with the dual mandate. Specifically, it stated that the longer-run inflation goal most consistent with the FOMC's price stability mandate is 2 percent, and that the central tendency of FOMC participants' estimates of the longer-run normal rate of unemployment ranged from 5.2 to 6 percent. As the statement also made clear, economic developments may cause inflation and unemployment to temporarily move away from the objectives, and the Committee will use a balanced approach to return both, over time, to the longer-run goals. On the one hand, for example, the current rate of unemployment, at 7.7 percent, is far above the 5.2 to 6 percent range in the statement and is expected to decline only gradually. Inflation, on the other hand, has been running at or below 2 percent and is expected to remain at similar levels for several years. In this circumstance, both legs of the dual mandate call for a highly accommodative monetary policy. With unemployment so far from its longer-run normal level, I believe progress on reducing unemployment should take center stage for the FOMC, even if maintaining that progress might result in inflation slightly and temporarily exceeding 2 percent. The Committee reaffirmed this statement in January 2013, and I expect it to remain a valuable roadmap for many years to come, indicating how monetary policy will respond to changes in economic conditions.11 Meanwhile, the FOMC has continued to enhance its communication about how it would use the federal funds rate to return inflation and unemployment to its longer-run objectives. Last December, the Committee replaced its calendar guidance for the federal funds rate with quantitative measures of economic conditions that would warrant continuing that rate at its current very low level. Specifically, the Committee said it anticipates that exceptionally low levels for the federal funds rate will be appropriate "at least as long as the unemployment rate remains above 6-1/2 percent, inflation between one and two years ahead is projected to be no more than a half percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored."12 I consider these thresholds for possible action a major improvement in forward guidance. They provide much more information than before about the conditions that are likely to prevail when the FOMC decides to raise the federal funds rate. As for the date at which tightening of monetary policy is likely to occur, market participants, armed with this new information about the Committee's "reaction function," can form their own judgment and alter their expectations on timing as new information accrues over time. These thresholds will, as a consequence, allow private-sector expectations of the federal funds rate to fulfill an important "automatic stabilizer" function for the economy. If the recovery is stronger than expected, the public should anticipate that one or both of the threshold values will be crossed sooner and, hence, that the federal funds rate could be raised earlier. Conversely, if the outlook for the economy unexpectedly worsens, the public should expect a later "liftoff" in rates--an expectation that would reduce longer-term interest rates and thereby provide more-accommodative financial conditions. Communication and Monetary Policy Challenges AheadThe threshold guidance for the federal funds rate looks ahead to a time when the economy has healed from the worst effects of the financial crisis. Getting back to more normal economic conditions will allow for a more normal approach to monetary policy. I look forward to the day when we can put away our unconventional tools and return to what now seems like the relatively straightforward challenge of setting the federal funds rate. At some point it will be appropriate to cease adding to accommodation and, later, to begin the process of withdrawing the significant accommodation required by the extraordinary conditions caused by the financial crisis. I believe that, once again, communication will play a central role in managing this transition. Let me start with our current program of asset purchases, which was launched in September 2012 and revised in December. Notably, the FOMC has described this program in terms of a monthly pace of purchases rather than as a total amount of expected purchases. The Committee has indicated that it will continue purchases until the outlook for the labor market has improved substantially in a context of price stability. In its most recent statement, the FOMC also indicated that the pace and composition of the purchases may be adjusted based on the likely efficacy and costs of such purchases, as well as the extent of progress toward the Federal Reserve's economic objectives.13In my view, adjusting the pace of asset purchases in response to the evolution of the outlook for the labor market will provide the public with information regarding the Committee's intentions and should reduce the risk of misunderstanding and market disruption as the conclusion of the program draws closer. The Federal Reserve's ongoing asset purchases continually add to the accommodation that the Federal Reserve is providing to help strengthen the economy. An end to those purchases means that the FOMC has ceased augmenting that support, not that it is withdrawing accommodation. When and how to begin actually removing the significant accommodation provided by the Federal Reserve's large holdings of longer-term securities is a separate matter. In its March statement, the FOMC reaffirmed its expectation that a highly accommodative stance of monetary policy will remain appropriate for a considerable time after the current asset purchase program ends and the economic recovery has strengthened.14Accordingly, there will likely be a substantial period after asset purchases conclude but before the FOMC starts removing accommodation by reducing asset holdings or raising the federal funds rate. To guide expectations concerning the process of normalizing the size and composition of the Federal Reserve's balance sheet, at its June 2011 meeting, the FOMC laid out what it called "exit principles." In these principles, the FOMC indicated that asset sales would likely follow liftoff of the federal funds rate. It also noted that, in order to minimize the risk of market disruption, the pace of asset sales during this process could be adjusted up or down in response to changes in either the economic outlook or financial conditions. For example, changes in the pace or timing of asset sales might be warranted by concerns over market functioning or excessive volatility in bond markets. While normalization of the Federal Reserve's portfolio is still well in the future, the FOMC is committed to clear communication about the likely path of the balance sheet. There will come a time when the FOMC begins the process of returning the federal funds rate to a more normal level. In their individual projections submitted for the March FOMC meeting, 13 of the 19 FOMC participants saw the first increase in the target for the federal funds rate as most likely to occur in 2015, and another expected it to occur in 2016. But the course of the economy is uncertain, and the Committee added the thresholds for unemployment and inflation, in part, to help guide the public if economic developments warrant liftoff sooner or later than expected. As the time of the first increase in the federal funds rate moves closer, in my view it will be increasingly important for the Committee to clearly communicate about how the federal funds rate target will be adjusted. I hope I've been able today to convey the vital role that communication plays in the Federal Reserve's efforts to promote maximum employment and stable prices. Communication became even more significant after the onset of the financial crisis when the FOMC turned to unconventional policy tools that relied heavily on communication. Better times and a transition away from unconventional policies may make monetary policy less reliant on communication. But I hope and trust that the days of "never explain, never excuse" are gone for good, and that the Federal Reserve continues to reap the benefits of clearly explaining its actions to the public. I believe further improvements in the FOMC's communication are possible, and I expect they will continue. It has been my privilege to share these thoughts with you. Thank you for inviting me here today. 1.I am indebted to members of the Board staff--Jon Faust, Thomas Laubach, and John Maggs--who contributed to the preparation of these remarks.Return to text 2.Like almost every government policy action, this hypothetical road project could affect expectations--it might influence decisions about where people live or commercial development, for example. The crucial difference is that these are not the primary and stated aim of this policy action, which is to reduce traffic congestion. As these remarks go on to explain, unlike most government policy actions, monetary policy is primarily concerned with affecting expectations of the future.Return to text 3.See Janet L. Yellen (2012), "Revolution and Evolution in Central Bank Communications," speech delivered at the Haas School of Business, University of California, Berkeley, November 13.Return to text 4.Previously, the public inferred policy changes by observing the Federal Reserve's behavior in securities markets.Return to text 5.Another factor that adds to the importance of expectations is that changes in monetary policy affect real activity and inflation with a substantial time lag.Return to text 6.See Board of Governors of the Federal Reserve System (2003), "FOMC Statement," press release, August 12.Return to text 7.See Board of Governors of the Federal Reserve System (2009), "FOMC Statement," press release, March 18.Return to text 8.See Board of Governors of the Federal Reserve System (2011), "FOMC Statement," press release, August 9.Return to text 9.See Board of Governors of the Federal Reserve System (2012), "Federal Reserve Issues FOMC Statement," press release, September 13.Return to text 10.See Board of Governors of the Federal Reserve System (2012), "Federal Reserve Issues FOMC Statement of Longer-Run Goals and Policy Strategy," press release, January 25.Return to text 11.See "Statement on Longer-Run Goals and Monetary Policy Strategy (PDF)," as amended effective January 29, 2013.Return to text 12.See Board of Governors of the Federal Reserve System (2012), "Federal Reserve Issues FOMC Statement," press release, December 12.Return to text 13.See Board of Governors of the Federal Reserve System (2013), "Federal Reserve Issues FOMC Statement," press release, March 20.Return to text 14.See Board of Governors, "FOMC Statement," March 20, in note 13.Return to text
Chairman Ben S. Bernanke At the "Resilience and Rebuilding for Low-Income Communities: Research to Inform Policy and Practice" Federal Reserve System Community Affairs Research Conference, Washington, D.C. Accessible Keys for Video [Space Bar]toggles play/pause; [Right/Left Arrows]seeks the video forwards and back (5 sec ); [Up/Down Arrows]increase/decrease volume; [M]toggles mute on/off; [F]toggles fullscreen on/off (Except IE 11); The[Tab]key may be used in combination with the[Enter/Return]key to navigate and activate control buttons, such as caption on/off. I am pleased to join you for the eighth biennial Federal Reserve System Community Affairs Research Conference. The work you are doing here--sharing research and exchanging ideas on how best to further the development of low-income communities--is vitally important. As this year's theme, "Resilience and Rebuilding," reflects, low-income communities were particularly hard hit by the Great Recession.1And, while employment and housing show signs of improving for the nation as a whole, conditions in lower-income neighborhoods remain difficult by many measures. For example, an analysis by Federal Reserve staff reveals that long-vacant housing units tend to be concentrated in a small number of neighborhoods that also tend to have high unemployment rates, low educational levels, and low median incomes.2While some of these neighborhoods are in the inner cities, others are in suburbs. This analysis and others like it illustrate the close interconnections of housing conditions, educational levels, and unemployment experience within neighborhoods. Moreover, as this work confirms, poverty is no longer primarily an urban phenomenon but has increasingly spread to suburban areas, many of which lack the social and community development services needed to mitigate poverty and its effects.3The implications of these trends for community development are profound. Successful strategies to rebuild communities cannot focus narrowly on a single problem, such as the physical deterioration of neighborhoods that suffered high rates of foreclosure. Rather, progress will require multipronged approaches that address housing, education, jobs, and quality-of-life issues in a coherent, mutually consistent way. Moreover, strategies will have to be adapted to meet the special circumstances of urban, suburban, and rural settings. As community development researchers and practitioners, you are confronting the challenge of effectively attending to the needs of both individuals and communities--of people as well as places. The Evolution of Community DevelopmentCommunity development has a long history of innovation and learning from experience. Notably, after decades of large-scale, top-down federal efforts, it became increasingly apparent that a one-size-fits-all approach did not serve local communities well. The urban renewal programs of the 1950s and 1960s were perhaps the most prominent examples of well-meaning but misguided efforts to revitalize decaying inner-city neighborhoods. In practice, these policies often devastated neighborhood cohesion, leading their critics to argue for local, bottom-up solutions. Perhaps the most influential critique of urban renewal and top-down planning was Jane Jacobs's 1961 book,Death and Life of Great American Cities.4In that book she celebrated the complexity and organic development of city neighborhoods in which intricate social networks enhance safety, quality of life, and economic opportunity. In Jacobs's view, a police force was not as effective at maintaining order as a neighborhood filled with "public actors" such as storekeepers, doormen, and interested neighbors acting as street watchers at all hours. The development of this sort of community self-monitoring is most likely to emerge, she argued, in neighborhoods with a rich mixture of activities taking place in buildings of varying age, character, and use. For the most part, social science research has vindicated Jacobs's perspective. For example, sociologists studying community resilience in the wake of natural disasters mapped deaths caused by an extreme heat wave in Chicago in 1995.5They found, not surprisingly, that death rates were higher in poor areas where air conditioners were scarce. But they also noticed a remarkable difference in the fatality rate in two adjacent neighborhoods--Englewood and Auburn Grisham--on Chicago's South Side. These neighborhoods were comparable by many measures: Both were 99 percent African American, with similar numbers of elderly residents and comparably high rates of poverty and unemployment. Yet Englewood experienced 33 deaths per 100,000 residents during the heat wave, while Auburn Grisham had among the lowest fatality rates in the city, 3 deaths per 100,000 residents. Researchers found that a key difference between Auburn Grisham and other neighborhoods lay in its physical and social topography--the vitality of its sidewalks, stores, restaurants, and community organizations that brought friends and neighbors together, making it easier for people to look out for each other. This example illustrates a point that many community development practitioners have come to embrace: Resilient communities require more than decent housing, important as that is; they require an array of amenities that support the social fabric of the community and build the capabilities of community residents. The movement toward a holistic approach to community development has been long in the making, but the housing crisis has motivated further progress. To be sure, implementing a holistic approach is easier said than done. Government resources are still largely managed in silos, and coordinating government agencies, philanthropy, and the private sector to meet the needs of local communities requires extraordinary commitment and effective leadership. But persistence and effort pay off. The holistic approach has the power to transform neighborhoods and, as a result, the lives of their lower-income residents. Let me give another example, drawn from the experience of the East Lake neighborhood in Atlanta, a neighborhood that exemplified the effects of concentrated poverty. In the early 1990s, East Lake had a crime rate 18 times higher than the national average. Nearly 60 percent of adults received public assistance, and only 5 percent of fifth grade children were able to meet state academic performance standards. A local philanthropist, Tom Cousins, wanted to improve the quality of life in this neighborhood by de-concentrating its poverty.6But he understood that East Lake's problems were interconnected: Replacing substandard housing would do little to attract families to the neighborhood if it lacked good schools, but schools couldn't perform well if students feared for their safety, arrived hungry, and were otherwise unprepared or unable to learn. High dropout rates in turn fueled the neighborhood's high rates of unemployment and crime. To deal with the interconnectedness of the neighborhood's problems, Cousins determined to attack them simultaneously. He created the East Lake Foundation to facilitate transformative change. The foundation partnered with the Atlanta Housing Authority to replace the neighborhood's low-income housing project with mixed-income housing that accommodated former tenants and other very low-income residents as well as attracting new, higher-income families. An independently operated public charter school for grades kindergarten through 12, named the Drew Charter School, and an early learning center serving 135 children were built. A new YMCA health and fitness center began to provide wellness programs and to serve as a neighborhood gathering place. Finally, the foundation worked to attract commercial investments in the neighborhood, including a grocery store, a bank branch, and restaurants. Creating this plan and navigating the complex array of interests and resources of the community, the local government, and the private sector took 10 years of effort. But the character of the neighborhood was fundamentally changed. Today crime in East Lake is down by 73 percent, and violent crime is down by 90 percent. The percentage of low-income adults employed has increased from 13 percent to 70 percent, and Drew Charter School moved from last place in performance among 69 Atlanta public schools after its first year of operation to fourth place. With 74 percent of its students receiving free and reduced-price lunches, Drew performs at the same level as public schools in far more affluent areas.7The educational outcomes alone argue for the wisdom of the holistic approach to community development. The success in East Lake raises the question of whether a similar approach can work in other communities. In 2009, Cousins launched a community development organization, Purpose Built Communities, to try to attain the same good outcomes that were achieved in Atlanta in other cities around the country. Experience so far suggests that, while the framework can be replicated, it requires certain neighborhood conditions to succeed. These conditions include (1) housing developments of concentrated poverty, which can feasibly be replaced by good-quality mixed-income housing at sufficient scale to change the housing and income characteristics of the neighborhood; (2) the opportunity to create one or more schools accountable to parents and the community; and (3) civic and business leadership that is prepared to create and support an organization charged with coordinating the necessary partnerships and seeing through the long-term plans. As those involved in this effort note, the Purpose Built strategy is quite different from that of most other bodies whose decisions affect community development.8For example, city governments rarely organize around neighborhoods. School boards, housing authorities, and transit systems all make decisions critical to the health of neighborhoods, but they generally act independently of city government. Moreover, the goals of such bodies are not typically measured in terms of the health of neighborhoods in any holistic sense. This mindset may be changing, however. For example, Los Angeles recently adopted a community-based approach to strategic planning. Its five-year consolidated plan recognizes that no single program or effort is likely, on its own, to lift families out of poverty or reduce crime in a neighborhood. Rather, the plan calls for a multifaceted approach to "build healthy communities by integrating community, economic, and housing development investments with transit opportunities to increase their positive impact on neighborhoods."9It also recognizes the need to build the city's institutional capacity so that it can effectively coordinate these efforts. To that end, the mayor created the Housing and Community Development Cabinet, which is composed of representatives from city departments from housing and transportation to health, family services, and economic development. The cabinet will be responsible for identifying neighborhoods for coordinated investment across sectors. Perhaps one of the most promising new partners in community development is the health-care sector. Factors such as educational attainment, income, access to healthy food, and the safety of a neighborhood tend to correlate with individual health outcomes in that neighborhood. Because these factors are linked to economic health as well as physical health, health-care professionals and community development organizations are seeing new opportunities for cooperation in low-income communities. For example, public health specialists and housing leaders are working together in Seattle to reduce the incidence in low-income homes of allergens that can cause or aggravate asthma. Because asthma results in a significant loss of school days and billions of dollars in treatment costs, it is easy to see that these efforts have the potential to improve not only health, but educational and economic outcomes as well.10 Beyond complementary interests with community development organizations, health professionals offer an important set of skills and tools, including unique data sets and sophisticated evaluation techniques. For example, using data from 38 children's hospitals, the Children's Hospital of Philadelphia Research Institute found an association between rates of foreclosures and poor health in children, including the incidence of abuse.11Health-related philanthropies are also investing in projects in low-income communities, ranging from projects to identify the health ramifications of proposed community improvements to increasing access to fresh food, by creating partnerships to subsidize grocery stores in low-income communities.12 Accelerating Transformative Development in CommunitiesThese examples illustrate the benefits of broad-based collaboration for rejuvenating communities that, in some cases, have been in decline for decades. Research is helping sharpen this approach and give more insight into what works. For example, in 2009, Federal Reserve Bank of Boston researchers evaluated the effects of concentrated poverty in Springfield, Massachusetts, as part of a larger study conducted by the Federal Reserve System. Intrigued by the results, the Boston Fed researchers turned their attention to trying to identify the factors that make it possible for some cities to adjust to changing economic conditions while others languish. To do this, the researchers identified 25 midsize manufacturing cities around the country that were similar to Springfield in 1960, when that city was at the height of its prosperity, and asked what accounted for the differences in the economic trajectories experienced by this group of cities over the past 50 years. Remarkably, their analysis indicated that industry mix, demographic makeup, and geographic location made less difference to success than the presence of a community leader and collaboration around a vision for the future. In some cases, leadership came in the form of an energetic mayor, but not always. In fact, the study found that leadership could come from almost anywhere. The successful leader was simply the person or entity that recognized the importance of preventing further deterioration in the local economy and agreed to take responsibility for the effort to turn things around. The leader helped facilitate local collaboration, which was essential not only because economic development is complicated and multidimensional, but also for the more prosaic reason that outside funders typically require that all interested stakeholders commit to a strategic direction. The specific avenues to recovery varied among the resurgent cities identified in the Boston Fed study. Some built on traditional strengths, while others created new business clusters from scratch. For example, Grand Rapids, Michigan, was once known for its furniture manufacturing. As those jobs disappeared, Grand Rapids worked to become a major medical center in the region, partnering with Michigan State University and Grand Valley State University to form the Medical Education and Research Center. Similarly, Jersey City has successfully transformed itself from a manufacturing-based economy to a financial center. Its proximity to New York City makes this transformation seem obvious in hindsight, but other similarly situated cities have not made comparable strides. Most of the cities in the study made significant investments in infrastructure and people to aid the transition to a knowledge-based economy. For example, Greensboro, North Carolina, worked with the nearby cities of Winston-Salem and High Point to build a regional airport and to replace its manufacturing economy with one based on high-tech research and production. In a common pattern, Greensboro drew on local resources in post-secondary education, with community colleges providing courses to enhance job skills and universities partnering with businesses to develop innovative products--in Greensboro's case, in nanotechnology and pharmaceuticals. In New Haven, Connecticut, local universities collaborate with private industry and local government to support biotech-related education in public schools by providing teacher training, assistance in curriculum design, and a mobile laboratory. Developing Local LeadersThese examples show that a city's path to economic recovery typically depends on its ability to draw on its own particular assets. Leaders that recognize the potential of those assets and foster collaboration in exploiting them can help communities remake themselves. The question then becomes how to develop and encourage local leadership. Technical assistance, networking opportunities, and mentoring programs are just some of the ways that leadership can be fostered locally. Based on its evaluation of Springfield and cities of similar size, the Boston Fed worked with its public, private, and philanthropic partners to come up with an idea to enhance leadership and spur transformative change. The Bank recently announced the Working Cities Challenge, a grant competition for smaller cities in Massachusetts that is designed to foster local collaboration to improve the economic health and well-being of low-income residents. Initiatives winning grants are expected to demonstrate cross-sector collaboration and involve groups that typically do not work together. Prize money is being provided by Living Cities, a national philanthropic collaborative; the Commonwealth of Massachusetts; and the Massachusetts Competitive Partnership; among others. The value of the competition goes beyond grant money, though that undoubtedly will help those who receive it. The real value of the competition is that it will encourage conversations among local stakeholders that are necessary to make real and lasting change. Moreover, participants will receive access to technical assistance and planning resources, as well as to a growing network of public, private, nonprofit, and philanthropic leaders in the state who are focused on improving the economies of its smaller cities. For practitioners of community development, as in any field, joining a network of like-minded professionals is important for building skills and becoming aware of opportunities and resources. NeighborWorks America, the leading provider of community development training in the country, has provided management and leadership training for community development professionals for more than 25 years. In the past few years, NeighborWorks has expanded its programs to develop leadership among its network organizations' executive directors and board members. Recognizing that effective board leadership is key to the health and effectiveness of its more than 235 member organizations across the country, NeighborWorks established the Achieving Excellence program in 2002 for its executive directors and others in the organization with significant responsibility. This 18-month program offers professional coaching and an opportunity to work with peers to solve a particular organizational challenge. NeighborWorks also trains community leaders through the Community Leaders Institute. The institute is an annual event that attracts some 800 resident leaders from across the country, making it the largest residential leadership development initiative in the field. Attendees arrive in teams of eight and choose from more than 40 workshops on topics such as public speaking, planning, youth development, and mobilizing senior citizens. After four days, the teams have not only learned new skills, but they have developed action plans addressing particular issues in their neighborhoods. They are given a $2,000 grant as seed money so that they can return to their communities and immediately go to work. More than 13,000 resident leaders have gone through the institute to date, and some cities have replicated the format to provide local training for residents.13These and similar programs not only train leaders, but they also create networks, partnerships, and the opportunity to learn from each other. ConclusionIn sum, community development is a complicated enterprise. Neighborhoods and communities are complex organisms that will be resilient only if they are healthy along a number of interrelated dimensions, much as a human body cannot be healthy without adequate air, water, rest, and food. But substantial coordination and dedication are needed to break through silos to simultaneously improve housing, connect residents to jobs, and help ensure access to adequate nutrition, health care, education, and day care. Moreover, each community has its own particular set of needs, which depend on local conditions and resources. Accordingly, local leadership, together with a vision of what each community can be, is essential. With that in mind, I want to thank all of you here today for the role you play in bringing your skills in research and analysis to the important work of rebuilding lower-income communities. Community development leaders have no shortage of commitment to their goals, but with the insights you provide, together with the opportunities to learn from the experiences of other communities, they will be better prepared and thus more successful in meeting the very difficult challenges they face. Thank you for being here. 1.For example, the Survey of Consumer Finances (SCF) data show that the average wealth of individuals in low- and moderate-income areas declined on a percentage basis more than that in higher-income areas (21 percent versus 17 percent). See the2007-09 SCF panel data.Return to text 2.Raven Molloy (2013), "Long-Term Vacant Housing Units: An Aggregate View," speech delivered at "Renters, Homeowners, and Investors: The Changing Profile of Communities," a conference sponsored by Board of Governors of the Federal Reserve System and Federal Reserve Banks of Philadelphia and Cleveland, Washington, February 26.Return to text 3.Alan Berube (2012), "The Continuing Evolution of American Poverty and Its Implications for Community Development (PDF)," in Federal Reserve Bank of San Francisco and Low Income Investment Fund,Investing in What Works for America's Communities: Essays on People, Place, and Purpose(San Francisco: FRBSF and LIIF), pp. 55-71.Return to text 4.Jane Jacobs (1961),The Death and Life of Great American Cities(New York: Random House).Return to text 5.Eric Klinenberg (2013), "Adaptation: How Can Cities Be ‘Climate-Proofed'?"New Yorker,January 7.Return to text 6.Shirley Franklin and David Edwards (2012), "It Takes a Neighborhood: Purpose Built Communities and Neighborhood Transformation (PDF)," in Federal Reserve Bank of San Francisco and Low Income Investment Fund,Investing in What Works for America's Communities: Essays on People, Place, and Purpose(San Francisco: FRBSF and LIIF), pp. 170-83.Return to text 7.For statistics cited in this paragraph, see pp. 177-78 in Franklin and Edwards,It Takes a Neighborhood(PDF), in note 6.Return to text 8.See Franklin and Edwards,It Takes a Neighborhood(PDF), in note 6.Return to text 9.Los Angeles Housing and Community Development (2013), "Five-Year Consolidated Plan 2013-2017 (PDF)" (Los Angeles: Community Development Department, February 26), Strategic Plan, p. 2, available on theLos Angeles CDD website.Return to text 10.Risa Lavizzo-Mourey (2012), "Why Health, Poverty, and Community Development Are Inseparable (PDF)," in Federal Reserve Bank of San Francisco and Low Income Investment Fund,Investing in What Works for America's Communities: Essays on People, Place, and Purpose(San Francisco: FRBSF and LIIF), pp. 215-25.Return to text 11.Researchers found that each 1 percent increase in 90-day mortgage delinquencies over a one-year period was associated with a 3 percent increase in hospital admissions due to child physical abuse and a 5 percent increase in admissions due to traumatic brain injury suspected to be caused by child abuse.Return to text 12.See Lavizzo-Mourey, "Health, Poverty, and Community Development (PDF)," in note 10.Return to text 13.Salt Lake City has formed its own leadership institute based on this model and has trained hundreds of local residents. In Seattle, training was provided in Vietnamese using translators and NeighborWorks staff. New Orleans, San Jose, and Charlotte have also begun to provide local leadership training for residents.Return to text
The Federal Open Market Committee on Friday announced its tentative meeting schedule for 2014: January 28-29 (Tuesday-Wednesday)March 18-19 (Tuesday-Wednesday)April 29-30 (Tuesday-Wednesday)June 17-18 (Tuesday-Wednesday)July 29-30 (Tuesday-Wednesday)September 16-17 (Tuesday-Wednesday)October 28-29 (Tuesday-Wednesday)December 16-17 (Tuesday-Wednesday)January 27-28, 2015 (Tuesday-Wednesday) The Chairman's quarterly news conferences will take place following the March, June, September, and December meetings.
The Federal Reserve Board on Wednesday announced that the redesigned $100 note will begin circulating on October 8, 2013. This note, which incorporates new security features such as a blue, 3-D security ribbon, will be easier for the public to authenticate but more difficult for counterfeiters to replicate. The new design for the $100 note was unveiled in 2010, but its introduction was postponed following an unexpected production delay. To ensure a smooth transition to the redesigned note when it begins circulating in October, the U.S. Currency Education Program is reaching out to businesses and consumers around the world to raise awareness about the new design and inform them about how to use its security features. More information about the new design $100 note, as well as training and educational materials, can be found atwww.newmoney.gov. For media inquiries, call 202-452-2955 Video The New Design $100 Note Current FAQs When will the new $100 note begin circulating? About the Fed Currency
The Federal Reserve plans to conduct fixed-rate offerings of term deposits with full allotment of tenders under the Term Deposit Facility (TDF) as part of the ongoing program of small-value offeringsannounced on September 8, 2010. The Board had previously announced that it would consider various formats for the TDF as part of the development of the facility. These small-value operations are designed to ensure the operational readiness of the TDF and to provide eligible institutions with an opportunity to gain familiarity with term deposit procedures. The development of the TDF and the ongoing small-value TDF operations are a matter of prudent planning and have no implications for the near-term conduct of monetary policy. The Federal Reserve plans to use a fixed-rate, full-allotment format to offer 28-day term deposits on May 20 with settlement on May 23. Under this format, the Federal Reserve will announce the operation interest rate, and each participating institution may submit one tender that will be awarded in full at the pre-determined rate. Official operation terms, including the fixed-rate and maximum tender size, will be announced nearer to the time of the operation. Additional information, including the steps that institutions must complete to be eligible to participate in term deposit operations are available athttp://www.frbservices.org/centralbank/term_deposit_facility.html. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Thursday announced the execution of the following enforcement action: HSH Nordbank AG (PDF), Hamburg, Germany and HSH Nordbank AG, New York Branch, New York, New YorkWritten Agreement dated March 25, 2013 Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Thursday announced the execution of the following enforcement action: Metropolitan Bank Group, Inc. (PDF), Chicago, IllinoisConsent Cease and Desist Order dated April 12, 2013 The Federal Reserve Board also announced the termination of the enforcement action listed below: IT & S of Iowa, Inc., Oskaloosa, IowaWritten Agreement dated June 16, 2009Terminated April 15, 2013 Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Tuesday announced the termination of the enforcement action listed below: Plumas Bancorp, Quincy, CaliforniaWritten Agreement dated July 25, 2011Terminated April 18, 2013 Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955.
The Federal Reserve Board on Wednesday announced approval of a final rule that establishes the requirements for determining when a company is "predominantly engaged in financial activities." The requirements will be used by the Financial Stability Oversight Council (FSOC) when it considers the potential designation of a nonbank financial company for consolidated supervision by the Federal Reserve. Under the Dodd-Frank Wall Street Reform and Consumer Protection Act, a nonbank financial company can be designated by the FSOC for supervision by the Federal Reserve only if it is "predominantly engaged in financial activities." A company is considered to be predominantly engaged in financial activities if 85 percent or more of the company's revenues or assets are related to activities that are defined as financial in nature under the Bank Holding Company Act. Additionally, the FSOC may issue recommendations for primary financial regulatory agencies to apply new or heightened standards to a financial activity or practice conducted by companies that are predominantly engaged in financial activities. The final rule largely adopts the approach in the proposed rule, with a few exceptions. For example, the final rule states that engaging in physically settled derivatives transactions generally will not be considered a financial activity, a change from the proposal. The final rule also defines the terms "significant nonbank financial company" and "significant bank holding company." Among the factors the FSOC must consider when determining whether to designate a nonbank financial company for consolidated supervision by the Federal Reserve is the extent and nature of the company's transactions and relationships with other significant nonbank financial companies and significant bank holding companies. If designated, those nonbank financial companies will be required to submit reports to the Federal Reserve, the FSOC, and the Federal Deposit Insurance Corporation on the company's credit exposure to other significant nonbank financial companies and significant bank holding companies as well as the credit exposure of such significant entities to the company. Consistent with the proposal, a firm will be considered significant if it has $50 billion or more in total consolidated assets or has been designated by the FSOC as systemically important. The final rule will become effective on May 6, 2013. For media inquiries, call 202-452-2955. Federal Register notice:HTML|PDF
The Federal Reserve Board on Thursday announced the finalization of standards for banking organizations regulated by the Federal Reserve that engage in certain types of foreign exchange transactions with retail customers. The rule, issued pursuant to the Dodd-Frank Wall Street Reform and Consumer Protection Act, establishes requirements for risk disclosures to customers, recordkeeping, business conduct, and documentation for retail foreign exchange transactions. Regulated institutions engaging in such transactions will be required to notify the Federal Reserve and to be well capitalized. They will also be required to collect margin for retail foreign exchange transactions.The types of transactions covered by the rule include foreign exchange transactions that are futures or options on futures, over-the-counter options on foreign currency, and so-called rolling spot transactions. The rule covers entities regulated by the Federal Reserve including state-chartered banks that are members of the Federal Reserve System, bank and savings and loan holding companies, Edge Act and agreement corporations, and uninsured, state-licensed branches and agencies of foreign banks.The Federal Reserve consulted with the Office of the Comptroller of the Currency and the Federal Deposit Insurance Corporation in developing the rule. The agencies have engaged in separate rulemakings as specified by Dodd-Frank.The rule will be effective on May 13, 2013.For media inquiries, call 202-452-2955.Federal Registernotice:HTML|PDF
The Federal Reserve Board on Monday invited comment on a proposal to establish an annual assessment of bank holding companies and savings and loan holding companies with $50 billion or greater in total consolidated assets and for nonbank financial companies designated by the Financial Stability Oversight Council for supervision by the Federal Reserve. The Dodd-Frank Wall Street Reform and Consumer Protection Act directs the Federal Reserve to collect assessments, fees, or other charges equal to the expenses the Board estimates are necessary and appropriate to carry out its supervisory and regulatory responsibilities for these large financial companies. The proposed rule outlines how the Federal Reserve Board would determine which companies are assessed, estimate the total expenses that are necessary or appropriate to carry out its supervisory and regulatory responsibilities for such companies, determine the amount of each company's assessment, and bill for and collect the assessments. Under the proposal, each calendar year would be an assessment period. The Federal Reserve would notify each company of the amount of its assessment no later than July 15 of the year following the assessment period. Payments would be due by September 30. Under the proposal, 2012 would be the first assessment period and payments would not be collected until the rule is finalized. Using the methodologies in the proposal, the Board estimates that for 2012 there would be approximately 70 companies assessed and the Board would collect a total of approximately $440 million. All assessments collected by the Federal Reserve would be transferred to the U.S. Treasury. Comments on the proposed rule must be submitted by June 15. For media inquiries, call 202-452-2955 Federal Registernotice:PDF|HTML Board Votes
The Federal Reserve Board on Thursday announced the execution of the following enforcement actions: Freedom Bancorporation, Inc. (PDF), Lindstrom, MinnesotaWritten Agreement dated April 22, 2013 Freedom Bank of Oklahoma (PDF), Tulsa, OklahomaWritten Agreement dated April 16, 2013 Search of Federal Reserve enforcement actions. For media inquiries, call 202-452-2955.
The paying agent for checks being sent to borrowers under the Independent Foreclosure Review has assured the Federal Reserve Board that early problems with some checks have been corrected and that funds are available to cash all checks. Some early recipients of checks informed the Federal Reserve's consumer helpline on Tuesday that they were told their checks could not be cashed. Members of the Board staff contacted the paying agent, Rust Consulting, Inc., and the paying bank, The Huntington National Bank. Rust subsequently corrected problems that led to some checks being rejected. The Board will continue to monitor the payments closely and encourages borrowers who have concerns or experience difficulties cashing their checks to call Rust at 1-888-952-9105. As previously announced, on April 12, payments began to 4.2 million borrowers following an agreement reached by federal bank regulatory agencies and 13 mortgage servicers. More than 50,000 people have already cashed or deposited checks. For media inquiries, call 202-452-2955
Chairman Ben S. Bernanke At the 13th Annual Redefining Investment Strategy Education (RISE) Forum, Dayton, Ohio (via prerecorded video) Hello. I'm Ben Bernanke, Chairman of the Board of Governors of the Federal Reserve System. I appreciate this opportunity to speak to the business and finance students and faculty--as well as the practicing financial professionals--attending the University of Dayton's 13th annual RISE forum.1Before I became Chairman, I had the pleasure of addressing the 5th annual forum as a member of the Board of Governors in 2005.2At that time, I spoke about the implementation of monetary policy and how crucial effective communication is to that implementation. Although I cannot join you in person this year, I note from the conference agenda that you are hearing from two Federal Reserve Bank presidents--Charles Evans of Chicago and Dennis Lockhart of Atlanta--as well as former Federal Reserve Board Vice Chairman Roger Ferguson. Effective communication in monetary policy is more important than ever, and I have little doubt that my current and former colleagues will provide you with insights about the Federal Reserve's ongoing efforts to achieve the goals that the Congress has given us: maximum employment and price stability. In my brief remarks today, I would like to mention another important mission of the Federal Reserve--promoting economic and financial knowledge among people of all ages and walks of life. The Board in Washington and the 12 Federal Reserve Banks throughout the country are all deeply involved in economic education and supporting the work of teachers, schools, and national organizations. For example, the Federal Reserve provides a financial and economic education website with a variety of resources for teachers as well as for students of various ages and levels of knowledge.3The site offers educational games, classroom lesson plans, online publications, and multimedia tools. Federal Reserve Banks offer professional development opportunities for teachers to improve their ability to present lessons on personal finance topics. A number of Reserve Banks also organize personal finance essay, video, and academic competitions for students. And we encourage students and teachers to visit Federal Reserve Bank learning centers and museums, which feature interactive exhibits about many aspects of banking, the financial system, and the economy. Among the lessons of the recent financial crisis is the need for virtually everyone--both young and old--to acquire a basic knowledge of finance and economics. Such knowledge is necessary for anyone who will be faced with managing a household budget, making financial investments, finding reliable information about buying a car or house, and preparing financially for retirement and other life goals. Accordingly, in addition to ensuring that students graduate with the financial literacy skills they need to navigate in the modern financial world, we, as a society, must also make sure that adults have opportunities to gain these skills or to refresh what they have learned. Many of you are, or will be, practitioners in the financial services industry--perhaps serving retail clients--and in that capacity I hope you will make the promotion of financial and economic education a part of your mission as well. These skills not only help people provide a better life for themselves and their families, but, by deepening their understanding of the world economy, having such skills also helps equip them to be engaged citizens and informed voters. Let me close by congratulating the University of Dayton for its leadership in hosting the RISE forum. I hope this innovative program, which I'm told is the world's largest student investment conference, succeeds in its ambitious goal of bringing together the current and future leaders of finance to focus on creating a better economic future. 1.RISE is Redefining Investment Strategy Education. For more information, seewww.udayton.edu/business/rise.Return to text 2.See Ben S. Bernanke (2005), "Remarks by Governor Ben S. Bernanke," speech delivered at the Redefining Investment Strategy Education Symposium, Dayton, Ohio, March 30.Return to text 3.See the Federal Reserve Education website,www.federalreserveeducation.org.Return to text
Governor Jeremy C. Stein At the "Finding the Right Balance" 2013 Credit Markets Symposium sponsored by the Federal Reserve Bank of Richmond, Charlotte, North Carolina I'd like to talk today about one important element of the international regulatory reform agenda--namely, liquidity regulation.1Liquidity regulation is a relatively new, post-crisis addition to the financial stability toolkit. Key elements include the Liquidity Coverage Ratio (LCR), which was recently finalized by the Basel Committee on Banking Supervision, and the Net Stable Funding Ratio, which is still a work in progress. In what follows, I will focus on the LCR. The stated goal of the LCR is straightforward, even if some aspects of its design are less so. In the words of the Basel Committee, "The objective of the LCR is to promote the short-term resilience of the liquidity risk profile of banks. It does this by ensuring that banks have an adequate stock of unencumbered high-quality liquid assets (HQLA) that can be converted easily and immediately in private markets into cash to meet their liquidity needs for a 30 calendar day liquidity stress scenario."2In other words, each bank is required to model its total outflows over 30 days in a liquidity stress event and then to hold HQLA sufficient to accommodate those outflows. This requirement is implemented with a ratio test, where modeled outflows go in the denominator and the stock of HQLA goes in the numerator; when the ratio equals or exceeds 100 percent, the requirement is satisfied. The Basel Committee issued the first version of the LCR in December 2010. In January of this year, the committee issued a revised final version of the LCR, following an endorsement by its governing body, the Group of Governors and Heads of Supervision (GHOS). The revision expands the range of assets that can count as HQLA and also adjusts some of the assumptions that govern the modeling of net outflows in a stress scenario. In addition, the committee agreed in January to a gradual phase-in of the LCR, so that it only becomes fully effective on an international basis in January 2019. On the domestic front, the Federal Reserve expects that the U.S. banking agencies will issue a proposal later this year to implement the LCR for large U.S. banking firms. While this progress is welcome, a number of questions remain. First, to what extent should access to liquidity from a central bank be allowed to count toward satisfying the LCR? In January, the GHOS noted that the interaction between the LCR and the provision of central bank facilities is critically important. And the group instructed the Basel Committee to continue working on this issue in 2013. Second, what steps should be taken to enhance the usability of the LCR buffer--that is, to encourage banks to actually draw down their HQLA buffers, as opposed to fire-selling other less liquid assets? The GHOS has also made clear its view that, during periods of stress, it would be appropriate for banks to use their HQLA, thereby falling below the minimum. However, creating a regime in which banks voluntarily choose to do so is not an easy task. A number of observers have expressed the concern that if a bank is held to an LCR standard of 100 percent in normal times, it may be reluctant to allow its ratio to drop below 100 percent when facing large outflows, even if regulators were to permit this temporary deviation, for fear that a decline in the ratio could be interpreted as a sign of weakness. My aim here is to sketch a framework for thinking about these and related issues. Among them, the interplay between the LCR and central bank liquidity provision is perhaps the most fundamental and a natural starting point for discussion. By way of motivation, note that before the financial crisis, we had a highly developed regime of capital regulation for banks--albeit one that looks inadequate in retrospect--but we did not have formal regulatory standards for their liquidity.3The introduction of liquidity regulation after the crisis can be thought of as reflecting a desire to reduce dependence on the central bank as a lender of last resort (LOLR), based on the lessons learned over the previous several years. However, to the extent that some role for the LOLR still remains, one now faces the question of how it should coexist with a regime of liquidity regulation. To address this question, it is useful to take a step back and ask another one: What underlying market failure is liquidity regulation intended to address, and why can't this market failure be handled entirely by an LOLR? I will turn to this question first. Next, I will consider different mechanisms that could potentially achieve the goals of liquidity regulation, and how these mechanisms relate to various features of the LCR. In so doing, I hope to illustrate why, even though liquidity regulation is a close cousin of capital regulation, it nevertheless presents a number of novel challenges for policymakers and why, as a result, we are going to have to be open to learning and adapting as we go. The Case for Liquidity RegulationOne of the primary economic functions of banks and other financial intermediaries, such as broker-dealers, is to provide liquidity--that is, cash on demand--in various forms to their customers. Some of this liquidity provision happens on the liability side of the balance sheet, with bank demand deposits being a leading example. But, importantly, banks also provide liquidity via committed lines of credit. Indeed, it is probably not a coincidence that these two products--demand deposits and credit lines--are offered under the roof of the same institution; the underlying commonality is that both require an ability to accommodate unpredictable requests for cash on short notice.4A number of other financial intermediary services, such as prime brokerage, also embody a significant element of liquidity provision. Without question, these liquidity-provision services are socially valuable. On the liability side, demand deposits and other short-term bank liabilities are safe, easy-to-value claims that are well suited for transaction purposes and hence create a flow of money-like benefits for their holders.5And loan commitments are more efficient than an arrangement in which each operating firm hedges its future uncertain needs by "pre-borrowing" and hoarding the proceeds on its own balance sheet; this latter approach does a poor job of economizing on the scarce aggregate supply of liquid assets.6 At the same time, as the financial crisis made painfully clear, the business of liquidity provision inevitably exposes financial intermediaries to various forms of run risk. That is, in response to adverse events, their fragile funding structures, together with the binding liquidity commitments they have made, can result in rapid outflows that, absent central bank intervention, lead banks to fire-sell illiquid assets or, in a more severe case, to fail altogether. And fire sales and bank failures--and the accompanying contractions in credit availability--can have spillover effects to other financial institutions and to the economy as a whole. Thus, while banks will naturally hold buffer stocks of liquid assets to handle unanticipated outflows, they may not hold enough because, although they bear all the costs of this buffer stocking, they do not capture all of the social benefits, in terms of enhanced financial stability and lower costs to taxpayers in the event of failure. It is this externality that creates a role for policy. There are two broad types of policy tools available to deal with this sort of liquidity-based market failure. The first is after-the-fact intervention, either by a deposit insurer guaranteeing some of the bank's liabilities or by a central bank acting as an LOLR; the second type is liquidity regulation. As an example of the former, when the economy is in a bad state, assuming that a particular bank is not insolvent, the central bank can lend against illiquid assets that would otherwise be fire-sold, thereby damping or eliminating the run dynamics and helping reduce the incidence of bank failure. In much of the literature on banking, such interventions are seen as the primary method for dealing with run-like liquidity problems. A classic statement of the central bank's role as an LOLR is Walter Bagehot's 1873 bookLombard Street. More recently, the seminal theoretical treatment of this issue is by Douglas Diamond and Philip Dybvig, who show that under certain circumstances, the use of deposit insurance or an LOLR can eliminate run risk altogether, thereby increasing social welfare at zero cost.7To be clear, this work assumes that the bank in question is fundamentally solvent, meaning that while its assets may not be liquid on short notice, the long-run value of these assets is known with certainty to exceed the value of the bank's liabilities.8One way to interpret the message of this research is that capital regulation is important to ensure solvency, but once a reliable regime of capital regulation is in place, liquidity problems can be dealt with after the fact, via some combination of deposit insurance and use of the LOLR. It follows that if one is going to make an argument in favor of adding preventative liquidity regulation such as the LCR on top of capital regulation, a central premise must be that the use of LOLR capacity in a crisis scenario is socially costly, so that it is an explicit objective of policy to economize on its use in such circumstances. I think this premise is a sensible one.9A key point in this regard--and one that has been reinforced by the experience of the past several years--is that the line between illiquidity and insolvency is far blurrier in real life than it is sometimes assumed to be in theory. Indeed, one might argue that a bank or broker-dealer that experiences a liquidity crunch must have some probability of having solvency problems as well; otherwise, it is hard to see why it could not attract short-term funding from the private market. This reasoning implies that when the central bank acts as an LOLR in a crisis, it necessarily takes on some amount of credit risk. And if it experiences losses, these losses ultimately fall on the shoulders of taxpayers. Moreover, the use of an LOLR to support banks when they get into trouble can lead to moral hazard problems, in the sense that banks may be less prudent ex ante. If it were not for these costs of using LOLR capacity, the problem would be trivial, and there would be no need for liquidity regulation: Assuming a well-functioning capital-regulation regime, the central bank could always avert all fire sales and bank failures ex post, simply by acting as an LOLR. This observation carries an immediate implication: It makes no sense to allow unpriced access to the central bank's LOLR capacity to count toward an LCR requirement. Again, the whole point of liquidity regulation must be either to conserve on the use of the LOLR or in the limit, to address situations where the LOLR is not available at all--as, for example, in the case of broker-dealers in the United States.10 At the same time, it is important to draw a distinction between priced and unpriced access to the LOLR. For example, take the case of Australia, where prudent fiscal policy has led to a relatively small stock of government debt outstanding and hence to a potential shortage of HQLA. The Basel Committee has agreed to the use by Australia of a Committed Liquidity Facility (CLF), whereby an Australian bank can pay the Reserve Bank of Australia an up-front fee for what is effectively a loan commitment, and this loan commitment can then be counted toward its HQLA. In contrast to free access to the LOLR, this approach isnotat odds with the goals of liquidity regulation because the up-front fee is effectively a tax that serves to deter reliance on the LOLR--which, again, is precisely the ultimate goal. I will return to the idea of a CLF shortly. The Design of RegulationOnce it has been decided that liquidity regulation is desirable, the next question is how best to implement it. In this context, note that the LCR has two logically distinct aspects as a regulatory tool: It is a mitigator, in the sense that holding liquid assets leads to a better outcome if there is a bad shock; it is also an implicit tax on liquidity provision by banks, to the extent that holding liquid assets is costly. Of course, one can say something broadly similar about capital requirements. But the implicit tax associated with the LCR is subtler and less well understood, so I will go into some detail here. An analogy may help to explain. Suppose we have a power plant that produces energy and, as a byproduct, some pollution. Suppose further that regulators want to reduce the pollution and have two tools at their disposal: They can mandate the use of a pollution-mitigating technology, like scrubbers, or they can levy a tax on the amount of pollution generated by the plant. In an ideal world, regulation would accomplish two objectives. First, it would lead to an optimal level of mitigation--that is, it would induce the plant to install scrubbers up to the point where the cost of an additional scrubber is equal to the marginal social benefit, in terms of reduced pollution. And, second, it would also promote conservation: Given that the scrubbers don't get rid of pollution entirely, one also wants to reduce overall energy consumption by making it more expensive. A simple case is one in which the costs of installing scrubbers, as well as the social benefits of reduced pollution, are known in advance by the regulator and the manager of the power plant. In this case, the regulator can figure out what the right number of scrubbers is and require that the plant install these scrubbers. The mandate can therefore precisely target the optimal amount of mitigation per unit of energy produced. And, to the extent that the scrubbers are costly, the mandate will also lead to higher energy prices, which will encourage some conservation, though perhaps not the socially optimal level.11This latter effect is the implicit tax aspect of the mandate. A more complicated case is when the regulator does not know ahead of time what the costs of building and installing scrubbers will be. Here, mandating the use of a fixed number of scrubbers is potentially problematic: If the scrubbers turn out to be very expensive, the regulation will end up being more aggressive than socially desirable, leading to overinvestment in scrubbers and large cost increases for consumers; however, if the scrubbers turn out to be cheaper than expected, the regulation will have been too soft. In other words, when the cost of the mitigation technology is significantly uncertain, a regulatory approach that fixes the quantity of mitigation is equivalent to one where the implicit tax rate bounces around a lot. By contrast, a regulatory approach that fixes the price of pollution instead of the quantity--say, by imposing a predetermined proportional tax rate directly on the amount of pollution emitted by the plant--is more forgiving in the face of this kind of uncertainty. This approach leaves the scrubber-installation decision to the manager of the plant, who can figure out what the scrubbers cost before deciding how to proceed. For example, if the scrubbers turn out to be unexpectedly expensive, the plant manager can install fewer of them. This flexibility translates into less variability in the effective regulatory burden and hence less variability in the price of energy to consumers.12 Scrubbers and High-Quality Liquid AssetsWhat does all this imply for the design of the LCR? Let's work through the analogy in detail. The analog to the power plant's energy output is the gross amount of liquidity services created by a bank--via its deposits, the credit lines it provides to its customers, the prime brokerage services it offers, and so forth. The analog to the mitigation technology--the scrubbers--is the stock of HQLA that the bank holds. And the analog to pollution is the net liquidity risk associated with the difference between these two quantities, something akin to the LCR shortfall. That is, when the bank offers a lot of liquidity on demand to its customers but fails to hold an adequate buffer of HQLA, this is when it imposes spillover costs on the rest of the financial system. In the case of the power plant, I argued that a regulation that calls for a fixed quantity of mitigation--that is, for a fixed number of scrubbers--is more attractive when there is little uncertainty about the cost of these scrubbers. In the context of the LCR, the cost of mitigation is the premium that the bank must pay--in the form of reduced interest income--for its stock of HQLA. And, crucially, this HQLA premium is determined in market equilibrium and depends on the total supply of safe assets in the system, relative to the demand for those assets. On the one hand, if safe HQLA-eligible assets are in ample supply, the premium is likely to be low and stable. On the other hand, if HQLA-eligible assets are scarce, the premium will be both higher and more volatile over time. This latter situation is the one facing countries like Australia, where, as I noted earlier, the stock of outstanding government securities is relatively small. And it explains why, for such countries, having a price-based mechanism as part of their implementation of the LCR can be more appealing than pure reliance on a quantity mandate. When one sets an up-front fee for a CLF, one effectively caps the implicit tax associated with liquidity regulation at the level of the commitment fee and tamps down the undesirable volatility that would otherwise arise from an entirely quantity-based regime. Moreover, it bears reemphasizing that having a CLF with an up-front fee is very different from simply allowing banks to count central-bank-eligible collateral as HQLA at no charge. Rather, the CLF is like the pollution tax. For every dollar of pre-CLF shortfall--that is, for every dollar of required liquidity that a bank can't obtain on the private market--the bank has to pay the commitment fee. So even if there is not as much mitigation, there is still an incentive for conservation, in the sense that banks are encouraged to do less liquidity provision, all else being equal. This would not be the case if the CLF were available at a zero price. What about the situation in countries where safe assets are more plentiful? The analysis here has a number of moving parts because in addition to the implementation of the LCR, substantial increases in demand for safe assets will arise from new margin requirements for both cleared and noncleared derivatives. Nevertheless, given the large and growing global supply of sovereign debt securities, as well as other HQLA-eligible assets, most estimates suggest that the scarcity problem should be manageable, at least for the foreseeable future. In particular, quantitative impact studies released by the Basel Committee estimate that the worldwide incremental demand for HQLA coming from both the implementation of the LCR and swap margin requirements might be on the order of $3 trillion.13This is a large number, but it compares with a global supply of HQLA-eligible assets of more than $40 trillion.14Moreover, the eligible collateral for swap margin is proposed to be broader than the LCR's definition of HQLA--including, for example, certain equities and corporate bonds without any cap. If one focuses just on U.S. institutions, the incremental demand number is on the order of $1 trillion, while the sum of Treasury, agency, and agency mortgage-backed securities is more than $19 trillion.15 While this sort of analysis is superficially reassuring, the fact remains that the HQLA premium will depend on market-equilibrium considerations that are hard to fully fathom in advance, and that are likely to vary over time. This uncertainty needs to be understood, and respected. Indeed, the market-equilibrium aspect of the problem represents a crucial distinction between capital regulation and liquidity regulation, and it is one reason why the latter is particularly challenging to implement. Although capital regulation also imposes a tax on banks‑‑to the extent that equity is a more expensive form of finance than debt--this tax wedge is, to a first approximation, a fixed constant for a given bank, independent of the scale of overall financial intermediation activity. If Bank A decides to issue more equity so it can expand its lending business, this need not make it more expensive for Bank B to satisfy its capital requirement. In other words, there is no scarcity problem with respect to bank equity--both A and B can always make more. By contrast, the total supply of HQLA is closer to being fixed at any point in time.16 Policy ImplicationsWhat does all of this imply for policy design? First, at a broad philosophical level, the recognition that liquidity regulation involves more uncertainty about costs than capital regulation suggests that even a policymaker with a very strict attitude toward capital might find it sensible to be somewhat more moderate and flexible with respect to liquidity. This point is reinforced by the observation that when an institution is short of capital and can't get more on the private market, there is really no backup plan, short of resolution. By contrast, as I mentioned earlier, when an institution is short of liquidity, policymakers do have a backup plan in the form of the LOLR facility. One does not want to rely too much on that backup plan, but its presence should nevertheless factor into the design of liquidity regulation. Second, in the spirit of flexibility, while a price-based mechanism such as the CLF may not be immediately necessary in countries outside of Australia and a few others, it is worth keeping an open mind about the more widespread use of CLF-like mechanisms. If a scarcity of HQLA-eligible assets turns out to be more of a problem than we expect, something along those lines has the potential to be a useful safety valve, as it puts a cap on the cost of liquidity regulation. Such a safety valve would have a direct economic benefit, in the sense of preventing the burden of regulation from getting unduly heavy in any one country. Perhaps just as important, a safety valve might also help to protect the integrity of the regulation itself, by harmonizing costs across countries and thereby reducing the temptation of those most hard-hit by the rules to try to chip away at them. Without such a safety valve, it is possible that some countries--those with relatively small supplies of domestic HQLA--will find the regulation considerably more costly than others. If so, it would be natural for them to lobby to dilute the rules--for example, by arguing for an expansion in the type of assets that can count as HQLA. Taken too far, this sort of dilution would undermine the efficacy of the regulation as both a mitigator and a tax. In this scenario, holding the line with what amounts to a proportional tax on liquidity provision would be a better outcome.17 One situation where liquid assets can become unusually scarce is during a financial crisis. Consequently, even if CLFs were not counted toward the LCR in normal times, it might be appropriate to count them during a crisis. Indeed, while the LCR requires banks to hold sufficient liquid assets in good times to meet their outflows in a given stress scenario, it implicitly recognizes that if things turn out even worse than that scenario, central bank liquidity support will be needed. Allowing CLFs to count toward the LCR in such circumstances would acknowledge the importance of access to the central bank, and this access could be priced accordingly. Finally, a price-based mechanism might also help promote a willingness of banks to draw down their supply of HQLA in a stress scenario. As I noted at the outset, one important concern about a pure quantity-based system of regulation is that if a bank is held to an LCR standard of 100 percent in normal times, it may be reluctant to allow its ratio to fall below 100 percent when facing large outflows for fear that doing so might be seen by market participants as a sign of weakness. By contrast, in a system with something like a CLF, a bank might in normal times meet 95 percent of its requirement by holding private-market HQLA and the remaining 5 percent with committed credit lines from the central bank, so it would have an LCR of exactly 100 percent. Then, when hit with large outflows, it could maintain its LCR at 100 percent, but do so by increasing its use of central bank credit lines to 25 percent and selling 20 percent of its other liquid assets.18This scenario would be the sort of liquid-asset drawdown that one would ideally like to see in a stress situation. Moreover, the central bank could encourage this drawdown by varying the pricing of its credit lines--specifically, by reducing the price of the lines in the midst of a liquidity crisis. Such an approach would amount to taxing liquidity provision more in good times than in bad, which has a stabilizing macroprudential effect. This example also suggests a design that may have appeal in jurisdictions where there is a relatively abundant supply of HQLA-eligible assets. One can imagine calibrating the pricing of the CLF so as to ensure that lines provided by central banks make up only a minimal fraction of banks' required HQLA in normal times--apart, perhaps, from the occasional adjustment period after an individual bank is hit with an idiosyncratic liquidity shortfall. At the same time, in a stress scenario, when liquidity is scarce and there is upward pressure on the HQLA premium, the pricing of the CLF could be adjusted so as to relieve this pressure and promote usability of the HQLA buffer. Such an approach would respect the policy objective of reducing expected reliance on the LOLR while at the same time allowing for a safety valve in a period of stress. The limit case of this approach is one where the CLF counts toward the LCR only in a crisis. ConclusionBy way of conclusion, let me just restate that liquidity regulation has a key role to play in improving financial stability. However, we should avoid thinking about it in isolation; rather, we can best understand it as part of a larger toolkit that also includes capital regulation and, importantly, the central bank's LOLR function. Therefore, proper design and implementation of liquidity regulations such as the LCR should take account of these interdependencies. In particular, policymakers should aim to strike a balance between reducing reliance on the LOLR on the one hand and moderating the costs created by liquidity shortages on the other hand--especially those shortages that crop up in times of severe market strain. And, as always, we should be prepared to learn from experience as we go. 1.The views that follow are my own and are not necessarily shared by my colleagues on the Federal Reserve Board. I am grateful to members of the Board staff--Sean Campbell, Mark Carlson, Burcu Duygan-Bump, Michael Gibson, William Nelson, and Mark Van Der Weide--for many helpful conversations and suggestions.Return to text 2.See Basel Committee on Banking Supervision (2013),Basel III: The Liquidity Coverage Ratio and Liquidity Risk Monitoring Tools (PDF)(Basel: Bank for International Settlements, January), p. 1.Return to text 3.Although bank liquidity was not regulated prior to the crisis, it played an important part in the supervisory process. For example, in the CAMELS ratings used by supervisors, the "L" stands for "liquidity."Return to text 4.For an elaboration of this argument, see Anil K. Kashyap, Raghuram Rajan, and Jeremy C. Stein (2002), "Banks as Liquidity Providers: An Explanation for the Coexistence of Lending and Deposit-Taking,"Journal of Finance, vol. 57 (February), pp. 33-73.Return to text 5.See Gary Gorton and George Pennacchi (1990), "Financial Intermediaries and Liquidity Creation,"Journal of Finance, vol. 45 (March), pp. 49-71. Demand deposits may also represent a form of insurance against liquidity shocks, as argued in Douglas W. Diamond and Philip H. Dybvig (1983), "Bank Runs, Deposit Insurance, and Liquidity,"Journal of Political Economy, vol. 91 (June), pp. 401-19.Return to text 6.See Bengt Holmström and Jean Tirole (1998), "Private and Public Supply of Liquidity,"Journal of Political Economy, vol. 106 (February), pp. 1-40.Return to text 7.See Diamond and Dybvig, "Bank Runs," in note 5.Return to text 8.The underlying premise of solvency is captured in Bagehot's famous dictum for use of the LOLR: In times of crisis, the central bank should lend freely (and at a penalty rate) to banks, provided that the banks are solvent and that the loans are adequately collateralized. See Walter Bagehot ([1873] 1999),Lombard Street: A Description of the Money Market(London: King; reprint, New York: Wiley).Return to text 9.This is, of course, not to say that the LOLR should not be used in extreme circumstances--only that doing so comes with a cost, so policy should seek to reduce the likelihood that it will have to be used.Return to text 10.The fact that broker-dealers do not have access to the LOLR in the United States is, of course, ultimately a policy choice, and one that can be thought of as reflecting exactly the considerations discussed here: Whatever its merits, extending the LOLR to broker-dealers would increase taxpayer exposure and potentially exacerbate moral hazard problems. Hence there may be a rationale for restricting its availability and relying on regulation instead.Return to text 11.Even in this simple full-information case, one cannot generally attain the social optimum on both the mitigation and conservation dimensions using just a mandate to install scrubbers as the only regulatory instrument. By contrast, a tax on pollution, which decentralizes output and mitigation decisions to the firm, can, under full information, attain the optimum on both dimensions.Return to text 12.On the flip side, however, the same flexibility means that there will be more variability in the total amount of pollution generated by the plant--because when costs of mitigation are high, less mitigation will be done. So in the face of uncertainty, one cannot conclude that a price-based tax regime is necessarily superior to a quantity-based mitigation regime. This reasoning follows the classic analysis of Weitzman; see Martin L. Weitzman (1974), "Prices vs. Quantities,"Review of Economic Studies, vol. 41 (October), pp. 477-91.Return to text 13.To be more precise, global incremental demand coming from swap margin requirements is estimated at $1.24 trillion; see Basel Committee on Banking Supervision and Board of the International Organization of Securities Commissions (2013),Margin Requirements for Non-Centrally Cleared Derivatives: Second Consultative Document(Basel: Bank for International Settlements and IOSCO, February). Of this $1.24 trillion, $810 billion reflects margin (net of collateral already collected) on uncleared swaps, and $420 billion reflects margin on swaps that will migrate to central clearing. In addition, global incremental demand coming from the LCR is estimated at $2.39 trillion; see Basel Committee on Banking Supervision (2012),Results of the Basel III Monitoring Exercise as of 30 June 2011(Basel: Bank for International Settlements, April). However this latter number is based on the December 2010 version of the LCR; the recalibration of the LCR in the January 2013 final version will reduce this value for U.S. banks by roughly one-third. Extrapolating this result to the global level suggests that incremental demand resulting from the LCR will fall by roughly $800 billion to $1.6 trillion.Return to text 14.Committee on the Global Financial System (forthcoming), Asset Encumbrance, Financial Reform and the Demand for Collateral Assets (Basel: Bank for International Settlements).Return to text 15.According to Federal Reserve Board flow of funds data, as of December 31, 2012 the total stock of U.S. Treasury securities stood at $11.6 trillion, and the total stock of agency debt and mortgage-backed securities stood at $7.5 trillion. A caveat here is that agency mortgage-backed securities are considered Level 2 assets, so they can count for at most 40 percent of any bank's total holdings of HQLA.Return to text 16.This is not to say that banks cannot adjust on other margins if HQLA is in unexpectedly short supply. For example, they can do less liquidity provision, by terming out their funding or by extending fewer credit lines. This is like the power plant doing more conservation and less mitigation: It reduces the upward pressure on the price of scrubbers (or HQLA), at the cost of cutting back on a set of services that presumably has some social value.Return to text 17.To be sure, it is possible that the rules could be diluted in the context of a price-based CLF mechanism as well, for example, through the administration of collateral-eligibility criteria or haircut requirements.Return to text 18.This presumes that the bank in question is able to present adequate collateral to the central bank to secure the central bank credit line.Return to text
The Federal Reserve Board on Tuesday released the minutes of its discount rate meetings from February 11 through March 18, 2013. The minutes are attached. For media inquiries, call 202-452-2955.
The Federal Reserve Board and the Federal Open Market Committee on Wednesday released the attached minutes of the Committee meeting held on March 19-20, 2013. A summary of economic projections made by Federal Reserve Board members and Reserve Bank presidents for the March 19-20, 2013 meeting is also included as an addendum to these minutes. The minutes for each regularly scheduled meeting of the Committee ordinarily are made available three weeks after the day of the policy decision and subsequently are published in the Board's Annual Report. Summaries of economic projections are released on a quarterly schedule. The descriptions of economic and financial conditions contained in these minutes and in the Summary of Economic Projections are based solely on the information that was available to the Committee at the time of the meeting. The FOMC minutes can be viewed on the Board's website atwww.federalreserve.gov/monetarypolicy/fomccalendars.htm Minutes of the Federal Open Market CommitteeMarch 19-20, 2013:HTML|PDF
Vice Chair Janet L. Yellen At the "Rethinking Macro Policy II," a conference sponsored by the International Monetary Fund, Washington, D.C. Thank you to the International Monetary Fund for allowing me to take part in what I expect will be a very lively discussion.1 Only five or six years ago, there wouldn't have been a panel on the "many instruments" and "many targets" of monetary policy. Before the financial crisis, the focus was on one policy instrument: the short-term policy interest rate. While central banks did not uniformly rely on a single policy target, many had adopted an "inflation targeting" framework that, as the name implies, gives a certain preeminence to that one objective. Of course, the Federal Reserve has long been a bit of an outlier in this regard, with its explicit dual mandate of price stability and maximum employment. Still, the discussion might not have gone much beyond "one instrument and two targets" if not for the financial crisis and its aftermath, which have presented central banks with great challenges and transformed how we look at this topic. Let me start with a few general observations to get the ball rolling. In terms of the targets, or, more generally, the objectives of policy, I see continuity in the abiding importance of a framework of flexible inflation targeting. By one authoritative account, about 27 countries now operate full-fledged inflation-targeting regimes.2The United States is not on this list, but the Federal Reserve has embraced most of the key features of flexible inflation targeting: a commitment to promote low and stable inflation over a longer-term horizon, a predictable monetary policy, and clear and transparent communication. The Federal Open Market Committee (FOMC) struggled for years to formulate an inflation goal that would not seem to give preference to price stability over maximum employment. In January 2012, the Committee adopted a "Statement on Longer-Run Goals and Monetary Policy Strategy," which includes a 2 percent longer-run inflation goal along with numerical estimates of what the Committee views as the longer-run normal rate of unemployment. The statement also makes clear that the FOMC will take a "balanced approach" in seeking to mitigate deviations of inflation from 2 percent and employment from estimates of its maximum sustainable level. I see this language as entirely consistent with modern descriptions of flexible inflation targeting. For the past four years, a major challenge for the Federal Reserve and many other central banks has been how to address persistently high unemployment when the policy rate is at or near the effective lower bound. This troubling situation has naturally and appropriately given rise to extensive discussion about alternative policy frameworks. I have been very keen, however, to retain what I see as the key ingredient of a flexible inflation-targeting framework: clear communication about goals and how central banks intend to achieve them. With respect to the Federal Reserve's goals, price stability and maximum employment are not only mandated by the Congress, but also easily understandable and widely embraced. Well-anchored inflation expectations have proven to be an immense asset in conducting monetary policy. They've helped keep inflation low and stable while monetary policy has been used to help promote a healthy economy. After the onset of the financial crisis, these stable expectations also helped the United States avoid excessive disinflation or even deflation. Of course, many central banks have, in the wake of the crisis, found it challenging to provide appropriate monetary stimulus after their policy interest rate hit the effective lower bound. This is the point where "many instruments" enters the discussion. The main tools for the FOMC have been forward guidance on the future path of the federal funds rate and large-scale asset purchases. The objective of forward guidance is to affect expectations about how long the highly accommodative stance of the policy interest rate will be maintained as conditions improve. By lowering private-sector expectations of the future path of short-term rates, this guidance can reduce longer-term interest rates and also raise asset prices, in turn, stimulating aggregate demand. Absent such forward guidance, the public might expect the federal funds rate to follow a path suggested by past FOMC behavior in "normal times"--for example, the behavior captured by John Taylor's famous Taylor rule. I am persuaded, however, by the arguments laid out by our panelist Michael Woodford and others suggesting that the policy rate should, under present conditions, be held "lower for longer" than conventional policy rules imply. I see these ideas reflected in the FOMC's recent policy. Since September 2012, the FOMC has stated that a highly accommodative stance of monetary policy will remain appropriate for a considerable time after the economic recovery strengthens. Since December 2012, the Committee has said it intends to hold the federal funds rate near zero at least until unemployment has declined below 6-1/2 percent, provided that inflation between one and two years ahead is projected to be no more than 1/2 percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored. I believe that the clarity of this commitment to accommodation will itself support spending and employment and help to strengthen the recovery. Asset purchases have complemented our forward guidance, and the many dimensions of different purchase programs arguably constitute "many instruments." In designing a purchase program, one must consider which assets to buy: Just Treasury securities or agency mortgage-backed securities as well? Which maturities? The Federal Reserve, the Bank of England, and, more recently, the Bank of Japan have emphasized longer-duration securities. At what pace should the securities be purchased? And how long should they be held once purchases cease? Each of these factors may affect the degree of accommodation delivered. Two innovations in the FOMC's current asset purchase program, for example, are that it is open-ended rather than fixed in size like past programs, and that the overall size of the program is explicitly linked to seeing a substantial improvement in the outlook for the labor market. In these brief remarks, I won't thoroughly review the benefits or costs of our highly accommodative policies, emphasizing only that I believe they have, on net, provided meaningful support to the recovery. But I do want to spend a moment on one potential cost--financial stability--because this topic returns us to the theme of "many targets" for central banks. As Chairman Bernanke has observed, in the years before the crisis, financial stability became a "junior partner" in the monetary policy process, in contrast with its traditionally larger role. The greater focus on financial stability is probably the largest shift in central bank objectives wrought by the crisis. Some have asked whether the extraordinary accommodation being provided in response to the financial crisis may itself tend to generate new financial stability risks. This is a very important question. To put it in context, let's remember that the Federal Reserve's policies are intended to promote a return to prudent risk-taking, reflecting a normalization of credit markets that is essential to a healthy economy. Obviously, risk-taking can go too far. Low interest rates may induce investors to take on too much leverage and reach too aggressively for yield. I don't see pervasive evidence of rapid credit growth, a marked buildup in leverage, or significant asset bubbles that would threaten financial stability. But there are signs that some parties are reaching for yield, and the Federal Reserve continues to carefully monitor this situation. However, I think most central bankers view monetary policy as a blunt tool for addressing financial stability concerns and many probably share my own strong preference to rely on micro- and macroprudential supervision and regulation as the main line of defense. The Federal Reserve has been working with a number of federal agencies and international bodies since the crisis to implement a broad range of reforms to enhance our monitoring, mitigate systemic risk, and generally improve the resilience of the financial system. Significant work will be needed to implement these reforms, and vulnerabilities still remain. Thus, we are prepared to use any of our many instruments as appropriate to address any stability concerns. Let me conclude by noting that I have touched on only some of the important dimensions of monetary policy targets and instruments that have arisen in recent years. I look forward to a discussion that I expect will explore these issues and perhaps raise others. 1.The views I express here are my own and not necessarily those of my colleagues in the Federal Reserve System.Return to text 2.See Gill Hammond (2012),State of the Art of Inflation Targeting(PDF), Centre for Central Banking Studies, CCBS Handbook No. 29 (London: Bank of England).Return to text
Board of Governors of the Federal Reserve SystemOffice of the Comptroller of the Currency WASHINGTON--Payments to 4.2 million borrowers are scheduled to begin on April 12 following an agreement reached by the Office of the Comptroller of the Currency and the Federal Reserve Board with 13 mortgage servicers. The agreement, which was reached earlier this year, provides $3.6 billion in cash payments to borrowers whose homes were in any stage of the foreclosure process in 2009 or 2010 and whose mortgages were serviced by one of the following companies, their affiliates, or subsidiaries: Aurora, Bank of America, Citibank, Goldman Sachs, HSBC, JPMorgan Chase, MetLife Bank, Morgan Stanley, PNC, Sovereign, SunTrust, U.S. Bank, and Wells Fargo. The payments will range from $300 to $125,000. For borrowers whose mortgages were serviced by 11 of the 13 servicers--all servicers but Goldman Sachs and Morgan Stanley--checks will be sent in several waves beginning with 1.4 million checks on April 12. The final wave is expected in mid-July 2013. More than 90 percent of the total payments to borrowers at those 11 servicers are expected to have been sent by the end of April. Information about payments to borrowers whose mortgages were serviced by Goldman Sachs and Morgan Stanley will be announced in the near future. In most cases, borrowers will receive a letter with an enclosed check sent by the Paying Agent--Rust Consulting, Inc. Some borrowers may receive letters from Rust requesting additional information needed to process their payments. Previously, Rust sent postcards to the 4.2 million borrowers notifying them of their eligibility to receive payment under the agreement. Rust is sending all payments and correspondence regarding the foreclosure agreement at the direction of the OCC and the Federal Reserve. Borrowers can call Rust at 1-888-952-9105 to update their contact information or to verify that they are covered by the agreement. Information provided to Rust will only be used for purposes related to the agreement. Borrowers should beware of scams and anyone asking them to call a different number or to pay a fee to receive payment under the agreement. Accepting a payment will not prevent borrowers from taking any action they may wish to pursue related to their foreclosure. Servicers are not permitted to ask borrowers to sign a waiver of any legal claims they may have against their servicer in connection with accepting payment. In determining the payment amounts, borrowers were categorized according to the stage of their foreclosure process and the type of possible servicer error. Regulators then determined amounts for each category using the financial remediation matrix published in June 2012 as a guide, incorporating input from various consumer groups. Regulators have published the payment amounts and number of people in each category on their web sites atwww.occ.gov/independentforeclosurereviewandwww.federalreserve.gov/consumerinfo/independent-foreclosure-review-payment-agreement.htm. While the agreement ended the Independent Foreclosure Review for the 13 companies identified above, the review continues for OneWest, Everbank, and GMAC Mortgage. Regulators continue to monitor the servicers' actions to correct the unsafe and unsound mortgage servicing and foreclosure practices required by other parts of regulators' enforcement actions, which remain in effect. Regulators have issued guidance to the servicers under foreclosure-related enforcement actions directing a review before foreclosure sales for all pending foreclosures. These reviews help prevent avoidable foreclosures by ensuring foreclosure-prevention alternatives are considered and foreclosure standards are met. Regulators encourage borrowers needing foreclosure prevention assistance to work directly with their servicer or to contact the Homeowner's HOPE Hotline at 888-995-HOPE (4673) (or atwww.makinghomeaffordable.gov) to be put in touch with a U.S. Department of Housing and Urban Development-approved nonprofit organization that can provide free assistance. Independent Foreclosure Review Payment Agreement Details (PDF)
Payments to more than 220,000 borrowers whose mortgages were serviced by Goldman Sachs and Morgan Stanley are scheduled to begin on Friday, May 3 following an agreement announced earlier this year by the Federal Reserve Board. Under the agreement, $247 million will be made in direct payments to borrowers whose homes were at any stage of the foreclosure process in 2009 and 2010 with the former subsidiaries of Goldman Sachs (Litton Loan Servicing LP) and Morgan Stanley (Saxon Mortgage Services, Inc.). Payments will range from $300 to more than $125,000. In most cases, borrowers will receive a letter with an enclosed check sent by the paying agent--Rust Consulting, Inc. Some borrowers may receive letters from Rust requesting additional information needed to process their payments. Previously, Rust sent postcards to borrowers notifying them of their eligibility to receive payment under the agreement. The payments stem from agreements reached earlier this year between 13 servicers and two agencies--the Office of the Comptroller of the Currency and the Federal Reserve. The agreements provide for a total of $3.6 billion in cash payments to 4.2 million borrowers. Distribution of checks to borrowers whose mortgages were serviced by the other 11 servicers began April 12 and will continue through mid-July. As of April 26, approximately 1.2 million checks have been cashed or deposited totaling approximately $1.2 billion dollars. As in the case of the other servicers, payment amounts for borrowers whose mortgages were serviced by Goldman Sachs and Morgan Stanley were determined after categorizing borrowers according to the stage of the foreclosure process and the type of possible servicer error. In some cases, the payment amounts for Goldman Sachs and Morgan Stanley borrowers differ from those received by borrowers in the same categories with the other 11 servicers. The amounts differ because borrowers whose mortgages were serviced by Goldman Sachs and Morgan Stanley were not able to request a review of their foreclosure file. As is the case for borrowers whose mortgages were serviced by the other 11 firms, borrowers whose mortgages were serviced by Goldman Sachs and Morgan Stanley who accept a payment will not be prevented from taking any action related to their foreclosure. Servicers are not permitted to ask borrowers, in connection with accepting these payments, to sign a waiver of any legal claims they may have against their servicer. Borrowers with all 13 servicers can call Rust at 1-888-952-9105 to update their contact information, verify that they are covered by the agreement, or with further questions. Information provided to Rust will only be used for purposes related to the agreement. Borrowers should beware of scams and anyone asking them to call a different phone number or to pay a fee to receive payment under the agreement. For media inquiries, call 202-452-2955. Independent Foreclosure Review Payment Agreement for Goldman Sachs and Morgan Stanley (PDF)
Governor Jeremy C. Stein At the "Rethinking Macro Policy II," a conference sponsored by the International Monetary Fund, Washington, D.C. Thank you. I'm delighted to be here, and want to thank the International Monetary Fund and the organizers of the conference for including me in a discussion of these important topics. I will focus my remarks today on the ongoing regulatory challenges associated with large, systemically important financial institutions, or SIFIs.1In part, this focus amounts to asking a question that seems to be on everyone's mind these days: Where do we stand with respect to fixing the problem of "too big to fail" (TBTF)? Are we making satisfactory progress, or it is time to think about further measures? I should note at the outset that solving the TBTF problem has two distinct aspects. First, and most obviously, one goal is to get to the point where all market participants understand with certainty that if a large SIFI were to fail, the losses would fall on its shareholders and creditors, and taxpayers would have no exposure. However, this is only a necessary condition for success, but not a sufficient one. A second aim is that the failure of a SIFI must not impose significant spillovers on the rest of the financial system, in the form of contagion effects, fire sales, widespread credit crunches, and the like. Clearly, these two goals are closely related. If policy does a better job of mitigating spillovers, it becomes more credible to claim that a SIFI will be allowed to fail without government bailout. So where do we stand? I believe two statements are simultaneously true. We've made considerable progress with respect to SIFIs since the financial crisis. And we're not yet at a point where we should be satisfied. All of you are familiar with the areas of progress. Higher and more robust capital requirements, new liquidity requirements, and stress testing all should help to materially reduce the probability of a SIFI finding itself at the point of failure. And, if, despite these measures, a SIFI does fail, the orderly liquidation authority (OLA) in Title II of the Dodd-Frank Wall Street Reform and Consumer Protection Act now offers a mechanism for recapitalizing and restructuring the institution by imposing losses on shareholders and creditors. In the interests of brevity, I won't go into a lot of detail about OLA. But my Board colleague Jay Powell talked in depth about this topic in a speech last month, and I would just register my broad agreement with his conclusion--namely that the Federal Deposit Insurance Corporation's (FDIC's) so-called "single point of entry" approach to resolution is a promising one.2The Federal Reserve continues to work with the FDIC on the many difficult implementation challenges that remain, but I believe this approach gets the first-order economics right and ultimately has a good chance to be effective. Perhaps more to the point for TBTF, if a SIFI does fail I have little doubt that private investors will in fact bear the losses--even if this leads to an outcome that is messier and more costly to society than we would ideally like. Dodd-Frank is very clear in saying that the Federal Reserve and other regulators cannot use their emergency authorities to bail out an individual failing institution. And as a member of the Board, I am committed to following both the letter and the spirit of the law. Still, we are quite a way from having fully solved the policy problems associated with SIFIs. For one thing, the market still appears to attach some probability to the government bailing out the creditors of a SIFI; this can be seen in the ratings uplift granted to large banks based on the ratings agencies' assessment of the probability of government support. While this uplift seems to have shrunk to some degree since the passage of Dodd-Frank, it is still significant.3All else equal, this uplift confers a funding subsidy to the largest financial firms. Moreover, as I noted earlier, even if bailouts were commonly understood to be a zero-probability event, the problem of spillovers remains. It is one thing to believe that a SIFI will be allowed to fail without government support; it is another to believe that such failure will not inflict significant damage on other parts of the financial system. In the presence of such externalities, financial firms may still have excessive private incentives to remain big, complicated, and interconnected, because they reap any benefits--for example, in terms of economies of scale and scope--but don't bear all the social costs. How can we do better? Some have argued that the current policy path is not working, and that we need to take a fundamentally different approach.4Such an alternative approach might include, for example, outright caps on the size of individual banks, or a return to Glass-Steagall-type activity limits. My own view is somewhat different. While I agree that we have a long way to go, I believe that the way to get there is not by abandoning the current reform agenda, but rather by sticking to its broad contours and ratcheting up its forcefulness on a number of dimensions. In this spirit, two ideas merit consideration: (1) an increase in the slope of the capital-surcharge schedule that is applied to large complex firms, and (2) the imposition at the holding company level of a substantial senior debt requirement to facilitate resolution under Title II of Dodd-Frank. In parallel with the approach to capital surcharges, a senior debt requirement could also potentially be made a function of an institution's systemic footprint. To illustrate my argument, let us take as given the central premise of those who favor size limits: namely, that society would be better off if the distribution of banks were not so skewed toward a handful of very large institutions. (To be clear, I am using the word "size" as shorthand for the broader concept of an institution's systemic footprint, which in addition to size, might reflect complexity, interconnectedness, and global span of operations.) In other words, let's simply posit that a goal of regulation should be to lean against bank size, and ask: What are the best regulatory tools for accomplishing that goal? As in many other regulatory settings, this question can be mapped into the "prices-versus-quantities" framework laid out by Martin Weitzman nearly 40 years ago.5Here a size cap is a form of quantity regulation, whereas capital requirements that increase with bank size can be thought of as a kind of price regulation, in the sense that such capital requirements are analogous to a progressive tax on bank size.6 A key challenge with quantity-based regulation is that one has to decide where to set the cap. Doing so requires a regulator to take a strong stand on the nature of scale and scope economies in large financial firms. Moreover, even if one reads the empirical literature as being quite skeptical about the existence of such economies beyond a certain point in the size distribution--a proposition which itself is debatable--the most that such large-sample studies can do is make on-average statements about scale and scope economies.7These studies still leave open the possibility of considerable heterogeneity across firms, and that some firms are able to add considerable value in a given line of business by being very big, even if the average firm in the population is not. And such heterogeneity alone is enough to create significant drawbacks to quantity-based regulation. Consider the following example. There are three banks: A, B, and C. Banks A and B both have $1 trillion in assets, while C is smaller, with only $400 billion in assets. Bank A actually generates significant economies of scale, so that it is socially optimal for it to remain at its current size. Banks B and C, by contrast, have very modest economies of scale, not enough to outweigh the costs that their size and complexity impose on society. From the perspective of an omniscient social planner, it would be better if both B and C were half their current size. Now let's ask what happens if we impose a size cap of say $500 billion. This size cap does the right thing with respect to Bank B, by shrinking it to a socially optimal size. But it mishandles both Banks A and C, for different reasons. In the case of A, the cap forces it to shrink when it shouldn't, because given the specifics of its business model it actually creates a substantial amount of value by being big. And in the case of C, the cap makes the opposite mistake. It would actually be beneficial to put pressure on C to shrink at the margin--that is, to move it in the direction of being a $200 billion bank instead of a $400 billion one--but since it lies below the cap, it is completely untouched by the regulation. Suppose instead we attack the problem by imposing capital requirements that are an increasing function of bank size. This price-based approach creates some incentive for all three banks to shrink, but lets them balance this incentive against the scale benefits that they realize by staying big. In this case, we would expect A, with its significant scale economies, to absorb the tax hit and choose to remain large, while B and C, with more modest scale economies, would be expected to shrink more radically. In other words, price-based regulation is more flexible, in that it leaves the size decision to bank managers, who can then base their decision on their own understanding of the synergies--or lack thereof--in their respective businesses. This logic can be thought of as supporting the approach taken by the Basel Committee on Banking Supervision in its rule imposing a common equity surcharge on designated global systemically important banks. The exact amount of the surcharge will range from 1 percent to 2.5 percent, and will depend on factors that include a bank's size, complexity, and interconnectedness, as measured by a variety of indicator variables.8These progressive surcharges are effectively a type of price-based regulation, and therefore should have the advantages I just noted. However, a proponent of size caps might reasonably reply: "Fine, but how do I know that these surcharges are actually enough to change behavior--that is, to exert a meaningful influence on the size distribution of the banking system?" After all, the analogy between a capital requirement and a tax is somewhat imperfect, since we don't know exactly the implicit tax rate associated with a given level of capital. Some view capital requirements as quite burdensome, which would mean that even a 2 percent surcharge amounts to a significant tax and, hence, a strong incentive for a bank to shrink, while others have argued that capital requirements impose only modest costs, which would imply little incentive to shrink.9 This uncertainty about the ultimate effect of a given capital-surcharge regime on the size distribution of banks could potentially tip the balance back in favor of quantity-based regulation, like size caps. And indeed, if we were faced with a static, once-and-for-all decision, I don't think economic reasoning alone could give us a definitive answer as to whether caps should be preferred to capital surcharges. This ambiguity is in some sense the central message of Weitzman's original analysis. One way to resolve this tension is to refrain from putting ourselves in the position of having to make a once-and-for-all decision in a setting of substantial uncertainty. Rather, it might be preferable to try to learn from the incoming data and adjust over time, particularly since the recent changes to capital regulation already on the books may represent an informative experiment. In my view, this observation about the potential for learning tips the balance in favor of capital surcharges. For example, the capital-surcharge schedule proposed by the Basel Committee for globally important systemic banks may be a reasonable starting point. However, if after some time it has not delivered much of a change in the size and complexity of the largest of banks, one might conclude that the implicit tax was too small, and should be ratcheted up.10In principle, this turning-up-the-dials approach feels to me like the right way to go: It retains the flexibility that makes price-based regulation attractive, while mitigating the risk that the implicit tax rate will be set too low. Of course, I recognize that its gradualist nature presents practical challenges, not least of which is sustaining a level of regulatory commitment and resolve sufficient to keep the dials turning so long as this is the right thing to do. Before wrapping up, let me briefly mention another piece of the puzzle that I think is sometimes overlooked, but strikes me as having the potential to play an important complementary role in efforts to address the TBTF problem--namely, corporate governance. Suppose we do everything right with respect to capital regulation, and set up a system of capital surcharges that imposes a strong incentive to shrink on those institutions that don't create large synergies. How would the adjustment process actually play out? The first step would be for shareholders, seeing an inadequate return on capital, to sell their shares, driving the bank's stock price down. And the second step would be for management, seeking to restore shareholder value, to respond by selectively shedding assets. But as decades of research in corporate finance have taught us, we shouldn't take the second step for granted. Numerous studies across a wide range of industries have documented how difficult it is for managers to voluntarily downsize their firms, even when the stock market is sending a clear signal that downsizing would be in the interests of outside shareholders. Often, change of this sort requires the application of some external force, be it from the market for corporate control, an activist investor, or a strong and independent board.11As we move forward, we should keep these governance mechanisms in mind, and do what we can to ensure that they support the broader regulatory strategy. ReferencesAdmati, Anat R., Peter M. DeMarzo, Martin F. Hellwig, and Paul Pfleiderer (2011). "Fallacies, Irrelevant Facts, and Myths in the Discussion of Capital Regulation: Why Bank Equity isNotExpensive (PDF)," working paper Baker, Malcolm, and Jeffrey Wurgler (2013). "Would Stricter Capital Requirements Raise the Cost of Capital? Bank Capital Regulation and the Low Risk Anomaly (PDF)," working paper Basel Committee on Banking Supervision (BCBS) (2011). "Global systemically important banks: assessment methodology and the additional loss absorbency requirement (PDF)," rules text (November) Fisher, Richard W. (2013). "Ending 'Too Big to Fail'," speech delivered at the Conservative Political Action Conference, National Harbor, Maryland, March 16 Haldane, Andrew G. (2010). "The $100 billion question (PDF)," speech delivered at the Institute of Regulation & Risk, Hong Kong, March 30 Hanson, Samuel G., Anil K. Kashyap, and Jeremy C. Stein (2011). "A Macroprudential Approach to Financial Regulation (PDF),"Journal of Economic Perspectives, vol. 25 (Winter) Jensen, Michael C. (1993). "The Modern Industrial Revolution, Exit, and the Failure of Internal Control Systems,"Journal of Finance, vol. 48(3), http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1993.tb04022.x/full Hughes, Joseph P., and Mester, Loretta J. (2011). "Who said large banks don't experience scale economies? Evidence from a risk-return-driven cost function (PDF)," Working Paper No. 11-27. Philadelphia: Federal Reserve Bank of Philadelphia, July Moody's Investors Service (2012). "Moody's downgrades firms with global capital markets operations," press release, June 21, www.moodys.com/research/Moodys-downgrades-firms-with-global-capital-markets-operations--PR_248989?WT.mc_id=BankRatings2012 Powell, Jerome H. (2013). "Ending 'Too Big to Fail'," speech delivered at the Institute of International Bankers 2013 Washington Conference, Washington, D.C., March 4 Tarullo, Daniel K. (2012). "Industry Structure and Systemic Risk Regulation," speech delivered at the Brookings Institution Conference on Structuring the Financial Industry to Enhance Economic Growth and Stability, Washington, D.C., December 4 Weitzman, Martin L. (1974). "Prices vs. Quantities (PDF),"The Review of Economic Studies, vol. 41 (October) 1. The thoughts that follow are my own, and are not necessarily shared by my colleagues on the Federal Reserve Board. I am grateful to members of the Board staff--Michael Gibson, Michael Hsu, Nellie Liang, and Mark Van Der Weide--for their advice.Return to text 2. See Powell (2013).Return to text 3. For example, in June of 2012, Moody's described its ratings process for Bank of America, Citigroup, and JP Morgan Chase as follows: "[Their] ratings benefit from three notches of uplift from the standalone credit assessment at the bank level, and from two notches of uplift at the holding company, reflecting Moody's assumptions about a very high likelihood of support from the US government for bondholders or other creditors in the event such support was required to prevent a default… . The negative outlook on the parent holding company reflects Moody's view that government support for U.S. bank holding company creditors is becoming less certain and less predictable, given the evolving attitude of U.S. authorities to the resolution of large financial institutions, whereas support for creditors of operating entities remains sufficiently likely and predictable to warrant stable outlooks."Return to text 4. See Fisher (2013), who said: "…we recommend that the largest financial holding companies be restructured so that every one of their corporate entities is subject to a speedy bankruptcy process, and in the case of the banking entities themselves, that they be of a size that is ‘too small to save'. Addressing institutional size is vital to maintaining a credible threat of failure, thereby providing a convincing case that policy has truly changed."Return to text 5. See Weitzman (1974). Haldane (2010) also uses Weitzman's framework to talk about price-versus-quantity regulation in the TBTF context. It should be noted that there are various hybrid approaches that are neither pure quantity nor pure price regulation. For example, Tarullo's (2012) discussion of limits on uninsured liabilities is not a rigid size cap, since it does not constrain an institution's absolute size, to the extent that it is able to adjust its funding mix.Return to text 6. To be clear, this taxation aspect of capital requirements is not their only appeal, or even their primary one. Even if it were almost costless to impose higher capital requirements on bigger banks--so that doing so provided essentially no disincentive to bank size--it might still be a good idea to do so, for purely prudential reasons. In other words, capital requirements serve as both a prudential buffer and a tax, and can be a useful regulatory tool for both reasons.Return to text 7. See Hughes and Mester (2011) for a recent contribution to the literature on scale economies in banking.Return to text 8. See BCBS (2011) for a description of the methodology.Return to text 9. For different estimates of the costs of capital requirements to banks, see Baker and Wurgler (2013), Admati and others (2011), and Hanson, Kashyap, and Stein (2011).Return to text 10. Again, it should be emphasized that the underlying problem is not simply an institution's size, but rather its systemic footprint--which in addition to sheer size, is related to its complexity, interconnectedness, and global span of operations.Return to text 11. Jensen (1993) is a classic treatment of the issues.Return to text
Chairman Ben S. Bernanke At the "Maintaining Financial Stability: Holding a Tiger by the Tail" financial markets conference sponsored by the Federal Reserve Bank of Atlanta, Stone Mountain, Georgia Let me begin by thanking President Lockhart and the organizers of the Financial Markets Conference for inviting me to speak here again this year. I have participated regularly in this conference and have always found it stimulating. Four years ago, in remarks at this very conference, I described the 2009 Supervisory Capital Assessment Program, or SCAP, popularly known as the bank stress tests.1The SCAP marked the first time the U.S. bank regulatory agencies had conducted a supervisory stress test simultaneously across the largest banking firms.2At the time of my 2009 speech, we had just published the results of the SCAP and were still evaluating its effects. In retrospect, the SCAP stands out for me as one of the critical turning points in the financial crisis. It provided anxious investors with something they craved: credible information about prospective losses at banks. Supervisors' public disclosure of the stress test results helped restore confidence in the banking system and enabled its successful recapitalization. The resilience of the U.S. banking system has greatly improved since then, and the more intensive use and greater sophistication of supervisory stress testing, as well as supervisors' increased emphasis on the effectiveness of banks' own capital planning processes, deserve some credit for that improvement. I will begin today with a brief discussion of the state of U.S. banking. I will then turn to the subject of what we have learned about stress testing in the four years since the SCAP, with a focus on the increasingly central role it is playing in bank supervision in the United States. Importantly, as I will elaborate, stress testing adds a macroprudential dimension to our supervision by helping us evaluate the aggregate capital position of the largest banking firms as well as their individual capital levels. The Federal Reserve--like all bureaucracies--has an unfortunate tendency to create acronyms, so, before I proceed further, let me explain our acronyms, in addition to SCAP, for stress tests. With the SCAP now in the past, we currently have two distinct but related supervisory programs that rely on stress testing. The first is the stress testing required by the Dodd-Frank Act, which we have shortened to the acronym DFAST--the Dodd-Frank Act stress tests. The purpose of DFAST is to quantitatively assess how bank capital levels would fare in stressful economic and financial scenarios. The second program, called the Comprehensive Capital Analysis and Review, or CCAR, combines the quantitative results from the stress tests with more-qualitative assessments of the capital planning processes used by banks. For example, under CCAR, supervisors evaluate the ability of banks to model losses for various categories of loans and securities and to estimate earnings and capital requirements in alternative scenarios. We recently completed the first set of DFAST stress tests and disclosed the results, followed a week later by the disclosure of our CCAR findings, which included our qualitative assessments of firms' capital planning.3 The State of the Banking System, Then and NowTo provide context for the developments in the banking system since the introduction of the SCAP in early 2009, it's worth briefly recalling the economic situation that prevailed at that time. The economy was in deep recession, with the unemployment rate having risen 4 percentage points, from 5 percent to 9 percent, over the preceding 12 months. The prices of real estate and equities had plummeted, interest rate spreads--such as the spread between rates on mortgages and Treasury securities--had widened to unprecedented levels, and securitization markets had frozen. Write-downs and losses continued to deplete banks' capital, unnerving investors and counterparties and exacerbating the severe funding pressures faced by many institutions. In the face of this instability, in 2008 and 2009 policymakers had taken a range of extraordinary measures: The Federal Reserve supplied liquidity to banks and other financial institutions, helping to calm the panic and begin the process of restoring the flow of credit to households and businesses; the Treasury Department guaranteed money market funds and injected capital into banks under the Troubled Asset Relief Program; the Congress expanded deposit insurance under the Federal Deposit Insurance Corporation (FDIC); and the FDIC guaranteed banks' issuance of long-term debt. And, as I noted, the SCAP helped to increase confidence in the banking system and restore banks' access to private capital markets. Ten of the 19 large bank holding companies that underwent the SCAP were required to raise equity capital--by $75 billion in total. Today the economy is significantly stronger than it was four years ago, although conditions are clearly still far from where we would all like them to be. Because bank credit for households and businesses is critical to continued economic expansion, it is positive for the recovery that banks are also notably stronger than they were a few years ago. For example, premiums on bank credit default swaps have fallen by more than half of their 2009 levels, and other measures of bank risk have also declined substantially. More than 90 percent of the public capital injections that were used to stabilize the banking system have been repaid, and the Federal Reserve's extraordinary liquidity programs and the FDIC's temporary guarantees for uninsured business deposits and bond issues have largely been wound down. The results of the most recent stress tests and capital planning evaluations continue to reflect improvement in banks' condition. For example, projected aggregate loan losses under this year's most stressful scenario (the so-called severely adverse scenario) were 7 percent lower than the comparable figure last year, in part because the riskiness of banks' portfolios continues to decline. The comparison of today's bank capital levels with those at the time of the SCAP is particularly striking. Over the past four years, the aggregate tier 1 common equity ratio of the 18 firms that underwent the recent tests has more than doubled, from 5.6 percent of risk-weighted assets at the end of 2008 to 11.3 percent at the end of 2012--in absolute terms, a net gain of nearly $400 billion in tier 1 common equity, to almost $800 billion at the end of 2012. Indeed, even under the severely adverse scenario of the latest stress test, the estimate of these firms' post-stress tier 1 common capital ratio is more than 2 percentage points higher thanactualcapital levels at the end of 2008.4Higher capital puts these firms in a much better position to absorb future losses while continuing to fulfill their vital role in the economy. In addition, a majority of the 18 CCAR firms already meet new internationally agreed-upon capital standards (the proposed Basel III capital requirements), and the others are on track to meet these requirements as they are phased in over time. Although the stress tests focus on the largest banks, the medium-sized and smaller banks outside of the 18 CCAR firms have also improved their aggregate capital position considerably since the SCAP. For that group of banks, aggregate tier 1 common equity stood at 12.4 percent of risk-weighted assets in the fourth quarter of 2012, more than 4 percentage points higher than at the end of 2008. Another key lesson of the crisis, given the intense funding pressures experienced by many financial institutions during the period, is the importance of maintaining adequate liquidity--that is, a stock of cash and unencumbered high-quality liquid assets that can be converted easily into cash. Here too, the news is mostly positive, as the broader banking system--including both larger and smaller banks--has generally improved its liquidity position relative to pre-crisis levels. For example, banks' holdings of cash and high-quality liquid securities have more than doubled since the end of 2007 and now total more than $2.5 trillion. However, in the area of liquidity and funding, continued improvement is still needed on some dimensions. Notably, supervisors will continue to press banks to reduce further their dependence on wholesale funding, which proved highly unreliable during the crisis. And, in analogy to the need for effective capital planning, banks of all sizes need to further strengthen their ability to identify, quantify, and manage their liquidity risks. The Evolution of Stress TestingLet me turn now to the evolution of stress testing as a supervisory tool. The main benefits of stress tests for supervision have not changed much since the SCAP was conducted in 2009. First, stress tests complement standard capital ratios by adding a more forward-looking perspective and by being more oriented toward protection against so-called tail risks; by design, stress tests help ensure that banks will have enough capital to keep lending even under highly adverse circumstances. Second, as applied by the Federal Reserve, the stress tests look horizontally across banks rather than at a single bank in isolation. This comparative approach promotes more-consistent supervisory standards. It also provides valuable systemic information by revealing how significant economic or financial shocks would affect the largest banks collectively as well as individually. Third, the disclosures of stress test results promote transparency by providing the public consistent and comparable information about banks' financial conditions. The basic methodology of our stress testing has also not changed materially since the SCAP. We continue to take a multidisciplinary approach, drawing on a wide range of staff expertise. To begin the process, our economists create a hypothetical macroeconomic scenario that incorporates an assumed sharp deterioration in economic and financial conditions. Supervisors estimate each bank's expected losses and revenues and we use these estimates to project post-stress capital levels and ratios under that hypothetical scenario. The estimated capital ratios are then compared with regulatory benchmarks. We use a common scenario for all firms; for the firms with the largest trading activities, we supplement the basic scenario with a market-shock scenario that incorporates market turbulence of severity similar to that of the latter half of 2008. Although the basic goals and approach of stress testing have remained largely unchanged since the SCAP, the implementation has evolved and improved from year to year. For example, we have continued to refine the formulation of the hypothetical scenarios that form the basis of the stress tests. As explained in a statement we released in the fall, the severely adverse scenario is designed to reflect, at a minimum, the economic and financial conditions typical of a severe post-World War II U.S. recession.5In devising recession scenarios, we draw on many of the same macroeconomic modeling tools used in making monetary policy. Of course, not all significant risks facing banks are tied to the business cycle. Accordingly, our scenarios now generally incorporate not only the typical consequences of a severe recession but also, simultaneously, other adverse developments such as an exceptionally large decline in house prices, sharp drops in the value of stocks and other financial assets, or a worsening of global economic conditions more severe than might normally be expected to accompany a deep recession in the United States. Importantly, in specifying the severely adverse scenario, we seek to avoid adding to the procyclicality of the financial system.In other words, in applying stress tests, we do not want to inadvertently set a standard that is easier to meet in good times (when banks should be preparing for possibly tougher times ahead) than in bad times (when banks need to be able to use accumulated capital to support lending). Accordingly, we will want to ensure that the stress scenario remains severe in an absolute sense even when the economy is strong and the near-term risks to the outlook seem relatively modest. We have also improved our tools for estimating projected bank losses, revenues, and capital under alternative scenarios. The original SCAP was supervisors' first attempt to produce comprehensive and simultaneous estimates of the financial conditions of the nation's largest banking firms, and the required data and analytical methods were developed under great time pressure. Of necessity, when projecting losses and revenues under alternative SCAP scenarios, supervisors relied on the firms' own estimates as a starting point. Although we scrutinized and questioned the firms' estimates and made significant adjustments based on our own analysis, for that inaugural round of stress tests, it was not possible to produce completely independent estimates. However, over the past four years, considerable progress has been made in data collection and in the development of independent supervisory models. For our most recent supervisory stress tests, we collected and analyzed loan- and account-level data on more than two-thirds of the $4.2 trillion in accrual loans and leases projected to be held by the 18 firms we evaluated this year. Those detailed data include borrower, loan, and collateral information on more than 350 million domestic retail loans, including credit cards and mortgages, and more than 200,000 commercial loans. Currently, the Federal Reserve uses more than 40 models to project how categories of bank losses and revenues would likely respond in hypothetical scenarios. The improvements in data and models have increased our ability to distinguish risks within portfolios. Importantly, these supervisory models are evaluated by a special model validation group made up of experts within the Federal Reserve who do not work on the stress tests. We have also created a Model Validation Council made up of external experts to provide independent views and advice.6These ongoing efforts are bringing us close to the point at which we will be able to estimate, in a fully independent way, how each firm's loss, revenue, and capital ratio would likely respond in any specified scenario. Another innovation since the SCAP is the increased supervisory focus on banks' internal capital planning practices, which are reviewed as part of CCAR. We see the requirement that banks with assets of $50 billion or more submit annual capital plans to the Federal Reserve as a critical enhancement.7While regulatory minimums and supervisory expectations provide floors for acceptable capital levels, the firms and their boards of directors are responsible for assessing their own capital needs over and above the minimums. Our supervisors scrutinize their practices and assess their capacity to fulfill that responsibility. In particular, we require firms to formulate their own scenarios that capture the risks that they face, and to assess potential losses and revenues under both the supervisory scenarios and their internal scenarios over a nine-quarter horizon. In CCAR, our qualitative assessment of a firm's capital planning is integrated with the quantitative results of both the supervisory and company-run stress tests. The Federal Reserve continues to increase the transparency of our stress testing process, the results of the exercises, and our assessments of banks' capital planning. The original SCAP set a new standard of supervisory transparency in disclosing bank-by-bank estimates of stress losses by type of exposure. This departure from the traditionally confidential treatment of supervisory information, as I noted earlier, was intended to restore public confidence by providing much-needed information about banks' potential losses and capital needs. In last month's results, in addition to projected losses and revenues, we disclosed for the first time whether we had objected to each firm's capital plan.8Also for the first time, banks were required to disclose their own estimates of stressed losses and revenues. The disclosures by banks give investors and analysts an alternative perspective on the test results; they also help them form judgments about banks' appetites for risk and their risk-management practices, particularly their abilities to measure losses in a severe downturn. Even outside of a period of crisis, the disclosure of stress test results and assessments provides valuable information to market participants and the public, enhances transparency, and promotes market discipline. In the four years since the SCAP, the Federal Reserve's stress testing program has been expanded and strengthened through both statute and regulation. The Dodd-Frank Act widened the scope of stress testing to all bank holding companies with $50 billion or more in total consolidated assets (approximately 11 companies in addition to the original SCAP participants) and to nonbank financial companies designated by the Financial Stability Oversight Council as systemically important, and therefore subject to consolidated supervision by the Federal Reserve. Dodd-Frank also requires these companies to conduct their own stress tests twice a year. In October, the Federal Reserve Board adopted rules implementing these requirements.9The 11 additional companies with assets of $50 billion or more will be subject to DFAST and CCAR for the first time next year. While no institutions below $50 billion in assets are subject to supervisory stress testing or the requirements of CCAR, the Dodd-Frank Act does require that institutions with between $10 billion and $50 billion in assets conduct their own stress tests.10The initial tests by these firms will begin this year and will be completed by March. While we believe that stress testing will help medium-sized institutions better understand the risks they face, we tailored our rule for these institutions to take account of differences in size, complexity, and business models. We specifically exempted community banking organizations with $10 billion or less in total assets from the requirement that they run their own stress tests as those institutions cannot reasonably be expected to have the resources that larger banks devote to stress testing.11 Benefits and Challenges of Stress TestingAs already noted, stress testing has a number of important benefits as a supervisory tool. From a microprudential perspective, the CCAR provides a structured means for supervisors to assess not only whether banks hold enough capital, but also whether banks are able to rapidly and accurately determine their risk exposures, an essential element of effective risk management. The cross-firm nature of the stress tests also helps supervisors identify outliers--both in terms of results and practices--that can provide a basis for further, more targeted reviews. From a macroprudential perspective, the use of a common scenario allows us to learn how a particular risk or combination of risks might affect the banking system as a whole‑‑not just individual institutions. This experience with stress testing has indeed been very useful for our efforts to better monitor and evaluate potential systemic risks. For example, in our macroprudential work, as in our stress tests, we tend to rely on horizontal examinations and comparative studies, as opposed to firm-by-firm assessments; we use multidisciplinary, specialized teams to supplement the work of on-site examiners; and we have increased our use of modeling and quantitative methods, using data drawn from different institutions and time periods. All of these features are apparent in the workings of our Large Institution Supervision Coordinating Committee, which provides coordinated oversight of the supervision of systemically important firms. We have also extended the lessons of systemwide stress testing to analysis of factors other than capital: For example, we recently completed a horizontal review of liquidity positions and liquidity risk-management practices at some of the largest CCAR firms. Like the CCAR review of capital planning, this review was a multidisciplinary effort that used quantitative information--in this case, detailed data on firms' liquidity positions--as well as qualitative information on liquidity risk-management practices. Notwithstanding the demonstrated benefits of comprehensive stress testing, this evolving tool also presents challenges. For example, even as we continue to explore ways to enhance the transparency of the models we use to estimate banks' projected revenues and losses, we have chosen not to publish the full specification of these models. As a result, we hear criticism from bankers that our models are a "black box," which frustrates their efforts to anticipate our supervisory findings. We agree that banks should understand in general terms how the supervisory models work, and, even more importantly, they need to be confident that our models are empirically validated and sound. I mentioned our internal efforts at model validation, which have increased the quality and accuracy of our models. We have also begun to host an annual stress test modeling symposium, which provides a venue for regulators, bankers, academics, and others to share their views. Over time, we expect banks to better understand the basic elements of the supervisory models, rendering them at least somewhat less opaque. At the same time, it is reasonable to worry that, with increased disclosure of supervisory models, firms would see a declining benefit to maintaining independent risk-management systems and would just adopt supervisory models instead. Doing so would certainly make it easier to "pass" the stress tests. However, all models have their blind spots, and such an outcome risks a "model monoculture" that would be susceptible to a single, common failure. The differences in stress test results obtained by supervisors' and banks' own models can be informative, and we do not want inadvertently to destroy the healthy diversity or innovation of the models and other risk-management tools used in the banking industry. Another challenge is that our stress scenarios cannot encompass all of the risks that banks might face. For example, although some operational risk losses, such as expenses for mortgage put-backs, are incorporated in our stress test estimates, banks may face operational, legal, and other risks that are specific to their company or are otherwise difficult to estimate. It is important for banking firms to consider the potential for losses from these other classes of risks as systematically as possible, and supervisors also account for these risks as best they can. Of course, unforeseen events are inevitable, which is why maintaining a healthy level of capital is essential. ConclusionAs I have discussed today, the banking system is much stronger since the implementation of the SCAP four years ago, which in turn has contributed to the improvement in the overall economy. The use of supervisory stress tests--a practice now codified in statute--has helped foster these gains. Methodologically, stress tests are forward looking and focus on unlikely but plausible risks, as opposed to "normal" risks. Consequently, they complement more conventional capital and leverage ratios. The disclosure of the results of supervisory stress tests, coupled with firms' disclosures of their own stress test results, provide market participants deeper insight not only into the financial strength of each bank but also into the quality of its risk management and capital planning. Stress testing is also proving highly complementary to supervisors' monitoring and analysis of potential systemic risks. We will continue to make refinements to our implementation of stress testing and our CCAR process as we learn from experience. As I have noted, one of the most important aspects of regular stress testing is that it forces banks (and their supervisors) to develop the capacity to quickly and accurately assess the enterprise-wide exposures of their institutions to diverse risks, and to use that information routinely to help ensure that they maintain adequate capital and liquidity. The development and ongoing refinement of that risk-management capacity is itself critical for protecting individual banks and the banking system, upon which the health of our economy depends. 1.See Ben S. Bernanke (2009), "The Supervisory Capital Assessment Program," speech delivered at "Financial Innovation and Crises," a financial markets conference sponsored by the Federal Reserve Bank of Atlanta, held in Jekyll Island, Ga., May 11-13.Return to text 2.For more information about the SCAP exercise, see the Board's website atwww.federalreserve.gov/bankinforeg/scap.htm.Return to text 3.See Board of Governors of the Federal Reserve System (2013), "Federal Reserve Releases Summary Results of Bank Stress Tests," press release, March 7; and Board of Governors of the Federal Reserve System (2013), "Federal Reserve Announces Results of Comprehensive Capital Analysis and Review (CCAR)," press release, March 14.Return to text 4.On an individual firm basis and taking into consideration planned capital actions--that is, capital raises or distributions--all but 1 of the 18 firms evaluated this year had post-stress capital ratios above the regulatory minimum.Return to text 5.See the proposed "Policy Statement on the Scenario Design Framework for Stress Testing (PDF)" of the Board of Governors of the Federal Reserve System (Nov. 15, 2012).Return to text 6.See Board of Governors of the Federal Reserve System (2013),Dodd-Frank Act Stress Test 2013: Supervisory Stress Test Methodology and Results (PDF), Appendix B: Models to Project Net Income and Stressed Capital (Washington: Board of Governors, March), pp. 37-47; and Board of Governors of the Federal Reserve System (2012), "Federal Reserve Announces the Formation of the Model Validation Council," press release, April 20.Return to text 7.A capital plan describes a firm's capital planning strategies and its processes for measuring potential capital needs both under expected and stressed operating environments and for ensuring that it is holding adequate capital to be able to continue to function even under stress. See Board of Governors of the Federal Reserve System (2011), "Capital Plans," final rule (Docket No. R‑1425),Federal Register,vol. 76 (December 1), pp. 74631-48.Return to text 8.See Board of Governors, "Federal Reserve Announces Results of CCAR," in note 3.Return to text 9.See Board of Governors of the Federal Reserve System (2012), "Supervisory and Company-Run Stress Test Requirements for Covered Companies," final rule (Docket No. 1438),Federal Register,vol. 77 (October 12), pp. 62377-96.Return to text 10.See Board of Governors of the Federal Reserve System (2012), "Annual Company-Run Stress Test Requirements for Banking Organizations with Total Consolidated Assets over $10 Billion Other Than Covered Companies," final rule (Docket No. 1438),Federal Register, vol. 77 (October 12), pp. 62396-409.Return to text 11.See Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, and Office of the Comptroller of the Currency (2012), "Agencies Clarify Supervisory Expectations for Stress Testing by Community Banks," press release, May 14.Return to text