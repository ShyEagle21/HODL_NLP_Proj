Remarks by Governor Susan S. Bies At the Carnegie Endowment for International Peace, Washington, D.C. October 1, 2002 The Challenge for Corporate Governance Posed by Financial Innovation I appreciate the opportunity to speak with you today about corporate governance in the United States. The unfolding concerns in recent months have thrust the quality of accounting, auditing, and disclosure practices of major U.S. companies into the limelight. At the heart of these issues is the breakdown in professionalism of independent auditors. Auditors have been too focused on cross-selling new services to corporations, and have lost sight of the fact that their independent attestation to the quality of financial reporting is the core value that they bring to the market place. The customers of an audit engagement are investors and creditors. The absence of leadership within the profession to call for true reform will make regaining market confidence all the more difficult. The weight of regulatory reform rests on the SEC and the new Public Company Accounting Oversight Board and we should all support this new entity as it endeavors by enforcement to change the culture of an industry. While I could focus on the issue of auditor independence, it has already received much attention. I want to instead talk about some broader, long-term issues affecting accounting and corporate governance that have not been the center of as much of the recent debate. Looking beyond the isolated cases of outright fraud, I believe a fundamental problem is this: As organizations have grown in size and scope, innovative financing techniques have made it more difficult for outside investors to understand a particular firm's risk profile and the performance of its various lines of business. Traditional accounting standards have not kept pace with the risk-management tools employed by sophisticated corporations. Thus, the disclosure of firms' risk-management positions and strategies is crucial to improve corporate transparency for market participants. The second issue I want to focus on is that financial innovation has helped increase the importance of institutional investors, such as mutual funds and pension funds, in our equity markets. Because shareholders play a key role in corporate governance, the emergence of institutional investors as major holders of corporate equity also has implications for corporate governance. As I shall discuss, a necessary response to the recent wave of financial innovation is a combination of enhanced transparency and market discipline applied by creditors, counterparties, and investors-including the institutional investors that now hold a large share of corporate equity. Together, these efforts should help lay a foundation for more effective corporate governance. Financial Innovation and Risk Management The last decades of the twentieth century were, without doubt, a period of dramatic change in financial engineering, financial innovation, and risk-management practices. Over this period, firms acquired effective new tools to manage financial risk, one of which was securitization. Many of the assets on a firm's balance sheet, such as receivables, can now be securitized--that is, grouped into pools and sold to outside investors. Securitization helps a firm manage the risk of a concentrated exposure by transferring some of that exposure outside the firm. By pooling a diverse set of assets and issuing marketable securities, firms obtain liquidity and reduce funding costs. Of course, moving assets off the balance sheet and into special-purpose entities, with the attendant creation of servicing rights and high-risk residual interests retained by firms, generates its own risks. Several types of securitization have grown rapidly over the past decade. One of the fastest growing has been asset-backed commercial paper, which soared from only $16 billion outstanding at the end of 1989 to more than $700 billion as of the second quarter of this year. Commercial mortgage securitizations have also proliferated noticeably since the early 1990s. The dollar amount of outstanding securities backed by commercial and multifamily mortgages has risen from $36 billion at the end of 1989 to nearly $400 billion as of this past June. In addition, commercial banks and finance companies have moved business loans off their books through the development of collateralized debt obligations. Securitized business loans amounted to $125 billion in the second quarter of 2002, up from a relatively miniscule $2 billion in 1989. Derivatives are another important tool that firms use to manage risk exposures. In the ordinary course of business, firms are exposed to credit risk and the risk of price fluctuations in currency, commodity, energy, and interest rate markets. For example, when an airline sells tickets months before a flight, the airline becomes exposed to fluctuations in the price of jet fuel. A higher price of jet fuel translates directly into lower profits and, perhaps, a greater risk of bankruptcy. Firms can now use derivatives--options, futures, forwards, and so on--to mitigate their exposure to some of these risks. The risk can be transferred to a counterparty that is more willing to bear it. In my example, the airline could buy a forward contract or a call option on jet fuel to hedge its risk and thereby increase its financial stability. The use of derivatives, like securitizations, has been growing rapidly in recent years. The most recent statistics from the Bank for International Settlements indicated that the notional amount of over-the-counter derivatives outstanding totaled $111 trillion in December 2001, up from $80 trillion just three years earlier. For exchange-traded derivatives, notional amounts outstanding rose from $14 trillion to $24 trillion over the same period. Complex Organizations Are Opaque As indicated by my brief discussion of securitization and derivatives, financial innovations have facilitated the separation and reallocation of risks to parties more willing and able to bear them. In the twenty-first century, businesses will use almost limitless configurations of products and services and sophisticated financial structures. A byproduct of these developments will be that outsiders will have ever more difficulty understanding the risk positions of many large, complex organizations; and traditional financial reporting--which provides a snapshot at a particular moment--will be even less meaningful than it is today. The intended or unintended consequences of the opaqueness that comes with complexity raise serious issues for financial reporting and corporate governance. Effective governance requires investors and creditors to hold firms accountable for their decisions. But its prerequisite is having the information necessary to understand the risks that the firm is bearing and those it has transferred to others. With sufficient, timely, accurate, and relevant information, market participants can evaluate a firm's risk profile and adjust the availability and pricing of funds to promote a better allocation of financial resources. Lenders and investors have an obvious interest in accurately assessing a firm's risk-management performance, the underlying trends in its earnings and cash flow, and its income-producing potential. In this regard, transparency is essential to providing market participants with the information they need to effect market discipline. Sound, well-managed companies will benefit if enhanced disclosure enables them to obtain funds at risk premiums that more accurately reflect their lower risk profiles. This would be a positive. Without such disclosure, otherwise well-managed firms will be penalized if market participants cannot perceive their fundamental financial strength and sound risk-management practices. In recent months, I have been heartened to see that renewed market discipline does appear to be forcing companies to compete for investors' support by improving the transparency of corporate reporting. Improving Accounting and Disclosure for Complex Firms Most firms and market participants favor sound accounting standards and meaningful disclosure, but some companies have not been completely transparent in their application of accounting and disclosure standards to specific transactions. In these situations, financial reports have neither reflected nor been consistent with the way the business has actually been run, or the risks to which the business has actually been exposed. In some of these cases, the company's external auditors appear to have forgotten the lessons they learned in Auditing 101. Auditors have focused on form over substance when looking at risk transfer activities, and they have failed to maintain the necessary independence from the client. But the issues run deeper than just a breakdown of basic auditing standards. As a result of the recently recognized failures of accounting, auditing, and disclosure, the market was unable to appropriately discipline the risk-taking activities of these firms on a timely basis because outsiders lacked the information from financial statements or other disclosures to do so. As critical information became available--after the fact, as it virtually always will--the market reflected its concerns about underlying business practices and accounting through the declining values of equity and debt. At this point, we do not have all of the facts about many of the situations involving alleged accounting and auditing problems, but a consensus is growing that changes should be made to some underlying accounting standards and to their application by companies and their auditors. Various groups are undertaking initiatives to correct the problems that have recently been identified. For example, the U.S. Financial Accounting Standards Board is considering how to improve the accounting standards for special-purpose entities. This is a direct response to the rapid growth of securitization and the opacity that securitization has introduced into financial reporting. The Sarbanes-Oxley Act, which became law in July of this year, contains a number of provisions to improve accounting and disclosure. CEOs and CFOs are now required to certify that their financial reports fairly represent the financial condition of the company, not just that the reports comply with Generally Accepted Accounting Principles. Sarbanes-Oxley directs the Securities and Exchange Commission to issue new rules on the disclosure of off-balance-sheet transactions. It strengthens the role of corporate audit committees and requires that audit committees are comprised exclusively of independent directors. To bolster the independence of external auditors, Sarbanes-Oxley prohibits them from providing certain internal audit and other consulting services to their clients. Finally, it creates a new Public Company Accounting Oversight Board, independent of the accounting industry, to regulate audits of public companies. These are all changes for the better. But improvements in accounting and auditing standards are also needed to address other problems that have been identified. In particular, it would be very helpful if fundamental principles and standards could be revised to emphasize that financial statements should clearly and faithfully represent the economic substance of business transactions. We need to insist on higher professional standards. We also need to move toward principles-based accounting standards rather than continue our reliance on rules-based accounting standards, since accounting rules tend to lag behind market innovation. Standards should ensure that companies give appropriate consideration to the substantive risks and rewards of ownership of their underlying assets in identifying whether risk exposures should be reflected in consolidated financial statements. Besides applying sound accounting treatments, company managers must ensure that public disclosures clearly identify all significant risk exposures--whether on or off the balance sheet--and their impact on the firm's financial condition and performance, cash flow, and earnings potential. With regard to securitizations, derivatives, and other innovative risk-transfer instruments, traditional accounting disclosures of a company's balance sheet at a point in time may not be sufficient to convey the full impact of a company's financial prospects. Equally important are disclosures about how risks are being managed and the underlying basis for values and other estimates that are included in financial reports. Unlike typical accounting reports, information generated by risk management tends to be oriented less to a point in time and more to a description of the risks. To take an example from the world of banking, where the discipline of risk management is relatively well developed, an accounting report might say that the fair value of a loan portfolio is $300 million and has dropped $10 million from the last report. However, the bank's internal risk report would show much more extensive information, such as the interest rate and credit quality of the assets and the range of values the portfolio would take under alternative future scenarios. The user of a risk-management report could determine whether changes in value were due to declining credit quality, rising interest rates, or sales or payoffs of loans. Corporate risk officers have developed other types of reports that provide information on the extent to which the total return in a particular line of business compensates for the line's comprehensive risk. On an enterprise basis, a reader of such a report can determine whether the growing lines of business have risk exposures that tend to offset those in other business lines -- thereby resulting in lower volatility for the earnings of the corporation as a whole. Complex organizations should continue to improve their risk-management and reporting functions. When they are comfortable with the reliability and consistency of the information in these reports, they should begin disclosing this information to the market, perhaps in summary form, paying due attention to the need for keeping proprietary business data confidential. Not only would such disclosure provide more qualitative and quantitative information about the firm's current risk exposure to the market, it would help the market assess the quality of the risk oversight and risk appetite of the organization. A sound risk-management system in a complex organization should continually monitor all relevant risks--including credit, market, liquidity, operational and reputation risks. Reputation risk, which recent events have shown can make or break a company, becomes especially hard to manage when off-balance-sheet activities conducted in a separate legal entity can affect the parent firm's reputation. For all these risks, disclosures consistent with the information used internally by risk managers could be very beneficial to market participants. Companies should ensure that they not only meet the letter of the standards that exist but also that their financial reports and other disclosures focus on what is really essential to help investors and other market participants understand their businesses. In this regard, I believe that the Financial Accounting Standards Board has missed an opportunity in their recent exposure draft proposing changes to the accounting treatment of special-purpose entities, or SPEs. The exposure draft focuses on the choice of consolidating or not consolidating an SPE but says little about disclosure. If FASB's goal is to make the financial reporting of firms' dealings with SPEs more informative, disclosure of the effect of the SPE on the firm would be equally necessary. For example, if firms securitize receivables through commercial paper conduits, those receivables are no longer on the company's books under current accounting standards. Yet the aging of receivables is a key indicator that investors and lenders use to assess the quality of sales and operations. If the receivables move off the balance sheet, information about the aging of the receivables should continue to be part of the firm's disclosures. Further, the disclosures should include the firm's internal assessment of how its dealings with the SPE alter its risk exposures. I hope that as FASB debates this issue in upcoming weeks, due attention will be paid to the benefits of enhancing disclosure of SPEs. I particularly want to emphasize that disclosure need not be in a standard accounting framework nor exactly the same for all organizations. Rather, we should all be insisting that each entity disclose the information its stakeholders need to evaluate the entity's risk profile. Companies should be less concerned about the vehicle of disclosure and more concerned with the substance of what information is made available to the public. And, we should keep in mind that disclosure without context may not be meaningful. These improvements in transparency are a necessary response to the recent corporate scandals and will help strengthen corporate governance in years to come. Financial Innovations, Equity Holdings, and Shareholder Activism Just as financial innovations spawned a variety of risk-management tools for businesses, they have also been responsible, in part, for changes in the structure of equity ownership. Along with advances in computer processing power that have facilitated the management of ever-larger portfolios, an increasing awareness among investors of the value of portfolio diversification has led to a dramatic secular rise in the share of equity that is held by institutional investors on behalf of households. According to the flow of funds accounts published by the Federal Reserve, the combined share of household equity managed by mutual funds, pension funds, and life insurance companies grew from only 3 percent in 1952 to over 50 percent at the end of 2001. Mutual funds held 16 percent of household equity at the end of last year, and public and private pension funds held about 10 and 20 percent, respectively. Life insurance companies held about 7 percent of household equity at that time, mainly through separate accounts that were, in effect, mutual funds with insurance wrappers. These changes are indeed dramatic and motivate an important policy question: Should we be comforted or concerned that an increasing share of household equity is in the hands of institutional investors? A primary issue is whether institutional investors are more "active shareholders" than individual investors. That is, are institutional investors more likely than individual investors to actively monitor and influence both management actions and corporate governance mechanisms at the firms in which they invest? Shareholder activism may provide market discipline directly by preventing management from pursuing its own interests at the expense of shareholders. Shareholder activism may also pave the way for other forms of market discipline--such as corporate takeovers, share price changes, and funding cost changes--by eliminating management-takeover protections and by inducing greater transparency. It is not clear whether institutional investors have more or less incentive to be activist shareholders than individual investors. On the one hand, because institutional investors make large investments in companies, they will have more bargaining power over company management than individual investors have, and they will derive more benefits from mitigating corporate malfeasance than individual investors will. Among institutional investors, pension funds and insurance companies are thought to benefit the most from shareholder activism because they tend to have relatively long-term investment horizons, while more actively managed mutual funds are thought to benefit the least. On the other hand, index fund managers may have no interest in shareholder activism since they merely adjust their holdings when the mix of the index changes and only want to follow the index, not influence it. In addition, mutual funds and pension funds may have conflicts of interest that encourage passivity. Activism by a mutual fund complex or a pension fund manager could strain its relationships with corporate clients. For example, a fund manager bidding for the management of a firm's 401-K plan may be reluctant to vote against the Board of Directors' proxy recommendations. In practice, institutional investors appear to have been relatively passive shareholders, in the sense that they have tended to initiate relatively few reform proposals. Prior to the past twenty years, most reform proposals were submitted by a handful of individuals and religious groups. Since the mid-1980s, some institutional investors--mainly large public pension funds and a few union funds--have stepped up to the plate and offered their own proposals, but corporate pension funds, mutual funds, and insurance companies have remained on the sidelines. However, appearances can be misleading. Some institutional investors are active behind the scenes, keeping close contact with the management of the firms in their portfolios directly rather than through reform proposals. Moreover, passive institutional investors may still benefit shareholders as a whole by facilitating the building of shareholder coalitions that are initiated by others or by posing a possible threat to managers who might fail to act in the interest of shareholders. Ultimately, the question of whether institutional investors mitigate corporate governance problems is an empirical one. Academic work in this area has not convincingly linked institutional holdings to firm performance, but some studies have shown that institutional shareholder activism does appear to be motivated by efforts to increase shareholder value, and other studies have confirmed that institutional activism is associated with a greater incidence of corporate governance events, such as shareholder lawsuits and corporate takeovers. Based on these findings, concluding that the rising share of household equity held by institutional investors is clearly good in terms of sound corporate governance would be premature. That said, it does seem reasonable to believe that there are benefits from institutional shareholder activism and that these benefits may help pave the way for market discipline in a broader sense. Looking ahead, I am encouraged by signs that institutional investors are becoming more active shareholders. Mutual funds reportedly have been paying closer attention to proxy voting in response to recent corporate accounting scandals. Two of the largest fund complexes in the United States now publicize their proxy voting guidelines, and one of them reportedly maintains a full-time governance staff. I am further encouraged by the recent activity of shareholder rights organizations, such as the International Corporate Governance Network, and other informal groups, which galvanize institutional and private investors to promote corporate governance reform. Also, I am hopeful that changes in the regulatory environment will promote greater attention to corporate governance. As you are no doubt aware, less than two weeks ago the SEC proposed a rule calling for compulsory disclosure of mutual fund proxy voting records. Currently, mutual funds have no legal obligation to disclose proxy votes, and in practice, few do so. As we go forward, even if transparency through corporate financial reports improves, shareholder activism will continue to be important in mitigating conflicts between management and shareholders. However, we must recognize that shareholder activism is not a substitute for disclosure. Neither activism nor the more common discipline device of selling the firm's debt and equity can work well without adequate disclosure. All forms of market discipline are built upon the solid foundation of accurate and complete disclosure.
For immediate release The Federal Reserve Board on Thursday announced the annual adjustments in the amount of net transaction accounts used in the calculation of reserve requirements and the cutoff level used to determine the detail and frequency of deposit reporting. All depository institutions must retain a percentage of certain types of deposits in the form of vault cash, or as a deposit in a Federal Reserve Bank, or a pass-through account at a correspondent institution. Reserve requirements currently are assessed on the depository institution's net transaction accounts (mostly checking accounts). For net transaction accounts in 2003, the first $6.0 million, up from $5.7 million in 2002, will be exempt from reserve requirements. A 3 percent reserve ratio will be assessed on net transaction accounts over $6.0 million to and including $42.1 million, up from $41.3 million in 2002. A 10 percent reserve ratio will be applied above $42.1 million. These annual adjustments, known as the low reserve tranche adjustment and the reservable liabilities exemption adjustment, are based on growth in net transaction accounts and total reservable liabilities, respectively, at all depository institutions between June 30, 2001 and June 30, 2002. For depository institutions that report weekly, the low reserve tranche adjustment and the reservable liabilities exemption adjustment will apply to the reserve computation period that begins November 26, 2002 and the corresponding reserve maintenance period that begins December 26, 2002. For institutions that report quarterly, the low reserve tranche adjustment and the reservable liabilities exemption adjustment will apply to the reserve computation period that begins December 17, 2002, and the corresponding reserve maintenance period that begins January 16, 2003. Additionally, the Board increased the deposit cutoff level that is used with the exemption level to determine the frequency and detail of deposit reporting. The attached Federal Register notice contains a description of the new boundaries for deposit reporting that will be effective September 2003. The Board's notice is attached.
Remarks by Vice Chairman Roger W. Ferguson, Jr. At the SWIFT Sibos World Forum, Geneva, Switzerland October 3, 2002 Business Continuity after September 11 Good afternoon ladies and gentlemen. I would like to thank the SWIFT organization for inviting me to speak to you about disaster recovery and business continuity, one of the main topics you have been discussing this week. It has now been a little more than one year since the events of September 11. Since then, bankers and the regulatory authorities in various financial centers have been intensively discussing new business-continuity challenges. This forum is very important for two reasons. First, SWIFT itself is a critical service provider for the largest financial institutions and markets. SWIFT’s efforts to provide leadership in strengthening business continuity are both welcome and important. Second, the annual Sibos meetings bring together financial industry leaders from around the world to discuss common issues affecting funds transfer, securities clearing, and other payment and settlement businesses. The people at this conference have both the responsibility and the experience to address serious common issues involving disaster recovery and business continuity. This afternoon I would like to share some thoughts with you about business-continuity challenges and to discuss a white paper on this topic that regulators in the United States have recently published for public consultation. I would also like to underscore the opportunities and responsibilities that financial firms and their financial utilities have in this new environment. Lessons from September 11 about business continuity in financial markets One of the essential lessons of September 11 is that the human spirit is both noble and resilient in the face of tragedy. Many acts of heroism have been recorded. I am sure that many more have not been recorded. Unparalleled cooperation in the financial markets supported both assistance to those in need and resumption of day-to-day operations. In the end, although the financial markets quickly returned to normal operations, I hope that we have learned from our experiences and are able, in a continuing spirit of cooperation, to address the vulnerabilities of the financial industry that were revealed by those events. It is critical that we vigorously address the possibility of terrorist attacks in areas where major financial markets or operational centers are concentrated. In discussions with financial institutions, someone typically asks, What are the specific threats or scenarios that we need to guard against? The answer to this question is not easy because law-enforcement officials and knowledgeable experts discuss a wide range of scenarios, including some with very serious consequences. In addition, the next event may be the one that we have not foreseen. We have therefore concluded that, for key planning purposes, financial institutions and financial authorities should place more emphasis on the potential effects of regional disruptions than on the potential sources of those disruptions. At the national and international level, we must focus on the systemic risk that could result from large-scale, regional disruptions in one or more financial centers. In a recent white paper issued jointly by the Federal Reserve, the Comptroller of the Currency, the Securities and Exchange Commission, and the New York State Banking Department, we identified critical financial markets in the United States. These include the markets for federal funds, foreign exchange, and commercial paper, as well as the markets for government, corporate, and mortgage-backed securities. Additionally, most of these markets are closely integrated with global financial markets with respect to institutional participation and liquidity management as well as pricing and overall risk management. From working with clearing organizations and private financial firms since September 11, we know that they are taking steps to reassess their vulnerabilities to regional events. They have strong incentives to strengthen their own resiliency. Their counterparties expect it. The regulatory community has also been working hard to strengthen the foundations of critical markets, for three reasons. First, because clearing and settlement functions are performed as part of an interdependent network of activity, there is a concern that the incentives of one organization to strengthen resilience may not fully reflect either the impact of its loss on others or the benefits of its greater resilience for the entire market. Second, there is a concern that in times of cost pressures organizations may be tempted to overly discount the risk of future regional events. Third, there is a concern that competitive pressures will lead some firms to delay improvements in resilience in the hope that others will shoulder the responsibility. In other words, there is a concern that some private organizations may not make sufficient and consistent investments in resilience for the sake of the industry as a whole. In addition, over the past thirty years the clearing and settlement infrastructure has become increasingly concentrated in the United States and in some other countries as financial firms have pursued the advantages of economies of scale and invested in technology to reduce costs and streamline procedures. In Europe, this process accelerated following the introduction of the euro. Not surprisingly, the overall consolidation of infrastructure has been accompanied by increasing technical linkages and interdependence within and across markets. In this type of environment, significant single points of failure within clearing and settlement processes can have far-reaching effects throughout the financial markets. To address these concerns, the regulatory community has adopted a strategy to help reduce systemic risk from regional disruptions to the clearing and settlement infrastructure. This strategy has three broad components: first, prevention; second, management; third, testing and assurance. The objective is to reduce the probability that a regional event would bring critical financial markets to a standstill and to ensure the smooth operation of critical infrastructure, if possible. Another objective is to allow the most active firms, at a minimum, to wind up transactions, manage the related financial risk, and to resume trading as soon as commercially reasonable. Sound practices Our recent white paper sets out several sound practices to achieve these objectives. To help prevent and contain the effects of a regional event, financial utilities and critical firms should regionally diversify their back offices and operational sites that support clearing and settlement for critical markets. In particular, primary operations and backup operations need to be significantly more diverse in order to meet the greater regional risks. The old model of having primary and backup operations centers in close proximity so that they can be served by a common labor pool does not address the possibility of a significant threat to an entire region and labor pool. To help manage a regional event, the white paper sets out as a sound practice that financial utilities should plan to recover and fully resume operations on an intraday basis. The paper notes that an emerging sound practice is for these utilities to plan to recover and to resume operations within two hours or less. Of course, actual recovery times will depend on circumstances. However, the objective of rapid intraday recovery provides an important focal point for planning and testing by both utilities and their financial institution customers. I should note that the Federal Reserve’s own current recovery objectives for Fedwire are much more aggressive than two hours. The paper recognizes clearly that financial firms’ ability to recover their overall operations is critically dependent on their financial utilities. This means, in general, that the utilities will have to recover and resume operations more quickly than their participants in order to enable those participants and the overall market to recover in an orderly way. Many financial institutions are shareholders and board members as well as participants in private-sector utilities. It will be very important for the management of these utilities and their shareholder-participants to work closely to ensure that the recovery and resumption strategies of both the utilities and the participants meet sound practices and are consistent with one another. The white paper also proposes that firms that play significant roles in critical financial markets should plan to recover their operations sufficiently so that they can clear and settle trades that have already been executed, as well as complete funds-transfer and other critical operations, on the same business day that an event occurs. The paper notes that an emerging sound practice in the industry would call on these significant players to plan to recover in four hours or less, again depending somewhat on circumstances. To help prepare for a regional event, the white paper encourages greater contingency and assurance testing. As we learned from Y2K and again from September 11, testing is one of the vital elements of contingency planning. Our white paper recommends that financial utilities and firms that play significant roles in critical markets routinely use or test their recovery and resumption arrangements for the required connectivity, functionality, and capacity. In particular, greater testing between the backup facilities of financial utilities and the backup facilities of their critical members would help the clearing and settlement infrastructure perform more smoothly in the event of a regional disruption. Much more coordinated testing among utilities and firms serving different markets would also help in the management of problems involving cross-market clearing and settlement linkages. Obviously, in preparing for Y2K we engaged in very large-scale testing. In the current context we understand that there may ultimately be diminishing returns from repeated testing and that we must learn from our experiences in preparing for Y2K. The industry again is working together to help define reasonable and meaningful tests and to cooperate by participating in them. In the United States, the Federal Reserve and Clearing House Interbank Payments System (CHIPS) have already coordinated their test schedules. The Federal Reserve Bank of New York’s Payment Risk Committee, the Securities Industry Association, and the Banking Industry Technology Secretariat are working together to address testing and similar issues. As I have said before, this spirit of cooperation in addressing critical, cross-industry problems of business continuity and testing is welcome. SWIFT played a very important role in preparations for Y2K and since September 11 has been working to share ideas and coordinate testing with other organizations. I hope the results of your meetings this week will provide additional ideas and the ongoing support necessary to address the difficult issues involved in strengthening the industry’s level of testing. SWIFT clearly can play an important role in promoting and facilitating testing. More broadly, SWIFT can adopt and foster emerging best practices for business continuity. Challenges in addressing the risks of regional disruptions I would now like to identify three primary challenges in implementing a strategy to address regional disruptions. These challenges involve people, business, and technology. In developing strategies for regional disruption, we must recognize that the safety of people--our colleagues, employees, and their families--is paramount. Different strategies of regional diversification, along with efforts to strengthen security and crisis response within regions, will help protect our people. One of the challenges that we face, however, is how to increase individual safety without losing the efficiencies that we have gained from concentrating staff and expertise at critical geographic locations. The effect of regional diversification on business also presents challenges. Firms will both incur costs and reap benefits with diversification, but it is often difficult to justify adding costs to address contingencies. Firms inevitably have a number of strategic priorities and projects that contend for resources. We also recognize that some firms are in different positions than others in addressing regional issues. Some firms have a national or international “footprint” that makes it somewhat easier to take important measures to diversify operational centers and back-office operations. Others, because of historical circumstances or regional specialization, have harder decisions to make. These issues are always difficult. Firms that play significant roles in critical markets, in particular, need to think very carefully about the new situation we are facing, along with their importance to their customers, counterparties, and the markets generally. At the highest levels of major firms, there is a real need for leadership in dealing with an issue that goes beyond ordinary business decisions. Our white paper asks a series of questions about how to identify critical firms that need to adopt sound practices for regional diversification and seeks guidance on cost and similar issues. The third important challenge involves technology. Some key technologies for data storage and communication do not accommodate regional diversification as readily as we all would like. The challenge here will be to modify existing arrangements, solve technological problems, and find new ways to facilitate diversification. I am sure that the firms attending Sibos are very aware of these issues, and I trust that the market for these technologies will see a flow of very creative solutions over the coming months. I would like to add a note about telecommunications. We have known for some time that our progress in automating the financial markets has made us highly dependent on telecommunications. In our own discussions within the Federal Reserve and our discussions with others, the issue of telecommunications circuit diversity is very important. I encourage firms to take this issue seriously and to discuss it with individual telecommunications providers, industry groups, and appropriate government officials. Conclusion In taking the next steps to strengthen the foundations of our critical financial markets, we need to constantly remember how dependent we are on one another. We will not accomplish our task if one or two organizations strengthen their resilience and others do not. Instead, we need to work hard to adopt consistent strategies to meet regional risks that together address prevention, management, and testing. The importance of creating and maintaining a highly resilient financial services sector is self-evident. Similarly, the challenges to achieving that goal are numerous, involving, as I indicated, people, business, and technology. Given the importance and complexity of this topic, senior management will need to become fully engaged. At the international level, the openness of our financial systems means that the business-continuity practices in one country can affect critical markets in another. We will therefore need to share information and sound practices that will help us address regional risks in various countries. At this stage, this does not necessarily mean traditional regulatory coordination. Rather, private firms and the financial authorities will need to work together within their various communities and with each other to make our key business-continuity practices more robust and more consistent. We also need to recognize that new business-continuity strategies need to be practical. We are looking forward to receiving the views of market participants and other knowledgeable experts to help ensure that the final white paper ultimately sets out sound practices that are well grounded and practical. As we work through these new challenges, however, we must keep in mind that to do nothing would leave serious risks unaddressed. I would like to close by noting the importance of our financial centers. These cities are a source of work, play, and inspiration for millions of people. These cities need to be vibrant and resilient, even as new challenges arise for security and stability. Our financial policies to address new regional challenges should be designed to strengthen the resilience of these great centers and their people, not to abandon them. The regional diversification of back offices and operational sites is intended as a prudent strategy that will enable financial centers and their markets to continue to serve as robust sources of economic progress.
No content found
Remarks by Chairman Alan Greenspan Banking At the annual convention of the American Bankers Association, Phoenix, Arizona (via satellite) October 7, 2002 It is a pleasure to once again join the members of the American Bankers Association at your annual meeting. This morning I would like to explore the apparent incongruity between the recent substantial losses on corporate credits and the continued strength of the U.S. banking system. Over the past two or three years, the U.S. financial system has suffered a sharp run-up in corporate bond defaults, business failures, and investor losses. At commercial banks, troubled loans--including charge-offs, classified loans, and delinquent credits--have also climbed to quite high levels. At the same time, banks in this country remain quite healthy--with strong profits and rates of return and with capital and reserves not much below recent historical highs. Our banks have been able to retain their strength in this business cycle, in contrast to the early 1990s when so many either failed or had near-death experiences. Why is this? The answer may tell us much about the changes in our financial and economic system over the intervening dozen years or so. Part of the answer, of course, is that the real economy was different during these two intervals. The most recent recession was less severe and centered mainly in the business sector. After years of rapid growth, capital spending plunged as firms realized that investments in capital goods, especially in the telecommunication and other high-tech sectors, were excessive. The financing of this high level of spending with debt, which was seen as prudent when equity valuations were high, led to a rise in defaults when firms were no longer able to repay bank loans and other debt through equity issuance in a depressed stock market. In contrast, despite the substantial destruction of wealth reflected in the decline in equity prices, households, encouraged by ongoing increases in income and housing wealth, have maintained their expenditures. Low mortgage rates encouraged households to purchase both new and existing homes, the latter enabling sellers to extract large amounts of home equity, previously enhanced by capital gains. Low rates also encouraged refinanced mortgage cash outs and rapid expansion of home equity loans. Consumer and mortgage loans have not suffered the sharp run-up in delinquencies that loans in the business sector have, and they have contributed significantly to the earnings of the banking system, providing it with the ability to absorb losses elsewhere, to maintain loss reserves, and still to show significant profits. Those banks with relatively large exposures to the business sector and insufficient offsets from other earning flows were able to avoid stresses because they entered the period with both substantial capital and reserves. These positions reflected not just diligent supervision and the Basel I capital reforms but also a marketplace that increasingly demands strength in financial institutions that serve as counterparties in frontier financial risk-management transactions. And bank managers who lived through the late 1980s and early 1990s found capital buffers comforting as well as useful. That banks had impressive earnings and balance sheets going into the current period of stress is of key significance. The strong balance sheets lowered funding costs and provided needed buffers. Some banks also benefited from the increased diversification and scale of their operations that had resulted from previous consolidations. The larger banks were better able not only to spread their portfolio risks across a wider range of customers but also to broaden their funding sources. An analysis of the resiliency of the U.S. banking system would be far from complete without a recognition of the new techniques in risk management that have been applied in banking during the past few years. To be sure, at most banks the application of these practices has just begun, and even the most advanced banks still have significant strides to make. Nonetheless, the efforts to quantify risk have provided management with a far more disciplined and structured process for evaluating credits, pricing risk, and deciding which credits to retain. In the process, banks are becoming much less dependent on the analysis and subjective judgments of lending officers. Although such judgments in the end are indispensable to the lending process, a methodical, systematic, and quantitative review of facts--including the effects of material new exposures on the lender's consolidated risk--provides a greater depth to risk management than we have had in decades past. Improved risk management and technology have also facilitated, of course, the growth of markets for securitized assets and the emergence of entirely new financial instruments--such as credit default swaps and collateralized debt obligations. These instruments have been used to disperse risk to those willing, and presumably able, to bear it. Indeed, credit decisions as a result are often made contingent on the ability to lay off significant parts of the risk. Such dispersal of risk has contributed greatly to the ability of banks--indeed of the financial system--to weather recent stresses. More generally, the development of these instruments and techniques have led to greater credit availability, to a more efficient allocation of risk and resources, and to stronger financial markets. The flexibility and size of the secondary mortgage market has been especially important in the United States. Since early 2000, this market has facilitated the large debt-financed extraction of home equity I just noted. That, in turn, has been critical in supporting consumer outlays in this country through the recession. This market's flexibility has been particularly enhanced by extensive use of interest rate swaps and options to hedge maturity mismatches and prepayment risk. Financial derivatives, more generally, have grown at a phenomenal pace over the past fifteen years. Conceptual advances in pricing options and other complex financial products, along with improvements in computer and telecommunications technologies, have significantly lowered the costs of, and expanded the opportunities for, hedging risks that were not readily deflected in earlier decades. Moreover, the counterparty credit risk associated with the use of derivative instruments has been mitigated by legally enforceable netting and through the growing use of collateral agreements. These increasingly complex financial instruments have been especial contributors, particularly over the past couple of stressful years, to the development of a far more flexible, efficient, and resilient financial system than existed just a quarter-century ago. Banks appear to have effectively used such instruments to shift a significant part of the risk from their corporate loan portfolios to insurance firms here and abroad, to foreign banks, to pension funds, to hedge and vulture funds, and to other organizations with diffuse long-term liabilities or no liabilities at all. Most of these transfers were made early in the credit-granting process, and significant exposures to telecommunication firms were laid off through credit default swaps, collateralized debt obligations, and other financial instruments. Other risk transfers reflected later sales at discount prices as credits became riskier and banks rebalanced their portfolios. Some of these sales were at substantial concessions to entice buyers to accept substantial risk. Whether done as part of the original credit decision or in response to changing conditions, these transactions represent a new paradigm of active credit management and are a major part of the explanation of the banking system's strength during a period of stress. Of course, sound risk-management techniques require more than adequate tools and diverse markets. Managers must also pay attention to changing risks and respond effectively to them. In this respect, developments in 1998 were key in alerting U.S. banks to mounting risk. After three or four years of economic expansion, loan growth, and rising profits, the Asian crisis and the Russian default sent a strong and timely message to U.S. banks to raise their credit standards and more actively manage their existing portfolios to limit risk exposures. I am aware of no other time when banks began so much before the cyclical peak to be highly sensitive to potential risks in either new or existing credits. That experience is indicative, I believe, of how better risk-management techniques can infuse the decisionmaking process with increased discipline and can focus attention on the need to balance risk and reward. We can have little doubt that we have seen a new response mechanism that has contributed to the health of the banking system, one that I trust will be more than transitory. To be sure, there were, and still are, substantial problems. Large losses have been taken, and more are yet to be recognized. No risk-management system will ever be flawless, and I emphasize that banks have just begun the process of applying the new quantification techniques. Indeed, quantification techniques require quantities--numbers --to work. The most recent credit cycle has created an abundant supply of exactly the kind of critical information that banks will need to improve their risk-management: information about default rates and the associated losses by borrower and loan type. Now is the time to collect and maintain these default and loss data in a disciplined and uniform fashion. Most banks missed that opportunity in the early 1990s, and some are going back at great cost to mine these data today. A decade ago, one might have been excused from undertaking such data collection efforts because of the technology then existing and the cost of data storage. These reasons are no longer justified. Further, the collection of data on defaulting credits, both from past cycles and on a continuing basis, is required to link internal default and loss estimates with the minimum regulatory requirements under the new Basel Capital Accord now being developed for the large internationally active banks. Banks of all sizes are familiar with the importance of data in the quantification of risk-management tools. The simplest of these techniques, credit-scoring models, have been in wide use over the past ten to fifteen years by lenders, insurers of loans, and participants in secondary markets. The technologies have been integrated into routine business operations. They all incorporate past data about borrowers to predict and rank potential borrowers by the risk of default. These technologies have sharply reduced the cost of credit evaluation and improved the consistency, speed, and accuracy of credit decisions. Credit-scoring technologies have served as the foundation for the development of our national markets for consumer and mortgage credit, allowing lenders to build highly diversified loan portfolios that substantially mitigate credit risk. Their use also has expanded well beyond their original purpose of assessing credit risk. Today they are used for assessing the risk-adjusted profitability of account relationships, for establishing the initial and ongoing credit limits available to borrowers, and for assisting in a range of activities in loan servicing, including fraud detection, delinquency intervention, and loss mitigation. These diverse applications have played a major role in promoting the efficiency and expanding the scope of our credit-delivery systems and allowing lenders to broaden the populations they are willing and able to serve profitably. The use of credit-scoring models, whether turnkey models purchased from providers or proprietary models developed in house, has taught bankers--sometimes through costly experience--the value of continually updating the database on which the model operates. Indeed, one can speculate that some of the problems this year in subprime credit card losses may well represent an insufficiently long data series to score successfully such credits during a recession. The experience with credit-scoring models underlines the necessity of basing more-sophisticated quantitative approaches, approaches that seem to have served the banking system so well when applied initially, on a longer and larger database of loss experience. Let me conclude by noting an often overlooked fact. The use of the more- sophisticated techniques I spoke of earlier, especially the various forms of derivatives, are, by construction, highly leveraged. They are thus prone to induce speculative excesses, not only in the U.S. financial system, but also through out the rest of the world. The greater potential for systemic risk can be contained by improvements in effective risk management in the private sector, including market discipline based on better public disclosure, and by improvements in bank supervision and regulation in the public sector. To be sure, as I have noted elsewhere, there is some level of risk that must be absorbed, as a last resort, by central banks if an economy is to obtain the full resource allocation benefits of financial intermediation. The supervisors of the industrial world have been working together for two decades, through the Basel Committee on Banking Supervision, to improve bank supervision and regulation. The revised Capital Accord, now almost fully developed, places much greater emphasis, implicitly and explicitly, on improved risk-management systems. All of this has the potential for placing even more responsibility on commercial banks for reducing both their own and systemic risk. Most financial institutions will neither need nor be expected to achieve the complex risk-management practices required by the new Basel Accord for large, complex banking organizations, but their operations will not be unaffected. Success, indeed survival, requires that we all adapt. The recent experience of the U.S. banking system suggests that it has begun to prepare itself for the task.
For immediate release The Federal Reserve Board announced today the approval of the application of Fortis Bank S.A./N.V., Brussels, Belgium, to establish branches in New York, New York, and Stamford, Connecticut. Attached is the Order relating to this action.
Remarks by Governor Susan S. Bies At the Annual International Symposium on Derivatives and Risk Management, Fordham University School of Law, New York, New York October 8, 2002 Corporate Governance and Risk Management I want to thank Dean Treanor and Alan Rechtschaffen for the invitation to participate in this timely symposium on corporate governance issues. When I joined the Federal Reserve Board of Governors last December, I knew I would be doing more than helping to set short-term interest rates. While the general public and market focus on the decisions of the Federal Open Market Committee, Board members spend much of their time on various operating committees, focusing on payment and settlement systems, and the safety and soundness of financial institutions and markets. But the rush of current events has meant that I have spent less of my time dusting off my economics Ph.D. and more time using my experience as a corporate chief financial officer, auditor, risk manager, and accountant, to consider the policy issues of recent corporate control failures. Today I want to focus on the role that risk management can play in strengthening corporate governance from the point of view of boards of directors, management, and internal control functions. Managing Risks The last decades of the twentieth century were, without a doubt, a period of dramatic change in financial engineering, financial innovation, and risk-management practices. Enterprise-wide risk management has been evolving as financial theory has advanced, new technology has made modeling of risks more feasible, and innovation has helped to find better ways to mitigate risk. Some types of risk are further along in the evolutionary process. While there are many ways to categorize risk, I will use three broad categories for illustration -- market, credit, and operating. Operating risk is the least developed, as conceptual frameworks, metrics, and databases are still in preliminary stages. I will come back to the issues surrounding operating risk in a few moments. Market risk arguably has evolved the furthest because of the transparency of markets, frequency of transactions, and financial engineering that can parse the various forms of risk exposure so that appropriate financial instruments can be developed to hedge the specific components of risk. The treasury functions of corporations routinely use models to assess and manage price, interest rate, liquidity, and foreign exchange risk. As a result, managers can better anticipate changes in revenue and expense due to these factors and develop responses to their specific circumstances. One tool for managing risk is securitization. Many of the assets on a firm's balance sheet, such as receivables and customer leases, can now be securitized--that is, grouped into pools and sold to outside investors. Securitization helps a firm manage the risk of a concentrated exposure by transferring some of that exposure outside the firm. By pooling a diverse set of assets and issuing marketable securities, firms obtain liquidity and reduce funding costs. Of course, moving assets off the balance sheet and into special-purpose entities, with the attendant creation of servicing rights and high-risk residual interests retained by firms, generates its own risks. Derivatives are another important tool for managing risk exposures. In the ordinary course of business, firms are exposed to credit risk and the risk of price fluctuations in currency, commodity, energy, and interest rate markets. For example, when an airline sells tickets months before a flight, it becomes exposed to fluctuations in the price of jet fuel. A higher price of jet fuel translates directly into lower profits and, perhaps, a greater risk of bankruptcy. Firms can now use derivatives--options, futures, forwards, and so on--to mitigate their exposure to some of these risks. The risk can be transferred to a counterparty that is more willing to bear it. In my example, the airline could buy a forward contract or a call option on jet fuel to hedge its risk and thereby increase its financial stability. Another major category of risk is credit risk, which also has become much more quantified. Models analyze a corporate customer's or borrower's probability of default, the loss in the case of default, and the borrower's likely exposure at the time of default, taking into consideration future draw-downs. The greater use of credit models in retail transactions provides a stronger framework to assess risk and ensure that pricing reflects credit quality. For consumer credit, however, models are less proven, since data collection and loss estimates generally evolved after the 1990-91 recession and so have not been proven under stress conditions or for subprime borrowers. Because many of these borrowers did not have significant access to credit in previous recessions, their ultimate default rate in the current cycle should help to validate the strength of the new statistical models. For example, the health of financial institutions today reflects the improvement in the risk management process that has been ongoing at banks for many years. Increasingly, the entire risk management process has become more quantitative, reflecting not only the enhanced ability and lower costs of collecting and processing data, but also improved techniques for measuring and managing risk. The banking industry has been able to report record earnings in the first half of this year, despite rising loan losses for large corporate credits and credit cards. Banks have diversified their revenue streams to mitigate the impact on earnings during credit cycles. And by improving risk management processes, bankers have learned to identify risk exposures that exceed the target return on capital and sell, hedge, or use controls to mitigate risk exposures. Risk Assessment As corporations grow larger and more diverse, it becomes more difficult for executive management and boards of directors to monitor activity across the company. Directors, particularly, do not have the time to understand all of the transactions occurring. Thus, a key issue for boards and audit committees is how to focus their attention to the appropriate areas. This is where a sound risk management and internal control framework can be very helpful. The Sarbanes-Oxley Act requires management to issue a report about the quality of internal controls. A similar requirement was put into effect for banks in the Federal Deposit Insurance Corporation Improvement Act of 1991. Since then, bankers have adopted approaches along the lines of the Committee of Sponsoring Organizations' of the Treadway Commission (COSO) Internal Control--Integrated Framework . This requires all managers, at least once a year, to step back from other duties, and evaluate risks and controls. Each manager considers current and planned operation changes, identifies the risks, and determines appropriate mitigating controls and the effectiveness of those controls. Managers then report their assessment up the chain of command to the chief executive officer, with each new level of management in turn considering the risks and controls under their responsibility. The external auditors attest to the results of this self-assessment in banks, and results are reported to the audit committee of the board of directors. Thus, the process helps management communicate among themselves and with the board about the dynamic issues affecting risk exposures, risk appetites, and risk controls throughout the corporation. Risk assessments such as the one outlined in COSO's internal control framework presumably could be useful in assessing the relative risk and returns from various lines of business when formulating business strategies. But not all corporations and boards consider risk as a part of their annual strategic planning or other evaluation processes. A study conducted this year by the Institute of Internal Auditors and the National Association of Corporate Directors showed that directors are not focusing on risk management. Forty-five percent of directors surveyed said their organization did not have a formal enterprise risk management process -- or any other formal method of identifying risk. An additional 19 percent said that they were not sure whether their company had a formal process for identifying risks. Sound corporate governance is an essential element of a strong risk management process. Governance involves many players, each with specific assigned responsibilities to ensure that the system as a whole is sufficient to support the business strategy and ensure the effectiveness of the systems of internal control. Directors are not expected to understand every nuance of every line of business or to oversee every transaction. They can look to management for that. They do, however, have the responsibility to set the tone regarding their corporations' risk-taking and to oversee the internal control processes so that they can reasonably expect that their directives will be followed. They also have the responsibility to hire individuals who they believe have integrity and can exercise a high level of judgment and competence. In the light of recent events, I might add that directors have the further responsibility to periodically determine whether their initial assessment of management's integrity was correct. Indeed, beyond legal requirements, boards of directors and managers of all firms should periodically test where they stand on ethical business practices. They should ask, for example, "Are we getting by on technicalities, adhering to the letter but not the spirit of the law? Are we compensating ourselves and others on the basis of contribution, or are we taking advantage of our positions?" Risk Management and Internal Controls Boards of directors are responsible for ensuring that their organizations have an effective audit process and that internal controls are adequate for the nature and scope of their businesses. The reporting lines of the internal audit function should be such that the information that directors receive is impartial and not unduly influenced by management. Internal audit is a key element of management's responsibility to validate the strength of internal controls. Internal controls are the responsibility of line management. Line managers must determine the level of risks they need to accept to run their businesses and to assure themselves that the combination of earnings, capital, and internal controls is sufficient to compensate for the risk exposures. Supporting functions such as accounting, internal audit, risk management, credit review, compliance, and legal should independently monitor the control processes to ensure that they are effective and that risks are measured appropriately. The results of these independent reviews should be routinely reported to executive management and boards of directors. Both executive management and directors should be sufficiently engaged in the process to determine whether these reviews are in fact independent of the operating areas under review and whether the officers conducting the reviews can, indeed, speak freely. In many of the recent corporate and audit firm failures that have received public attention, basic tenets of internal control, particularly those pertaining to operating risks, were not followed. Recent events should remind boards of directors, management, and auditors that internal controls and sound governance become even more important when firms' operations move into higher-risk areas. Indeed, when changes are happening, control failures often increase significantly. Rapid growth, merger of operation centers, and introduction of new products and delivery channels are examples of situations that put stress on the control environment. When these types of changes occur, "people risks" rise. These are risks that are related to training employees in new products and processes. Employees who join the organization need to learn the culture of the company and the control environment. Employees unfamiliar with their new responsibilities--the systems they use, the services they provide customers, the oversight expected by supervisors and members of internal control functions--are all more likely to create control breaks. Rapid growth and change also modify the relative risks to an organization. New lines of business may require different customer-qualification tests to meet the expected levels of customer risk exposure. Further, the pressure to beat a competitor to market with new products may shortcut the design-review process and omit an important control or allow a programming error to adversely affect the software used to deliver the services. Many of the companies that have been the center of recent governance failures demonstrate some similar characteristics. They were lead by hard-charging entrepreneurs whose ability to think outside the box pioneered advances in new lines of business. But the personalities of these individuals, in many cases, led to a focus on sales growth and support and inadequate time spent building the control infrastructure. Another form of people risk is internal fraud. When expectations of the market and supervisors, or pressures of personal life become overwhelming key officers may step over the ethical and legal boundaries and cover up errors or purposely steal from the corporation. While executive fraud is very difficult to detect, it is eventually discovered. Obviously, during the past year, we've seen severe reactions to observed failures within corporations--not only from investors and creditors, but also from lawmakers and regulators. Although risk management has become much more quantitative, considerable management judgement must be applied to the risk management process. Frequent, small losses can generally be absorbed in the operating margin of the product or service. It is the low-probability, large losses that provide the greatest challenge. And, it is just such risks--the ones that can severely damage, if not kill, an organization--that too many enterprises do not formally take into consideration. When one looks at the extreme loss events for many types of operating risks, for example, executive frauds, it is easy to recognize that the normal bell-shaped probability distribution does not fit. Rather, the extremely long-or fat-tailed distributions emphasize that risk management and internal control judgments must be applied. What is even more difficult, is that some exposures can better be classed as uncertainties than as risks. That is, patterns of losses, and risk drivers, are very hard to identify. Terrorist attacks, technology breakthroughs, and other events that cannot be defined ahead of time often have significant implications for the loss exposures of corporations. Indeed, recent events have demonstrated that the complexity and size of modern corporations create significant market risk exposures that give management and the board of directors little time to react after serious breaches in internal controls become known. Reputation risk, especially in a trust business like banking, can lead to loss of liquidity, cancellation of major new contracts, and indictments, which bring the ultimate corporate loss--failure of the firm. And as we have seen, the market's response can be harsh. Risk Management and Disclosure The intended or unintended consequences of the opaqueness that comes with complexity raise serious issues for financial reporting and corporate governance. Effective governance requires investors and creditors to hold firms accountable for their decisions. But they must first have the information necessary to understand the risks that the firm is bearing and those it has transferred to others. Here again, enterprise risk management can provide a framework through which management and boards can convey appropriate information that will allow outsiders to understand the company's risk exposures and how the company limits and manages those risks. Public disclosures by corporations need not follow a standard framework that is exactly the same for all. Rather, we should insist that each entity disclose the information it believes its stakeholders need to evaluate its risk profile. Each business line in a complex organization is unique, and--to be most effective--the specific disclosures of its risks should be different, too. Even in smaller organizations, disclosures should be tailored to reflect the activities of the organization. A summary of the information that executive management and the board of directors need to monitor the health of the enterprise is an excellent place to start when tailoring the information that would be useful to investors and customers. Disclosure rules that are too rigid may become incompatible with risk management processes that continually evolve. Disclosures should clearly identify all significant risk exposures--whether on or off the balance sheet--and their impact on the firm's financial condition and performance, cash flow, and earnings potential. With regard to securitizations, derivatives, and other innovative risk-transfer instruments, traditional accounting disclosures of a company's balance sheet at a single point in time may not be sufficient to convey the full impact of a company's financial prospects. For example, if a firm securitizes receivables through commercial paper conduits, those receivables are no longer on the company's books under current accounting standards. Yet the aging of receivables is a key indicator that investors and lenders use to assess the quality of sales and operations. If the receivables move off the balance sheet, information about the aging of the receivables should continue to be part of the firm's disclosures. Equally important are disclosures about how risks are being managed and the underlying basis for values and other estimates that are included in financial reports. These disclosures should identify key risk drivers and describe the range of possible outcomes. Unlike typical accounting reports, information generated by risk management tends to be oriented less to a point in time and more to a description of the risks and the variability of results. To take an example from the world of banking where the discipline of risk management is relatively well developed, an accounting report might say that the fair value of an investment portfolio is $300 million and has dropped $10 million from the last report. However, the bank's internal risk report would show much more extensive information, such as the interest rate, maturity, and credit quality of the assets and the range of values the portfolio would take under alternative future scenarios. The user of a risk-management report could determine whether changes in value were due to declining credit quality, rising interest rates, portfolio sales, or payoffs of underlying loans. Corporate risk officers have developed other types of reports that provide information on the extent to which the total return in a particular line of business compensates for the line's comprehensive risk. On an enterprise basis, a reader of covariance reports can determine whether the growing lines of business have risk exposures that tend to offset those in other business lines--thereby resulting in lower volatility for the earnings of the corporation as a whole. If the lines of business have high correlations, investors would expect management and the boards of directors to have in place more significant processes to monitor and mitigate those risks. Complex organizations should continue to improve their risk-management and reporting functions. When they are comfortable with the reliability and consistency of the information in these reports, they should begin disclosing this information to the market, perhaps in summary form, paying due attention to the need for keeping proprietary business data confidential. Not only would such disclosure provide more qualitative and quantitative information about the firm's current risk exposure to the market, it would also help the market assess the quality of the risk oversight and risk appetite of the organization. A sound risk-management system in a complex organization should continually monitor all relevant risks, including credit, market, liquidity, operational, and reputation risks. Reputation risk, which recent events have shown can make or break a company, becomes especially hard to manage when off-balance-sheet activities conducted in a separate legal entity can affect the parent firm's reputation. For all these risks, disclosures consistent with the information used internally by risk managers could be very beneficial to market participants. Conclusion In conclusion, an effective enterprise-wide risk management process can provide executive management and the board of directors with a framework to strengthen the governance process. Risk management can identify where exposures exceed the risk- tolerance limits and determine where investments in enhanced controls can most effectively mitigate remaining risks. The evolution of risk management can provide metrics for management and the board of directors to assess the relative returns from various forms of risk exposures and can help shape strategic decisions. For companies undergoing rapid growth and those engaged in relatively new business processes and practices, risk management can provide a method for developing an internal control infrastructure to support the success of the business strategy. Further, the risk management framework can improve the transparency of disclosures to help investors and customers better understand the operations of the firm. I particularly want to emphasize that disclosure need not be in a standard accounting framework or exactly the same for all organizations. Rather, each entity should disclose the information its stakeholders need to best evaluate the entity's risk profile. Companies should be less concerned about the vehicle of disclosure and more concerned about the substance of the information made available to the public. No business can afford to remain static, and firms of all sizes should continually pursue better ways to manage risk. The discipline of risk management is still relatively young. Investments in better forms of risk management processes often reduce losses and provide a more robust framework for evaluating business alternatives. Following sound risk management, governance, and disclosure practices consistently is also crucial to maintaining the confidence of capital and financial markets. Boards of directors and executive management are responsible for ensuring that the corporate governance process is conducted with competence and integrity. If they do, our economic system should grow stronger. Footnotes After Enron: A Survey for Corporate Directors, Institute of Internal Auditors and National Association of Corporate Directors, 2002.
Remarks by Vice Chairman Roger W. Ferguson, Jr. At the Bond Market Association 2002 Awards Dinner, New York, New York October 9, 2002 Central Banks and Markets I thank the members of the Bond Market Association for selecting me to receive the 2002 Distinguished Public Service Award. I am particularly honored to join the company of previous recipients, who have included my colleagues Alan Greenspan and Bill McDonough, former Treasury Secretary Rubin, and Senators Christopher Dodd and Kay Bailey Hutchinson. I understand that the proceeds from this dinner will be used to support the work of the Bond Market Foundation, whose mission includes advancing the financial literacy of disadvantaged Americans. That this is a high purpose is beyond doubt. I know that I could speak for much longer than you care to listen about why the understanding of economics and finance is crucial for individuals in a market economy. Knowledgeable and astute consumers can avoid making those investment errors that come from misunderstanding or being misled. They also promote competition among providers, which benefits us all. Personal financial security enhances individual well-being. And, at a more fundamental level, our social fabric and national image are intimately connected to our material aspirations. The United States cannot be the land of opportunity unless all of our citizens have both the tools and the ability to use those tools to improve their livelihoods and lives. Fortunately, the increasing supply of services provided by our financial system--and the increasing complexity and diversity of product offerings--have increased consumer demand for improved financial education. The Bond Market Foundation, like the Federal Reserve, has been looking for new ways to meet that demand. There are numerous other ways in which the Federal Reserve and the Bond Market Association, and the fixed-income markets more generally, work together to improve the well-being of our fellow citizens. Obviously, the impulse of monetary policy is transmitted, in part, through interest rates set by the market. We target only the overnight rate, and traders and investors, such as those represented and serviced by those here this evening, determine longer-term interest rates on Treasury and private securities. The resulting structure of rates and spreads in the fixed-income markets can in turn be a valuable tool that we can use when analyzing the current state of macroeconomic conditions and forecasting the future. Clearly, however, the roles of the fixed-income markets and the Federal Reserve are complementary, not identical. Your role is to allocate scarce savings among competing demands. Ours is to set overall conditions, particularly by maintaining price stability, that allow market prices to accurately reflect supply and demand dynamics. A price system that is accurate in that way supports the market allocation of all resources, including capital, to their most productive uses. At times, markets and Federal Reserve policy are complementary in an additional way. As we saw last September 11, when conditions in markets become so stressed that they no longer function efficiently for pricing and allocating risk, the Federal Reserve may be called upon to provide temporary infusions of liquidity. However, it is also important to understand the limits of what the Federal Reserve, or monetary policy more generally, can do. First, monetary policy action cannot appropriately be targeted to benefit one industry, region, or economic group. We key our policy on the average macroeconomic condition that prevails, knowing that conditions may vary greatly among industries, regions, and groups. Of course, that means that those individuals and businesses whose conditions are significantly different from the average might feel aggrieved. A closely related logic applies to relative prices. With one major exception, the Federal Reserve does not attempt to adjust the relative price of any class of goods, services, or assets. That major exception is the overnight funds rate. In that market, in which we have a monopoly on supply, we set the price and let the market determine the quantity demanded. We do this because we find that adjusting the price of overnight credit is currently the most efficient way to achieve our mandate of low and stable inflation and maximum sustainable growth. But that is where our monopoly ends. Short-term interest rates are such a powerful tool for central banks because so many other financial assets are priced based, in part, on the price of short-term credit and market expectations about the future adjustment of that price. In all other markets, the forces of supply and demand determine prices. Some have suggested that under some circumstances central banks should adjust the overnight funds rate to affect intentionally the relative price of another asset class, namely equities. But if a central bank elevates another set of relative prices to being targets of policy, I believe that it should have strong conviction in two areas. First, that its tool, the provision of reserves to the banking system, will predictably influence that relative price, and with minimal unintended consequences. Second, that adjusting that relative price will, in turn, have a predictable and significant role in achieving our mandate. In the case of equities, I believe that we cannot hold a strong conviction in either regard. The link between overnight reserves and prices of equities is too remote and indirect, and the impact of equity prices on the balance of aggregate supply and demand is too uncertain, for those prices to be a target of policy. To be clear, this is not an argument for never considering prices in asset markets when determining how well we are likely to do in achieving our goals. Monetary policymakers follow developments in the equity and other asset markets as part of the process of evaluating and forecasting economic conditions. That is, the values of equity claims affect spending decisions and help forecast economic activity. But, in that regard, a similar role is played by many other important determinants of spending, including long-term interest rates, the foreign exchange value of the currency, the government's fiscal position, and economic activity abroad. We can employ our one instrument to temper or augment the net effect of changes in these factors on spending and production, but we do not have the tools to respond to each individually. Our tool is most efficiently deployed to adjust overnight interest rates. There is a more general principle at work here. No doubt, the balance sheet of the Federal Reserve is large and the attention paid to our pronouncements intense. Nobody would deny that central banks can be quite powerful and that monetary policy works, over time. But in the scheme of things, a central bank's ability to smooth asset prices (if it wanted to) or to buffer shocks to spending or production is somewhat limited. The textbooks teach that monetary policymakers can vary interest rates to offset fluctuations in aggregate demand. The reality is that when the shortfall in desired spending is large or arises quite quickly, as was the case last year when businesses slashed their investment plans in light of a perceived overhang of capital, the initial monetary policy offset can be only partial and not necessarily synchronous. Eventually, of course, monetary policy does work; but the lags continue to be unpredictable and both the level of rates and the time required for policy to have the desired equilibrating impact depend greatly on the force of the macroeconomic instability that must be confronted and are not knowable at the start of a cyclical event. Similarly, the central bank can meet elevated demands for liquidity during times of crisis, but the private sector cannot look to the central bank to eliminate all risk, just as it cannot look to us to support specific subsets of the economy or alter relative prices. Real decisions result in uncertain outcomes, and sometimes the result is adverse. What we can do, of course, is strive to minimize macroeconomic risks--such as the risk that the general price level will fluctuate erratically and unpredictably, as is the case when inflation is high, or that the adjustment of economic activity will be made more difficult because the overall price level is declining. We can also make your job in pricing and trading risk easier by reducing uncertainty about the goals and tactics of monetary policy in dealing with macroeconomic forces. There have been many changes over the years in how the Federal Reserve communicates with the public. Currently, the Federal Open Market Committee issues a statement to the public shortly after every meeting. The statement provides information about and a rationale for the policy stance adopted at the meeting, the Committee's view about the balance of risks to the outlook, and a tally that identifies how each member voted. The balance-of-risks statement does not itself predict the future course of monetary policy but rather provides the Committee's assessment of the risks to good economic performance going forward. Although this judgment may have obvious implications for policy if those risks are realized, it is up to investors to draw out the expected path of short-term interest rates, looking primarily to incoming data and changed forecasts of the real economy. The Committee recently chose to identify the votes of members, including the policy preferences of any dissenters, in order to give market participants a more accurate view of its opinions. On too many prior occasions, market participants formed inferences about the Committee's vote, from indirect and frequently misleading sources of information, before the vote was released as part of the minutes after the next meeting. Therefore, we decided to eliminate that potential source of misunderstanding, and, for a central bank, we made that decision relatively quickly. I am pleased with the Committee's quick response, since I believe that part of the trust that the Federal Reserve now enjoys is built on the belief that we will attempt to minimize sources of misunderstanding. Let me close by thanking you again for bestowing this honor on me. Public service has many benefits. Working directly and indirectly with members of the Bond Market Association was an expected benefit, but receiving this award was certainly an unexpected and much appreciated honor for me.
For immediate release The Federal Reserve Board on Friday announced the appointment of chairmen and deputy chairmen of the twelve Federal Reserve Banks for 2003. Each Reserve Bank has a nine-member board of directors. The Board of Governors in Washington appoints three of these directors and designates one of its appointees as chairman and a second as deputy chairman. Following are the names of the chairmen and deputy chairmen appointed by the Board for 2003: Boston James J. Norton, Vice President, AFL-CIO, Washington, D.C., named Chairman. Samuel O. Thier, M.D., President and Chief Executive Officer, Partners HealthCare System, Inc., Boston, Massachusetts, named Deputy Chairman. New York Peter G. Peterson, Chairman, The Blackstone Group, New York, New York, renamed Chairman. John E. Sexton, President, New York University, New York, New York, named Deputy Chairman. Philadelphia Glenn A. Schaeffer, President Emeritus, Pennsylvania Building and Construction Trades Council, Harrisburg, Pennsylvania, named Chairman. Ronald J. Naples, Chairman and Chief Executive Officer, Quaker Chemical Corporation, Conshohocken, Pennsylvania, named Deputy Chairman. Cleveland Robert W. Mahoney, Retired Chairman and Chief Executive Officer, Diebold, Incorporated, Canton, Ohio, named Chairman. Charles E. Bunch, President and Chief Operating Officer, PPG Industries, Inc., Pittsburgh, Pennsylvania, named Deputy Chairman. Richmond Wesley S. Williams, Jr., Partner, Covington & Burling, Washington, D.C., named Chairman. Irwin Zazulia, Retired President and Chief Executive Officer, Hecht's, Arlington, Virginia, named Deputy Chairman. Atlanta Paula Lovell, President, Lovell Communications, Inc., Nashville, Tennessee, named Chairman. David M. Ratcliffe, President and Chief Executive Officer, Georgia Power Company, Atlanta, Georgia, named Deputy Chairman. Chicago Robert J. Darnall, Former Chairman, President, and Chief Executive Officer, Inland Steel Industries, Inc., Chicago, Illinois, renamed Chairman. W. James Farrell, Chairman and Chief Executive Officer, Illinois Tool Works Inc., Glenview, Illinois, renamed Deputy Chairman. St. Louis Charles W. Mueller, Chairman and Chief Executive Officer, Ameren Corporation, St. Louis, Missouri, renamed Chairman. Walter L. Metcalfe, Jr., Chairman, Bryan Cave LLP, St. Louis, Missouri, renamed Deputy Chairman. Minneapolis Ronald N. Zwieg, President, United Food & Commercial Workers, Local 653, Plymouth, Minnesota, renamed Chairman. Linda Hall Whitman, Chief Executive Officer, QuickMedx, Inc., Edina, Minnesota, renamed Deputy Chairman. Kansas City Terrence P. Dunn, President and Chief Executive Officer, J.E. Dunn Construction Company, Kansas City, Missouri, renamed Chairman. Richard H. Bard, Founder and Manager, IdeaSpring, LLC, Denver, Colorado, renamed Deputy Chairman. Dallas Ray L. Hunt, Chairman, President, and Chief Executive Officer, Hunt Consolidated, Inc., Dallas, Texas, named Chairman. Patricia M. Patterson, President, Patterson Investments, Inc., Dallas, Texas, renamed Deputy Chairman. San Francisco Nelson C. Rising, Chairman and Chief Executive Officer, Catellus Development Corporation, San Francisco, California, renamed Chairman. George M. Scalise, President, Semiconductor Industry Association, San Jose, California, renamed Deputy Chairman.
Remarks by Governor Ben S. Bernanke Before the New York Chapter of the National Association for Business Economics, New York, New York October 15, 2002 Asset-Price "Bubbles" and Monetary Policy I am very pleased to have this opportunity to address the National Association for Business Economics. Thank you for inviting me. My talk today will address a contentious issue, summarized by the following pair of questions: Can the Federal Reserve (or any central bank) reliably identify "bubbles" in the prices of some classes of assets, such as equities and real estate? And, if it can, what if anything should it do about them? By way of background, I note that monetary policy in the United States has achieved quite a good record over the past two decades. Since the Fed's conquest of inflation in the 1980s, the American economy has moved steadily toward price stability and--except for two recessions that appear to have been relatively mild by historical standards--has enjoyed solid economic growth and high employment as well. Quarter-to-quarter volatility in both output growth and inflation has dropped markedly in the past twenty years, in comparison with the turbulent 1960s and 1970s. New eras bring new challenges, however, and with inflation quiescent for the moment, public attention has shifted to a different source of potential instability in the economy: specifically, large swings in the prices of assets, both financial and real. As everyone here knows, the second half of the 1990s saw a major bull market in equities in the United States, followed by a bear market that began in the spring of 2000. The decline in stock values since March 2000 has not only vaporized trillions of dollars in wealth, but also likely played a role in worsening the recession that, according to the National Bureau of Economic Research, began in the United States in March 2001. This experience has led a number of observers--including academics, journalists, and businesspeople--to assert that the Federal Reserve should have acted earlier to contain the sharp run-up in stock prices. If the Fed had had the foresight to "prick the bubble" at an early stage, the argument goes, the economy might have been spared needless trauma. My goal today is to look more closely at this argument and its implications. Dealing with Asset-Market Instability: Use the Right Tool for the Job As a preliminary to assessing the critics' argument, and to get my own views on the table right away, let me briefly sketch a policy framework that I believe is useful for thinking about these issues. Before I do so, I will state the usual proviso, that the opinions expressed here are mine alone and not necessarily those of my colleagues at the Federal Reserve. In particular, I emphasize that my comments today should not be interpreted in any way as representing an official policy position of the Board of Governors or the Federal Open Market Committee. My suggested framework for Fed policy regarding asset-market instability can be summarized by the adage, Use the right tool for the job . As you know, the Fed has two broad sets of responsibilities. First, the Fed has a mandate from the Congress to promote a healthy economy--specifically, maximum sustainable employment, stable prices, and moderate long-term interest rates. Second, since its founding the Fed has been entrusted with the responsibility of helping to ensure the stability of the financial system. The Fed likewise has two broad sets of policy tools: It makes monetary policy, which today we think of primarily in terms of the setting of the overnight interest rate, the federal funds rate. And, second, the Fed has a range of powers with respect to financial institutions, including rule-making powers, supervisory oversight, and a lender-of-last resort function made operational by the Fed's ability to lend through its discount window. By using the right tool for the job, I mean that, as a general rule, the Fed will do best by focusing its monetary policy instruments on achieving its macro goals--price stability and maximum sustainable employment--while using its regulatory, supervisory, and lender-of-last resort powers to help ensure financial stability. Let me discuss the two parts of this recommendation in a bit more detail. The first part of the prescription implies that the Fed should use monetary policy to target the economy, not the asset markets. As I will argue today, I think for the Fed to be an "arbiter of security speculation or values" is neither desirable nor feasible. Of course, to do its job the Fed must monitor financial markets intensively and continuously. The financial markets are vital components of the economic machinery. Moreover, asset prices contain an enormous amount of useful and timely information about developments in the broader economy, information that should certainly be taken into account in the setting of monetary policy. For example, to the extent that a stock-market boom causes, or simply forecasts, sharply higher spending on consumer goods and new capital, it may indicate incipient inflationary pressures. Policy tightening might therefore be called for--but to contain the incipient inflation not to arrest the stock-market boom per se. The second part of my prescription is for the Fed to use its regulatory, supervisory, and lender-of-last-resort powers to protect and defend the financial system. In particular, alone and in concert with other agencies, the Fed should ensure that financial institutions and markets are well prepared for the contingency of a large shock to asset prices. The Fed and other regulators should insist that banks be well capitalized and well diversified and that they stress-test their portfolios against a wide range of scenarios. The Fed can also contribute to reducing the probability of boom-and-bust cycles occurring in the first place, by supporting such objectives as more-transparent accounting and disclosure practices and working to improve the financial literacy and competence of investors. Finally, if a sudden correction in asset prices does occur, the Fed's first responsibility is to do its part to ensure the integrity of the financial infrastructure--in particular, the payments system and the systems for settling trades of securities and other financial instruments. If necessary, the Fed should provide ample liquidity until the immediate crisis has passed. The Fed's response to the 1987 stock market break is a good example of what I have in mind. I have expressed these two principles in rather simple terms; they could be elaborated much further. Taken together, they provide a strategy for policy that has a number of advantages: It keeps monetary policy focused on the appropriate goal variables, economic activity and inflation. It is transparent and easy to communicate to the public. It does not require that central bankers be systematically better than the market at valuing financial assets nor substitute policymakers' judgments of company prospects for those of investors. Finally, and crucially, it is a robust strategy, in that--although it certainly does not eliminate all economic and financial instability--it protects the economy against truly disastrous outcomes, which history has shown are possible when monetary policy goes severely off the track. The Opposing View: Preemptive Strikes against Bubbles As I noted at the beginning, however, the framework just articulated is not universally accepted, particularly the aspect that precludes attempts to guide the course of asset prices. Instead, a number of critics have argued that monetary policy should be more proactive in trying to correct incipient "imbalances" in asset markets. What can be said about these assertions? This debate is clarified considerably, in my view, by recognition that, in practice, the advocates of a more vigorous monetary policy response to asset prices fall into two broad camps, differing primarily in how aggressive they think the Fed ought to be in attacking putative bubbles. The first group, who favor what I will call the lean-against-the-bubble strategy, agree that the Fed should take account of and respond to the implications of asset-price changes for its macro goal variables. But also, according to this view, the Fed should try to gently steer asset prices away from a presumed bubble path. For example, seeing a rapid appreciation of stock prices, not only should the Fed tighten enough to offset the likely effects of the boom on inflation and output, but also it should add another 25 to 50 basis points for good measure, in the hope of discouraging increases in stock prices it judges to be excessive. My sense is that this more moderate camp comprises the great majority of serious researchers who have advocated a monetary-policy response to bubbles. And, in my opinion, the theoretical arguments that have been made for the lean-against-the-bubble strategy are not entirely without merit. At the risk of oversimplifying a large body of literature, I think one can usefully boil down many of these arguments to the idea that it may be worthwhile for the Fed to take out a little "insurance," so to speak, against the formation of an asset-price bubble and its potentially adverse effects. Like all forms of insurance, bubble insurance carries a premium, which includes (among other costs) the losses incurred if the Fed misjudges the state of the asset market or the cost of a possible reduction in the transparency of Fed policies. But, as a matter of theory, it is rarely the case in economics that the optimal amount of insurance in any situation is zero. On that principle, proponents of leaning against the bubble have argued that completely ignoring incipient potential bubbles, if in fact they can be identified, can't possibly be the best policy. I will discuss below why I believe that, nevertheless, "leaning against the bubble" is unlikely to be productive in practice. The second group of critics is those preferring a more activist approach, which I will call here aggressive bubble popping . Aggressive bubble-poppers would like to see the Fed raise interest rates vigorously and proactively to eliminate potential bubbles in asset prices. To be frank, this recommendation concerns me greatly, and I hope to persuade you that it is antithetical to time-tested principles and sound practices of central banking. Problems with the Proactive Approach to Bubbles If we could accurately and painlessly rid asset markets of bubbles, of course we would want to do so. But as a practical matter, this is easier said than done, particularly if we intend to use monetary policy as the instrument, for two main reasons. First, the Fed cannot reliably identify bubbles in asset prices. Second, even if it could identify bubbles, monetary policy is far too blunt a tool for effective use against them. The Identification Problem Let's first discuss the identification problem. Aspiring bubble poppers cannot get around the fact that their strategy requires identifying bubbles as they occur, preferably quite early on. Identifying a bubble in progress is intrinsically difficult. Though the price of (say) a share of stock is readily observable, the corresponding fundamentals--such as the dividends that investors expect to receive and the risk premium that they require to hold the stock--are generally not observable, even after the fact. Of course, one can always try to estimate a fundamental value for stocks and other assets--I will discuss some possible indicators of fundamental value and overvaluation in a moment. But there is the additional difficulty that the prices of equities and other assets are set in competitive financial markets, which for all their undeniable foibles are generally highly sophisticated and efficient. Thus, to declare that a bubble exists, the Fed must not only be able to accurately estimate the unobservable fundamentals underlying equity valuations, it must have confidence that it can do so better than the financial professionals whose collective information is reflected in asset-market prices. I do not think this expectation is realistic, even for the Federal Reserve. Moreover, I worry about the effects on the long-run stability and efficiency of our financial system if the Fed attempts to substitute its judgments for those of the market. Such a regime would only increase the unhealthy tendency of investors to pay more attention to rumors about policymakers' attitudes than to the economic fundamentals that by rights should determine the allocation of capital. If we nevertheless persist in trying to measure bubbles, what indicators might be useful? Several have been suggested, including the rate of appreciation of asset prices, various ratios that attempt to measure the return on stocks, and growth in bank credit. None of these provides a reliable indicator of a developing bubble. First, many people appear to consider sustained increases in the prices of assets as prima facie evidence of a bubble, on the principle that what goes up must come down. This view is simplistic at best. In fact, although no bull market goes on forever, historically it has by no means been the case that strong bull markets are inevitably followed by raging bears. Further, the fact that a particular rise in asset prices happens to be followed by a price decline does not prove that the initial increase was irrational or unjustified--sometimes strategies that are perfectly reasonable ex ante just don't pan out, as every bridge player knows. Because risk-taking is essential for economic dynamism, we do not want an economy in which investors and businesspeople are not free to take bets that might turn out badly. Various price-return ratios, such as price-earnings or dividend-price ratios, may seem to have more potential as indicators of bubbles than do simple rates of price appreciation. But even these are far from reliable--for a host of reasons, including changes in institutions, tax and accounting procedures, inflation, and underlying growth rates. The most difficult problem in using such ratios to assess fundamental values is that one cannot avoid taking a stand on the appropriate value of the equity premium, the extra return that investors require to hold equities rather than bonds. Economists have an extraordinarily poor understanding of the determinants of the equity premium, yet relatively small changes in this variable can have major effects on assessments of fundamental values. I will give one illustration of the potential pitfalls of relying too heavily on ratio indicators, even in the hands of the most sophisticated practitioners. In December 1996, before my time at the Board, John Campbell of Harvard and Robert Shiller of Yale made a presentation at the Fed, in which they used dividend-price ratios and related measures to argue that the stock market was overvalued. (A version of their presentation was later published in the Journal of Portfolio Management , which is the source for all my comments here.) Campbell and Shiller, whom I know well and respect greatly as preeminent financial economists, rightly deserve credit for calling the possibility of a bubble to people's attention, at a time when (lest we forget) there was significant diversity of opinion about which way the market would go. Shiller, of course, has gone on to write a best-selling book about stock market manias. Though Campbell and Shiller were among those warning of a bubble in stock prices, and deserve credit for doing so, we should not lose sight of a simple quantitative point: According to their published article, their analysis of dividend-price ratios implied that, as of the beginning of 1997, the broad stock market was priced at three times its fundamental value (Campbell and Shiller, 1998, p. 13). At that time the Standard & Poor's 500 index was about 750, compared with a close of 842 on October 1 of this year. I do not know, of course, where the stock market will go tomorrow, much less in the longer run (that's really my whole point). But I suspect that Campbell and Shiller's implicit estimate of the long-run value of the market was too pessimistic and that, in any case, an attempt to use this assessment to make monetary policy in early 1997 (presumably, a severe tightening would have been called for) might have done much more harm than good. Part of the reason that the standard ratios were too pessimistic in 1997 was that at least some of the run-up in stock prices in the latter 1990s was apparently justified by fundamentals, as evidenced by the remarkable growth in output and productivity in recent years, the recent recession notwithstanding. Pure bubbles--increases in asset prices that are 100 percent air--are, I suspect, rare. So the problem of a bubble-popping Fed is much tougher than just deciding whether or not a bubble exists; to follow this strategy, the Fed must also assess the portion of the increase in asset prices that is justified by fundamentals and the part that is not. In my view, somehow preventing the boom in stock prices between 1995 and 2000, if it could have been done, would have throttled a great deal of technological progress and sustainable growth in productivity and output. Another possible indicator of bubbles cited by some authors is the rapid growth of credit, particularly bank credit (Borio and Lowe, 2002). Some of the observed correlation may reflect simply the tendency of both credit and asset prices to rise during economic booms. However, to the extent that credit expansion is indicative of bubbles, I think that empirical linkage points to a better policy approach than attempts at bubble-popping by the central bank. During recent decades, unsustainable increases in asset prices have been associated on a number of occasions with botched financial liberalization, in both emerging-market and industrialized countries. The typical pattern is that lending institutions are given substantially expanded powers that are not matched by a commensurate increase in regulatory supervision (think of the savings and loans in the United States in the 1980s). A situation develops in which institutions can directly or indirectly take speculative positions using funds protected by the deposit insurance safety net--the classic "heads I win, tails you lose" situation. When this moral hazard is present, credit flows rapidly into inelastically supplied assets, such as real estate. Rapid appreciation is the result, until the inevitable albeit belated regulatory crackdown stops the flow of credit and leads to an asset-price crash. Bubbles of this type may be identifiable to some extent after they have begun, but the right policy is to do the financial deregulation correctly--that is, in a way that does not allow speculative misuse of the safety net--in the first place. Or failing that, to intervene and fix the problem when it is recognized. The Difficulty of "Safe Popping" As a matter of logic, the fact that bubbles are difficult to identify with precision does not necessarily justify ignoring potential ones (although it does suggest that the optimal response to them should be highly attenuated). For example, an advocate of the lean-against-the-bubble philosophy could appeal to the "insurance" argument I noted earlier: Even if we can measure bubbles only imprecisely, is the optimal response of monetary policy to a perceived bubble literally zero? Shouldn't there be at least a bit of response, for "insurance" purposes? To evaluate this argument, we must keep in mind an underlying premise of the lean-against-the-bubble strategists, which is that the response of incipient bubbles to monetary policy is more or less proportional to the policy action. In other words, for the insurance argument to apply, a small increase in the federal funds rate must lead to some correspondingly modest decline in the likelihood or size of a bubble. But such a smooth response is not well supported by either theoretical or empirical research on asset price dynamics. If a bubble--a speculative mania, in the more colorful language of the past--is actually in progress, then investors are presumably expecting outsized returns: 10, 15, 20 percent or more annually. Is it plausible that an increase of ï¿½ percentage point in short-term interest rates, unaccompanied by any significant slowdown in the broader economy, will induce speculators to think twice about their equity investments? All we can conclude with much confidence is that the rate hike will tend to weaken the macroeconomic fundamentals through the usual channels, while the asset bubble, if there is one, may well proceed unchecked. Although neither I nor anyone else knows for sure, my suspicion is that bubbles can normally be arrested only by an increase in interest rates sharp enough to materially slow the whole economy. In short, we cannot practice "safe popping," at least not with the blunt tool of monetary policy. The situation is further complicated if, as is usually the case, the suspected bubble affects only a specific class of assets, such as high-tech stocks. Certainly there is no way to direct the effects of monetary policy at a single class of assets while leaving other financial markets and the broader economy untouched. One might as well try to perform brain surgery with a sledgehammer. The problem of safe popping applies with double force to the aggressive bubble-popping strategy. A truly vigorous attempt by a central bank to rein in a supposed speculative bubble may well succeed but only at the risk of throttling a legitimate economic boom or, worse, throwing the whole economy into depression. Rather than discuss this point further in the abstract, let me give a concrete historical example: the role of Federal Reserve policy at the onset of the Great Depression in the United States. An Historical Example: Federal Reserve Policy in the 1920s The U.S. experience of the 1920s illustrates many of the points I have been making. As you know, the "Roaring Twenties" was a prosperous decade, characterized by extensive innovation in technology and in business practices, rapid growth, American economic dominance, and general high spirits. Stock prices rose accordingly. As early as the mid-1920s, however, various policymakers and commentators expressed concern about the rapidly rising stock market and sought so-called corrective action by the Federal Reserve. The corrective action was not forthcoming, however. According to some authors, this was in large part because of the influence of Benjamin Strong, long-time Governor of the Federal Reserve Bank of New York and America's pre-eminent central banker of that era. Strong resisted attempts to aim monetary policy at the stock market, arguing that raising interest rates sufficiently to slow the market would have highly adverse effects on the rest of the economy. "Some of our critics damn us vigorously and constantly for not tackling stock speculations," Strong wrote about the debate. "I am wondering what will be the consequences of such a policy if it is undertaken and who will assume responsibility for it." However, Strong died from tuberculosis early in 1928, and the Fed passed into the control of a coterie of aggressive bubble-poppers, of whom the most determined was probably Board Governor Adolph Miller. Miller was supported in his objective by another fervent enemy of "speculation"--and Miller's neighbor and close friend--Herbert Hoover, soon to be President. Under Miller's influence the debate within the Federal Reserve System shifted from whether to try to stop stock-market speculation to how best to do it. The Board in Washington favored "direct pressure," which in practice meant threatening New York City banks that made loans to brokers with being cut off from the discount window. Strong's successor at the New York Fed, George Harrison, argued correctly that the availability of alternative sources of credit made this approach ineffectual and pushed for higher interest rates instead. Ultimately, frustrated by the ineffectiveness of direct pressure, the Board in Washington came around to Harrison's view. Hence, in 1928, in a situation in which the inflation rate was actually slightly negative and the economy was only barely emerging from a mild recession, the Fed began to raise interest rates. The New York Fed's discount rate, at 3.5 percent in January 1928, reached 6 percent by August 1929, its highest value since 1921. Rates on term stock-exchange loans peaked in that month at almost 9 percent, and the rate on call loans exceeded 10 percent in early August. For short periods the rates on these loans sometimes spiked above 20 percent. As is well known, U.S. common stock prices peaked in September 1929 and fell sharply in panicky selling in October. The popular view is that the market crash was the harbinger of the Great Depression. In fact, the weight of historical research has shown that this interpretation gets the causality largely backward. The economy was already slowing by the fall of 1929 (the NBER peak, marking the beginning of the Depression cycle, was in August 1929), largely as a result of monetary tightness. Economic indicators, which had been uniformly strong, were becoming more mixed: The Federal Reserve's industrial production index began to decline in July, construction contracts fell sharply in August and September, and automobile sales dipped suddenly at the beginning of October. Conditions abroad were weakening, and both foreign and U.S. interest rates were rising. The famous warning by Roger Babson that led to the "Babson break" in stock prices in September 1929 was based on mounting evidence that an economic slowdown was already in progress, implying that continued strong earnings growth could not be counted on. Thus the stock market decline was more the result of developing economic weakness (and tight money) than the cause of the slowdown--though, obviously, falling stock prices did not help the broader economic situation in late 1929 and 1930. Some additional evidence that the stock market was as much a victim as a cause of the Depression is that, to a degree not fully appreciated today, the stock market boom of the 1920s was surprisingly hard to kill. Indeed, stock prices did not collapse in 1929 but only began to plummet when the depth of the general economic decline became apparent. For example, stock prices in April 1930 were still about the same level as in January 1929; and someone who bought stock in early 1928 and sold in October 1930 would have almost broken even. Only as the bad economic news kept rolling in, in the fall of 1930, did stock prices finally fall below 1928 levels. The correct interpretation of the 1920s, then, is not the popular one--that the stock market got overvalued, crashed, and caused a Great Depression. The true story is that monetary policy tried overzealously to stop the rise in stock prices. But the main effect of the tight monetary policy, as Benjamin Strong had predicted, was to slow the economy--both domestically and, through the workings of the gold standard, abroad. The slowing economy, together with rising interest rates, was in turn a major factor in precipitating the stock market crash. This interpretation of the events of the late 1920s is shared by the most knowledgeable students of the period, including Keynes, Friedman and Schwartz, and other leading scholars of both the Depression era and today. New York Fed Governor Harrison and other participants argued after the fact that the problem with their policy was not that they tried to burst the stock-market bubble but that their efforts were too little and too late. This attempt to defend the Fed's policies of the latter 1920s does not hold up. There is little credible evidence of a bubble in the U.S. stock market before March 1928 (Galbraith, 1954; White, 1990); yet, in part because of the workings of the gold standard, U.S. monetary policy had already turned exceptionally tight by late 1927 (Hamilton, 1987). Tighter policy earlier would have brought the Depression on all the more quickly and sharply (see Eichengreen, 1992, p. 214, for further discussion). The Federal Reserve went on to make a number of serious additional mistakes that deepened and extended the Great Depression of the 1930s. Besides trying to pop the stock market bubble, the Fed made little or no effort to protect the banking system from depositor runs and panics. Most seriously, it permitted a severe deflation in the price level, which drove real interest rates sky-high and greatly increased the pressure on debtors. A small compensation for the enormous tragedy of the Great Depression is that we learned some valuable lessons about central banking. It would be a shame if those lessons were to be forgotten. Conclusion Understandably, as a society, we would like to find ways to mitigate the potential instabilities associated with asset-price booms and busts. Monetary policy is not a useful tool for achieving this objective, however. Even putting aside the great difficulty of identifying bubbles in asset prices, monetary policy cannot be directed finely enough to guide asset prices without risking severe collateral damage to the economy. A far better approach, I believe, is to use micro-level policies to reduce the incidence of bubbles and to protect the financial system against their effects. I have already mentioned a variety of possible measures, including supervisory action to ensure capital adequacy in the banking system, stress-testing of portfolios, increased transparency in accounting and disclosure practices, improved financial literacy, greater care in the process of financial liberalization, and a willingness to play the role of lender of last resort when needed. Although eliminating volatility from the economy and the financial markets will never be possible, we should be able to moderate it without sacrificing the enormous strengths of our free-market system. Endnotes The phrase is due to Friedman and Schwartz (1963, p. 290). See Bernanke and Gertler (1999, 2001) and Gramlich (2001) for further discussion. Because equity valuations may pose asymmetric risks to the economic forecast, the implied optimal responses of policy to changes in asset prices may be nonlinear. In this respect I agree with Bordo and Jeanne (2002). In this regard, some have suggested greater use of the Fed's ability to set margin requirements. Most evidence suggests that changes in margins have little direct effect on asset prices. Possibly, it has been argued, changing margin requirements would have a "psychological" effect on the market. I don't think that an attempt to manage the psychology of investors or consumers is a particularly useful or even appropriate policy strategy for the central bank, however. A better strategy is for the Fed to be transparent and direct in stating its assessment of the economy and of policy options. Mishkin and White (2002) emphasize the importance of focusing on financial stability following a stock market crash. To clarify this point, support of the financial system in a crisis does not by any means imply a generalized bailout of threatened, firms. Any support that is given should be done under conditions that minimize potential moral hazards. Bernanke and Gertler (1999, 2001) present simulations that suggest that simple policy rules focused on stabilizing macroeconomic goal variables deliver good economic performance in the face of large moves in asset prices. The 1987 stock market crash is a real-world example of how monetary policy aimed at macro stability coupled with other types of policy emphasizing financial stability can minimize the economic fallout of a sharp decline in asset prices. Later in the talk I discuss the 1929 episode as an example of what can happen when the Federal Reserve strays from this framework. A sampling of recent work advocating more-proactive responses to bubbles includes Bordo and Jeanne (2002); Borio and Lowe (2002); Cecchetti, Genberg, Lipsky, and Wadhwani (2000); Cecchetti, Genberg, and Wadhwani (2002; Dupor (2002); and International Monetary Fund (2000). Though these papers are in the same camp, they differ considerably in their specific arguments and approaches. Some may believe that stock prices are set largely by uninformed and unsophisticated traders and thus have little connection to fundamentals. I find that belief hard to reconcile with the general level of American prosperity, in which I believe the efficient allocation of capital by financial markets has played a central role. Moreover, even if bubbles arise from the behavior of uninformed traders, they should have no substantial effect on capital allocation unless those who make capital expenditures believe the market's valuations. For example, in an interesting recent paper, Bordo and Jeanne (2002) used mechanical rules to identify booms in stock and residential property prices since 1970 in 15 industrial countries. They defined a "boom" to be a situation in which asset-price growth over a three-year period lies significantly above its long-run average and a "bust" to be a situation in which the three-year asset-price growth is correspondingly lower than normal. Out of 24 boom episodes that they identified for stock prices, only 3 were followed by busts. Bordo and Jeanne found more evidence for boom-bust cycles in residential property: Busts followed ten of nineteen property booms. However, none of these instances was in the United States. Bordo and Jeanne note that property boom-bust cycles tend to be local phenomena associated perhaps with only one city. This tendency may explain why they found most boom-bust cycles in property in small countries, in which a significant portion of the real estate value (or the data collection) is associated with one or two major cities. Various ratio measures continue to give divergent readings on stock fundamentals even today. See, for example, Jesse Eisinger's article on the divergent predictions of two leading analysts, Wall Street Journal (September 30, 2002), p. C1. Supervisors of financial institutions can help here by insisting on tough underwriting standards. Alan Blinder has likened bubble-popping strategies to sticking a needle in a balloon; one cannot count on letting out the air slowly or in a finely calibrated amount. Much of the concern of contemporary observers in the twenties centered on the ability of world gold stocks to "support" the much higher postwar price levels. Readers of historical documents from this period should take care to understand that references to "inflation," "excessive credit creation," and "speculation" were often related to this issue rather than to the issues we associate those terms with today. The 1920s were in fact far from an inflationary decade in the modern sense; the Consumer Price Index in 1929 was essentially identical to its value in 1923, and prices fell from 1926 to 1929. Strong's biographer quotes him as follows (Chandler, 1958, p. 427): "I think the conclusion is inescapable that any policy directed solely to forcing liquidation in the stock loan account and concurrently in the price of securities will be found to have a widespread and somewhat similar effect in other directions, mostly to the detriment of the healthy prosperity of this country." The subsequent quote in the text is from the same source. Bierman (1991) reproduces this quote and gives additional useful discussion of Fed policies during the run-up to the crash. The National Bureau of Economic Research has designated November 1927 as a recession trough. These and subsequent data are from Board of Governors (1943). Monetary tightening was also motivated by concerns about outflows of gold to France, which had recently stabilized its currency; see for example Hamilton (1987). John Maynard Keynes (1930, p. 196), writing at the time, was quite explicit: "Nevertheless the high market-rate of interest which, prior to the collapse, the Federal Reserve System, in their effort to control the enthusiasm of the speculative crowd, caused to be enforced in the United States--and, as a result of the sympathetic self-protective action, in the rest of the world--played an essential role in bringing about the rapid collapse. . . Thus I attribute the slump of 1930 primarily to the deterrent effects on investment of the long period of dear money which preceded the stock-market collapse, and only secondarily to the collapse itself." The early monetarist Lauchlin Currie (1934) expressed similar views. More recently, Milton Friedman and Anna Schwartz, in their monumental study of monetary policy in the United States, (1963, p. 290) wrote: "Nonetheless, there is no doubt that the desire to curb the stock market boom was the major if not dominating factor in [Federal] Reserve actions during 1928 and 1929. . . In the event [the Fed] followed a policy which was too easy to break the speculative boom, yet too tight to promote healthy economic growth. In our view, the Board should not have made itself an arbiter of security speculation or values and should have paid no direct attention to the stock market boom, any more than it did to the earlier Florida land boom." In his classic study of the stock market crash of 1929, economic historian Eugene White came to similar conclusions. He wrote (1990, p. 179), "Fearful of financial and economic dislocations, the Federal Reserve tried to restrain speculation first by direct pressure [that is, on the banks] and then by raising interest rates. These efforts had no discernible effect on the boom. It did however produce a general rise in interest rates that slowed the American economy and induced foreign central banks [who were constrained by gold standard rules to match American tightening] to raise their rates. Tighter credit then contributed to the beginning of a recession that was picked up in the mixed economic indicators of early August and September. These dispelled hopes that earnings would continue to grow at a rapid rate. As the economy faltered, wiser investors began leaving the market. When selling picked up speed, margin calls and delayed information from the ticker ensured a dramatic panic." White goes on to call the Fed's policies during this period "inappropriate." He wrote, "Instead of allowing the stock market bubble to run its course, the Federal Reserve's tighter monetary policy pushed the economy further into recession, rendering it more vulnerable to the shock that came when the bubble finally burst." A final, recent quotation is from Cecchetti (1998, p. 178): "There are two important lessons to be taken away from this experience. . . First, I believe that if central bankers allow the fluctuations in asset market prices to affect their decisions, it may distract them from concentrating on some combination of output growth and inflation. The focus of the Federal Reserve on the level of equity prices in 1929 clearly led to a disastrously contractionary path for policy. . . [The second lesson is the importance of lender-of-last resort actions during a crisis.]" More recent research has shown that attempted bubble popping by monetary policymakers played an even greater role in the onset of the Great Depression than we had thought. An insightful article by Hans-Joachim Voth (forthcoming) has shown how the German central bank, under the famous central banker Hjalmar Schacht, contributed mightily to the demise of the Weimar Republic by aggressively attempting to bring down stock prices in 1927. Schacht's policy was successful, in the sense that the stock market crashed. But investment plummeted as well, and the German economic boom of 1924-1928 degenerated into depression and played a role in the global slowdown. Ironically enough, Voth argues persuasively that in fact there was no bubble in German stock prices, so that Schacht's actions were purely destructive.
Remarks by Vice Chairman Roger W. Ferguson, Jr. Paper presented to an International Monetary Fund conference on Challenges to Central Banking from Globalized Financial Markets, Washington, D.C. September 17, 2002 Should Financial Stability Be an Explicit Central Bank Objective? Against the backdrop of the wide swings in equity prices in recent years, the financial market repercussions accompanying corporate accounting scandals in the United States, and the current difficulties in key emerging market economies, it seems appropriate to reconsider the role of central banks in fostering financial stability. This session asks us to address a deceptively simple question: Should financial stability be an explicit central bank objective on a par with other objectives such as price stability and sustainable economic growth? At the outset, let me emphasize that all of the views I will express in answer to this question are my own and not necessarily those of my colleagues on the Board. To summarize the discussion below, financial stability has been and always will be a fundamental objective of central banks. Indeed, many central banks around the world—including the Federal Reserve—were established in part to serve as bulwarks against chronic episodes of financial instability and the attendant adverse consequences for the economy. So at this basic level, a financial stability objective for central banks seems entirely appropriate. That said, difficult issues may arise at times in judging how much weight should be attached to financial stability versus other central bank objectives and also in judging just how “activist” central banks should be in pursuing their financial stability objectives. In this connection, the Federal Reserve has found it useful to focus on its financial stability objectives primarily through the lens of its macroeconomic goals—price stability and sustainable long-run growth. That is, the Federal Reserve seeks to foster conditions that will contribute to price stability and sustainable output growth now and in the future. 1. Public Policy and Financial Stability It seems useful at the outset to define financial stability and to do so by defining its opposite, financial instability. In my view, the most useful concept of financial instability for central banks and other authorities involves some notion of market failure or externalities that can potentially impinge on real economic activity. Economic research in recent years has identified a variety of market imperfections such as moral hazard and asymmetric information that, if widespread and significant, can result in threats to the functioning of any financial system, such as panics, bank runs, asset price bubbles, excessive leverage, and inadequate risk management. Such outcomes are typically highly undesirable from a social welfare perspective; financial prices can diverge sharply and for prolonged periods from fundamentals, credit conditions may be too lax at times and at other times far too restrictive, and spending and real activity may be subject to much wider swings than would otherwise be the case. Thus, for the purposes of this paper, I’ll define financial instability as a situation characterized by these three basic criteria: (1) some important set of financial asset prices seem to have diverged sharply from fundamentals; and/or (2) market functioning and credit availability, domestically and perhaps internationally, have been significantly distorted; with the result that (3) aggregate spending deviates (or is likely to deviate) significantly, either above or below, from the economy’s ability to produce. With this definition of financial instability, a clear public policy interest arises for central banks and other authorities to act in two distinct roles in pursuing financial stability—prevention of instability and management of the consequences once markets become unstable. In the area of prevention, perhaps the single most important thing a central bank can do is to foster a macroeconomic environment of low and stable inflation and sustainable economic growth. Absent such desirable macro fundamentals, the risks of financial instability are almost certainly higher and the effects of financial instability when it arises all the more pernicious. Beyond conducting sound macro policy, central banks have traditionally been involved in myriad activities, such as formulating appropriate financial regulations, implementing effective bank supervision, and operating or overseeing efficient payment systems, all of which help to attenuate the risks of financial instability. Under the heading of management, central banks can alter monetary policy to forestall or mitigate the consequences of financial instability for the economy. When such instability slides into crisis, they can employ their basic tools to help alleviate liquidity pressures and to bolster public confidence. Liquidity pressures can be addressed, for example, through generous provision of reserves via open market operations and direct lending to depository institutions via a lender-of-last-resort or discount window function. Other monetary policy tools can be employed as well, such as possibly cutting reserve requirements and, of course, lowering policy interest rates to provide a boost to the economy. The events of September 11 last year underscored how important it is for central banks to be ready to act promptly in a crisis to execute all of their core functions and flexibly adapt their rules. An important aspect of this preparedness is ensuring that critical systems and policy tools are robust to any and all contingencies. To this end, the Federal Reserve has been very actively implementing additional layers of backup and contingency arrangements for all of our key payment systems and operations. In the same vein, we are also encouraging banks and other financial institutions to ensure the robustness of their own systems. Although private firms that maximize profits do have market incentives to maintain adequate backup and contingency arrangements, they may not take into account the full social, or external, value of such arrangements. Because of this, central banks and other authorities have a useful role to play in encouraging and supporting private sector planning and investments that fully reflect the social value of contingency arrangements. Having now proposed a definition of financial stability and listed a variety of ways in which central banks can promote financial stability, I would add a cautionary note. Focusing on the various threats of financial disruptions and the need for public intervention to promote financial stability, one can sometimes lose sight of how remarkably efficient and stable financial markets typically have been in recent decades. When new information arrives, we expect that financial asset prices should respond quickly, and, thus, there is every reason to believe that asset prices may be volatile at times. We must also bear in mind that financial markets are dynamic and evolving. The incorporation of new technologies and the constant interplay of the forces of competition, deregulation, and globalization imply that some firms, possibly even quite important ones, will fail over time through a process of economic “natural selection” or “creative destruction” in which more efficient business models displace the status quo. Thus, there is a challenge and a tension for central banks and other authorities in differentiating between developments that truly represent externalities or market failures, and thus warrant public intervention, versus those that are just part of the normal, unavoidable, and largely positive turbulence in a dynamic market. 2. Central Banks’ Interest in Financial Stability For obvious reasons, central banks have long had a keen interest in financial stability. First and foremost, financial instability as defined above poses a severe threat to important macroeconomic objectives such as sustainable output growth and price stability. Largely for this reason, nearly all central banks are empowered and expected to act as a lender of last resort in financial crises. Indeed, recognition of the role of central banks in stemming financial crises dates back to Thornton and Bagehot in the eighteenth and early nineteenth centuries, respectively. This historical function of central banks as a potential source of emergency liquidity assistance to markets—through open market operations—or to particular institutions—through discount window lending—creates a need for central banks to keep close tabs on markets for signs of instability and to be prepared for action should the provision of emergency liquidity assistance prove necessary. Moreover, monetary policy is implemented largely through operations in financial markets, and the transmission of monetary policy to the real economy depends crucially on the smooth functioning of key financial institutions and markets. Attainment of sustainable real growth with stable prices in turn will make the economy less prone to financial instability. Finally, yet another manifestation of central banks’ interest in financial stability stems from their role in the operation or oversight of payment systems that, in turn, act as the critical “plumbing” supporting activity in financial markets. As noted above, financial stability is an important objective for all central banks, and this fact has been incorporated, to varying degrees, in central bank charters. In the case of the Federal Reserve, financial stability concerns were at the core of the Federal Reserve Act. Indeed, the Federal Reserve owes its existence to the financial instability of the U.S. economy in the nineteenth and early twentieth centuries. Early attempts to create a central bank in the United States—the First Bank of the United States (1791-1811) and the Second Bank of the United States (1816-1836)—were undone by the deep public distrust, particularly in southern and western states, of the concentration of financial power in an institution created by the federal government. Left without a central bank for the entire period between 1836 and 1913, the U.S. financial system had no effective backstop to guard against the periodic financial panics that occurred over these years. As a rule, these panics were soon followed by sharp contractions in economic activity. The panic and economic downturn sparked by the failure of the Knickerbocker Trust Company in 1907 were particularly acute, and prompted the appointment of a National Monetary Commission in 1908 to study and recommend structural changes that could improve the stability of the financial system. After the Commission concluded a lengthy and exhaustive report (twenty-three volumes) and following intense public debate, Congress finally passed the Federal Reserve Act in 1913, which created the Federal Reserve System. The preamble of the Federal Reserve Act, stating the purpose of the Federal Reserve, simply read that it was created “To provide for the establishment of Federal reserve banks, to furnish an elastic currency, to afford means of rediscounting commercial paper, to establish a more effective supervision of banking in the United States, and for other purposes.” This language implicitly embodied financial stability as an objective of the Federal Reserve. The references to an “elastic currency” and the “rediscounting of commercial paper” fundamentally reflected concerns about financial market liquidity, and the reference to “more effective supervision of banking” captured the desire to develop a means to avoid or mitigate banking crises. More specific references to financial stability were implemented twenty years later with the revisions of the Federal Reserve Act that were implemented in the depth of the financial and economic crisis of the Great Depression. These Depression-era revisions granted the Federal Reserve “emergency” lending powers. More than forty years more were to pass before the Federal Reserve Act would contain an explicit statement of its macro policy objectives. Those objectives, added in 1977, state that “The Board of Governors of the Federal Reserve System and the Federal Open Market Committee shall maintain long run growth of the monetary and credit aggregates commensurate with the economy's long run potential to increase production, so as to promote effectively the goals of maximum employment, stable prices, and moderate long-term interest rates.” Other Central Bank Charters Other countries have also recognized the interdependence of macroeconomic performance and financial stability and, as a result, many central bank charters reflect a concern for both macro objectives—such as price stability and satisfactory economic performance—and financial stability. reports some key passages from several central bank statutes. Text in italics indicates passages that would seem to provide an explicit goal for the central bank in pursuing financial stability. Text that is highlighted could be interpreted as encompassing financial stability as an implicit central bank objective. What can be said about the overall pattern of statutory financial stability objectives among central banks? At least among the small sample of central banks listed in Table 1, all have at least some implicit references to financial stability and many have quite explicit references to financial stability as a factor that central banks need to consider. In many cases, the explicit references to financial stability fall in the realm of banking and the efficient operation of the payment system. However, some have references that seem to embody a broader notion of financial stability. 3. Financial Stability Objectives: Relative Weight and Activism The foregoing discussion suggests that financial stability to some degree already is an important objective for central banks around the world, even for those that are sometimes viewed as solely concerned with price stability. The real question then may not be so much whether financial stability should be a central bank objective, but rather how policymakers should weigh that objective in reaching policy decisions. Here one could imagine a range of possibilities. At one extreme, a central bank might focus almost entirely on an objective such as price stability with financial stability concerns only entering in an extreme scenario when a crisis is underway. Svensson (2002) labels this a strict inflation targeting regime. At another extreme, a central bank might be highly sensitive to signs of financial instability and be quite willing to take pre-emptive policy actions to address potential instabilities even when such steps might not be warranted solely by reference to the near-term outlook for price stability and economic activity. In a thought-provoking paper, Borio and Lowe (2002) develop a rationale for just such an activist, pre-emptive approach by a central bank in a pursuing financial stability objective. In a nutshell, they argue that financial imbalances may develop even at times when prices are stable and output is close to potential. As a result, central banks need to be prepared to take pre-emptive actions to head off potential financial instability even when such policy actions may not be fully justified by the outlook for inflation and output. There seem to be at least three basic issues that arise in contemplating the degree of activism that central banks should adopt in pursuing a financial stability objective. To summarize briefly: The first basic issue involves questions about how a financial stability objective would affect central bank incentives and interact with the central bank’s other policy goals. Although I do not want to overemphasize the point, a financial stability objective that is accorded too much weight could, at the margin, impair the conduct of monetary policy in achieving macro ends. A second issue involves how a financial stability objective might be perceived by the public and investors. On this score, it seems likely that a central bank adopting a highly activist approach in the pursuit of a financial stability objective would court moral hazard. And finally, there are serious questions about whether a very activist approach to financial stability could end up contributing to the volatility of economic variables. Interactions with Other Policy Objectives One basic issue is how much weight central banks should attach to financial stability as an objective vis-à-vis their other objectives. Of course, in many cases, the relative weight a central bank places on financial stability may not be especially important if a financial stability objective is essentially auxiliary and tends primarily to reinforce the rationale for policy actions warranted by other objectives. For example, a sudden seizing up in financial markets is likely to be associated with a weakening in aggregate demand. In this case, the pursuit of monetary policy objectives and a financial stability objective would be largely in accord and both would be served by additional monetary policy stimulus. Conversely, a significant and unwarranted easing in credit supply conditions might be accompanied by growth of output well above that of potential. Again, in this case, financial stability considerations would tend to support the tightening of monetary policy that is justified in the first instance by the goal of economic stabilization. However, there is some potential for perceived conflicts between the traditional macro policy objectives and a financial stability objective. Sometimes in tightening the stance of policy, for example, policymakers are concerned about the possibility that outsized financial market reactions could occur or that an associated decline in asset prices will reveal financial vulnerabilities in some sectors. At the margin, it would seem that a financial stability objective that was weighted quite heavily would tend to make that concern more pronounced, which arguably could hinder the effectiveness of monetary policy in securing price stability and sustainable real growth. For example, one might wonder whether the Federal Reserve’s changes in procedures in the late 1970s to target a narrow monetary aggregate, with the attendant rapid increase in the level of the federal funds rate, would have been possible in a regime that tended to view sharp swings in interest rates as a threat to financial stability. Potential problems also can arise when central banks need to implement policy easings. For example, some have argued that the Bank of Japan was too slow in easing policy in response to the decline in economic activity in the early 1990s, partly because it feared that an aggressive easing would risk reinflating asset price bubbles. Moral Hazard Another important issue raised by a very activist approach to pursuit of financial stability objectives is how such an approach would affect the incentives of market participants. It seems quite possible that wide recognition that central banks place heavy weight on warding off financial instability could work to exacerbate moral hazard. Investors might conclude that a central bank with a very activist approach in addressing financial instability would be more inclined in many scenarios to step in to forestall a crisis. For example, investors may perceive that an activist central bank would be more likely to come to the rescue of large financial institutions that are perceived to be systemically important—a perception that would tend to reinforce a view that some institutions are “too big to fail.” Moral hazard may also arise at the macro level as well. If investors are convinced the Federal Reserve will aggressively ease policy in response to adverse shocks to particular markets, they may undervalue the risks they assume in their investment decisions. This perception could also lead to a misallocation of resources and, paradoxically, contribute to a deterioration in financial stability over a long horizon. Inadvertent Destabilizing Actions Still another concern that might be associated with a highly activist pursuit of a financial stability objective is the possibility of inadvertently contributing to greater variability in macroeconomic variables. As Milton Friedman famously cautioned many years ago, when the lags and impact of monetary policy actions are uncertain, activist monetary policy aimed at damping output fluctuations, albeit well-intentioned, can easily end up amplifying such fluctuations instead. One scenario in which this concern seems especially relevant today is the case of asset price bubbles. Some authors, including Borio and Lowe, have suggested that a central bank may be able to take actions to burst such bubbles at an early stage and thereby avert some especially serious future consequences if the bubble otherwise were to continue to inflate for some time before bursting. To be sure, central banks can and should lean against the wind to the extent that such asset price distortions affect the outlook for inflation and output. But to go beyond this to a policy of actively seeking to burst a bubble seems very problematic—there are simply too many uncertainties involved. One can never be sure that a bubble is inflating. And even if a bubble could be identified with certainty, calibrating the necessary policy actions necessary to burst a bubble without significant damage to the real economy would be extraordinarily difficult. 4. Incorporating Financial Stability in a Decision-Making Framework The previous discussion suggests that there may be significant problems associated with an overly activist approach in pursuing financial stability objectives. But this begs the question of just how a central bank should take financial stability considerations into account in reaching policy decisions. In conducting monetary policy, the Federal Reserve normally prefers to focus on its broad macro policy objectives—low inflation and sustainable output growth—and to consider financial instability implicitly through its effect on these fundamental variables. Financial instabilities that are significant enough to cause the expected path either of output to move significantly above or below that of estimated potential output or of inflation to deviate from intentions are then a cause for concern and policy can be eased or tightened as appropriate. Admittedly, determining what is “appropriate” over an extended horizon may involve complicated and difficult judgments about the short- and long-run effects of alternative policy prescriptions: It is possible, for example, that attaining long-run goals for sustainable growth may require some sacrifice of output in the near term. Nonetheless, concerns about financial instability in this instance would be evaluated largely by reference to expectations about inflation and output. But there may also be cases in which a central bank faced with the prospect of financial instability needs to adjust policy by more than could be justified solely by the forecasts for output and inflation. In my view, though, this is perfectly consistent with a central bank that conducts monetary policy using forecasts for key macro variables as its primary guideposts but also considers the risks to the forecasts for those key macro variables. One might think of this as a process of stress testing by monetary policy decision makers in which they regularly assess not just the likely path of output and inflation in reaching their policy decisions but also the potential for adverse outcomes in light of recent or potential shocks. For example, the FOMC reviews documents prior to each meeting that give the staff’s forecasts for inflation, output, and other variables based on economic models and the informed judgment of the staff. That forecast forms a baseline for discussion of policy alternatives at each FOMC meeting, although FOMC members of course develop their own view of the economic outlook. Issues of financial stability can be fairly readily incorporated in this process by considering “what if” exercises. For example, following a sharp increase in risk spreads in fixed-income markets, FOMC members might look not just at a baseline forecast but also how that forecast might change if some type of financial instability—perhaps a further, more extreme deterioration in credit availability—were to ensue. This scenario might influence the FOMC’s monetary policy decision, depending on the likelihood of the scenario and the potential costs in terms of output or inflation variability associated with it. This basic framework of guiding policy not just by the likely path of key macro variables but also by a sense of the risks to that outlook provides a structured way to incorporate concerns about financial instability into the broader policy discussion. Recent Episodes of Financial Instability Unfortunately, central banks including the Federal Reserve have faced an elevated frequency of episodes involving real or potential financial instability in recent years. The discussion below provides a brief review of the Federal Reserve’s approach in three such instances, and illustrates how its actions could be rationalized in the decision-making framework described above. Fall of 1998: The period of global financial turmoil touched off by the Russian debt default in August 1998 and then greatly exacerbated by the well-publicized travails of the hedge fund Long Term Capital Management (LTCM) was perhaps the most intense episode of financial instability in recent years. The Federal Reserve, like other central banks, paid close attention to an array of financial indicators at this time. Nearly all such indicators portrayed a dour picture of economic prospects—risk spreads widened sharply, stocks prices fell, and banks reported tightening terms and standards on business loans. Also disturbing were reports from contacts with market participants that capital markets were seizing up as dealers and other market makers recoiled from risk-taking. A sharp widening in the spread between off-the-run and on-the-run Treasury securities underscored the fact that investors were willing to pay a very high premium for liquidity. Facing what some were referring to as the most acute financial crisis in decades, the Federal Reserve eased policy by 75 basis points in three equal steps, including an intermeeting move in mid-October of 1998, and maintained that lower funds rate through June of the subsequent year. In part, these actions were motivated by a change in economic forecasts. But at least part of this cautious behavior reflected the FOMC’s concerns about financial instabilities and associated downside risks to the economic forecast. Indeed, the minutes from the September 29, 1998, FOMC meeting reported: “In the Committee's discussion of current and prospective economic conditions, members focused on developments that pointed to the potential for a significant weakening in the growth of spending . They recognized that there were at present few statistical indications that the economy was on a significantly slower growth track. Indeed, the available data suggested that consumer expenditures and business investment retained considerable strength. At the same time, however, investors' perceptions of risks and their aversion to taking on more risk had increased markedly in financial markets around the world. That change in sentiment was exacerbating financial and economic problems in a number of important trading partners of the United States. In addition, it was generating lower equity prices and tightening credit availability in U.S. financial markets. As a consequence, the downside risks to the domestic expansion appeared to have risen substantially in recent weeks .” [emphasis added] Productivity Growth and the Stock Price Runup: Economic developments in the United States in the late 1990s were quite favorable. Output growth was unusually strong and, in no small part, that strength seemed attributable to a sizable pickup in the trend growth of labor productivity spurred by the proliferation of new technologies, especially in the computing and telecommunications sectors. Investors read the favorable productivity trends as auguring enhanced profit growth, prompting a substantial runup in equity prices in 1999 and into 2000 that pushed standard valuation measures—such as price-earnings ratios—well above historical benchmarks. Although it is difficult to identify an equity risk premium with great precision, it certainly seemed at the time that investors were quite optimistic about the returns they could expect to earn by holding equities. The rise in equity wealth and strong growth of income over this period contributed to a brisk pace of consumer spending and an accompanying decline in the personal savings rate. Core measures of inflation, however, remained quite subdued even as the unemployment rate and other measures of resource utilization moved to levels that previously would have been viewed as threatening a rise in inflation pressures. In a sense, this period is similar to the situation that Borio and Lowe posit in which “imbalances” may develop even during a period when the current macroeconomic environment is viewed as quite favorable. The FOMC, however, did not frame its policy deliberations over this period in terms of the need to take action to address a potential bubble in the stock market. Rather, it focused on the outlook for output and inflation and the risks to that outlook. The FOMC was particularly aware that the stronger trend productivity growth would tend to be associated with a higher level of “equilibrium” real interest rates and that the degree of monetary policy restraint associated with any given setting of the target funds rate would need to be judged in this light. The FOMC responded to these economic developments by tightening policy appreciably, moving the target federal funds rate up from 4-3/4 percent in early 1999 to 6-1/2 percent in May of 2000. In explaining its actions, the FOMC noted that it was concerned that growth of aggregate demand would outstrip the growth in potential supply, leading to imbalances that would pose a risk of inflation pressures. For example, in explaining its actions in August of 1999 and February of 2000, the FOMC stated: “Today's increase in the federal funds rate, together with the policy action in June and the firming of conditions more generally in U.S. financial markets over recent months, should markedly diminish the risk of rising inflation going forward .” (August 24, 1999). “The Committee remains concerned that over time increases in demand will continue to exceed the growth in potential supply, even after taking account of the pronounced rise in productivity growth. Such trends could foster inflationary imbalances that would undermine the economy's record economic expansion .” (February 1, 2000). [emphasis added] An important factor underlying the Committee’s sense of the risks of inflationary pressures was the role of accelerating productivity growth in boosting earnings expectations and stock prices which, in turn, were providing considerable impetus to wealth and spending. For example, the minutes of the February 2000 meeting noted: “In the Committee's review of current and prospective economic developments, members commented that the economy still seemed to be growing very vigorously as it entered the new year…. Accelerating productivity, although adding to the growth of the economy's potential output, also had induced expectations of rapidly accelerating business earnings that in turn had generated sharp increases in stock market wealth and lifted the growth of purchasing power and spending above that in incomes. Relatively high real interest rates that reflected the increased productivity and damped the rise in asset values would be needed to help restore balance .” [emphasis added] September 11 Attacks: The terrorist attacks offered another example of the way in which policy decisions could be shaped importantly by concerns about potential financial instabilities viewed as risks to the economic forecast. On top of the appalling loss of life, the attacks caused major damage to the physical infrastructure of a number of key firms central to trading and market making activities. In an economy that had already been weakening prior to the attacks, many policy makers worried that the decline in stock prices, widening in risk spreads, and impairment of market functioning raised the odds of highly adverse events in which economic activity could plunge. In view of these risks, the FOMC eased policy 50 basis points prior to the reopening of markets on Monday, September 17. In explaining that action, the FOMC pointed both to a less sanguine economic outlook and to significant uncertainties (downside risks) associated with that outlook. The minutes from the FOMC’s August 2001 meeting (which included a summary of the FOMC teleconference call held on the morning of the September 17th ) reported: “Subsequently, on September 17, 2001, the Committee members voted unanimously to ease reserve conditions appreciably further, consistent with a reduction in the federal funds rate of 50 basis points to a level of 3 percent. This policy action was associated with the approval by the Board of Governors of a reduction of equal size in the discount rate to a level of 2-1/2 percent. These actions were taken against the backdrop of heightened concerns and uncertainty created by the recent terrorist attacks and their potentially adverse effects on asset prices and the performance of the economy . In conjunction with these policy moves, the Federal Reserve would continue to supply, as needed, an atypically large volume of liquidity to the financial system. As a consequence, the Committee recognized that the federal funds rate might fall below its target on occasion until more normal conditions were restored in the functioning of the financial system. The Committee's vote encompassed the retention of a statement in its press release indicating that the balance of risks remained weighted toward weakness for the foreseeable future.” [emphasis added] The September 11 attacks also provided an example of the way in which the Federal Reserve employed its full range of policy tools to address risks to the forecast. On the morning of September 11, the Federal Reserve issued a brief public statement indicating that it was operating and that the discount window was available. With an important market mechanism for distributing reserves among banks—the brokered federal funds market—significantly impaired, there were huge imbalances in reserve positions across the banking system. These were met through extraordinarily large levels of discount window lending for a few days and also by huge injections of reserves via the open market desk. A sizable portion of the funding needs on some days was concentrated at foreign banking organizations. To allow foreign central banks to better meet the dollar-denominated funding needs of their institutions, the Federal Reserve arranged swap lines with the ECB and the Bank of England and expanded its existing swap line with the Bank of Canada. To augment bank liquidity further, the Federal Reserve waived all daylight overdraft fees and the penalty portion of charges for overnight overdrafts and lengthened Fedwire operating hours for several days after the attacks. The Federal Reserve also greatly eased the limits on its security lending facility, thereby helping to reduce the pressure firms faced in acquiring securities made scarce by settlement difficulties. In addition, as noted earlier, the federal banking regulators issued a joint statement recognizing the possibility of significant balance sheet expansion for some banks and suggesting that banks contact them if they had concerns about how this would affect their capital ratios. These temporary arrangements were gradually unwound as financial conditions returned to normal. 5. Conclusion Financial stability is and always will be of vital interest to central banks and is certainly an appropriate objective for central banks. There are some complexities, however, in determining just how financial stability considerations should be taken into account in reaching policy decisions. In this context, the Federal Reserve has found it useful to view financial stability in terms of its impact on the economic outlook, including its effects on the forecasts for key economic variables and the risks to those forecasts. Much of the discussion above was framed in terms of an individual central bank balancing concerns about domestic financial stability with other objectives. But in today’s globally integrated markets, it is more important than ever for central banks and other financial authorities to share information, to communicate about crisis prevention measures, and to recognize a common interest in effective crisis management actions. In this vein, the work being done in various forums to develop a deeper understanding of the international dimensions of financial instability and to foster important structural improvements in areas such as payment systems, banking and securities market regulations, and accounting standards is especially important and relevant. Table 1: Financial Stability As An Explicit Central Bank Objective Among Other Countries Bank of Canada “ regulate credit and currency in the best interest of the economic life of the nation , to control and protect the external value of the national monetary unity and to mitigate by its influence fluctuations in the general level of production, trade, prices and employment so far as may be possible within the scope of monetary action, and generally to promote the economic and financial welfare of Canada .” Bank of England “Objectives of the Bank of England shall be (a) to maintain price stability, and (b) subject to that, to support the economic policy of Her Majesty’s Government, including its goals for economic growth and employment .” Note: There is a memorandum of understanding between the Bank of England and the government that delineates the Bank’s responsibilities in the area of financial stability. It assigns the Bank of England responsibility in three broad areas including stability of the monetary system, stability of financial system infrastructure particularly in the area of payment systems, and monitoring of the financial system as a whole. Bank of Japan “The objective of the Bank of Japan, as the central bank of Japan, is to issue bank notes and to carry out currency and monetary control.” “In addition to what is prescribed by the preceding Paragraph, the Bank’s objective is to ensure smooth settlement of funds among banks and other financial institutions, thereby contributing to the maintenance of an orderly financial system .” “(Currency and monetary control shall be aimed at, through the pursuit of price stability, contributing to the sound development of the national economy .)” ECB “the primary objective of the ESCB shall be to maintain price stability. Without prejudice to the objective of price stability, it shall support the general economic policies in the Community with a view to contributing to the achievement of the objectives of the Community .” “ the basic tasks to be carried out through the ECSB shall be…to promote the smooth operation of the payment systems .” “ The ECSB shall contribute to the smooth conduct of policies pursued by the competent authorities relating to the prudential supervision of credit institutions and the stability of the financial system .” Reserve Bank of New Zealand “The primary function of the Bank is to formulate and implement monetary policy directed to the economic objective of achieving and maintaining stability in the general level of prices.” “In formulating and implementing monetary policy the Bank shall--- (a) Have regard to the efficiency and soundness of the financial system :” Riksbank “The objective of the Riksbank's operations shall be to maintain price stability.” “ In addition, the Riksbank shall promote a safe and efficient payment system .” Footnotes 1. The emergency lending powers in Section 13(3) were amended slightly in 1991 with the passage of the Federal Deposit Insurance Corporation Improvement Act (FDICIA) of 1991. The changes removed certain restrictions on the type and maturity of collateral that can be accepted to secure such lending, which, in turn, allows the Federal Reserve somewhat more flexibility in addressing such an emergency funding need. 2. Lars Svensson, “Monetary Policy and Real Stabilization,” presented at a symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyoming, August 29-31, 2002. 3. Claudio Borio and Phillip Lowe, “Asset Prices, Financial and Monetary Stability: Exploring the Nexus,” BIS Working Papers, July 2002. 4. Borio and Lowe, for example, p. 22. 5. Whether the Bank of Japan was, in fact, greatly concerned that aggressive easing would reinflate asset bubbles is unclear, but market participants perceived this to be a significant factor in the BoJ’s policy deliberations. See Ahearne, Gagnon, Haltmaier and Kamin et al., “Preventing Deflation: Lessons from Japan’s Experience in the 1990s,” International Finance Discussion Papers, Board of Governors of the Federal Reserve System, June 2002, p. 23. 6. These issues are discussed in more detail by Alan Greenspan, “Economic Volatility,” presented at a symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyoming, August 29-31, 2002. 7. Svensson (2002) argues that optimal policy is based predominantly on an evaluation of forecasts for output and inflation and that financial stability is best viewed as a constraint on policy that becomes binding only on occasion. The FOMC tends to follow a more nuanced approach in which an assessment of the asymmetries in the outlook is part of its normal deliberations. Such risks sometimes include discussions of various types of financial imbalances. Table 1: Financial Stability As An Explicit Central Bank Objective Among Other Countries Bank of Canada “ regulate credit and currency in the best interest of the economic life of the nation , to control and protect the external value of the national monetary unity and to mitigate by its influence fluctuations in the general level of production, trade, prices and employment so far as may be possible within the scope of monetary action, and generally to promote the economic and financial welfare of Canada .” Bank of England “Objectives of the Bank of England shall be (a) to maintain price stability, and (b) subject to that, to support the economic policy of Her Majesty’s Government, including its goals for economic growth and employment .” Note: There is a memorandum of understanding between the Bank of England and the government that delineates the Bank’s responsibilities in the area of financial stability. It assigns the Bank of England responsibility in three broad areas including stability of the monetary system, stability of financial system infrastructure particularly in the area of payment systems, and monitoring of the financial system as a whole. Bank of Japan “The objective of the Bank of Japan, as the central bank of Japan, is to issue bank notes and to carry out currency and monetary control.” “In addition to what is prescribed by the preceding Paragraph, the Bank’s objective is to ensure smooth settlement of funds among banks and other financial institutions, thereby contributing to the maintenance of an orderly financial system .” “(Currency and monetary control shall be aimed at, through the pursuit of price stability, contributing to the sound development of the national economy .)” ECB “the primary objective of the ESCB shall be to maintain price stability. Without prejudice to the objective of price stability, it shall support the general economic policies in the Community with a view to contributing to the achievement of the objectives of the Community .” “ the basic tasks to be carried out through the ECSB shall be…to promote the smooth operation of the payment systems .” “ The ECSB shall contribute to the smooth conduct of policies pursued by the competent authorities relating to the prudential supervision of credit institutions and the stability of the financial system .” Reserve Bank of New Zealand “The primary function of the Bank is to formulate and implement monetary policy directed to the economic objective of achieving and maintaining stability in the general level of prices.” “In formulating and implementing monetary policy the Bank shall--- (a) Have regard to the efficiency and soundness of the financial system :” Riksbank “The objective of the Riksbank's operations shall be to maintain price stability.” “ In addition, the Riksbank shall promote a safe and efficient payment system .”
For immediate release The Federal Reserve Board on Thursday announced the execution of a Written Agreement by and among O.A.K. Financial Corporation, Byron Center, Michigan; the Byron Center State Bank, Byron Center, Michigan; the Federal Reserve Bank of Chicago; and the State of Michigan Office of Financial and Insurance Services. A copy of the Written Agreement is attached.
For immediate release The Federal Reserve Board, along with the Federal Reserve Banks of Chicago, Minneapolis, Kansas City, and San Francisco, will sponsor a conference this fall to explore ways to encourage banking opportunities in tribal communities. "Banking Opportunities in Indian Country" will be held November 18-20 in Scottsdale, Arizona. The conference will focus on methods and resources for encouraging initiatives and partnerships that increase access to credit and capital and strengthen local economies. Featured speakers include: Federal Reserve Board Governor Mark Olson; Rebecca Adamson (Eastern Cherokee), founder of the First Nations Development Institute; Robert Cheadle (Chickasaw), legislative counsel for the Chickasaw Nation; J.D. Colbert (Muscogee), president of the Native American Bankers Association; Stephen Cornell, Director of the Udall Center for Studies in Public Policy at the University of Arizona; Mary S. Gabler, vice president and community development manager for Wells Fargo; and Lance Morgan (Winnebago), founder of Ho-Chunk, Inc. of the Winnebago Tribe of Nebraska. The conference is designed for bankers, tribal leaders, tribal economic and housing development specialists, attorneys, and resource staff for community development. General sessions each day will address issues and opportunities for financial service providers, tribes and tribal members. Breakout sessions will provide specific information from experts on how to lay the groundwork for making capital and credit available in Indian Country, build relationships with key partners, leverage financial opportunities, and use financial resources for community economic development initiatives. The conference will be held at the Doubletree Paradise Valley Resort in Scottsdale, Arizona. For more information call 866-226-7167 (toll free) or see the conference web site at .
Remarks by Governor Mark W. Olson At the Federal Reserve Bank of St. Louis Conference: "Rays of Hope: A New Day for America's Distressed Urban Areas," East St. Louis, Illinois October 22, 2002 Urban Revitalization: Shared Responsibilities I am pleased to participate in this conference on urban revitalization. Much insight has been gained during the past fifty years. And, this city's work to revitalize its economy offers valuable lessons in the importance of community involvement, broad-based partnerships, and local sustainable investment by the private sector. East St. Louis has shown other cities an example of how an individual, namely Jackie Joyner-Kersee, can play an important role in revitalization. Virtually every time she is introduced or covered in print, Jackie Joyner-Kersee is identified with her hometown, East St. Louis. If that were the only ongoing identification this city were to have with her, East St. Louis still would benefit from the association with one of America's most successful and well-respected athletes. To her credit, however, she has chosen to do much more for her hometown. She has been a catalyst for local community development. Jackie Joyner-Kersee clearly understands what is required for meaningful community renewal. It requires residents to be involved in the ownership and management of community housing projects. It requires partnerships involving financial, community, and government resources, and it requires a commitment to the ongoing education of its residents. Each of these characteristics is evident in the involvement of the Jackie Joyner-Kersee Foundation with East St. Louis. Like many cities, East St. Louis has a history that includes a period of great economic vitality. In the early and mid-1900s, the city was a hub of commerce. Its natural resources and access to both river and rail transportation made it an ideal location for glass and metal manufacturing, refineries, and meatpacking. They offered abundant employment opportunities and provided economic stability to the area. The vitality of the city was recognized in 1959, when the National Civic League named East St. Louis an "All-America City," honoring its culture of civic excellence and the cooperative spirit among residents, businesses, nonprofits, and government. However, even at that time, the city had begun a thirty-year decline triggered by a number of factors: a significant reduction in population, urban flight by industry and business, and the decline of the railroads. Once a regional economic engine, East St. Louis became a city marked by fiscal, social, and physical deterioration. As a result, it has been grappling with the same challenges that have gripped a number of our nation's cities: decreased tax revenues, increased poverty and unemployment, and deficient infrastructure. A review of Census Bureau data reveals that during the past thirty years, much of the population and economic growth in metropolitan areas across the country has occurred in the suburbs, not in the central cities. East St. Louis, in particular, lost 55 percent of its population between 1970 and 2000, while the surrounding suburbs increased nearly 28 percent. The number of residents employed in manufacturing, East St. Louis's primary source of jobs, decreased 67 percent between 1970 and 1990, while it increased 8 percent in this area's suburbs. While the average annual unemployment rate in East St. Louis decreased between 1991 and 2001, it is still high, consistently registering in the double digits. Despite these less-than-favorable data, other information points to the strides that East St. Louis is making in improving its economic picture. For example, home ownership in East St. Louis has risen steadily since 1970, with building permit data showing a dramatic increase in the construction of single-family homes in 2000 and 2001. Another promising trend is revealed by the dramatic increase in the education level of its residents: The number of residents with some college credits or an associate degree has nearly tripled since 1970. These data demonstrate the real changes that residents of East St. Louis are seeing from collaborative redevelopment strategies implemented through its Enterprise Community and local community organizations. For example, the increase in home ownership is consistent with the development of Parson's Place, a partnership led by the Emerson Park Development Corporation (EPDC) to create affordable housing, which is viewed as a catalyst for East St. Louis's economic comeback. In addition, gains in education attainment levels track job training and youth education programs sponsored by EPDC and the Jackie Joyner-Kersee Foundation. These activities involve the local investment of both monetary and human capital, which is critical to revitalization and redevelopment. Such investment yields sustainable growth. The trend toward local investment tracks the evolution of community development policy and financing. A discussion of this progression provides some context for the strategies that are now considered effective for inner city revitalization. Evolution of Housing and Community Development Policy Urban policy began in this country as an offshoot of housing policy. Both were considered exclusively the purview of the federal government from the beginning of enabling legislation in the 1930s through the 1960s. During that time, federal laws and agencies were dedicated to stabilizing the residential housing markets by providing funding to finance home mortgages, as well as to construct public housing to alleviate overcrowding and replace substandard housing in cities. The conventional wisdom at the time was that improvements in housing conditions would enhance urban residents' overall quality of life, thereby resolving other social and economic ills that had beset inner-city neighborhoods. Indeed, in 1949 the federal government's housing policy expanded into urban renewal as programs were established with the objective of providing "a decent home and suitable environment" for every family. Given the enormity of such an undertaking, the federal government was seen as the logical resource for tackling the problems of inner-city blight and deterioration. With a large budget and a heavy hand, neighborhoods were transformed as urban planners demolished long-standing homes and businesses and replaced them with high-density, subsidized apartment buildings for low-income residents. In cities throughout the country, public housing projects were created. Examples include Cabrini-Green in Chicago, Jamaica Plains in Boston, Bedford-Stuyvesant in New York, and Cochran Gardens in St. Louis. Although these efforts originated with the vision of updating and improving the housing and economic conditions in urban neighborhoods, over time this one-dimensional federal housing policy had unintended consequences, including displacing residents, demoralizing communities, and creating concentrations of poverty, unemployment, and crime. These and future approaches by the federal government resulted increasingly in frustration and unmet expectations because the individuals affected by these policies had no voice in the formation or implementation of the redevelopment that drastically affected their lives. Policymakers crafting programs intended to revive central cities began to recognize the consequences of unilateral approaches to community development and began to incorporate community involvement in the redevelopment process in the mid-1950s. Over time, the role of community participation continued to increase. In response to this policy shift, community groups and public housing tenant organizations began to play a more-active role in planning for neighborhood revitalization and property management. Such involvement by resident stakeholders conveyed an ownership interest in the community that is essential to sustainable redevelopment. This involvement was deemed to be so vital that by 1970, local community development corporations (CDCs) were formally created and provided with federal assistance in recognition of their importance in mobilizing communities to improve their economic and social conditions. By way of illustration, East St. Louis is familiar with the impact that such groups can have on neighborhood revitalization when they work with local, regional, state, and federal governments. The evidence is the recent residential, retail, and support services development that is altering the economic profile of this city. Evolution of Community Development Finance Just as urban development policy grew to recognize the importance of local participation in the development of strategies for revitalization, so too did the process of funding such initiatives. For example, the Community Development Block Grant program authorized local governments to allocate federal funding for community redevelopment, rather than the direction being dictated by federal agencies. The delegation of funding priorities for community redevelopment began a process that would continually engage and expand the base of involvement and investment, using philanthropic and private-sector funds to leverage federal dollars for revitalizing distressed communities. Foundations became important sources of capital for urban redevelopment, as did banks. The Community Reinvestment Act of 1977 codified banks' responsibility for facilitating the credit flow in their markets, including low- and moderate-income neighborhoods, and formally established their role in community revitalization. The change in the base of capital providers for community development also redefined the roles of funding sources and fostered innovation in the financing strategies for community development. The federal government's role shifted from being the sole source of funding through direct appropriation to providing tax incentives and credit enhancements, such as loan guarantees and insurance, to encourage private investment by offsetting risk. As financial institutions increased their participation in community development activities, credit became vital for leveraging grant monies, and partnerships between CDCs and financial institutions became important vehicles for funding revitalization activities. This fundamental shift in community development financing philosophy engendered market-based strategies for redeveloping distressed communities. I want to emphasize the importance of the active engagement of the banking community in revitalization efforts. A strong and involved banking community is a tremendous asset in an area's development. Experienced loan officers who are well acquainted with their markets can channel funds into those loans that are most likely to benefit the local economy and can bring vital information and technical assistance to partnerships dedicated to reinvigorating the local marketplace. Establishing and maintaining banking relationships are critical to sustainable development that is not dependent on public funding. Over time, banks have become more engaged with CDCs as community groups have expanded their role from primarily advocacy to housing and community economic development. Comprehensive Approaches to Community Development While the availability of credit and capital has long been recognized as critical to fostering economic growth, many other factors contribute to the success of a market, including a skilled workforce and adequate support systems, such as educational institutions and transportation. In recognition of this, community developers came to realize that bricks-and-mortar development alone cannot revitalize distressed communities and that more-comprehensive approaches are necessary to foster sustainable growth. This more holistic approach moved community development beyond the realm of exclusively improving housing conditions and increasing home ownership. Community development now includes programs that increase residents' capacity to make economic contributions to the community by supporting entrepreneurs, providing job training, and facilitating transportation and child care. At the same time, government initiatives focused on developing markets by increasing private-sector investment in underserved communities, and by offering businesses financial incentives to locate in and employ residents of redevelopment areas. The vital importance of both human capital and private investment became apparent in the changes in community development policy and financing strategies. Initiatives became more comprehensive and partnerships, more broad based. As the scope of community development increased, so too did the breadth of partnering organizations. With the federal government, foundations, and banks well established in the process, CDCs sought new partners, such as insurance companies, major corporations, and universities, to support their work through funding and technical assistance. In addition, national community development intermediaries were created to provide funding support and technical assistance to larger-scale development and services. The expansion of these players led to new capital sources, and increased the complexity and sophistication of community development finance. For example, the need for equity financing to serve as a buffer against economic shocks and to increase ownership interests in underserved communities has led to the creation of community development venture capital funds, angel investor networks, and other mechanisms. More recently, organizations have begun to explore strategies for gaining access to capital markets to exponentially increase the capacity of community development finance. The Importance of Partnerships While many factors in East St. Louis's history contributed to the problems that this city is working to overcome, the fundamental concerns are similar to those of cities across the country: promoting local investment, creating affordable housing, and supporting workforce development. In this regard, the progression of community development policy is instructive in both effective and ineffective strategies and underscores the importance of creative partnerships in spearheading growth and development. Indeed, recent development in East St. Louis is attributable to strong collaborations among its stakeholders. One of the city's most-effective partnerships is with the University of Illinois at Urbana-Champaign, which sponsors the East St. Louis Action Research Project (ESLARP). This initiative provides technical assistance and volunteer services to help neighborhood organizations devise comprehensive plans, clean up sites, conduct research, and offer legal advice. Through its active engagement, community groups have increased their capacity and effectiveness. For example, EPDC, with assistance from ESLARP, was instrumental in ensuring that East St. Louis residents benefited from MetroLink, the region's light rail transit system, which was recently completed. By collaborating with ESLARP to create an alternate proposal for the development of the rail, EPDC secured a stop on the line for Emerson Park. This accomplishment is a critical link in revitalization efforts because it provides residents with ready access to jobs and services. In addition to EPDC, ESLARP has helped many other groups organize to address a myriad of issues, ranging from crime prevention to dependent care services. Another important asset in East St. Louis is its Enterprise Community. It has facilitated collaboration among local government agencies and community organizations to integrate housing, economic development, and support services into solutions for overcoming market failures and creating sustainable development. The Enterprise Community has tapped federal, state, and local resources to expand community development groups, provide workforce development programs, and make infrastructure improvements, thus cultivating new private-sector investment to assist existing businesses and recruit new enterprises. Among its many accomplishments, the Enterprise Community recognized the importance of a strong banking presence by making the construction and expansion of its oldest bank, Union Bank of Illinois, a priority. Other partners committed to improving the future of East St. Louis include the Casino Queen Foundation, which has funded a 24-hour daycare facility to help meet the child care demands of a wide variety of workers, and the Jackie Joyner-Kersee Boys & Girls Club, which recently partnered with Intel Corporation to provide computer access and training for youth through Intel Computer Club houses. These developments are significant strides in the revitalization of East St. Louis. With newfound investment and renewed strength, the city is creating its own opportunities by leveraging resources, creating partnerships to foster private-sector investment, and identifying strategies to overcome a variety of barriers to development. The Federal Reserve System's Community Affairs Office is particularly interested in supporting revitalization in localities where market failures have led to disinvestment. The Community Affairs Office conducts outreach, provides technical assistance and research, convenes stakeholders, and hosts conferences and other forums. This conference, with its information sharing and networking opportunities, is one example of how the Federal Reserve helps communities' revitalization efforts. In conclusion, I would like to underscore that while the history of community development policy and finance has been characterized as difficult, it provides important lessons that are now serving communities like East St. Louis as they bring sustainable change to their neighborhoods. This history demonstrates the importance of addressing the improvement of both physical and human infrastructure to create a vibrant community that attracts investment. These lessons show that private-sector investment is the life-blood of community development. Certainly, the success of this city's Enterprise Community is indicative of this precept. And, lastly, this history establishes the power of partnerships in tackling community development challenges. Broad-based collaborations that cross sectors, industries, and disciplines demonstrate the interdependence of market participants and serve to further community redevelopment by increasing investment, dispersing risk, and creating ownership in a community--vital elements in sustainable revitalization. These components are developing here in East St. Louis and should serve to redefine the economic profile of this city over time. At a recent leadership forum for adults and youth held at Marshall University, Jackie Joyner-Kersee concluded her presentation as follows: "Spread the positive fight, know why you are here and continue to make a difference." Thank you for allowing me to be a part of this information exchange. The Federal Reserve will continue to take a keen interest in your progress. I wish you well in your journey to economic revitalization.
For immediate release The Federal Reserve Board announced today the approval of the application of China Merchants Bank, Shenzhen, People's Republic of China, to establish a representative office in New York, New York. Attached is the Order relating to this action.
Remarks by Chairman Alan Greenspan Productivity At the U.S. Department of Labor and American Enterprise Institute Conference, Washington, D.C. October 23, 2002 The increase in nonfarm business output per hour over the past year will almost surely be reported as one of the largest advances, if not the largest, posted over the past thirty years. We at the Federal Reserve, along with our colleagues in government and the private sector, are struggling to account for so strong a surge. We would not be particularly puzzled if the increases in output per hour were occurring during a period of very rapid economic growth, such as has often attended recoveries from steep recessions. Historically, such recoveries have allowed overhead and maintenance employee hours to be spread over a rapidly increasing level of production. But during the past year we averaged only modest economic growth. The reported estimates of output per hour do not appear to have resulted principally from faulty data or measurement error. Whether output is measured from the expenditure side or from the independently estimated income side of the national accounts, and whether hours of work are measured from the survey of establishments or the survey of households, the same basic result is clearly evident: an impressive gain in output per hour over the past year. This conclusion is buttressed by recent sizable increases estimated for labor productivity for the manufacturing sector, derived from a data system that, for the most part, is independent of the national accounts. To be sure, because the productivity feast of recent quarters has been so difficult to explain, many analysts expect a productivity famine in the period ahead. Others, however, are not so pessimistic. Regardless of how events unfold, we will need to confront difficult questions posed by the recent performance of productivity, if we are to properly evaluate economic developments going forward. Indeed, if the recent surge in measured productivity is not a statistical mirage, or if it is not expunged by data revisions, then we need to ask about its possible causes. Clearly, over the past year corporate managers, confronted with tepid demand and a virtual disappearance of pricing power, have struggled to maintain profit margins. With price increases largely off the table and demand soft, lowered costs have become the central focus of achieving increased profitability. On a consolidated basis for the corporate sector as a whole, lowered costs are generally associated with increased output per hour. Much of the recent reported improvements in cost control doubtless have reflected the paring of so called "fat" in corporate operations--fat that accumulated during the long expansion of the 1990s when management attention was focused primarily on the perceived profitability of expansion and less on the increments to profitability that derive from cost savings. Managers, now refocused, are pressing hard to identify and eliminate those redundant or non-essential activities that accumulated in the boom years. Now, with margins under pressure, businesses effectively have been reorganizing work processes and re-allocating resources so as to use them more productively. Moreover, for capital with active secondary markets, such as computers and networking equipment, productivity may also have been boosted by a reallocation to firms that could use the equipment more efficiently. For example, healthy firms reportedly have been buying equipment from failed dot-coms. Businesses also may have managed to eke out increases in output per hour by employing their existing workforce more intensively. Unlike cutting fat, which permanently elevates the levels of productivity, these gains in output per hour are often temporary, as more demanding workloads eventually begin to tax workers and impede efficiency. Perhaps the return to a low-inflation environment in recent years in itself explains the intensification of competitive pressures, which has been a spur to the growth of productivity. Indeed, the data do suggest a relationship between inflation and productivity growth over the long run. But that statistical relationship is modest at best and inferring causality is complicated by a circularity that arises because increased growth in output per hour depresses unit labor costs and, hence, prices. Taken at face value, historical relationships suggest low inflation would explain very little of the most recent surge in output per hour. To be sure, while lack of pricing power and associated competitive pressures may have initiated much of the cost cutting and organizational changes that have occurred, it will ultimately be the quantity of fat in the system and the opportunities for productive reorganization that will determine the potential gains in productivity. Only in retrospect, if then, will we be able to ascertain how much of the past year's elevated growth in output per hour was transitory--that is, growth that resulted from cutting of fat, reorganizing operations, and more fully exploiting technologies already embedded in the existing capital stock. Such improvements, even though they are long-lasting, are, of course, a level adjustment with no necessary implications for productivity growth going forward. Moreover, there is an upper limit to the amount of output that can be produced from an existing facility, even in the short run, no matter how intensively it is employed and how much fat is taken out of the system. Corporate management can not unendingly reduce cost without at some point curtailing output or embodying new technologies through investment to sustain it. The recent upsurge in the growth of output per hour has understandably renewed interest in the relationship between investment and so-called adjustment costs. Firms do not necessarily reap the full benefits of their capital investments immediately because of the disruptions to activity that can be initially created when new equipment is installed; these disruptions may include learning to use the new equipment and software or getting the new machines to mesh with existing systems. Thus, although capital investment ultimately boosts output per hour, these adjustment costs temper the initial benefits to increased production obtained from new investment. It is likely that as capital spending fell over the past couple of years, so did the disruptions that accompanied its installation. Moreover, the dislocations associated with the substantial investment of the late 1990s and 2000 also likely were waning. This lower level of disruption provides a boost to growth in output per hour for a time. How much remains an open question. The quantitative evidence on the magnitude of this effect spans the range from significant to small. The ability of businesses to boost productivity with what seems to be minimal new capital investment over the past two years suggests that output per hour growth in the later years of the 1990s likely trailed the growth in underlying productivity in those years. If this inference is accurate, part of that earlier growth in underlying productivity is being reflected in today's gains in output per hour. The difficulty in explaining the recent past is most evident when we decompose gains in output per hour into the contribution from changes in worker quality, the amount of capital used by workers--that is, capital deepening--and the contribution from all other factors, a notion that economists label "multifactor productivity." By definition, multifactor productivity includes technical change, organizational improvements, cyclical factors, and myriad other influences on output per hour, apart from capital investment. With capital spending sluggish over the past year, and no evident acceleration of worker quality, it is likely that growth of multifactor productivity accounts for an appreciable portion of the rise in output per hour. Based on historical experience, it seems improbable that all of the large rise in multifactor productivity could be attributed to cyclical or transitory factors. Conversely, it seems very unlikely that all of the increase in the growth of productivity could be attributed to structural influences. The truth, presumably, lies between these two extremes, but where has yet to be determined. At minimum, however, it seems reasonable to conclude that the step-up in the pace of structural productivity growth that occurred in the latter part of the 1990s has not, as yet, faltered. Indeed, high growth of productivity over the past year merely extends recent experience. Over the past seven years, output per hour has been growing at an annual rate of more than 2-1/2 percent, on average, compared with a rate of roughly 1-1/2 percent during the preceding two decades. Although we cannot know with certainty until the books are closed, the growth of productivity since 1995 appears to be among the largest in decades. Our nation has had previous concentrated bursts of technological innovation. In those instances, business practices slowly adapted to take advantage of the new technologies. The result was an outsized increase in the level of productivity spread over a decade or two, with unusually rapid growth rates observed during the transition to the higher level. For example, as the benefits that attended the development of the electric dynamo and the internal combustion engine more than a century ago became manifest in both the capital stock and the organization of production, the growth of labor productivity surged. From an average annual rate of 1-3/4 percent in the late nineteenth and early twentieth century, it jumped to a 3-3/4 percent rate in the decade following World War I. Subsequently, productivity growth returned to a 1-3/4 percent pace. Then, for the quarter century following World War II, productivity growth rose to an average rate of 2-3/4 percent before subsiding to a pace of 1-1/2 percent annually from the mid-1970s to the mid-1990s. Arguably, the pickup in productivity growth since 1995 largely reflects the ongoing incorporation of innovations in computing and communications technologies into the capital stock and business practices. Indeed, the transition to the higher permanent level of productivity associated with these innovations is likely not yet completed. Surveys of purchasing managers in recent quarters consistently indicate that an appreciable share reports that their firms still have a considerable way to go in achieving the desired efficiency from the application of technology to supply management. If the backlog of unexploited long-term profitable technologies remains high, it should be assumed that once currently elevated risk premiums and the heightened cost of equity capital (and some debt) recedes, or cash flows expand, new productivity-enhancing capital investment will pick up. Further evidence that firms still have not fully adapted their operations to the latest state of technology also is provided in a recent study that attempts to measure the "technological gap"--that is, the difference between the productivity of leading-edge capital and the average productivity embodied in the current capital stock. This gap is estimated to be quite wide currently, which suggests that there are still significant opportunities for firms to upgrade the quality of their technology and with it the level of productivity. The paper presented by Stephen Oliner and Dan Sichel this morning also provides a basis for arguing that a significant portion--and possibly all--of the productivity revival of the mid-1990s is sustainable. Based on an analysis of a multisector growth model, their work suggests that a range for sustainable growth in labor productivity over the next decade is 2 percent to 2-3/4 percent per year. Jorgenson, Ho, and Stiroh use a similar methodology and find a range from a little less than 1-1/2 percent to about 3 percent with a central tendency of around 2-1/4 percent. These estimates are clearly plausible, but history does raise some warning flags concerning the length of time that productivity growth continues elevated. Gains in productivity remained quite rapid for years after the innovations that followed the surge of inventions a century ago. But in other episodes, the period of elevated growth of productivity was shorter. Regrettably, examples are too few to generalize. Hence, policymakers have no substitute for continued close surveillance of the evolution of this current period of significant innovation. * * * In summary then: given the difficult adjustments that our economy has been undergoing, long-term productivity optimism may currently seem a bit out of place. It may appear even more so in the months ahead should output per hour soften following this period of outsized gains. Nevertheless, it is both remarkable and encouraging that, despite all that has transpired over the past couple of years, a significant step-up in the growth of productivity appears to have persisted. Footnotes There are those who point out, quite correctly, that a significant part of the output of the late 1990s was wasted in a misallocation of capital to pie-in-the-sky ventures. But that output was misused does not subtract from the evident capacity to produce that output, and it is this that our measures of structural productivity attempt to capture. Susanto Basu, John Fernald, and Matthew Shapiro, in their paper "Productivity Growth in the 1990s: Technology, Utilization, or Adjustment?," Carnegie Rochester Conference Series on Public Policy, (April 2001) pp. 117-165, find significant effects. Frank Lichtenberg, in his paper "Estimation of the Internal Adjustment Costs Model Using Longitudinal Establishment Data," Review of Economics and Statistics , vol. 70 (1988), pp. 421-430, finds much smaller effects. In contrast to the boom in productivity after World War I, which many economists associate with a few key innovations, analysts usually ascribe the post-World War II boom to innovations in many sectors reflecting the diffusion through the private economy of (a) new technologies that appeared in the 1930s but were not fully implemented during the Depression, and (b) a gradual application to civilian activities of military-related innovations. Sectors with major innovations included electronics, chemicals, pharmaceuticals, and transportation (jet travel). Jason G. Cummins and Giovanni L. Violante, "Investment-Specific Technical Change in the United States (1947-2000): Measurement and Macroeconomic Consequences," Review of Economic Dynamics, vol. 5 (April 2002), pp. 243-284. Dale W. Jorgenson, Mun S. Ho, and Kevin J. Stiroh, "Projecting Productivity Growth: Lessons from the U.S. Growth Resurgence," Federal Reserve Bank of Atlanta Economic Review, Third Quarter 2002, p. 1-13. Footnotes There are those who point out, quite correctly, that a significant part of the output of the late 1990s was wasted in a misallocation of capital to pie-in-the-sky ventures. But that output was misused does not subtract from the evident capacity to produce that output, and it is this that our measures of structural productivity attempt to capture. Susanto Basu, John Fernald, and Matthew Shapiro, in their paper "Productivity Growth in the 1990s: Technology, Utilization, or Adjustment?," Carnegie Rochester Conference Series on Public Policy, (April 2001) pp. 117-165, find significant effects. Frank Lichtenberg, in his paper "Estimation of the Internal Adjustment Costs Model Using Longitudinal Establishment Data," Review of Economics and Statistics , vol. 70 (1988), pp. 421-430, finds much smaller effects. In contrast to the boom in productivity after World War I, which many economists associate with a few key innovations, analysts usually ascribe the post-World War II boom to innovations in many sectors reflecting the diffusion through the private economy of (a) new technologies that appeared in the 1930s but were not fully implemented during the Depression, and (b) a gradual application to civilian activities of military-related innovations. Sectors with major innovations included electronics, chemicals, pharmaceuticals, and transportation (jet travel). Jason G. Cummins and Giovanni L. Violante, "Investment-Specific Technical Change in the United States (1947-2000): Measurement and Macroeconomic Consequences," Review of Economic Dynamics, vol. 5 (April 2002), pp. 243-284. Dale W. Jorgenson, Mun S. Ho, and Kevin J. Stiroh, "Projecting Productivity Growth: Lessons from the U.S. Growth Resurgence," Federal Reserve Bank of Atlanta Economic Review, Third Quarter 2002, p. 1-13.
Remarks by Vice Chairman Roger W. Ferguson, Jr. At the Stockton Lectures 2002, London Business School, London, U.K. October 24, 2002 Productivity Growth: A Realistic Assessment I want to thank Laura Tyson and the other members of the London Business School for inviting me to participate in your Stockton lecture series. As Laura requested several months ago, my topic this evening will be the "new economy" and more specifically the growth of labor productivity. This issue is one of the most studied in macroeconomics, yet it is an area in which obviously far too many puzzles remain. Of course, the usual disclaimer applies to my remarks: I will express my own views, and you should not interpret them as the position of the Federal Open Market Committee or of the Board of Governors. How--you might reasonably ask--could so many questions remain after so much research on this key topic? The answer--I submit--is not that the productivity of my fellow economists is low or that the economics profession has failed in a key mission. Rather, it is that the underlying sources of productivity growth are very complex. On the surface, the determinants of productivity growth might seem straightforward: factors such as technological progress, capital deepening, and the changing institutional structure of labor and product markets. However, these fundamental determinants shift in importance over time and often do not lend themselves to measurement in the real world. As you know, to measure the hours worked of a lawyer, a doctor, a business school dean, or even a governor of a central bank is easy. But evaluating the quantity of our collective output is much more difficult. Thus, before embarking on any serious discussion of productivity growth, one must recognize the very difficult measurement challenges that we face. Different methods of data construction will yield different answers to important questions. But if we are consistent in our methods, I believe both our aggregate statistics and also microeconomic studies of productivity growth at the firm and industry level can yield important insights. With that caveat about productivity measurement aside, let me state right from the outset of this lecture that I continue to be cautiously optimistic about productivity growth in the United States. Based on my reading of the data and my understanding of numerous business case studies, I believe that trend labor productivity in the United States accelerated in the mid-1990s. That acceleration reflected several factors not tied to the strong business expansion: notably, an apparent pickup in the pace of technological progress--especially in the so-called high-tech sector--as well as a surge in capital spending by businesses. But other factors were also at work, including well-aligned monetary and fiscal policies that created an economic environment conducive to noninflationary economic growth. In addition, our economy continued to benefit from past actions by the government to deregulate industries. The removal of unnecessary government regulation began more than twenty years ago, during the administration of President Ford, and gathered momentum during the Carter years. It has altered the business landscape. Deregulation allowed, indeed forced, businesses to focus more clearly on a marketplace that had become more competitive, with fewer constraints and increased flexibility. The Statistical Evidence I think it would be useful at this point to review what the data actually tell us about the pattern of productivity growth in the United States. From the beginning of 1960 until the fall of 1973, labor productivity in the nonfarm business sector grew about 3 percent per year. Productivity growth then fell to an annual pace of 1-1/2 percent, likely in response to the supply shocks that hit the world economy during that period, higher inflation, a rise in uncertainty about the prospects for future economic growth, and public policy decisions that diverted resources from activities that would have generated more measured output. I should stress that, although I have listed several likely contributors, the ultimate cause or causes of this post-1973 productivity slowdown have eluded researchers. Productivity continued to grow at an annual pace of about 1-1/2 percent from 1973 to 1995. We can divide this period into several subperiods, yet the results are essentially the same: continued gains in labor productivity but well below the pre-1973 pace. From 1995 to 2001, labor productivity grew at an annual pace of 2-1/4 percent. Research by my colleagues at the Federal Reserve--Steve Oliner and Dan Sichel--sheds some light on the sources of this faster productivity growth. Using a growth accounting methodology, they find that about half the acceleration in productivity can be attributed to capital deepening. As you know, providing workers with more equipment improves their efficiency. At the aggregate level, the high levels of business investment raised the amount of capital per worker and thereby boosted productivity. Also, most of the faster capital deepening reflected spending by businesses on high-tech equipment, mainly computer hardware and software. The other half of the pickup in productivity growth reflected technological innovations in the actual production of computer hardware and semiconductors as well as better management--perhaps assisted by these high-tech investments--of the nation's capital and labor. Oliner and Sichel estimate that, if one consolidates all the influences of high-tech investments, they fully account for the acceleration in productivity over the 1995-2001 period. The Oliner-Sichel estimates are broadly consistent with the results of most other researchers in this field. I should also note that their conclusions have not changed in any fundamental way since they were first published in 2000. I mention this fact to address the concerns of some observers that recent revisions to the national income and product accounts have changed the evidence on post-1995 productivity growth. The last two annual revisions have indeed lowered output growth, but these adjustments followed several years of upward revisions. To focus on the most recent revisions is natural, but we should not lose sight of the complete record of historical revisions. Research by Board economists--Karen Dynan and Doug Elmendorf--clearly shows that we initially overestimate growth during recessions and periods of economic weakness. But we also initially underestimate growth in recovery periods. Thus, based on the revisions to growth over the past three years, I do not believe that one should presume that future data revisions will whittle away the post-1995 acceleration in productivity. Microeconomic studies provide corroborating information to the macroeconomic evidence of a post-1995 acceleration in productivity growth. Industry studies indicate a pattern of greater efficiency gains after 1995, and one clearly gets that impression from talking to business leaders. These executives consistently say that, when they have little leverage to raise their prices, the key to boosting profits is productivity growth. Many corporate CEOs cite the more efficient use of information technology as one vehicle for cost saving, and I doubt that anyone would question the assertion that all of us are working "smarter and faster" than we were in 1995. Researchers can and will debate the exact magnitude of that increment to our efficiency, but it was doubtless a key economic development of the past decade and one that will continue to pay dividends in future years. Having said that I think the post-1995 productivity acceleration was real, let me also assert that we should constantly challenge our assumptions. With the passage of time and the acquisition of more information, we are better able to distinguish between events that have true long-run significance and those whose effects prove fleeting. In that spirit, I am the first to admit that we do not fully understand the boom and subsequent bust that has occurred worldwide in the high-tech sector--especially in the telecommunications area. There apparently was overinvestment in the late 1990s, but we do not yet know the exact magnitude. Furthermore, we don't understand how this overinvestment should be factored into our analysis of productivity growth over this period. It seems straightforward not to count nonproductive capital as part of the productive capital stock. But should we also exclude the value of such equipment from our measures of output as well? These tricky questions are important for us to resolve. Similarly, I don't think we yet fully understand the role of Year 2000 preparations in either the late 1990s investment boom or the acceleration in productivity. Billions of dollars were invested to fix the Y2K bug, and we don't know how much of that spending was for the replacement of obsolete systems (and hence should be considered as depreciation in measuring the stock of available capital) or for the expansion and upgrading of systems (which, parenthetically, is the assumption we use in all our growth accounting exercises). But although these Y2K remediation efforts were costly and at times painful, virtually all the business leaders I know would assert that the efforts produced significant efficiency gains in the use and management of their information systems. Thus, the net effect of Y2K on our economy is still very much an unanswered question, and I'd like to see the research community systematically assess it. Current and Prospective Productivity Growth The cyclical slowing in 2001 and gradual expansion in 2002 have raised a critical issue. That question is: Will productivity growth in the years ahead more closely resemble the substantial gains over the 1960-73 period or the weaker performance of the 1973-95 slowdown? I tend to believe that future growth will most likely follow the 1960-73 pattern, and the most recent record of productivity growth reinforces that view. Productivity is a cyclical variable that typically falls in recessions. However, during the most recent downturn, productivity never declined and instead continued to grow at a fairly strong pace. Moreover, after the tragic events of September 11, many economists feared that the U.S. economy would weaken substantially and that productivity growth would suffer a severe setback as well. In the event, output per hour in the nonfarm business sector has grown in excess of 5 percent over the last four quarters. How should we interpret this truly extraordinary performance? Cyclical forces probably played some role. After September 11, many businesses sharply reduced their payrolls in anticipation of a slump in demand. But demand continued to grow briskly, and these companies learned to squeeze more output out of a smaller workforce. These efficiency gains likely were facilitated by the capital investments of recent years. Adjusting to new technologies takes time, and it is plausible that such an adjustment process has continued to boost productivity growth in recent years. Although cyclical forces and lags in the assimilation of new technologies have been important, their influence is likely to be transitory. More fundamentally, I believe that the trend in productivity growth has ratcheted up, and this development has been the driving force behind the recent extraordinary productivity growth. What might be wrong with this assessment? Some analysts have cited the low level of business confidence today and the possibility that it could inhibit economic growth. But sentiment rises and falls, and this period of pessimism, too, will pass. Others contend that productivity growth itself can be a problem because efficiency gains are achieved by a reduction in payrolls, which tends to deflate aggregate demand. I do not want to dismiss the notion that "downsizing" or "rightsizing" can be painful in the short run. It can be. But, this pain is transitory, and ultimately, the faster productivity growth raises real wages, stimulates growth in real incomes, and contributes to an increase in our standard of living. A third risk, however, is that we will not get a meaningful recovery in profitability. Without such renewed corporate profits, firms will be reluctant to invest in research and development or to purchase new efficiency-improving equipment. In many cases, new technologies are introduced into our economy through capital investment, and the important productivity gains of recent years will not be repeated unless businesses continue to invest in new plant and equipment. Increases in business fixed investment, particularly equipment and software, are unlikely to return to the extraordinary levels experienced in the period immediately prior to the recent slowdown. However, a period of inadequate corporate investment that results in "capital shallowing" rather than capital deepening would almost surely hurt our productivity performance. I do not attach a high probability to this latter scenario. Although some industries have suffered severe losses and have sharply curtailed their capital expenditures, other sectors have posted growth in earnings and have continued to invest. Thus, in the aggregate, the underlying picture of both corporate profits and capital spending is not as bleak as the experiences of some industries might suggest. Indeed, as measured in the national income and product accounts, economic profits in the second quarter--the latest available data--were 8-3/4 percent above year-earlier levels. And ultimately, if I'm right about the stronger underlying pace of productivity growth, aggregate profits will continue to recover once the sectoral imbalances are eliminated. That brings me to the current state of the high-tech sector and its future prospects. To understand what is happening in that sector, we may find it helpful to put recent developments into a longer-term historical perspective. In the 1990s, the high-tech boom appears to have been sparked by the confluence of three key trends: the rapid growth in computing power generated by explosive advances in semiconductor technology; the advent of new networking technologies that permitted computers to communicate more easily with each other in private networks and through the public Internet; and the development of software programs that facilitated these interactions and greatly expanded the uses of personal computers. During such a period of rapid change, the rate of return to investing in these new technologies and applications seemed to be very high. The spectacular financial returns from investing in leading-edge technology companies induced new firms to enter these markets, supported by investors eager for windfall financial gains. As these new firms set up or expanded their operations, capital spending surged. For a time, investors seemed to think that high-tech companies were low-risk, high-return investments. But, as we all now know, they were wrong. Ultimately, more businesses entered the high-tech field than could be supported by the substantial growth in demand in this sector. Businesses overinvested in high-tech equipment, and when profits failed to materialize, many of these firms went bankrupt. In the end, the economy was left with an overhang of high-tech capital, which is exerting a drag on economic activity to this day. Does this experience call into question the economic potential of these new information technologies? I don't think so. In the exigencies of the moment, one can easily lose sight of how much progress has been made over the past decade as a result of these new technologies. It is true that rates of return to high-tech investments were not as high as the most optimistic once thought. However, these technologies have truly changed the way businesses operate, and I believe that they will continue to do so in the future. The progress that is occurring today may not seem as revolutionary as it did five or six years ago. Nonetheless, the ongoing evolution of these technologies is continuing to generate productivity gains. We all have a natural tendency to look for the next "killer application" that will once again revolutionize the high-tech marketplace. This is the high-tech equivalent of "waiting for Godot," and we should not ignore the many, smaller changes to business practices that are continuing to yield real efficiency gains. When will the high-tech sector recover? I can't give you an exact time or date, but I will assert that its economic prospects still seem positive over the long run. The capital overhang--especially in the telecommunications industry--obviously must be eliminated before any meaningful expansion can occur, and some additional consolidation may be necessary if businesses are to be profitable in the long run. But I, like many other observers, think such change is occurring and is likely to bear fruit in the years to come. Conclusion To sum up, none of us, obviously, can see the future, and instead we shall have to monitor incoming data closely for evidence of any shifts in recent productivity trends. Nonetheless, I remain cautiously optimistic that the U.S. economy can continue to enjoy strong productivity-led growth that will raise living standards in the years to come. I believe this based on analyses at the firm, the industry, and the macroeconomic levels. The unbelievable stories of high-tech revolution were proven to be just that, unbelievable. But the more moderate and credible explanations remain.
For immediate release The Federal Reserve Board today announced its approval of the proposal by Citigroup Inc., New York, New York, to acquire Golden State Bancorp Inc. and its subsidiary savings association, California Federal Bank, both of San Francisco, California. Attached is the Board's Order relating to this action.
Remarks by Chairman Alan Greenspan Education At the International Understanding Award Dinner, Institute of International Education, New York, New York October 29, 2002 It is an honor to be here this evening to accept the Stephen P. Duggan Award for International Understanding. After a year during which violence and terror have so engaged our public discussions both here and abroad, I appreciate this opportunity to share with you some more civilizing and constructive thoughts. I plan to address the important role that education has played in raising standards of living, especially in the United States, and in contributing to positive social and economic relationships across the globe. Although I will focus on institutions of formal education, we need to be reminded that people have been educating themselves one way or the other since the dawn of history. Our faculty for rational thought has carried us one arduous step at a time into a deeper understanding of how the world works. Decade by decade, scholars have recorded their insights, building knowledge from one generation to the next. Although wars, international conflicts, and economic crises have interrupted our progress from time to time, we have, nonetheless, persisted in learning to use our hard-won knowledge to alter our physical and social environment for the better. Especially notable has been our application of both scientific advances and organizational paradigms to raise living standards across most of the population, and, as a consequence, engender marked increases in average longevity and quality of life. Over the last century, for example, real gross domestic product in the United States has grown at an average of more than 3 percent per year. Only a small fraction of that increased value represents a rise in the tonnage of physical materials--oil, coal, ores, wood, and raw chemicals, for example. The remainder represents new insights into how to rearrange those physical materials to better serve human needs. This process has enabled valued goods to be transported more easily and to be produced with ever fewer workers, allowing a more efficient division of labor to propel overall output and standards of living progressively higher. The share of the nation's output that is conceptual appears to have accelerated after World War II with the insights that led to the development of the transistor and microprocessor. They have spawned remarkable alterations in how we, and many other societies, live. Computers, telecommunications, and satellite technologies have enabled data and ideas--the ever more important elements of valued output--to be expeditiously transferred geographically to where they can be put to best use. Thus, these advanced means of communication have added much the same type of value that the railroads added in transporting the more-physical goods of an earlier century. Here in the United States, we have developed an exceptionally sophisticated stock of capital assets--fostered by the most conceptual and intangible of all new products--software. Breakthroughs in all areas of technology--despite the recent slowdown--have been continually adding to the growing list of almost wholly conceptual elements in our economic output. These developments are affecting how we produce output and are demanding greater specialized knowledge. In broad terms, the available empirical economic research has identified a complex of factors as key determinants of how successful any country will be in transforming its physical and human assets into economic growth: openness to trade, a strong institutional infrastructure, disciplined macroeconomic policies, and an effective system of education--formal or otherwise. Although the relative contribution of any single factor remains under debate, most observers would agree that the success of these factors in accounting for relative rates of economic growth across countries lies importantly in the interactions of the determinants themselves. An educated workforce, then, is a necessary ingredient for economic advance, but it is apparently much more powerful when combined with a strong, competitive economic system, where rights of persons and property are protected. In that regard, an economist can scarcely fail to notice the advantages that we have accrued in this country by having the marketplace work efficiently to guide our educational system, defined in its widest sense, toward the broader needs of our economy. The history of education in the United States traces a path heavily influenced by the need for a workforce with the skills required to interact productively with the evolving economic structure. Over the generations, technological advance has brought with it not only improvements in the capital inputs used in production but also new demands on workers who must interact with that increasingly more complex stock of capital. Early last century, these advances required workers with a higher level of cognitive skills--for instance the ability to read manuals, to interpret blueprints, or to understand formulas. Our educational system responded: In the 1920s and 1930s, high school enrollment in this country expanded rapidly, pulling youth from rural areas, where opportunities were limited, into more productive occupations in business and broadening the skills of students to meet the needs of an advancing manufacturing sector. It became the job of these institutions to prepare students for work life, not just for a transition to college. In the context of the demands of the economy at that time, a high school diploma represented the training needed to be successful in most aspects of American enterprise. The economic returns for having a high school diploma rose and, as a result, high school enrollment rates climbed. By the time that the United States entered World War II, the median eighteen year-old was a high school graduate--an accomplishment that set us apart from other countries. I should note that I regret that, more recently, international comparisons have not been so favorable; tests of student achievement in mathematics and science suggest that our high schoolers have been falling short of their peers in other countries. I trust that this degradation will prove to be transitory. As was the case with our high schools, the evolution of our system of higher education was also influenced importantly by the need to respond to advances in economic processes. Although many states had established land grant schools earlier, their support strengthened in the late nineteenth century as those whose economies specialized in agriculture and mining sought to take advantage of new scientific methods of production. Early in the twentieth century, the content of education at an American college had evolved from a classically based curriculum to one combining the sciences, empirical studies, and modern liberal arts. Universities responded to the need for the application of science--particularly chemistry and physics--to the manufacture of steel, rubber, chemicals, drugs, petroleum, and other goods requiring the newer production technologies. Communities looked to their institutions of higher learning for leadership in scientific knowledge and for training of professionals such as teachers and engineers. The scale and scope of higher education in America was being shaped by the recognition that research--the creation of knowledge--complemented teaching and training--the diffusion of knowledge. In broad terms, the basic structure of higher education remains much the same today, and it has been one that has proven sufficiently flexible to respond to the needs of a changing economy. Market economies have succeeded over the centuries by granting rewards to those who could anticipate changes in the value preferences of society. America's system of higher education has evolved into a highly diverse and complex range of institutions--large research universities that combine undergraduate and graduate offerings, small liberal arts colleges, and vocation-oriented community colleges--all seeking their competitive advantage. What makes that system work effectively is that it has been influenced importantly by the values of a strong market economy--competition, risk-taking, and innovation. America's reputation as a world leader in higher education is grounded in the ability of these versatile institutions, taken together, to serve the practical needs of an economy and, more important, to unleash the creative thinking that moves a society forward. It is the recognition of these values that has attracted such a large segment of the world student population to our institutions of higher learning. In a global environment in which prospects for economic growth now depend importantly on a country's capacity to develop and apply new technologies, the research facilities of our universities are world class. The payoffs--in terms of the flow of expertise, new products, and start-up companies, for example--have been impressive. With the emergence of significant centers of commercial innovation and entrepreneurship--Silicon Valley, the Research Triangle, and the clustering of biotech enterprises in the Northeast corridor--creative ideas flow freely between local academic scholars and those in industry. Those ventures that succeeded have materially added to our base of knowledge. But even those that failed, as many did, left residual insights that may spark future research. Beyond these highly visible achievements, what has made our research universities so extraordinarily productive is their promotion of peer-reviewed scholarship and the value they place on creativity and risk-taking. Although some innovations move quickly from the development stage to applications, we usually cannot accurately predict which particular scientific advance, or synergy of advances, will ultimately prove valuable. One has only to recall our experience with the laser, which had to wait for improvements in fiber optics to yield important applications. Indeed, according to Nobel Laureate Charles Townes, in the late 1960s the attorneys for Bell Labs initially refused to patent the laser because they believed it had no applications in the field of telecommunications. Our universities have shown the patience and the flexibility to accept that uncertainty, confident that the rigorous effort to explore ideas would eventually lead to discovery. What our colleges and universities produce is obviously highly valued in today's economy. The rise in that value over the past several decades has been reflected in a widening spread between compensation paid to college-educated workers relative to those with less schooling. This increased investment in college-trained human capital has resulted in a flow of labor input into the economy that has made an important ongoing contribution to U.S. economic growth. Early in the twentieth century, high school education was challenged to meet the needs of an evolving economy; in the twenty-first century, our institutions of higher learning will bear the enormous responsibility of ensuring that our society is prepared for the demands of rapid economic change. We must ensure that teaching and research continue to supply the creative intellectual energy that drives our system forward. As the conceptual inputs to the value added in our economic processes continue to grow, the ability to think abstractly will be increasingly important across a broad range of professions. Critical awareness and the abilities to hypothesize, to interpret, and to communicate are essential elements of successful innovation in a conceptual-based economy. The roots and nature of how the human mind innovates have always been subject to controversy. Yet, even without hard indisputable evidence, a remarkable and broad presumption is that the ability to think conceptually is fostered through exposure to philosophy, literature, music, art, and languages. So-called liberal education is presumed to spawn a greater understanding of all aspects of living--an essential ingredient to broaden one's world view. As the President of the University of Pennsylvania, Judith Rodin, put it, such an understanding comes by "vaulting over disciplinary walls" and exploring other fields of study. Most great conceptual advances are interdisciplinary and involve synergies of different specialities. Yet the liberal arts embody more than a means of increasing technical intellectual efficiency. They encourage the appreciation of life experiences that reach beyond material well-being and, indeed, are comparable and mutually reinforcing. The intense pleasure many experience from listening to Mozart's great D Minor Piano Concerto has much in common with the deep satisfaction of solving a complex mathematical problem. The challenge for our institutions of higher education is to successfully blend the exposure to all aspects of human intellectual activity, especially our artistic propensities and our technical skills. The challenge is particularly daunting because scientific knowledge expands and broadens the measurable rewards of its curriculum at a pace that liberal arts, by their nature, have difficulty matching. The depth of knowledge in nuclear physics is today far greater than it was a century ago, and useful teaching hours have doubtless expanded many fold. But do the same possibilities exist for courses in English literature? Similar differences between science and the arts arise in the nonacademic world: Engineering and metallurgical insights have reduced the number of people required to produce a ton of steel, but the same number of musicians will be needed to perform a Beethoven quartet this evening as were needed a century ago. Many of you will recognize this application of Baumol's law. To make the point even more graphically, Daniel Patrick Moynihan has noted that the Minute Waltz could be played in fifty seconds, but he wondered whether it would sound as good. Overwhelmed with the increasing scientific knowledge base, our universities are going to have to struggle to prevent the liberal arts curricula from being swamped by technology and science. This institute, by encouraging Americans to seek wider educational experiences abroad, is doing its part to prevent that from happening. The advent of the twenty-first century will certainly bring new challenges for our society and for our education system. We cannot know the precise directions in which advances in technology, conceptual thinking, and the transmission of knowledge will take us. However, we can be certain that our institutions of higher education will remain at the center of the endeavor to comprehend those profound changes and to seize the opportunities to direct them toward ever-rising standards of living and quality of life. A global society reflects an ever more open economic environment in which participants are free to engage in commerce, finance, and education wherever in the world the possibilities of increased value added arise. The breaking down of barriers to commerce fosters ever greater cross-border contact and further exploitation of the values of specialization, but on a global scale. Fear of terrorist acts, however, has the potential to induce disengagement from activities, both domestic and cross-border. If we allow terrorism to undermine our freedom of action, we could reverse at least part of the palpable gains to the United States and our trading partners achieved by postwar economic integration. It is incumbent upon us not to allow that to happen. In that regard, I was pleased to hear that the recent survey that your organization conducted among international education professionals showed no diminution of enthusiasm for study abroad by U.S. students and for study in the United States by international students. As your President, Allan Goodman, remarked, this is a time for more international exchange, not less, and a time for open, not closed, minds.
For immediate release The Federal Reserve Board on Thursday decided to issue a final Regulation W that comprehensively implements sections 23A and 23B of the Federal Reserve Act. These statutory provisions and Regulation W restrict loans by a bank to its affiliates, asset purchases by a bank from its affiliates, and other transactions between a bank and its affiliates. The purpose of the statute and the rule is to limit a bank's risk of loss in transactions with affiliates and to limit a bank's ability to transfer to its affiliates the benefits arising from its access to the Federal safety net. Regulation W unifies in one public document the various interpretations of sections 23A and 23B that the Board and its staff have issued over the years as well as several new interpretations of the statute. The Board expects to publish the rule in the Federal Register shortly, with an effective date of April 1, 2003. The Board also approved a final rule that rescinds the Board's existing interpretations of sections 23A and 23B in part 250 of title 12 of the Code of Federal Regulations (which have been incorporated into Regulation W) as of April 1, 2003. In addition, the Board decided to seek public comment on a proposed rule that would prevent a bank from using an exemption in Regulation W for the purchase of extensions of credit from an affiliate if purchases made under the exemption exceeded 100 percent of the bank's capital. Comment on the proposed rule is requested within thirty days of publication in the Federal Register, which is expected shortly.