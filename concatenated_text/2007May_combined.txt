The federal bank, thrift, and credit union regulatory agencies on Thursday issued final illustrations of consumer information intended to help institutions implement the consumer protection portion of the Interagency Guidance on Nontraditional Mortgage Product Risks that the agencies adopted October 4, 2006. The consumer protection section of the guidance sets forth recommended practices to ensure that consumers have clear and balanced information about nontraditional mortgages before choosing a mortgage product or before selecting a payment option for an existing mortgage. The illustrations consist of (1) a narrative explanation of nontraditional mortgage products, (2) a chart comparing interest-only and payment option adjustable rate mortgages (ARMs) to a traditional fixed-rate loan, and (3) a table that could be included with monthly statements for a payment option ARM showing the impact of various payment options on the loan balance. Institutions are not required to use the illustrations. They may choose to use the illustrations, provide information based on the illustrations, or provide the consumer information described in the guidance in an alternate format. To assist institutions that wish to use the illustrations, the agencies will be posting each of the illustrations on their respective web sites in a form that can be downloaded and printed for easy reproduction. The final document, Illustrations of Consumer Information for Nontraditional Mortgage Products, is attached. Illustration 1 (101 KB PDF)Explanation of nontraditional mortgage products Illustration 2 (17 KB PDF)Comparison of interest-only loans and payment-option ARMs to fixed-rate and traditional adjustable-rate loans Illustration 2 (17 KB PDF)Comparison of interest-only loans and payment-option ARMs to fixed-rate and traditional adjustable-rate loans (template) Illustration 3 (22 KB PDF)Table for inclusion with monthly statement for a payment option ARM Federal Register Notice395 KB PDF|TEXT
The Federal Reserve Board on Tuesday announced its approval of the application under section 3 of the Bank Holding Company Act by 1st Source Corporation, South Bend, to acquire FINA Bancorp, Inc. and its subsidiary bank, First National Bank, Valparaiso, both of Valparaiso, all of Indiana. Attached is the Board's Order relating to this action.
The Federal Reserve Board on Thursday announced its approval of the proposal filed by C-B-G, Inc., West Liberty, Iowa, to acquire up to 35 percent of the voting shares of Washington Bancorp and thereby indirectly acquire an additional interest in Federation Bank, both of Washington, Iowa. Attached is the Board’s Order relating to this action.
Sandra Braunstein, Director, Division of Consumer and Community Affairs Before the Subcommittee on Domestic Policy, Committee on Oversight and Government Reform, U.S. House of Representatives, at the Carl B. Stokes U.S. Court House, Cleveland, Ohio Chairman Kucinich, Ranking Member Issa, and members of the Subcommittee, I appreciate this opportunity to appear in Cleveland to address a number of issues that are of interest to you and your constituents. In my comments, I will describe the Federal Reserve System’s role in evaluating banks’ performance under the Community Reinvestment Act (CRA), how the Federal Reserve analyzes applications from banking organizations proposing mergers or acquisitions, and matters relating to subprime mortgage lending. As you may know, the Federal Reserve System has supervisory authority for state-chartered banks that are members of the Federal Reserve System. These institutions total approximately 900 banks and represent 12.4 percent of total domestic assets of all U.S. banks and thrifts. In Ohio, the Federal Reserve has supervisory authority for 33 banks, comprising roughly 6 percent of banking assets in Ohio. Federal Reserve examiners evaluate and rate these banks for safety and soundness, compliance with banking laws and regulations--including those for consumer protection--and for performance under the CRA. As Director of the Division of Consumer and Community Affairs at the Board, I oversee staff who have responsibility for the consumer compliance and CRA examination program, and I coordinate the process of developing policy recommendations to the Board relating to consumer protection laws and regulations, including the CRA. The Consumer and Community Affairs Division participates in the Board’s analysis of merger and acquisition applications by state-member banks and bank holding companies by assessing the applicants’ records of serving the convenience and needs of their communities. “Convenience and needs” analysis includes reviewing the institution’s record of performance with respect to CRA. We also review its compliance with consumer protection laws and regulations, including fair lending. The Division also engages in consumer education and research efforts and oversees the Federal Reserve Banks as they undertake community development and other outreach activities in lower-income and traditionally underserved markets. Each of the Reserve Banks have Community Affairs Officers (CAO) who are actively engaged with local and regional organizations to identify and address financial services needs in lower-income neighborhoods and among low- and moderate-income individuals. The CAO of the Federal Reserve Bank of Cleveland, for example, has been a leader in developing collaborative groups to address predatory lending, provide foreclosure intervention, and enhance financial education programming. CRA ExaminationsYou have asked that I speak about theCommunity Reinvestment Act. The CRA applies to insured banks and savings associations and thrifts, but not to companies that own these institutions. It affirms that federally insured banks and thrifts have an obligation to help meet the credit needs of the entire communities they serve, including low- and moderate-income neighborhoods, in a safe and sound manner. Under the CRA, it is the responsibility of the federal financial supervisory agencies to evaluate the performance of institutions under their jurisdiction in meeting this obligation. Neither the statute nor the agencies’ regulation specifieshowdepository institutions are to fulfill their obligation to meet the credit needs in the communities they serve. Instead, the statute directs the federal supervisory agencies to assign a rating of Outstanding, Satisfactory, Needs to Improve, or Substantial Noncompliance to describe an institution’s performance. The regulations prescribe the method for assigning an institution’s rating. Currently, about 12 percent of all banks and thrifts examined for CRA have an Outstanding rating, 87 percent have earned a Satisfactory rating, and less than .5 percent are assigned either Needs to Improve or Substantial Noncompliance. These ratings are public, as are the Performance Evaluations prepared by the examining agency that describe the banks’ CRA performance using both data and qualitative descriptions. The agencies’ CRA regulations specify that institutions of different sizes will be subject to different types of examination. For depository institutions with assets over $1.033 billion, the CRA examination consists of a lending test, an investment test, and a service test. Under the lending test, an institution’s practices in lending to low- and moderate-income people and neighborhoods are evaluated on both quantitative and qualitative factors and the outcome is weighted to count for 50 percent of the institution’s overall CRA rating. Investments benefiting low- and moderate-income neighborhoods are assessed and services to the entire community, including low- and moderate-income individuals and neighborhoods, are reviewed. Each account for 25 percent of the bank’s overall rating. Examiners also weigh the innovativeness of a bank’s community development lending, investment, and service programs and activities. Banks and thrifts with assets of $1.033 billion or less are subject to a somewhat different examination. Those with assets of between $258 million and $1.033 billion are designated as intermediate small institutions and are evaluated on their record of lending in low- and moderate-income areas and to lower-income people in the institutions’ assessment area. A community development test is also included in the review of such institutions. This criterion is designed to encourage institutions to engage in a range of community development lending, investment, and services but provides flexibility in determining the volume and mix of these activities. The institutions that are highly rated are responsive to needs and opportunities within their assessment areas in ways that are consistent with their capacity and business strategy. Small institutions--those with less than $258 million in assets--are evaluated primarily on their lending performance in their communities, including low- and moderate-income areas and populations. Given their more limited capacity and resources, small institutions are not expected to engage in the more complex community development activities. During the CRA examination, a bank or thrift’s performance is assessed within the context of factors such as overall economic conditions in the area and the degree to which there are community development activities in which an institution can participate. This performance context recognizes that while depository institutions have an affirmative obligation to meet the credit needs of the communities in which they are chartered, they must engage only in activities that are safe and sound. The community has a role in the CRA examination process as well. The public can offer comments on an institution’s CRA performance and those comments are available to anyone who requests them. Examiners, of course, review the public comment file and take it into account when evaluating an institution’s overall CRA performance. Comments from the public are also taken into account when a banking institution submits an application to its regulator to expand through an acquisition or merger with another institution or to increase the number of its branches. Let me now turn to the application review process and how the Federal Reserve considers a bank’s record of meeting the credit and banking needs of the communities it serves. The Applications FunctionAs directed by the Bank Merger Act and the Bank Holding Company Act, the Federal Reserve takes into account a number of factors when it reviews applications for expansion. These include the competitive effects of the proposal in the relevant markets; the financial and managerial resources and future prospects of the bank holding company and its banking subsidiaries; and the convenience and needs of the communities affected. The public is notified when applications are filed and interested parties may comment on any of the statutory factors. Sometimes members of the public, advocacy organizations, and other interested parties comment in order to “protest” applications when they have concerns that the outcome might be diminished services to communities. In fact, it is not uncommon for the Federal Reserve to receive several hundred comment letters as part of the applications process when large banking organizations are involved. Substantive comments are always given a high degree of consideration in the evaluation of the proposal. In evaluating a banking application that is the subject of a protest, Federal Reserve staff consider the entire supervisory record of the institutions involved in the proposed transaction. Applications are evaluated on a case-by-case basis, but in every instance the following information is taken into account: The Federal Reserve holds public meetings to gather input from the community when information cannot be effectively obtained from written comments, other sources, or supervisory processes. Of the thirteen public meetings held since 1990, two involved banking institutions active in the Ohio regional banking market: Banc One Corporation’s acquisition of First Chicago in 1998 and the application for JPMorgan Chase to acquire Bank One Corporation in 2004.1Transcripts of all public meetingsheld since 1998 are available on the Federal Reserve Board’s website. In some cases, financial institutions have made lending and/or service commitments to private organizations, such as community groups, to address the needs of the affected communities. The Board views the enforceability of pledges, initiatives, and agreements with third parties as matters outside the scope of the CRA, and neither the CRA nor the federal banking agencies’ CRA regulations require depository institutions to make pledges or enter into commitments or agreements with any organization. An applicant must demonstrate a satisfactory record of performance under the CRA without reliance on plans or commitments for future action. Therefore, the Federal Reserve System does not track performance of private commitments between financial institutions and interested third parties. Of course, any commitments made to the Board for specific actions or improvements are monitored through appropriate follow-up. Since 1988, there have been more than 13,500 applications for the formation, acquisition, or merger of bank holding companies or state-member banks reviewed by the Federal Reserve Board. Over this time, twenty-five of these applications have been denied, with eight of those failing to obtain Board approval involving unsatisfactory consumer protection and community needs issues. The low incidence of applications that have not received regulatory approval may be due to the fact that institutions seeking to expand their operations are typically in sound financial and managerial condition and have good supervisory records. Management of applicant institutions has generally recognized the benefit that strong community investment and relations programs offer. In addition, the supervisory and public scrutiny that the CRA brings has prompted many banks to create specialized CRA business units within their organizations. The few cases in which the Board has denied an application on CRA grounds have sent an unmistakable message that it is crucial to have a satisfactory record of CRA performancebeforeapplying to expand. Institutions likely understand that the Board will not allow promises of future corrective action to substitute for inadequate current performance. I should note that those who comment often express concern that a bank merger or acquisition will diminish competition and thus reduce access to banking services and/or increase the cost of those services. Maintaining robust and competitive banking markets is a critical objective in the Federal Reserve’s review of banking applications. Staff economists evaluate the likely competitive effects of the proposed transaction in all affected banking markets and assess the impact of the proposed transaction pursuant to well established quantitative measures of banking market concentration. An examination of these measures in both metropolitan and non-metropolitan areas in Ohio since 1990 reveals that Ohio banking markets are less concentrated than the national average, suggesting that the level of banking competition in Ohio markets is generally greater than in many other communities across the country. In addition, it is worth noting that although the average number of banks operating in metropolitan areas of Ohio has declined somewhat over the past fifteen years, the number of banking offices per person has been quite stable and has remained well below the national average. In non-metropolitan communities in Ohio, the average number of banks has remained relatively stable over the same time period and is above the national average, while the average number of banking offices per person has been fairly stable and close to the national average. These data suggest that, on average, the banking markets in Ohio are at least as competitive as those in other parts of the country, and, over the past fifteen years, there has been no significant decline in competition or consumer access to banking offices in Ohio banking markets. Subprime Mortgage LendingAs you can see from these comments, promoting the availability of credit through the banking system is an important part of the Federal Reserve’s statutory mandate. Another part of the Federal Reserve’s responsibilities involves consumer protection, and it is in that role that I would like to address subprime mortgage lending. As you know, the term “subprime” is used to designate loans to borrowers with minimal or blemished credit records or who may present other factors that suggest an elevated degree of credit risk. In recent years, the subprime market has grown dramatically because of advances in credit scoring and underwriting technology, which enables lenders to charge different borrowers different prices on the basis of calculated creditworthiness. These loans are recognized by the higher prices they carry, which reflect the subprime lender’s decision to seek additional compensation for the credit risk they incur. In 1994, fewer than 5 percent of mortgage originations were subprime, but by 2006 about 20 percent of new mortgage loans were subprime. As the overall mortgage market has grown, many new lenders and distribution channels have developed and most of those are outside the direct jurisdiction of the federal banking agencies. A review of data provided by mortgage lenders pursuant to the Home Mortgage Disclosure Act reveals that lenders that are not subject to oversight by a federal banking agency originated just over half of the higher-priced conventional mortgage loans reported in 2005. In Ohio, nearly 47 percent of all higher-priced conventional loans were originated by independent lenders, while in the City of Cleveland 66 percent of higher-priced conventional mortgage loans were extended by independent lenders that do not fall under the jurisdiction of the federal banking agencies. While the expansion of the subprime mortgage market over the last decade has increased access to credit, the market has more recently seen increased delinquencies and foreclosures, partly as a consequence of broader economic conditions, including rising interest rates and slowing house price growth. This increase has also called into question the practices of some lenders, with concerns ranging from imprudent underwriting standards to abusive lending practices and even fraud. While recent growth in serious delinquencies and foreclosures appear to be predominately in the subprime market, which at 14 percent of all loans is a relatively small percentage of all outstanding mortgage loans, the Federal Reserve System understands the significance of the matter to regional markets, communities, and families. Analysis reveals that the majority of subprime foreclosures relate to adjustable rate mortgages (ARM). These loans are often characterized by a rate that will adjust periodically--as frequently as every six months for some products. In times of rising interest rates, borrowers can be subject to significant increases in their payments. When housing prices are appreciating, borrowers with ARMs can cope with payment increases by refinancing the loan, or, in some cases, selling their homes at a gain. In 2006, however, mortgage interest rates hit four-year highs, the volume of home sales declined, and the rate of house price appreciation slowed. In some markets, home prices fell. In a rising rate environment, even borrowers with enough equity to refinance their ARMs may face difficulty finding a new loan with affordable payments. Most recently, an unusually large number of subprime loans have defaulted shortly after origination. In many of these “early payment defaults,” borrowers stopped making payments, presumably knowing that they would be unable to meet their ongoing mortgage obligation. This suggests that in 2006 some lenders may have lowered their underwriting standards to maintain volume as borrower demand slackened. The rapid expansion of subprime lending in recent years and generally rising house values may have led lenders, investors, and ratings agencies to underestimate risks, particularly since they had limited data with which to model credit risk posed by new borrowers or novel mortgage types. A number of lenders have already been forced out of the subprime market, in part because of the wave of early payment defaults on mortgages they originated. Ill-suited loan products or terms are not the only factors that contribute to financial difficulty for borrowers. There can be numerous trigger events--such as the loss of a job, a medical crisis, or divorce--that can undermine homeowners’ capacity to fulfill their mortgage obligation. The financial impact of these unfortunate life circumstances is magnified when the leveling or depreciation of housing prices results in a debt obligation exceeding the value of the property. When confronted with both difficult individual financial circumstances and broader economic challenges, homeowners may be unable to refinance their debt or sell their home to pay off the mortgage. As you know, Ohio has experienced delinquency rates on subprime mortgage loans at a higher rate than the national average for the last two years and has one of the highest foreclosure start rates in the country. Unfortunately, this state has seen a confluence of factors that have made mortgage borrowers more vulnerable to delinquency and foreclosure, as Ohio reports a lower rate of housing appreciation than the national average, unemployment rates that exceed the national average, and a somewhat higher level of subprime mortgages than the national average. The issues surrounding each mortgage delinquency or foreclosure vary, as does the solution that is best for helping a particular borrower. Thus, loss mitigation and foreclosure intervention efforts typically involve customized assistance in order to devise remedies appropriate to the situation. Fortunately, many community leaders, government officials, and lenders across the country are now collaborating to develop approaches and protocols to help borrowers who are experiencing mortgage delinquencies avoid foreclosure. Federal Reserve Activities in Response to Mortgage Lending ConcernsThe Board believes that mortgage market problems need to be addressed in a way that addresses unfair and abusive practices while preserving incentives for responsible subprime lenders. A robust and responsible subprime market is beneficial to consumers, allowing borrowers with non-prime credit histories or those without a credit history to become homeowners, utilize the existing equity in their homes, or have the flexibility to refinance their loans as needed. Accordingly, it is important that any actions we take are well calibrated and do not have unintended consequences. Constricting the market and returning to a situation where some borrowers have very limited access to credit is not acceptable and reduces the flexibility of individuals and communities. We want to encourage, not limit, mortgage lending to qualified borrowers by responsible lenders. Over the past several years, the Federal Reserve System has monitored developments in subprime lending and has taken steps to address emerging problems. Among those steps are issuance of regulatory guidance in concert with the other federal banking agencies to address weaknesses in underwriting and risk management at the institutions we supervise; revising regulations to address concerns about abusive practices; and publishing materials to help consumers make informed mortgage credit decisions. The Board has also been actively engaging representatives from the mortgage lending, servicing, and capitalization arena, as well as from borrower and community support organizations, to learn about opportunities for intervention and foreclosure mitigation. The remainder of my comments provides additional information about these initiatives. Supervisory GuidanceThe federal regulatory agencies have the ability to issue supervisory guidance to address their concerns in a relatively expeditious manner and with greater flexibility than rules. Guidance is a tool to signal areas of practice that will receive scrutiny during examinations. Over the last fifteen years, the agencies have issued guidance involving depository institutions’ and their affiliates’ real estate lending standards and practices to address supervisory concerns that emerged as a result of an evolving mortgage lending market. Since the early 1990s, the agencies have required these institutions to establish and maintain comprehensive, written real estate lending policies that are consistent with safe and sound banking practices. Supervisory guidance has also underscored the need for the underwriting standards of depository institutions and their affiliates to reflect all relevant credit factors, including the capacity of the borrower to adequately service the debt. Expanded Subprime Guidance In 2001, an expansion ofInteragency Guidance on Subprime Lending, which was originally issued in 1999, addressed essential components of a well-structured risk-management program for subprime lenders. The expanded guidance emphasized that lending standards should include well-defined underwriting parameters such as acceptable loan-to-value ratios, debt-to-income ratios, and minimum acceptable credit scores. It also addressed concerns about predatory or abusive lending practices, such as making unaffordable loans based on the assets of the borrower rather than on the borrower’s ability to repay an obligation; inducing a borrower to refinance a loan repeatedly (“loan flipping”); or engaging in fraud or deception to conceal the true nature of the loan obligation, or ancillary products. The guidance cautioned institutions that higher fees and interest rates, combined with compensation incentives, can foster predatory pricing or discriminatory practices. Guidance on Unfair or Deceptive Acts or Practices In March 2004, the Board and the FDIC issued guidance onUnfair or Deceptive Acts or Practices(UDAP) to state-chartered banks. The guidance is based on long-standing Federal Trade Commission policy statements that have been applied by courts. The UDAP guidance outlines strategies for banks to use to avoid engaging in unfair or deceptive acts or practices, to minimize their own risks and to protect consumers. Among other things, the guidance focuses on credit advertising and solicitations, loan servicing, and managing and monitoring creditors’ employees and third-party service providers. 2006 Guidance on Nontraditional Mortgage Product Risks In 2006, the Federal Reserve and the other federal banking agencies issued the Interagency Guidance on Nontraditional Mortgage Product Risks (NTM Guidance). The NTM guidance covers loans such as interest-only loans and payment-option ARMs, including those with the potential for negative amortization. The NTM guidance highlights sound underwriting procedures, portfolio risk management, and consumer protection practices that institutions should follow to prudently originate and manage nontraditional mortgage loans. A major aspect of this guidance is the recommendation that a lender’s analysis of repayment capacity should include an evaluation of the borrower’s ability to repay debt by final maturity at the fully indexed rate, assuming a fully amortizing repayment schedule. The guidance also reminds institutions that they should clearly communicate the risks and features of these products to consumers in a timely manner, before consumers have applied for a loan. Proposed Guidance on Subprime Mortgage Lending In March 2007, the agencies issued a proposedStatement on Subprime Mortgage Lending. This proposed guidance is directed at ARM loans targeted to subprime borrowers and includes ARMs that are fully amortizing. The proposed guidance provides that lenders should use the same qualification standards as the NTM guidance. It emphasizes the added dimension of risk when subprime ARM products are combined with other features such as simultaneous second lien loans in lieu of a down payment, or with the use of underwriting that involves little or no documentation of borrowers’ income or assets. The proposal differs from earlier guidance in that it highlights the need for lenders to underwrite based not only on principal and interest but also on taxes and insurance. The proposal indicates that lenders should inform consumers of the need to budget for taxes and insurance payments if escrows are not required. This proposed subprime guidance would apply to all depository institutions, to their subsidiaries, and to non-depository affiliates. To protect borrowers in the portion of the subprime market that is outside the purview of the federal banking agencies, and to ensure a “level playing field” for depository institutions and independent mortgage companies, we coordinated the development of the proposed guidance with the Conference of State Bank Supervisors (CSBS). (State-regulated independent mortgage companies originated slightly more than half of subprime loans, according to 2004 and 2005 HMDA data.) Once the guidance is finalized, we understand that CSBS will strongly encourage the states to adopt similar guidance for state-regulated lenders. Statement on Working with Mortgage Borrowers Most recently, the agencies issued apolicy letterto the industry encouraging financial institutions to work with homeowners who are unable to make mortgage payments, underscoring that prudent workout arrangements are generally in the long-term interest of both the financial institution and the borrower. Examples of constructive workout arrangements include modifying loan terms, and/or moving borrowers from variable-rate loans to fixed-rate loans. Bank and thrift programs that transition low- or moderate-income homeowners from higher-cost loans to lower-cost loans may also receive favorable consideration under the CRA. The policy letter also urges borrowers who are unable to make their mortgage payments to contact their lender or servicer as soon as possible to discuss available options. Regulatory ActionsIn addition to guidance, the Board has used its rulewriting authority to address other aspects of concern within the mortgage lending market. HOEPA Rules In 2001, the Board revised the rules implementing the Home Ownership and Equity Protection Act (HOEPA) in response to renewed concerns about predatory lending. The revised rules became effective in 2002 and extended HOEPA’s protections to more high-cost loans. They strengthened HOEPA’s prohibitions and restrictions, including by requiring that lenders generally document and verify a consumer’s ability to repay a high-cost mortgage loan. In addition, the new rules addressed concerns that high-cost loans were “packed” with credit life insurance or other similar products that increased the loan’s cost without providing commensurate benefit to consumers. To increase protections for consumers, the Board extended the prohibitions against unfair or deceptive practices for HOEPA loans and revised the rules to prohibit a HOEPA lender from refinancing one of its own loans with another HOEPA loan (“flipping”) within the first year, unless the new loan is “in the borrower’s interest.” In addition, the Board prohibited creditors from evading HOEPA’s requirements and consumer protections for closed-end loans by documenting the transaction as an “open-end” line of credit when it does not qualify, because there is no expectation of repeat transactions under a reusable line. These revisions addressed cases where the Board determined that it could write “bright-line” rules defining an unfair or deceptive practice. Because a determination of unfairness or deception depends heavily on the facts of an individual case, the Board has not issued other rules under this provision. However, the Board has undertaken a major review of Regulation Z, the implementing regulation for the Truth in Lending Act (TILA), of which HOEPA is a part. During this review, the Board will determine if there are opportunities to further address issues related to HOEPA loans. The Board’s Review of Mortgage Disclosures Under Regulation Z With the objective of ensuring that consumers get timely information regarding credit transactions in a form that is readily understandable, the Board will study alternatives for improving both the content and format of disclosures for mortgage loans, including revising the model forms published by the Board. As a general matter, in crafting regulations, the Board seeks to gather as much information as possible by conducting outreach to the industry, consumer groups, consumers, regulators, and other interested parties. We use research and survey data, consumer focus groups, and consumer testing to learn how consumers use and process information about financial services. After regulatory proposals have been published, we obtain input through the public comment process. In addition, we obtain input from the Board’s Consumer Advisory Council, comprised of representatives from consumer and community organizations, financial institutions, industry trade groups, academics, and state and local officials from across the country. At times, the Board also holds public hearings, as it has under HOEPA, to gather information about the subprime mortgage market. During the summer of 2006,four HOEPA hearingsconsidered (1) predatory lending and the impact of the HOEPA rules and state and local anti-predatory lending laws on the subprime market; (2) nontraditional mortgage products such as interest-only mortgage loans and payment-option ARMs, and reverse mortgages; and (3) how consumers select lenders and mortgage products in the subprime mortgage market. Afifth HOEPA hearingin June will be used to gather information on how the Board might use its rulemaking authority to curb abusive lending practices in the home mortgage market, including the subprime sector. In considering how to improve disclosures for ARMs and other alternative mortgage products under TILA, the Board will conduct extensive consumer testing to determine what information is most important to consumers, when that information is most useful, what wording and formats work best, and how disclosures can be simplified, prioritized, and organized to reduce complexity and information overload. The Board will use design consultants to assist in developing model disclosures that will be effective in communicating information to consumers. Based on its review of Regulation Z, the Board will revise Regulation Z within the existing framework of TILA or, if it determines that useful changes to the closed-end disclosures are best accomplished through legislation, it will inform the Congress. The regulatory review process is necessarily complex and takes time. So, in the interest of providing improved information to consumers sooner rather than later, the Board, in partnership with the Office of Thrift Supervision, recently revised theConsumer Handbook on Adjustable Rate Mortgages(CHARM booklet) to include additional information about nontraditional mortgage products. The CHARM booklet is an effective means of reaching consumers because creditors are required to provide a copy of the booklet to each consumer when an application for an ARM is provided. Consumer Education and Community EngagementConsumer education efforts have been another important component of our response to concerns in the subprime lending market. The Board has sought to increase consumer awareness of the risks of nontraditional mortgage loans by providing consumers with information, both in print and on the web, on adjustable rate, interest-only, and payment-option mortgages. We recently published a consumer education brochure titled:Interest-Only Mortgage Payments and Payment-Option ARMs--Are They for You?The brochure is designed to assist consumers who are shopping for a mortgage loan. These informational brochures complement a host of other financial education resources that can be found at:http://www.federalreserveeducation.org/. As I mentioned earlier, the Board has been actively engaging leaders of the various components of the mortgage lending industry, as well as community leaders, to learn about opportunities for loss mitigation and foreclosure intervention. In April, the Board, along with the other federal banking agencies, cosponsored a forum of secondary market participants to develop a better understanding of the challenges in addressing delinquencies and mitigating foreclosures, such as the unintended consequences of contractual obligations among lenders, servicers, and investors. Currently, the Board is convening follow-up meetings with key market players to further identify strategies that may provide solutions for working with borrowers who are unable to meet their mortgage obligations. Engagement of private, public, and nonprofit sector participants is one way that the Federal Reserve seeks to work toward practical solutions for issues that may be beyond our supervisory reach. Collaborations to further community development and financial education have long been part of the Federal Reserve System’s approach to facilitate solutions to matters that may be most effectively addressed at a local or regional level. In addition, the Community Affairs Offices throughout the Federal Reserve System have been actively engaged in collaborations with local and regional government agencies, lenders, and nonprofit organizations to identify strategies to assist troubled mortgage borrowers. Many Reserve Banks have collaborated with NeighborWorks America® organizations in their districts. This national nonprofit organization, which has a Federal Reserve Board member serving on its board of directors, is dedicated to promoting and sustaining homeownership.NeighborWorks America® has been on the front line in developing hotlines, counseling, and loan funds to help mitigate foreclosure in many communities throughout the country. Here in Ohio, the Federal Reserve Bank of Cleveland has been proactive in connecting with lenders, community leaders, government officials, and academics to help bring understanding to the issues and highlight best practices and resources for addressing mortgage delinquencies and foreclosures. The Reserve Bank is serving as a convener of government, financial institutions, and community-based organizations in assessing and addressing regional foreclosure issues. Among the events the Reserve Bank has co-hosted was an Ohio Foreclosure Summit in 2005, which led to the introduction of the NeighborWorks 1-800 hotline in Ohio, and addressed issues of financial education, predatory lending, policy, regulation, and enforcement. In addition, the Reserve Bank helped organize and participated in a 2006 Ohio Foreclosure Summit in Toledo. Both summits included community, industry, and government representatives. Last year, the Federal Reserve Bank of Cleveland also hosted high-level panel presentations in their Cleveland and Pittsburgh offices so that representatives from lending institutions, nonprofit organizations, and local governments could present their concerns to senior Federal Reserve Bank officials. In addition, the Cleveland Federal Reserve convened financial education consortia in Dayton, Cincinnati, and Northeast Ohio that brought together providers and funders to help expand the reach and impact of the many financial education programs designed to help low- and moderate-income consumers. These consortia have created websites and directories of services and hosted meetings to share best practices. The website and directories are resource guides for residents and community-based organizations that they can use to find professional service providers to help them with basic money management and resolving difficult financial situations such as foreclosure. The Federal Reserve Bank is currently working on an analysis of data availability and gaps that exist in accurately tracking foreclosures within the district. The report explains the challenges that exist in assessing the scope and scale of the issue and barriers that exist due to lack of information. In closing, I would like to commend the local leaders and organizations that are collaborating in Ohio to develop creative programs to respond to their constituents’ needs. I had the opportunity to meet with several of them earlier this month, and benefited from their analyses of the issues and the strategies they are undertaking to support borrowers through rescue loan programs, intervention and work outs, and financial education and counseling. As real estate markets are driven by local and regional dynamics, it is essential to have localized efforts that address the underlying problems, not just the symptoms, and to effectively reach individual borrowers to provide assistance in working through their financial crises and avoiding foreclosure. One of the many challenges that we confront in this environment is to address concerns regarding mortgage lending practices while preserving the flexibility necessary to allow lenders to help troubled borrowers by employing various foreclosure prevention strategies, including debt restructuring and refinance. Certainly, we all recognize the importance of preserving the record rate of homeownership, which is to the benefit of both consumers and the economy. And, a robust and disciplined subprime market is vital to ensuring continued progress in broad access to credit and homeownership. Footnotes 1.At the time of this application, Bank One Corporation had moved its headquarters from Columbus, Ohio, to Chicago, Illinois.Return to text
The Federal Reserve Board on Friday announced the appointment of Elizabeth A. Coleman as Inspector General for the Board, effective May 6. In her new role, Coleman will lead a staff responsible for promoting economy, efficiency, and effectiveness within Board programs and operations. The Office of Inspector General (OIG) is also responsible for preventing and detecting waste, fraud, and abuse at the Board, among other duties. The OIG achieves its legislative mandate through audits, evaluations, investigations, legislative reviews, and by keeping the Chairman of the Board and Congress fully informed. Coleman joined the Board's OIG staff in 1989 as a senior auditor. She was promoted to program manager in 1999 and to senior program manager in 2001. She was appointed to the official staff in 2004 as the Assistant Inspector General for Communications and Quality Assurance. Before joining the Board, Coleman worked at the Government Accountability Office. Coleman succeeds Barry Snyder, who will retire today after nearly nineteen years of service at the Board, including nine years as Inspector General. Coleman has a BBA from James Madison University and is a graduate of the Stonier Graduate School of Banking, Georgetown University. She is a Certified Information Systems Auditor.
The Federal Reserve Board in May will begin a statistical study of household finances, the Survey of Consumer Finances, that will provide policymakers with important insight into the economic condition of all types of American families. The survey has been undertaken every three years since 1983. It is being conducted for the Board by the National Opinion Research Center (NORC), a social science research organization at the University of Chicago, through December of this year. The data collected will provide a representative picture of what Americans own--from houses and cars to stocks and bonds--how and how much they borrow and how they bank. Past study results have been important in policy discussions regarding pension and social security reform, tax policy, deposit insurance reform, consumer debt and a broad range of other issues. "The results of the survey will fill a gap in our knowledge about the financial circumstances of different types of households," Ben S. Bernanke, Chairman of the Board of Governors of the Federal Reserve System, said in a letter to prospective survey participants. "Our previous surveys ... have helped the Federal Reserve and other parts of the government make policy decisions and have also supported a wide variety of basic research," the Chairman noted. The 2007 survey will contain a revised set of questions on home mortgages with variable interest rates and other variable terms. The questions will address how much interest rates or other features of such loans can change. Taken together with other survey variables, they will allow a better understanding of the types of households that have such loans. Another set of new questions will address the connection between self-employment and business ownership.Participants in the study are chosen at random from seventy-nine areas, including metropolitan areas and rural counties across the United States, using a scientific sampling procedure. A representative of NORC contacts each potential participant personally to explain the study and request time for an interview. "I assure you that we give the highest priority to guarding the privacy of the survey participants and the confidentiality of their answers," Chairman Bernanke said. NORC uses names and addresses only for the administration of the survey, and that identifying information will be destroyed at the close of the 2007 study. NORC is required never to give the names and addresses of participants to anyone at the Federal Reserve or anywhere else. Summary results for the 2007 study will be published in early 2009 after all data from the survey have been assessed and analyzed. The attached letter from Chairman Bernanke was mailed to approximately 10,000 households urging their participation in the study.
The Federal Reserve Board on Wednesday issued for public comment proposed amendments to Regulation Z (Truth in Lending) that are intended to improve the effectiveness of the disclosures consumers receive in connection with credit card accounts and other revolving credit plans by ensuring that information is provided in a timely manner and in a form that is readily understandable. “The goal of the proposed revisions is to make sure that consumers get key information about credit card terms in a clear and conspicuous format and at a time when it would be most useful to them,” said Federal Reserve Board Chairman Ben S. Bernanke. “Greater clarity in credit disclosures allows consumers to make more-informed credit decisions and enhances competition among credit card issuers.” The proposed amendments principally focus on the rules for open-end credit accounts that are not home-secured, chiefly general-purpose and retail credit card plans. The proposal would require changes to the format, timing, and content requirements for credit card applications and solicitations and for the disclosures that consumers receive throughout the life of an open-end account, including account-opening and periodic statements. These changes largely reflect the result of consumer testing conducted on behalf of the Board as part of its comprehensive review of the open-end credit rules. “One significant novel aspect of the Regulation Z review has been the extent of consumer testing by the Board,” said Federal Reserve Board Governor Randall S. Kroszner. “Although we have used consumer focus groups in the past to study the effectiveness of consumer disclosures, the proposed changes are based on one-on-one consumer interviews to assess consumer understanding and use of disclosures. This testing helped us to identify the key information consumers need to make informed choices about how they use their accounts.” Disclosures accompanying credit card applications and solicitations would highlight fees and the reasons penalty rates might be applied, such as for paying late. Creditors would be required to summarize key terms at account opening and when terms are changed. Periodic statements would break out costs for interest and fees. Two alternatives are proposed regarding the “effective” or “historical” annual percentage rate disclosed on periodic statements. The proposal would also expand the circumstances under which consumers receive written notice of changes in the terms applicable to their accounts, including requiring an advance notice before a penalty is required, and increase the amount of time these notices must be sent before the change becomes effective. The proposal follows the Board’s comprehensive review of the open-end credit rules (other than home-secured) and takes into consideration comments from the public on two previously issued advance notices of proposed rulemaking. TheFederal Registernotice is attached. The comment period ends 120 days after publication of the proposal in theFederal Register, which is expected shortly. Model forms and samples Design and Testing of Effective Truth-in-Lending Disclosures (8.4 MB PDF)Report submitted to the Board of Governors of the Federal Reserve System by Macro International Inc. Board meeting materials Statement by Governor Randall S. Kroszner (16 KB PDF) Submit comment on this proposalView comments on this proposal Federal Register Notice3 MB PDF|TEXT
The Federal Reserve Board on Thursday announced that it will hold a public hearing under the Home Ownership and Equity Protection Act (HOEPA) on June 14, to gather information on how it might use its rulemaking authority to curb abusive lending practices in the home mortgage market, including the subprime sector. "The goal is to find ways to promote sustainable homeownership through responsible lending, informed consumer choice, and effective guidance and regulation," said Federal Reserve Board Governor Randall S. Kroszner, who will chair the hearing. "We want to encourage, not limit, mortgage lending by responsible lenders, so it is crucial that any actions the Board might take are well calibrated and do not have unintended consequences." The Board held four hearings in the summer of 2006 under HOEPA. Those hearings addressed three topics: (1) predatory lending and the impact of the existing HOEPA rules, and state and local anti-predatory lending laws on the subprime market; (2) nontraditional mortgage products such as interest-only mortgage loans and payment option adjustable rate mortgages, and reverse mortgages; (3) and, how consumers select lenders and mortgage products in the subprime mortgage market. Based on testimony and public comment from the 2006 hearings, and in response to increased subprime mortgage foreclosures,the Board plans to hold a fifth hearing that will focus on how it might use its rulemaking authority to address concerns about abusive lending practices in the home mortgage market. The hearing is scheduled for Thursday, June 14, 2007, at the Federal Reserve Board at 20th and C Streets, N.W., Washington, D.C. The Board will invite consumer advocacy organizations, lenders, and other interested parties to participate in panel discussions. In addition to the panel discussions, the Board intends to reserve about one hour in the afternoon to permit interested parties other than those on the panels to make brief statements. To allow as many as possible to offer their views during this period, oral statements will be limited to three minutes; written statements of any length may be submitted for the record. The Board anticipates that the hearing will begin at 8:30 a.m. EDT and conclude at 4:00 p.m., however, this schedule is tentative and further information about the hearing, including the final schedule and the procedure for registering for security purposes to attend the hearing, will be published in theFederal Registerand on the Board's web site at http://www.federalreserve.gov/. The Board is holding the hearing under HOEPA, which was enacted in 1994 in response to reports of predatory home equity lending practices in underserved markets. HOEPA amended the Truth in Lending Act (TILA) to impose additional disclosure requirements and other limits on certain high-cost, home-secured loans. HOEPA authorizes the Board to issue rules that prohibit certain acts or practices in connection with home mortgage loans. HOEPA also directs the Board to periodically hold public hearings to examine the home equity lending market and the adequacy of existing regulatory and legislative provisions for protecting the interests of consumers, particularly low-income consumers.
The Federal Reserve Board announced Thursday that the Consumer Advisory Council will hold its next meeting on Thursday, June 21. The meeting will take place in Dining Room E, Terrace Level, in the Board’s Martin Building. The session will begin at 9:00 a.m. and is open to the public. Anyone planning to attend the meeting should, for security purposes, register no later than Tuesday, June 19, by completing the form found online at:https://www.federalreserve.gov/secure/forms/cacregistration.cfm. Additionally, attendees must present photo identification to enter the building. The Council’s function is to advise the Board on the exercise of its responsibilities under various consumer financial services laws and on other matters on which the Board seeks its advice. Time permitting, the Council will discuss the following topics: Reports by committees and other matters initiated by the Council members may also be discussed. The Board invites comments from the public on any of these matters. The Board’s notice is attached.
Governor Randall S. Kroszner At the George Washington University School of Business, Financial Services Research Program Policy Forum, Washington, D.C. Information is critical to the effective functioning of markets. A core principle of economics is that markets are more competitive, and therefore more efficient, when accurate information is available to both consumers and suppliers. When information on alternatives is readily available, product offerings will have to meet customers’ demands and offering prices will have to reflect those of market competitors.1In addition, information helps individual consumers by improving their ability to compare products and to choose those that will help them meet their personal goals. These arguments are not just theoretical. There is systematic evidence that in practice, changes in disclosure affect both consumer and supplier behavior in a number of consumer product markets.2In 1968, Congress passed the Truth in Lending Act (TILA), which significantly changed a number of consumer credit disclosure practices. For example, it required that creditors disclose an “annual percentage rate.” These disclosures are generally believed to have improved competition and helped individual consumers.3 Today, we face the challenge of ensuring that disclosures for consumer credit remain effective. To be effective, disclosures must give consumers information about credit pricing at a time when it is relevant, and in language consumers can easily understand. The information must also be in a format that allows consumers to pick out and use the information that is most important to them. Effective disclosures give consumers information they notice, understand, and can use. Better credit disclosure permits better-informed credit decisions and, hence, more effective competition among credit card issuers. In a nutshell, effective disclosure empowers consumers and enhances competition. The Federal Reserve Board has recently undertaken an innovative approach to improve the effectiveness of disclosure--namely, surveying and responding to consumers through consumer testing. Having taught at a business school for many years, I am well aware of the types of consumer testing that firms have long employed: surveys, focus groups, and so-called “mall intercepts” in which shoppers are interviewed at random. Systematically using such techniques to improve the effectiveness of disclosure requirements set out in the regulations of the Federal Reserve and other financial regulators, is, however, relatively novel. Consumer testing can help the Federal Reserve address the considerable challenge of making disclosures more effective. Consumers increasingly face more-diverse and more-complex financial products, including nontraditional mortgages and credit cards with multiple features. Given this complexity, we have to be mindful of the dangers of information overload. We must seek to carry out the responsibilities Congress has given us to design disclosures that are not only accurate, but also clear and simple enough that they are meaningful and useful to consumers. In other words, pages and pages of fine print may provide comprehensive descriptions that lawyers might love but that consumers find confusing, or, worse, useless. We need to translate legalese into something consumers can use. This requires the Board to make judgments about which credit terms are most important to highlight and which could be eliminated. However, we plan to make these judgments with the benefit of feedback from actual consumers gathered through surveys and testing. We recently completed several rounds of consumer testing for credit card disclosures, and that testing was critical to our effort to redesign and, I believe, dramatically improve those disclosures. Just this morning, the Board took a major step toward making credit disclosure more effective, by voting to seekpublic comment on proposed revisions to the Board’s Regulation Z, which implements the Truth In Lending Act--revisions that will improve credit card disclosures. I will share with you some of the results of our consumer testing, how they influenced our newly issued proposal concerning credit card disclosures, and how consumer testing will influence future proposals for improvements of mortgage loan disclosures. The Board’s Recent Actions Related to Mortgage Loan DisclosuresFirst, however, I want to note that the Board has already taken some steps to improve disclosures concerning mortgages, including subprime mortgages, which is the topic of this forum. Last summer, the Board held a series offour public hearings on home-equity lending, where we gathered views on the impact of federal and state predatory lending laws and on the adequacy of mortgage disclosures, particularly those concerning nontraditional mortgage products. Following those hearings, the Board revised theconsumer handbookthat creditors are required to provide with applications for adjustable-rate mortgages, or ARMs. As you well know, a substantial majority of recent subprime mortgage originations have been ARMs. The revised handbook gives consumers a better explanation of the features and risks of nontraditional ARMs, especially “payment shock” and the risk of increasing loan balances, also known as “negative amortization.” The Board will be holding afifth hearingon June 14, here in Washington, D.C., and I will chair that meeting. We will focus on how the Board might use its rulemaking authority under the Home Ownership and Equity Protection Act, or HOEPA, to address concerns about abusive mortgage lending practices. The purpose of the hearing is to gather information to evaluate how the Federal Reserve can prevent predatory lending in a way that also preserves incentives for responsible lenders. A robust and responsible subprime mortgage market benefits consumers by allowing borrowers with non-prime or limited credit histories to become homeowners, access the equity in their homes, or have the flexibility to refinance their loans as needed. Following the hearing, we will consider whether there are lending practices that should be prohibited under HOEPA. The Federal Reserve will do all that it can to prevent fraud and abusive mortgage lending practices. However, any new rules should be drawn clearly to avoid creating legal or regulatory uncertainty that could have the unintended consequence of restricting consumers' access to responsible subprime credit. As I mentioned earlier, effective disclosure can make markets more competitive and weed out abuse. Therefore, we will also consider how mortgage disclosures can be improved to ensure a robust subprime market and responsible subprime lending. In fact, the Board is conducting a comprehensive review of all Truth in Lending Act disclosures. As the Board reviews mortgage disclosures, it will consider a variety of recent suggestions. For example, given the large volume of documents presented to consumers at mortgage loan closings, the Board will consider whether creditors should be required to provide disclosures for home-refinance loans and home-equity loans within three days of application instead of at consummation, as currently required for home-purchase loans. The Board will also review the requirements concerning advertisements, to ensure that when lenders promote low initial rates and low monthly payments they also adequately disclose the limits of those low rates and payments and the potential payment shock. Our review of mortgage disclosures is now under way. I would now like to turn to the initial phase of the Board’s review of credit disclosures, which has focused on credit cards and other revolving credit accounts. The substantial investment we have made in developing and testing revised credit card disclosures has given us insights that will surely contribute to our ability to make mortgage disclosures more effective. The Challenges of Disclosing Credit Card CostsIn our effort to create more effective credit card disclosures, we face several challenges. First, disclosing the cost of revolving credit to facilitate consumer shopping is inherently challenging because key variables are not known in advance, such as the amount of credit that the consumer will use and the timing and amount of the consumer’s payments. Creditors’ solicitations disclose only a nominal APR based on the periodic interest rate, and they list any fees separately. Related variables, such as the grace period and balance calculation method, also have to be explained. On periodic billing statements, an “effective APR” can be disclosed after the credit is extended, but even then assumptions must be made about the consumer’s payments. For example, the effective APR assumes that transaction fees are amortized over one billing cycle, regardless of how long the credit is actually outstanding. The increasing complexity and diversity of credit card features and pricing present a second challenge. Because creditors use risk-based pricing, their solicitations might disclose a range of possible rates for which the consumer could qualify. Creditors discount their initial interest rates, sometimes deeply. While competing on the initial rate, creditors compensate with “back-end” pricing.4Temporary introductory rates are followed by a higher rate, and penalty rates and fees have increased and are now easier to trigger. Consumers might not focus on costs that are contingent on future events, and it can be challenging to explain clearly how these contingencies can increase consumers’ costs. A third major challenge is crafting disclosure rules that are, on the one hand, clear and specific enough to facilitate compliance and promote consistency among creditors but, on the other hand, flexible enough to accommodate market developments as products and pricing continue to change. We have a responsibility to avoid undue burdens that would hinder innovation and raise costs without producing sufficient offsetting benefits in the credit card market. Faced with these developments, the Board’s challenge is to determine what information should be highlighted for consumers. How much information is enough, and how much is too much? How can we encourage plainer language, recognizing that there may be a trade-off between simplicity and accuracy? What formats work best in presenting the information? When is the best time to present information so it will be most relevant and useful to consumers? How can we craft disclosure requirements that are flexible enough to accommodate innovation and change and to enhance competition? Using Consumer Testing to Improve Credit Card Disclosures: Highlights of the Proposal and Lessons LearnedAlthough the Board has used consumer focus groups in the past, this is the first time that we have conducted extensive, in-depth interviews with individual consumers to study the effectiveness of disclosures. The first step was using both focus groups and one-on-one interviews to evaluate how well consumers understand and use the current credit card disclosures. With a consultant’s help, we then redesigned the disclosures and conducted more one-on-one interviews using the revised formats. We went through this process several times, each time adjusting our designs to incorporate the lessons learned. We plan to follow the same testing process with mortgage disclosures. In addition, there were other sources of information, such as public comment letters and informal input from industry and consumer groups, discussions by the Board’s Consumer Advisory Council, a study by the Government Accountability Office, and data from consumer surveys. As I noted earlier, our task is to take a complex credit product and design disclosures that can explain the terms not only accurately but also clearly enough to be meaningful and useful to consumers--all while enhancing, not stifling, competition and innovation. I will briefly describe the highlights of the proposal issued by the Board this morning and use them to illustrate some general lessons we have learned about making disclosure more effective for consumers. First, we learned firsthand what information consumers find useful when making credit decisions and what information they ignore. Second, we learned what information consumers comprehend and what information they do not. Third, we saw the impact that different formats and presentation can have on consumers’ ability to notice and use the information. The first significant lesson from our consumer testing was that there are some disclosures that consumers just do not find useful. Most participants acknowledged that they do not read the cardholder agreements that contain their account-opening disclosures because they are often written in small print and dense prose. At the same time, they wanted some sort of disclosure they could use, before opening an account, to confirm that the terms are what they expect. Participants also said that often they do not carefully read their change-in-terms notices because they are frustrated by the format and technical language. With this information in hand, we explored how we could improve the disclosures to change consumer behavior. Under the proposed rules, when an account is opened, the consumer would receive a summary of the credit agreement in the form of a table, which they can compare with the original solicitation. Creditors would also have to provide a disclosure table with their change-in-terms notices, to summarize the changes. In our tests, such a table was very effective in making the change-in-terms notice more usable, and consumers were more likely to correctly identify the changes to the terms of their accounts. The Board’s proposal also would require creditors to give consumers more advance notice before increasing the interest rate or making changes to other key terms. Creditors would have to send a notice to consumers 45 days in advance of a rate increase, compared with the current 15 days. The intent is to give consumers more time to make other credit arrangements, if necessary, before the higher rate becomes effective. The Board is expressly seeking comment on whether 45 days is the appropriate amount of time. The second lesson learned from our consumer testing was which disclosures consumers comprehend and which they do not. Before deciding that the core information was not useful, we explored other ways to explain complex information and to improve consumers’ understanding. We explored whether consumers would benefit from using different terminology or whether particular terms need to be accompanied by an explanation. This is a particular challenge in the case of the term “effective APR.” We experimented with terminology and explanatory language as well as formats. The proposed changes for disclosing the effective APR have shown promise, but this is an area where we will be conducting additional consumer testing. The test participants also often did not correctly understand what creditors meant by the term “fixed rate.” They equated this with the fixed rate on their mortgage. Thus, under the proposed rules we would allow creditors to describe their rates as “fixed” only if there is a specified period during which the rate cannot be increased for any reason. If no period is specified, the term “fixed” could be used only if the rate cannot increase while the credit plan is open. Consumers in our tests also did not understand the term “default APR.” We would therefore require creditors to refer to the “penalty APR” rather than the “default APR,” which improved consumer understanding in our tests. Consumers also did not consistently understand the term “grace period,” which is significant considering the cost implications of not paying on time. Based on language we tested with consumers, we are proposing to add an explanation of the term. The third lesson of our consumer testing was the impact that different formats and presentation can have on consumers’ ability to notice and use the information. Our testing confirmed that one of the most effective ways to present credit card disclosures is in the table provided with solicitations, commonly known as the “Schumer box.” Although this table is effective, we were nevertheless able to use the one-on-one interviews to improve both the content and format. For example, when a creditor uses risk-based pricing, solicitations may show a range of rates, and many test participants had trouble understanding how a card issuer would select an initial APR. We are therefore proposing to add a simple explanation that consumers’ initial rate is based on their creditworthiness. We also reformatted the Schumer box into two major sections, to separate information about rates from the information about fees. This seemed to enhance consumers’ understanding and improve the usability of the disclosures. In addition, disclosures inside the Schumer box were more readily noticed than when the same information was placed just beneath it. We propose to move information that was more important to consumers--such as the circumstances that trigger a penalty APR--inside the Schumer box. The creditor’s balance-calculation method, however, was removed and located beneath the Schumer box, because our testing showed that consumers do not use the information to shop. A related finding concerning format is that regrouping information in the Schumer box improved consumers’ ability to use the disclosures. Specifically, we found that grouping certain information together on periodic statements made it easier to understand. For example, consumers more easily determined the number and amount of fees when they were itemized, grouped together, and totaled. So the revised rules would require creditors to locate the fees and interest charges in one place on the statement. Fees would have to be grouped together with a total dollar amount instead of listed chronologically with purchase transactions, as they are today. Interest charges would also be grouped together, with a total dollar amount. Finally, most consumers said that they throw away any inserts included with their periodic statement, including any inserts that describe changes to their account terms. To alert consumers to the significance of the insert, creditors that insert a change-in-terms notice with the periodic statement would have to summarize the changes on the front of the periodic statement rather than on the insert. Similar Challenges in Improving Mortgage DisclosuresAs I mentioned earlier, the Board also plans to conduct consumer testing as part of its review of mortgage disclosures. Like credit cards, mortgage products have become more diverse and more complex. In some cases, creditors are using pricing strategies similar to those used for credit cards, for example, offering customers discounted introductory rates that will be replaced in a short time by a much higher rate, often a variable rate. Of course there is an inherent difficulty in adjustable-rate mortgage disclosures because future interest rate changes are not known. Consumer testing is needed to determine whether consumers would find disclosure of the maximum rate and a worst-case payment example useful, given that these might not occur for several years or more and that the consumer’s own financial circumstances may change. The wider marketing of payment-option mortgages presents another challenge. Consumers have the choice of making low minimum monthly payments that increase the overall cost of the credit and may ultimately lead to longer amortization periods. Just as with credit cards, however, disclosing a consumer’s repayment obligation and the cost of the credit is more complex when there are unknowns--such as the rate, the amount of the consumer’s monthly payment, and the possibility of negative amortization. When the Board reviews mortgage disclosures, it will consider these developments and conduct consumer testing to determine how the features and risks of today’s mortgage products can be communicated effectively. The Board’s Upcoming Hearing on Mortgage Lending PracticesAs I mentioned earlier, in June the Board will be conducting another public hearing on mortgage lending, which will focus on how the Board might use its rulemaking authority to prevent abusive lending. Some of these concerns may call for more-effective disclosures. Last year, the federal agencies that supervise depository institutions issued guidance on nontraditional mortgage products, and they recently proposed similar guidance for subprime mortgages. Both guidance statements discuss underwriting practices as well as the need for lenders to give consumers more complete and balanced information while they are still shopping for a mortgage, before they apply for the loan. Prepayment penalties as well the use of “stated-income” or “low-doc” loans will also be discussed at the upcoming hearing. We will hear arguments about such practices and consider whether disclosures can be made more effective to adequately inform consumers about how penalty clauses operate and the implications of not documenting their income. ConclusionIn fulfilling its responsibility to protect consumers, the Federal Reserve will do all that it can to prevent fraudulent and abusive mortgage lending practices. Because information is critical to more competitive, and thus more efficient, markets, effective disclosure also has the capacity to weed out abuses. Consumers who do not have accurate information and an understanding of what that information means will have difficulty choosing among competing products and making decisions that are in their best interest. This is true in both credit card and mortgage markets. Accordingly, we will consider how mortgage disclosures can be more effective and empower consumers to make better-informed decisions and achieve their financial goals. Better-informed consumers will strengthen market competition. The Federal Reserve also will consider how we might use our rulemaking authority to address predatory practices without restricting consumers' access to responsible subprime credit. Footnotes 1.See, for example, George J. Stigler (1961), “The Economics of Information,” Journal of Political Economy, vol. 69 (June), pp. 213-25.Return to text 2.Alan D. Mathios (2000), “The Impact of Mandatory Disclosure Laws on Product Choices: An Analysis of the Salad Dressing Market,” Journal of Law and Economics, vol. 43 (October), pp. 651-675; Ginger Zhe Jin and Phillip Leslie (2003), “The Effect of Information on Product Quality: Evidence from Restaurant Hygiene Grade Cards,” The Quarterly Journal of Economics, vol. 118 (May), pp. 409-451.Return to text 3.Board of Governors of the Federal Reserve System (1987), Annual Percentage Rate Demonstration Project (Washington: Board of Governors of the Federal Reserve System). See also Consumer Credit in the United States: The Report of the National Commission on Consumer Finance (GPO 1972).Return to text 4.Furletti, Mark (2003), "Credit Card Pricing Developments and Their Disclosure (739 KB PDF)," discussion paper, Payment Cards Center, Federal Reserve Bank of Philadelphia.Return to text
The Federal Reserve Board on Tuesday announced the discussion topics for its June 14 public hearing under the Home Ownership and Equity Protection Act (HOEPA). The purpose of the hearing is to gather information about how the Board might use its rulemaking authority to curb abusive lending practices in the home mortgage market, including the subprime sector, in a way that preserves incentives for responsible lenders to provide credit to borrowers. Hearing participants will discuss whether the Board should use its rulemaking authority to address concerns about certain terms and practices related to home mortgage loans, including:Prepayment penaltiesEscrow accounts for taxes and insurance on subprime loans"Stated income" or "low doc" loansConsideration of a borrower's ability to repay a loanParticipants will also discuss the effectiveness of state laws that have prohibited or restricted these and other terms or practices, and whether the Board should consider adopting similar regulations to curb abusive lending practices. The Board is also soliciting written comments from the public. Comments are due August 15, 2007.The hearing is scheduled for Thursday, June 14, 2007, at the Federal Reserve Board at 20th and C Streets, N.W., Washington, D.C. Additional information about the hearing can be found at www.federalreserve.gov. Those planning to attend the hearing should, for security purposes, register no later than June 12. An online registration form can be found at:https://www.federalreserve.gov/secure/forms/hoeparegistration.cfm.A notice of the hearing and request for public comment is attached.Attachment Participants will also discuss the effectiveness of state laws that have prohibited or restricted these and other terms or practices, and whether the Board should consider adopting similar regulations to curb abusive lending practices. The Board is also soliciting written comments from the public. Comments are due August 15, 2007. The hearing is scheduled for Thursday, June 14, 2007, at the Federal Reserve Board at 20th and C Streets, N.W., Washington, D.C. Additional information about the hearing can be found at www.federalreserve.gov. Those planning to attend the hearing should, for security purposes, register no later than June 12. An online registration form can be found at:https://www.federalreserve.gov/secure/forms/hoeparegistration.cfm. A notice of the hearing and request for public comment is attached.
Chairman Ben S. Bernanke At the Montana Economic Development Summit 2007Butte, Montana Trade is as old as humanity, or nearly so. Archaeological sites demonstrate that ancient peoples traded objects such as rare stones and shells across fairly long distances even in prehistoric times (Guisepi, 2000). Over the centuries, with stops and starts, the volume of trade has expanded exponentially, driven in large part by advances in transportation and communication technologies. Steamships replaced sailing ships; railroads succeeded canal barges; the telegraph supplanted the Pony Express. Today, in a world of container ships, jumbo jets, and the Internet, goods and many services are delivered faster and more cheaply (in inflation-adjusted terms) than ever before.1 Today I will discuss the crucial economic benefits we receive from the ongoing expansion of international trade. I will also address the adverse effects of trade and some possible ways to mitigate them. I will argue that one possible response to the dislocations that may result from trade--a retreat into protectionism and isolationism--would be self-defeating and, in the long run, probably not even feasible. Instead, our continued prosperity depends on our embracing the many opportunities provided by trade, even as we provide a helping hand to individuals and communities that may have suffered adverse consequences. The Benefits of TradeAt the most basic level, trade is beneficial because it allows people to specialize in the goods and services they produce best and most efficiently. For example, we could conceivably all grow our own food and provide our own medical care. But because farming and medicine require special knowledge and skills, a far more efficient arrangement is for the farmer to specialize in growing food and for the doctor to specialize in treating patients. Through the specialization made possible by trade, the farmer can benefit from the doctor's medical knowledge and the doctor can enjoy lunch. The opportunity to trade allows everyone to play to his or her own strengths while benefiting from the productive skills of the whole community. Indeed, economists have demonstrated that trade between two people can be beneficial even if one of them is more skilled than the other ateverytask, so long as the more-skilled person specializes in those tasks at which he or she is relatively more productive. What applies to individuals applies to nations as well. Two centuries ago the economist David Ricardo famously observed that, if England specialized in making cloth while Portugal specialized in producing wine, international trade would allow both countries to enjoy more of both goods than would be possible if each country produced only for domestic consumption and did not trade. As in the case of individuals, this conclusion applies even if one country can produce both clothandwine more cheaply than the other, so long as each country specializes in the activity at which it is relatively more productive. A telling confirmation of Ricardo's insight is that, when nations go to war, their first order of business is often to try to block the other's access to trade. In the American Civil War, the North won in large part because its blockade of Southern ports prevented the Confederacy from exporting its cotton. In the twentieth century, the fact that Great Britain and its allies were able to disrupt German trade more successfully than Germany could impede the flow of goods into and out of Great Britain bore importantly on the ultimate outcomes of both world wars. Patterns of trade are determined by variations in a number of factors, including climate, the location of natural resources, and the skills and knowledge of the population. I suppose that one could grow roses commercially here in Montana for Valentine's Day, but it would likely require climate-controlled greenhouses complete with artificial lighting--very expensive. A much less costly solution is for Montanans to grow and sell wheat, then use the proceeds to buy roses from localities where the weather is balmy in February. This is all standard textbook material, and it may well leave you unconvinced of the importance of international trade. After all, the United States is a big country, and we can certainly achieve many of the benefits of specialization by trading within our own borders. How important is it for the health of our economy to trade actively with other countries? As best we can measure, it is critically important. According to one recent study that used four approaches to measuring the gains from trade, the increase in trade since World War II has boosted U.S. annual incomes on the order of $10,000 per household (Bradford, Grieco, and Hufbauer, 2006).2The same study found that removing all remaining barriers to trade would raise U.S. incomes anywhere from $4,000 to $12,000 per household. Other research has found similar results. Our willingness to trade freely with the world is indeed an essential source of our prosperity--and I think it is safe to say that the importance of trade for us will continue to grow. In practice, the benefits of trade flow from a number of sources. By giving domestic firms access to new markets, trade promotes efficient specialization, permits economies of scale, and increases the potential returns to innovation.3U.S. firms increasingly seek to expand production and profits through new export opportunities; indeed, U.S. exports grew about 9 percent in real (that is, inflation-adjusted) terms last year. Export-oriented U.S. manufacturing industries include producers of aircraft, construction equipment, plastics, and chemicals. The United States also excels in the manufacture and export of sophisticated capital goods and scientific equipment. Outside of manufacturing, a number of U.S. high-tech companies, including software developers and online service providers, are world leaders in their fields. American films and music attract large worldwide audiences. Montana's exports include wheat, metal ores, and high-tech materials that are critical to the production of semiconductors. Firms that emphasize exports are among America's most dynamic and productive companies. Relative to firms that produce strictly for the domestic market, exporters tend to be more technologically sophisticated and to create better jobs. Among U.S. manufacturers, for example, exporters pay higher wages and add jobs more rapidly than non-exporters (Bernard and Jensen, 1999). A significant portion of U.S. international trade is conducted by multinational firms; studies show that these firms generally pay higher wages than purely domestic firms, both in the United States and in developing countries (Doms and Jensen, 1998; Bhagwati, 2004, p. 172). U.S. firms with a global reach tend to be better diversified and are better able to respond to new market opportunities wherever they may arise. Exports are important, but so are imports. Without trade, some goods would be extremely expensive or not available at all, such as the Valentine's Day roses of my earlier example or out-of-season fruits and vegetables. Trade also makes goods available in more brands and varieties; examples include automobiles, consumer electronics, garments and footwear, wines, and cheeses. One of the great attractions of globalization is that it brings to consumers the best of many cultures. And of course, global trade allows many types of goods, especially consumer goods, to be purchased at lower prices. Lower prices help all consumers but may be especially helpful to those with tight budgets. Indeed, a number of the large, import-intensive retail chains in the United States are focused on low- and moderate-income consumers, who benefit from being able to buy a wide variety of lower-priced goods. Another substantial benefit of trade is the effect it tends to have on the productivity of domestic firms and on the quality of their output.4By creating a global market, trade enhances competition, which weeds out the most inefficient firms and induces others to improve their products and to produce more efficiently. The U.S. manufacturing sector, which is perhaps the sector most exposed to international competition, has achieved truly remarkable increases in its productivity in the past decade or so. In addition, international supply chains, made possible by advances in communication and transportation, reduce costs and increase the competitiveness of U.S. firms. Trade also promotes the transfer of technologies, as when multinational firms or transplanted firms bring advanced production methods to new markets. Trade and finance are closely linked and mutually supporting, and in recent decades international financial flows have grown even more quickly than trade volumes. The globalization of finance plays to the strengths of U.S. financial institutions and financial markets. The United States has a large surplus in trade in financial services, and U.S. firms are leaders in providing banking, investment, and insurance services to the world. Financial openness allows U.S. investors to find new opportunities abroad and makes it possible for foreigners to invest in the United States. The ability to invest globally also permits greater diversification and sharing of risk. Trade benefits advanced countries like the United States, but open trade is, if anything, even more important for developing nations. Trade and globalization are lifting hundreds of millions of people out of poverty, especially in Asia, but also in parts of Africa and Latin America (Bhagwati, 2004). As a source of economic growth and development in poor countries, trade is proving far more effective than traditional development aid (Easterly, 2006). The transition economies of central and eastern Europe have also benefited greatly from trade, especially trade with the rest of the European Union. A recent study by the World Bank compared two groups of developing countries, dubbed the "globalizers" and the "nonglobalizers." Collectively, the globalizers have doubled the ratio of trade to their gross domestic product (GDP) over the past twenty years, in part because of sharp cuts in tariffs on imports; the nonglobalizers, collectively, have seen a decline in their trade-to-GDP ratio over the same period (Dollar and Kraay, 2004). Among the globalizers, economic growth accelerated from 2.9 percent per year in the 1970s, to 3.5 percent in the 1980s, to 5 percent in the 1990s. In contrast, the nonglobalizers have seen their growth decline from 3.3 percent per year in the 1970s to 0.8 percent in the 1980s and 1.4 percent in the 1990s. The study also found that, among the globalizers, absolute poverty declined significantly and the degree of income inequality changed little.5 If trade is so beneficial, why do we sometimes see political resistance to freer, more open trade? Notably, negotiations in the so-called Doha Round of trade talks now under way have proceeded very slowly, notwithstanding a consensus among economists that all countries involved would enjoy substantial benefits from further trade liberalization. One important reason is that, although trade increases overall prosperity, the benefits for some people may not exceed the costs, at least not in the short run. Clearly, the expansion of trade helps exporting firms and their workers. As consumers, nearly all of us benefit from trade by gaining access to a broader range of goods and services. But some of us, such as workers in industries facing new competition from imports, are made at least temporarily worse off when trade expands. Because the benefits of trade are widely diffused and often indirect, those who lose from trade are often easier to identify than those who gain, a visibility that may influence public perceptions and the political process. That said, the job losses and worker displacement sometimes associated with expanded trade are a legitimate economic and social issue. In the remainder of my remarks, I will focus on the impact of trade on U.S. jobs--both positive and negative--and discuss some possible policy responses. Trade and JobsDoes opening U.S. markets to foreign producers destroy jobs at home? The expansion of trade or changes in trading patterns can indeed destroy specific jobs. For example, foreign competition has been an important factor behind declining employment in the U.S. textile industry, including in my home state of South Carolina. Job loss--from any cause--can create hardship for individuals, their families, and their communities. I will return shortly to the question of how we should respond to the problem of worker displacement. For now, however, I will point out that trade also creates jobs--for example, by expanding the potential market overseas for goods and services produced in the United States, as I have already discussed. Trade creates jobs indirectly as well, in support of export activities or as the result of increased economic activity associated with trade. For example, gains in disposable income created by lower consumer prices and higher earnings in export industries raise the demand for domestically produced goods and services. Domestic production and employment are also supported by expanded access to raw materials and intermediate goods. The U.S. jobs created by trade also tend to offer higher pay and demand greater skill than the jobs that are destroyed--although a downside is that, in the short run, the greater return to skills created by trade may tend to increase the wage differential between higher-skilled and lower-skilled workers and thus contribute to income inequality (Bernanke, 2007). The effects of trade on employment must also be put in the context of the remarkable dynamism of the U.S. labor market. The amount of "churn" in the labor market--the number of jobs created and destroyed--is enormous and reflects the continuous entry, exit, and resizing of firms in our ever-changing economy. Excluding job layoffs and losses reversed within the year, over the past decade an average of nearly 16 million private-sector jobs have been eliminated each year in the United States, an annual loss equal to nearly 15 percent of the current level of nonfarm private employment.6The vast majority of these job losses occur for a principal reason other than international trade (Kletzer, 2001; Bernanke, 2004). Moreover, during the past ten years, the 16 million annual job losses have been more than offset by the creation of about 17 million jobs per year--some of which, of course, are attributable to the direct and indirect effects of trade. Truly, the U.S. labor market exhibits a phenomenal capacity for creative destruction. If trade both destroys and creates jobs, what is its overall effect on employment? The answer is, essentially none. In the long run, the workings of a competitive labor market ensure that the number of jobs created will be commensurate with the size of the labor force and with the mix of skills that workers bring. Thus, in the long run, factors such as population growth, labor force participation rates, education and training, and labor market institutions determine the level and composition of aggregate employment. To see the irrelevance of trade to total employment, we need only observe that, between 1965 and 2006, the share of imports in the U.S. economy nearly quadrupled, from 4.4 percent of GDP to 16.8 percent. Yet, reflecting growth in the labor force, employment more than doubled during that time, and the unemployment rate was at about 4-1/2 percent at both the beginning and end of the period. Furthermore, average real compensation per hour in the United States has nearly doubled since 1965. Although many readily accept that balanced trade does not reduce aggregate employment, some might argue that the United States' current large trade deficit must mean that the number of U.S. jobs has been reduced on net. However, the existence of a trade deficit or surplus, by itself, does not have any evident effect on the level of employment. For example, across countries, trade deficits and unemployment rates show little correlation. Among our six Group of Seven partners (the world's leading industrial countries), three have trade surpluses (Canada, Germany, and Japan). However, based on the figures for February of this year, the unemployment rates in Canada (5.3 percent) and in Germany (9.0 percent) are significantly higher than the 4.5 percent rate in the United States; and Japan's unemployment rate, at 4.0 percent, is only a bit lower.7Factors such as the degree of flexibility in the labor market, not trade, are the primary source of these cross-country variations in unemployment. What About Outsourcing Abroad?The debate about the effects of trade on employment has been intensified by the phenomenon of outsourcing abroad, or "offshoring." Offshoring has been driven by several factors, including improvements in international communication, the computerization and digitization of some business services, and the existence of educated, often English-speaking workers abroad who will perform the same services for less pay. A portion, though not all, of these wage differentials reflects differences in skills and productivity; for example, outsourced programming work is usually simpler and more routine than programming done in the United States. The increase in outsourcing abroad has led to dire predictions about a wholesale "export" of U.S. jobs in coming years. Although globalization and trade will continue to be forces for economic change, concerns about a massive loss of jobs due to offshoring do not seem justified. Companies have found outsourcing abroad profitable primarily for jobs that can be routinized and sharply defined. Certainly, advancing technology will continue to increase the feasibility of providing services from remote locations. For the foreseeable future, however, most high-value work will require creative interaction among employees, interaction which is facilitated by physical proximity and personal contact. Moreover, in many fields, closeness to customers and knowledge of local conditions are also of great importance. These observations suggest that, for some considerable time, outsourcing abroad will be uneconomical for many types of jobs, particularly high-value jobs.8 Moreover, a balanced discussion of outsourcing abroad should reflect that, just as U.S. firms use the services of foreigners, foreign firms make considerable use of the services of U.S. residents. Many do not realize that, in contrast to its trade deficit in goods, the United States runs a significant trade surplus in services--particularly in business, professional, and technical services. This country provides many high-value services to users abroad, including financial, legal, engineering, architectural, and software development services, whereas many of the services imported by U.S. companies are less sophisticated and hence of lower value.9A recent study of twenty-one occupations that are most likely to be affected by outsourcing found that net job losses were concentrated almost exclusively in the lower-wage occupations and that strong employment gains have occurred in the occupations that pay the highest wages.10Further expansion of trade in services will help, not hurt, the U.S. economy and the labor market. Just as discussions of the outsourcing of business services tend to ignore the services U.S. firms sell to other countries, so do discussions of the movement of jobs offshore ignore the fact that foreign firms also move jobs to the United States. Between 1996 and 2004 (the most recent data available), the employment of U.S. residents by majority-owned nonbank affiliates of foreign companies operating within the United States increased by about 1 million jobs. In 2004, U.S. affiliates of foreign companies accounted for more than $500 billion in value added (about half in manufacturing) and about $180 billion in exports. Globalization and offshoring work both ways. Responding to Job DisplacementAlthough trade has many positive effects in the labor market, nothing I have said this morning is intended to minimize the real costs imposed on workers and communities when new competition from abroad leads to job losses and displacement. What can be done to help workers who lose their jobs as a consequence of expanded trade? Restricting trade by imposing tariffs, quotas, or other barriers is exactly the wrong thing to do. Such solutions might temporarily slow job loss in affected industries, but the benefits would be outweighed, typically many times over, by the costs, which would include higher prices for consumers and increased costs (and thus reduced competitiveness) for U.S. firms. Indeed, studies of the effects of protectionist policies almost invariably find that the costs to the rest of society far exceed the benefits to the protected industry. In the long run, economic isolationism and retreat from international competition would inexorably lead to lower productivity for U.S. firms and lower living standards for U.S. consumers (Bernanke, 2004). The better approach to mitigating the disruptive effects of trade is to adopt policies and programs aimed at easing the transition of displaced workers into new jobs and increasing the adaptability and skills of the labor force more generally. Many suggestions for such policies have been made. Currently, the government's principal program for helping workers displaced by trade is the Trade Adjustment Assistance program, which is up for renewal before the Congress this year. As now structured, the program offers up to two and a half years of job training, allowances for job search and relocation, income support for eligible workers, and health insurance assistance for some. Elements of other proposals being discussed (Kletzer and Rosen, 2006; Kling, 2006; Mann 2003, 2004) include job-training tax credits and wage insurance, which would help offset pay cuts that often occur when displaced workers change jobs. Another approach is to focus on establishing policies that reduce the cost to workers of changing jobs, for example, by increasing the portability of pensions or health insurance between employers. As new technologies expand the range of occupations that may be subject to international competition, measures to assist affected workers become all the more important. It would not be appropriate for me to endorse specific programs; that is the prerogative of the Congress. However, I can safely predict that these and other policy proposals to address concerns about worker displacement will be the subject of active debate in coming years. More generally, investing in education and training would help young people entering the labor force as well as those already in mid-career to better manage the ever-changing demands of the workforce (Bernanke, 2007). A substantial body of research demonstrates that investments in education and training pay high rates of return to individuals and to society as a whole (Acemogulu and Angrist, 2001; Becker, 1964; Card, 1999; Topel, 2004). Importantly, workforce skills can be improved not only through K‑12 education, college, and graduate work but also through a variety of expeditious, market-based channels such as on-the-job training, coursework at community colleges and vocational schools, extension courses, and online training. An eclectic, market-responsive approach to increasing workforce skills is the most likely to be successful. Whatever the specific approaches chosen, helping workers who have lost jobs--whether because of trade or other causes--to find new productive work is good for the economy as well as for the affected workers and their families. Moreover, if workers and their families are less fearful of change, political pressure in favor of trade barriers or other measures that would reduce the flexibility and dynamism of the U.S. economy would be reduced (Kull, 2004). ConclusionTo sum up, international trade in goods, services, and assets, like other forms of market-based exchange, allows us to transform what we have into what we need or want under increasingly beneficial terms. Trade allows us to enjoy both a more productive economy and higher living standards. Of course, current trading arrangements are far from perfect. Some features of the world trading regime, such as excessive restrictions on trade in services and the uneven protection of intellectual property rights, are both unfair and economically counterproductive. Working through the World Trade Organization or in other venues, we should continue to advocate the elimination of trade distortions and barriers in our trading partners even as we increase the openness of our own economy. We should also work to ensure that both we and our trading partners live up to existing agreements under the World Trade Organization. When trading partners do not meet their obligations, we should vigorously press our case. Ultimately, a freer and more open trading system is in everyone's best interest. Although expansion of trade makes the U.S. economy stronger, as I have noted today, the broad benefits of trade and the associated economic change may come at a cost to some individuals, firms, and communities. We need to continue to find ways to minimize the pain of dislocation without standing in the way of economic growth and change. Indeed, the willingness to embrace difficult challenges is a defining characteristic of the American people. With our strong institutions, deep capital markets, flexible labor markets, technological leadership, and penchant for entrepreneurship and innovation, no country is better placed than the United States to benefit from increased participation in the global economy. If we resist protectionism and isolationism while working to increase the skills and adaptability of our labor force, the forces of globalization and trade will continue to make our economy stronger and our citizens more prosperous. References Acemoglu, Daron, and Joshua Angrist (2001). "How Large Are Human Capital Externalities? Evidence from Compulsory Schooling Laws," in Ben S. Bernanke and Kenneth Rogoff, eds.,NBER Macroeconomics Annual.Cambridge, Mass.: MIT Press, pp. 9-59. Becker, Gary S. (1964).Human Capital: A Theoretical and Empirical Analysis with Special Reference to Education. New York: National Bureau of Economic Research. Bernanke, Ben S. (2004). "Trade and Jobs," speech delivered at the Distinguished Speaker Series, Fuqua School of Business, Duke University, March 30, www.federalreserve.gov/boarddocs/speeches/2004/20040330/default.htm ______ (2006). "Global Economic Integration: What's New and What's Not?" speech delivered at the thirtieth annual economic symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyo., August 25, www.federalreserve.gov/newsevents/speech/bernanke20060825a.htm ______ (2007). "The Level and Distribution of Economic Well-Being," speech delivered at the Greater Omaha Chamber of Commerce, February 6, www.federalreserve.gov/newsevents/speech/bernanke20070206a.htm Bernard, Andrew B., and J. Bradford Jensen (1999). "Exceptional Exporter Performance: Cause, Effect, or Both?"Journal of International Economics,vol. 47 (February), pp. 1-25. Bernard, Andrew B., J. Bradford Jensen, and Peter K. Schott (2006). "Trade Costs, Firms, and Productivity,"Journal of Monetary Economics,vol. 53 (July), pp. 917-37. Bhagwati, Jagdish (2004).In Defense of Globalization.New York: Oxford University Press. Bradford, Scott C., Paul L. E. Grieco, and Gary Clyde Hufbauer (2006). "The Payoff to America from Globalisation,"The World Economy,vol. 29 (July), pp. 893-916. Card, David (1999). "The Causal Effect of Education on Earnings," in Orley Ashenfelter and David Card, eds.,Handbook of Labor Economics, vol. 3A. New York: Elsevier, pp. 1801-63. Cox, Michael, and Richard Alm (2007). "The Best of All Worlds: Globalizing the Knowledge Economy," in Federal Reserve Bank of Dallas,2006 Annual Report, pp. 3-28. Davis, Steven, John Haltiwanger, and Scott Schuh (1996).Job Creation and Destruction. Cambridge, Mass.: MIT Press. Dollar, David, and Aart Kraay (2004). "Trade, Growth, and Poverty,"The Economic Journal,vol. 114 (February), pp. F22-F49. Doms, Mark E., and J. Bradford Jensen (1998). "Comparing Wages, Skills, and Productivity between Domestically and Foreign-Owned Manufacturing Establishments in the United States," in Robert E. Baldwin, Robert E. Lipsey, and J. David Richardson, eds.,Geography and Ownership as Bases for Economic Accounting.Chicago: University of Chicago Press. Easterly, William (2006).The White Man's Burden: Why the West's Efforts to Aid the Rest Have Done So Much Ill and So Little Good.New York: Penguin Press. Guisepi, Robert A. (2000). "The Stone Age: The General Picture,"International World History Project,http://history-world.org/stone_age2.htm(accessed April 13, 2007) Hummels, David (2006). "Transportation Costs and Trade over Time," in David Hummels, Anthony Venables, Harry Broadman, and John S. Wilson, rapporteurs,Transport and International Trade: Round Table 130. Organisation for Economic Co-operation and Development and European Conference of Ministers of Transport. Paris: OECD. Institute of International Education (2006). "New Enrollment of Foreign Students in the U.S. Climbs in 2005/06," press release, November 13,http://opendoors.iienetwork.org/?p=89251. Kletzer, Lori G. (2001).Job Loss from Imports: Measuring the Costs. Washington: Institute for International Economics. Kletzer, Lori G., and Howard Rosen (2006). "Reforming Unemployment Insurance for the Twenty-First Century Workforce," Hamilton Project Discussion Paper. Washington: Brookings Institution, September. Kling, Jeffrey R. (2006). "Fundamental Restructuring of Unemployment Insurance: Wage-Loss Insurance and Temporary Earnings Replacement Accounts," Hamilton Project Discussion Paper. Washington: Brookings Institution, September. Kull, Steven (2004).Americans on Globalization, Trade, and Farm Subsidies, The American Public on International Issues, PIPA/Knowledge Networks Poll, Program on International Policy Attitudes and Knowledge Networks, January 22,www.pipa.org/OnlineReports/Globalization/GlobalTradeFarm_Jan04/GlobalTradeFarm_Jan04_rpt.pdf (900 KB PDF). Mann, Catherine L. (2003). "Globalization of IT Services and White Collar Jobs: The Next Wave of Productivity Growth," International Economics Policy Briefs PB03-11. Washington: Institute for International Economics, December,www.iie.com/publications/pb/pb03-11.pdf(389 KB PDF). ______ (2004). "Global Sourcing and High-Tech Jobs: Productivity Gains and Policy Challenges," presentation on "White Collar Outsourcing" at the Institute for International Economics, March 11,www.iie.com/publications/papers/mann0304.pdf(138 KB PDF). ______ (2006).Accelerating the Globalization ofAmerica: The Role for Information Technology,with Jacob Funk Kirkegaard. Washington: Institute for International Economics. Topel, Robert (2004). "The Private and Social Values of Education," inEducation and Economic Development, proceedings of a conference held at the Federal Reserve Bank of Cleveland, November 18-19, pp. 47-57,www.clevelandfed.org/research/conferences/2004/November/cbook.pdf(891 KB PDF). Footnotes 1.Hummels (2006). Bernanke (2006) provides a brief history of globalization.Return to text 2.The estimates ranged from $7,000 to $13,000.Return to text 3.Cox and Alm (2007) discuss the benefits of trade in the modern global economy.Return to text 4.Bernard and Jensen (1999) find that exporting firms are more productive than non-exporters. Bernard, Jensen, and Schott (2006) document the tendency of trade to reduce production at low-productivity plants and to increase output at high-productivity plants in the United States, a shift that raises average productivity.Return to text 5.Refer also to Bhagwati (2004).Return to text 6.According to the Bureau of Labor Statistics (BLS), over the past ten years, gross job losses in the United States have averaged about 7.8 million per quarter. Multiplying 7.8 million by 4 suggests that about 31 million U.S. jobs come to an end each year. This figure includes temporary layoffs, seasonal closings, and other short-term job losses; some research suggests that longer-term job losses amount to about half of the total (Davis, Haltiwanger, and Schuh, 1996). Dividing 31 million gross job losses by 2 yields about 16 million long-term job losses each year.Return to text 7.February 2007 is the latest month for which these rate comparisons are available. The data are from the Bureau of Labor Statistics, which has adjusted them to approximate the U.S. definition of unemployment.Return to text 8.The economic importance of physical proximity is the underlying reason that people and businesses are willing to pay high rents and other costs to live in or near major cities, where they can be near large numbers of other people and businesses that have related expertise and interests.Return to text 9.Another type of service in which the United States has a strong export position is higher education. In 2005-06, U.S. institutions of higher learning trained nearly 600,000 foreign students, of whom about half were studying for graduate and professional degrees. Many foreign students who study in the United States spend at least some time here subsequently, adding their skills to those of the domestic workforce (Institute of International Education, 2006).Return to text 10.Mann (2006, pp. 140-41) analyzes changes from 1999 to 2004. Updating the analysis with 2005 data from the Bureau of Labor Statistics does not change these results. Some of the low-wage occupations, such as data entry and word processing, may have lost jobs to automation rather than outsourcing.Return to text
Governor Frederic S. Mishkin At the Conference on Price Measurement for Monetary Policy, Federal Reserve Bank of Dallas, Dallas, Texas This conference focuses on measurement issues, and in my remarks I want to focus on one of the most important measurement issues that we at the Federal Reserve and other central banks face: How do we determine whether the economy is operating above or below its maximum sustainable level? That is, how do we estimate the path of potential output?1 The Federal Reserve operates under a dual mandate to achievebothprice stability and maximum sustainable employment. In that context, it is natural to think of potential output as the level of output that is consistent with the maximum sustainable level of employment: That is, it is the level of output at which demand and supply in the aggregate economy are balanced so that, all else being equal, inflation tends to gravitate to its long-run expected value. The combination of the dual mandate and this definition suggests two reasons that estimating the path of potential output is so central to the conduct of monetary policy. First, to evaluate whether our policies will help achieve the maximum sustainable employment objective of the dual mandate, we need know the level of future output that would be consistent with that objective. Second, the level of output relative to potential output, which is referred to as theoutput gap, plays an important role in the inflation process. When the actual level of output is above potential output--so that the output gap is positive--labor and product markets are excessively tight; then, if things such as expected inflation and temporary supply factors are held constant, inflation will tend to rise. Conversely, when the output gap is negative and labor and product markets are slack, inflation will tend to fall. Estimates of the future path of potential output are therefore needed to assess whether the projected path of output that is implied by current monetary policy will lead inflation to move in a direction that is consistent with price stability. Because estimates of potential output are an important part of central bankers' toolkits, the Federal Reserve and other central banks devote considerable resources to getting the best measures of potential output possible. In this talk, I want to explore something that Bismarck warned us we shouldn't want to examine: "what goes into the sausage"--or in this case, what goes into central bankers' thinking about how to estimate potential output. Broadly speaking, there are three basic approaches to estimating potential output: (1) aggregate approaches; (2) production function, or growth-accounting, approaches; and (3) the newest kid on the block, dynamic stochastic general equilibrium (DSGE) approaches. Let's look at each of these in turn, with the major focus on the production function approach, one to which we at the Federal Reserve currently pay a lot of attention. (Please note that my comments here reflect my own views and not necessarily those of the Board of Governors or the Federal Reserve System.) Aggregate ApproachesAggregate approaches to estimating potential output can be thought of as top down approaches because they look at relationships involving aggregate variables and use them to derive measures of potential output. For example, one way of estimating potential output is to assume that if a change in employment or output is sustainable, then it is likely to be permanent. This assumption suggests using univariate statistical methods to identify the permanent component of changes in output, which could then be viewed as a reasonable measure of potential output. Examples of such an approach include the work of Beveridge and Nelson (1981) and Clark (1987). Although univariate approaches to measuring potential output have the advantage of simplicity and can provide a feel for what potential output might be, they suffer from several disadvantages. First, they require a variety of statistical assumptions about which economic theory provides little guidance--for example, about the correlation between permanent and transitory components or whether the permanent component should be modeled as a random walk. Perfectly sensible alternative assumptions can lead to very different estimates of potential output. Second, these purely statistical approaches do not tell us whether this measure of the permanent component of output movements provides information about the most important aspect of potential output from a central banker's perspective--namely, its association with a stable rate of inflation. In measuring potential output, we therefore need to bring in some economics. One potentially valuable economic relationship we can use is the "natural rate" version of the Phillips curve, which followed from the seminal research of Nobel prize winners Milton Friedman (1968) and Edmund (Ned) Phelps (1967). Friedman and Phelps demonstrated that there should not be a long-run tradeoff between inflation and unemployment and that the economy will gravitate to some natural rate of unemployment in the long run no matter what the rate of inflation is. In other words, the long-run Phillips curve is vertical, and attempts to lower unemployment below the natural rate will only result in higher inflation. According to the natural-rate hypothesis, there is a natural rate of unemployment--also more commonly referred to as the NAIRU (non-accelerating inflation rate of unemployment)--at which inflation tends to gravitate to its long-run expected value.2A natural rate of output--that is, potential output--corresponds to the NAIRU. The difference between actual and potential output, the output gap, tells us whether inflation will tend to move up or down, holding things like inflation expectations, energy prices, import prices, and so forth constant. The natural-rate hypothesis thus suggests that potential output can be estimated from a multivariate approach in which potential output is an unobserved component in the relationship between inflation and the output gap. Kuttner (1994) provides a good example of this approach.3 An alternative approach involves deriving the NAIRU directly from estimates of Phillips curves and then using Okun's law--which relates the output gap to the unemployment gap (the actual unemployment rate minus the NAIRU)--to estimate potential output.4These multivariate approaches are reasonably simple and make intuitive sense, but they also have serious drawbacks. First, they require that the specification of the Phillips curve is correct. For example, the model needs to correctly characterize the relationship between the unemployment rate gap and inflation dynamics while taking into account how inflation expectations are formed, and it should not leave out any other variables that have an impact on inflation.5Indeed, many economists criticize the Phillips curve, with some even declaring it dead.6 Second, using Okun's law to derive potential output requires an appropriate specification for the dynamics of the relationship between output and unemployment gaps. However, cyclical fluctuations in productivity and labor supply can complicate this relationship. Moreover, Okun's law can be thrown well off course during periods of unanticipated structural change in the economy, such as the early 1970s, when U.S. productivity growth slowed. As a result of these influences, Okun's law has not always been a reliable guide to the relationship between the unemployment gap and the output gap and thus has not always been the most useful guide for estimating potential output.7Finally, even if the Phillips curve and the Okun's law relationships are specified correctly--a big if--the statistical uncertainty about the estimates of the NAIRU, and therefore also about potential output, is very large--certainly larger than a policymaker would like. For example, the estimates of Staiger, Stock, and Watson (1997a and b) of the 95 percent confidence interval for the NAIRU were as much as 3 percentage points wide. Thus estimates of the NAIRU, in isolation, provide policymakers with little real-time insight for assessing the effect of labor markets on inflation pressures. Production Function (Growth-accounting) ApproachesBecause of the shortcomings of the aggregate approaches described above, some researchers estimate potential output using a production function approach that generates an estimate of potential from the underlying factors of production. This approach is sometimes referred to as "growth accounting" because, after the log of a production function is differentiated, output growth can be expressed as a weighted average of the growth of factor inputs--that is, capital services and labor input (hours worked and labor quality)--and a residual--multifactor (also called total factor) productivity growth. The NAIRU concept still plays an important role in this approach because it helps to determine thelevelof potential output. A major advantage of the growth-accounting approach is that it focuses on the various factors that drive growth in potential output, rather than simply on the historical behavior of output growth or on the historical relationship between output and labor inputs as in Okun's law. The disaggregated nature of the growth-accounting approach means that more data can be used to estimate potential output. These additional data are likely to be particularly valuable when the economy is undergoing major structural changes--for example, the productivity slowdown starting around the early 1970s, the surge and subsequent slowdown in population growth from the baby-boom generation's entry and (now) exit from the labor force, the remarkable upsurge in labor participation of females in the 1970s and 1980s, and the pickup in productivity growth starting in the second half of the 1990s. Given these advantages, it is not surprising that the growth-accounting framework is widely used to estimate the path of potential output, both by central banks such as the Federal Reserve and by academic researchers. In its simplest formulation, the growth-accounting framework characterizes output growth as the sum of the growth rate of raw labor hours and the growth rate of output per hour, that is, labor productivity.8In turn, the growth rate of labor hours is described as the sum of population growth (civilian non-institutional population aged sixteen and older), the rate of change of the labor force participation rate, the rate of change in the employment rate, and the rate of change in the number of hours in the average workweek. Labor productivity is decomposed into the contributions of capital deepening (the marginal product of capital--typically estimated as capital's share of income--times the growth rate of capital services per hour), changes in labor quality, and the growth rate of multifactor productivity. To obtain estimates of potential output growth, researchers can use economic analysis to estimate the individual components above that go into the growth-accounting framework. Much research has been conducted along these lines in the Federal Reserve System and elsewhere. For example, Aaronson and others (2006) examine what variables influence individual decisions to participate in the labor market (birth cohort, age, sex, number and age of children, and so forth). They then use this information together with the relative size of different cohorts to show that the aging of the baby-boom cohort can explain much of the decline in labor force participation since 2000 and why the participation rate is likely to continue to decline further in the future. Given slower projected population growth and what appears to be a downward trend in the number of hours in the average workweek, these results suggest that potential output growth will be slower than it otherwise would have been. Of course, such projections are subject to uncertainty, and economists hold a range of views about the prospects for future labor force growth. One important unknown is whether increases in longevity and better health will boost the labor force participation rates of older individuals more than currently embedded in these projections. Similarly, economists at the Fed have been at the forefront of research on why labor productivity growth ratcheted upward in the second half of the 1990s and continued at a surprisingly robust pace over the first half of this decade. Oliner, Sichel, and Stiroh (2007), for example, find that the IT (information technology) sector has been a key element in the higher productivity growth that we have been experiencing since the mid-1990s.9But they also find that the sources of growth in the second half of the 1990s were quite different than in the period after 2000. In the 1995-2000 period, labor productivity growth was driven by substantial gains in multifactor productivity in the tech sector, which, in turn, led to sharp reductions in the prices of high-tech equipment and stimulated investment in this type of capital in other sectors of the economy. Since 2000, high productivity growth has apparently been driven importantly by industry restructuring in response to pressures on profits (the firms that saw the sharpest drops in profits were those that had the largest gains in labor productivity) and by a reallocation of material and labor inputs across industries. Their estimate for the current trend labor productivity growth is centered around 2-1/4 percent, but they find large uncertainty around this estimate, with a 95 percent confidence interval that ranges from 1-1/4 percent to 3-1/4 percent. Roberts (2001) estimates even larger uncertainty around structural labor productivity growth. Despite the advantages of the growth-accounting framework, it still presents some difficulties. For one, there is, as I just highlighted, a large degree of uncertainty surrounding the estimates of the components that go into the growth-accounting formulas. In addition, the growth-accounting framework requires a substantial amount of data, some of which are not especially reliable. For example, it is especially difficult to measure the growth rate of capital services, and the Bureau of Labor Statistics releases its initial estimates with a lag of at least one year. In addition, the bureau's two measures of employment, one derived from a survey of firms and the other from a survey of households, often provide very different pictures of what is happening in the labor market. Also data for capital services, labor composition, and multifactor productivity are not readily available for all sectors of the U.S. economy. Because it is so difficult to reliably estimate potential output using either the aggregate or the growth-accounting approach, it should come as no surprise that we at the Federal Reserve use a lot of judgment in constructing our estimates of potential output. In particular, we see judgment as playing three important roles in our procedures. First, it enables us to take account of the effects of structural changes in the economy that cannot be modeled directly. Second, it allows us to deal with model misspecifications that cannot be corrected. Third, we can use judgment to correct for measurement errors or inconsistencies in economic data. For example, we judgmentally adjust model-based estimates of the NAIRU to account for movements in the unemployment rate unrelated to changes in labor market slack. Of these, the most important has been the shift in the demographic composition of the labor force, driven largely by the entrance and subsequent maturation of the baby-boom generation. But economists have pointed to a number of other factors that would influence the NAIRU as well. Another example relates to the way in which we estimate the trend growth rate of multifactor productivity. In particular, estimates of trend multi-factor productivity growth tend to be sensitive to the choice of modeling strategy, a problem that became particularly apparent during the "jobless recovery" of the early 1990s, when the normal relationship between output growth and employment growth appeared to break down. Statistical filtering models like those described by Roberts (2001) tended in real time to attribute much of the weak employment growth to an acceleration in trend productivity. Later on, however, after employment recovered, it became clear that the unusual behavior of employment during that period was explained better as a temporary reluctance by firms to hire than as a step-up in the rate of trend productivity growth. In a similar vein, it may at times make sense to down weight more-recent estimates of the data used in filtering exercises to account for the possibility of future revisions to the data. Finally, it can often be useful to look at Okun's law as a check on the estimates of potential output derived from the growth-accounting approach. Although, as I noted above, one should not expect Okun's law to hold from quarter to quarter, the relationship is relatively robust over longer periods, and a persistent deviation in the unemployment rate from that predicted by Okun's law might call into question the estimated trends in one or more of the components in potential output. Dynamic Stochastic General Equilibrium ApproachesThe real business cycle literature, which started with the work of Nobel Prize winners Finn Kydland and Edward Prescott (1982), features optimizing agents and emphasizes the role of technology shocks in explaining both economic growth and business cycles. Dynamic stochastic general equilibrium (DSGE) models contain many features of the earlier real business cycle literature, but, because they allow for rigidities and imperfections in markets, they are often referred to as New Keynesian models. The New Keynesian DSGE models provide more-realistic, yet still theoretically elegant, representations of the economy, and their development has been an exciting area of research in macroeconomics in recent years. New Keynesian DSGE models provide a somewhat different, but complementary, perspective on the definition of potential output than the one I outlined at the beginning of this speech. In particular, we might think of potential output as the level of output that an economy could attain if the inefficiencies resulting from nominal wage and price rigidities were removed--that is, if wages and prices were fully flexible.10The definition of potential output as a flexible price equilibrium has much in common with the more conventional definition I discussed earlier because over time prices (and wages) do gravitate toward their equilibrium levels. As a result, the DSGE definition accords with the idea that potential output is the level of output at which inflation tends neither to rise nor fall. That said, the DSGE view of potential output also has important differences with the earlier approaches to estimating potential output. Although research on using DSGE models to estimate potential output is in its infancy and so should be read cautiously, papers such as Neiss and Nelson (2005) and Edge, Kiley, and Laforte (2007) are finding that the properties of potential output and output gap fluctuations can be quite different from conventional measures. For example, in many DSGE models, potential output can undergo swings over the business cycle, a result that should not be surprising considering that the early real business cycle models viewed the business cycle as being primarily an efficient response to shocks to the economy. In addition, fiscal policy shocks, changes in households' preferences with regard to saving and consumption, changes in preferences about leisure that affect labor supply, and terms-of-trade shocks can all cause potential output to fluctuate. In contrast, growth-accounting approaches to estimating potential output generally assume that such shocks have no important effects on potential output at business-cycle frequencies. As a consequence, their estimates typically have smaller fluctuations than measures of potential output derived from DSGE models, and thus the output gaps in the current generation of DSGE models tend to be less variable than conventional measures and can be quite different for particular periods. Although the research on DSGE models is promising, measures of potential output and the output gap from these models are controversial. The DSGE measures of potential output are far more model dependent than more-conventional measures because they depend on the estimated parameters of the model and on the model's estimates of the structural shocks hitting the economy. As a result, DSGE models with different characterizations of the economy's underlying structure can produce substantially different estimates of potential output. This is apparent, for example, in the large differences between the potential output measures in the DSGE models of Neiss and Nelson (2005) from those in Edge, Kiley, and Laforte (2007). Moreover, DSGE models often require strong assumptions to identify the shocks to potential output from model equation residuals. The finding that these models imply smaller and less persistent output gaps than traditional models may simply reflect the fact that inefficiencies other than price rigidities, such as real wage rigidities, are important for output fluctuations.11As a result, some policymakers have been quite critical of the implication of DSGE models that a substantial fraction of business-cycle fluctuations are efficient and so do not require a response from monetary policymakers.12 Implications for PolicyNow that we have looked inside the sausage of estimating potential output, I hope you have not lost your appetite for thinking about what these measurement issues mean for monetary policy. As I indicated earlier, considerable uncertainty surrounds the measures of potential output derived from any of the approaches I have discussed. In addition, there is also what economists call Knightian uncertainty (named after the famous University of Chicago economist Frank Knight)--the fact that we are not even sure of the appropriate modeling approach to measure potential output. Adding even more to the uncertainty of potential output measures are (1) that the observable data do not always correspond to the data we would like to have to produce measures of potential output and (2) that initial estimates of observable data can subsequently be revised substantially, resulting in a very different picture of what is happening to potential output and the output gap. Orphanides (2001) points out that output gaps were grossly mismeasured in the 1970s, in part because the initially published data did not reflect the true state of the economy.13 Where does the high uncertainty about actual and potential output leave us at central banks? Does it mean that we should abandon our focus on potential output and output gaps in making decisions on monetary policy? I think not. For better or worse, we cannot escape the need for information on output gaps so that we can forecast the future path of inflation and evaluate the current setting of our monetary policy instruments. However, we also need to recognize that because measures of potential output and output gaps are so uncertain, we must always be aware that they might be providing misleading signals as to the future course of inflation and the appropriateness of the stance of policy. In assessing whether there is slack in the economy, we at central banks look not only at our estimates of output gaps but also at a wide range of indicators drawn from the labor, product, and financial markets to provide us with a perspective on the balance of supply and demand in the economy. Most important, the substantial uncertainty in our measures of potential output implies that we need to be cautious about taking on board the implications of our current estimates of the output gap. For example, if inflation is moving in a different direction than the output gap would suggest, then we should take seriously the possibility that our output gap measure is not providing us with reliable information. The bottom line is that we must never take our eye off of the inflation ball. Good policymaking requires that we acknowledge what we are unsure about, and this requirement applies particularly to measures of potential output. References Aaronson, Stephanie, Bruce Fallick, Andrew Figura, Jonathan Pingle, and William Wascher (2006). "The Recent Declines in the Labor Force Participation Rate and Its Implications for Potential Labor Supply,"Brookings Papers on Economic Activity, 1: 2006, pp. 69-154. Altig, David, Terry Fitzgerald, and Peter Rupert (1997). "Okun's Law Revisited: Should We Worry about Low Unemployment?"Economic Commentary, Federal Reserve Bank of Cleveland (May). Apel, Mikael, and Per Jansson (1999). "A Theory-Consistent System Approach for Estimating Potential Output and the NAIRU,"Economics Letters, vol. 64, pp. 271-75. Atkeson, Andrew, and Lee Ohanian (2001). "Are Phillips Curves Useful for Forecasting Inflation?"Federal Reserve Bank of Minneapolis Quarterly Review, vol. 25, no. 1, pp. 2-11. Bean, Charles (2005). "Comment on Bob Hall's 'Separating the Business Cycle from Other Economic Fluctuations'," speech delivered at "The Greenspan Era: Lessons for the Future," a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 25-27.http://www.kansascityfed.org/PUBLICAT/SYMPOS/2005/PDF/Bean2005.pdf (86 KB PDF) Beveridge, Stephen, and Charles R. Nelson (1981). "A New Approach to Decomposition of Economic Time Series into Permanent and Transitory Components with Particular Attention to Measurement of the 'Business Cycle',"Journal of Monetary Economics, vol. 7 (March), pp. 151-74. Blanchard, Olivier, and Jordi Gali (2007). "Real Wage Rigidities and the New Keynesian Model,"Journal of Money, Credit, and Banking, vol. 39 (February), pp. 35-65. Clark, Peter K. (1987). "The Cyclical Component of U.S. Economic Activity,"Quarterly Journal of Economics, vol. 102 (November), pp. 797-814. Cochrane, John H. (1994). "Permanent and Transitory Components of GNP and Stock Prices,"Quarterly Journal of Economics, vol. 109 (February), pp. 241-65. Corrado, Carol, and Lawrence Slifman (1999). "Decomposition of Productivity and Unit Costs,"American Economic Review, vol. 89 (May), pp. 328-32. Dupasquier, Chantal, Alain Guay, and Pierre St-Amant (1999). "A Survey of Alternative Methodologies for Estimating Potential Output and the Output Gap,"Journal of Macroeconomics, vol. 21 (Summer), pp. 577-95. Edge, Rochelle M., Michael T. Kiley, and Jean-Pierre Laforte (2007). "Natural Rate Measures in an Estimated DSGE Model of the U.S. Economy," Finance and Economics Discussion Series 2007-8 (Washington: Board of Governors of the Federal Reserve System, March). Estrella, Arturo, and Frederic S. Mishkin (1999). "Rethinking the Role of NAIRU in Monetary Policy: Implications of Model Formulation and Uncertainty," in John B. Taylor, ed.,Monetary Policy Rules.Chicago: University of Chicago Press, pp. 405-30. Fallick, Bruce, Charles A. Fleischman, and Jonathan Pingle (2006). "How the Graying of the Baby Boom Affects the U.S. Labor Market," inThe Economic Outlook for 2007: Papers Presented at the Fifty-Third Annual Conference on the Economic Outlook.Ann Arbor: University of Michigan, pp. 102-18. Friedman, Milton (1968). "The Role of Monetary Policy,"American Economic Review, vol. 58 (March), pp. 1-17. Goodfriend, Marvin, and Robert G. King (1997). "The New Neoclassical Synthesis and the Role of Monetary Policy," in Ben S. Bernanke and Julio J. Rotemberg, eds.,NBER Macroeconomics Annual, 1997.Cambridge, Mass.: MIT Press, pp. 231-83. Gordon, Robert J. (1982). "Inflation, Flexible Exchange Rates, and the Natural Rate of Unemployment," in Martin Neil Baily, ed.,Workers, Jobs, and Inflation.Washington, D.C.: Brookings Institution, pp. 89-158. Groshen, Erica L., and Simon Potter (2003). "Has Structural Change Contributed to a Jobless Recovery?"Current Issues in Economics and Finance, Federal Reserve Bank of New York, vol. 9 (August). Jorgenson, Dale W., Mun Sing Ho, and Kevin Stiroh (2004). "Will the Productivity Resurgence Continue?"Current Issues in Economics and Finance, Federal Reserve Bank of New York, vol. 10 (December). Kydland, Finn E., and Edward C. Prescott (1982). "Time to Build and Aggregate Fluctuations,"Econometrica, vol. 50 (November), pp. 1354-70. Kuttner, Kenneth N. (1994). "Estimating Potential Output as a Latent Variable,"Journal of Business and Economic Statistics, vol. 12 (July), pp. 361-68. Modigliani, Franco, and Lucas Papademos (1978). "Optimal Demand Policies against Stagflation,"Weltwirtschafliches Archiv, vol. 114, no. 4, pp. 736-82. Neiss, Katharine S., and Edward Nelson (2005). "Inflation Dynamics, Marginal Cost, and the Output Gap: Evidence from Three Countries,"Journal of Money, Credit, and Banking, vol. 37 (December), pp. 1019-45. Okun, Arthur (1962). "Potential GNP: Its Measurement and Significance,"Proceedings of the Business and Economics Section of the American Statistical Association, pp. 98-104. Oliner, Stephen D., and Daniel E. Sichel (2000). "The Resurgence of Growth in the late 1990s: Is Information Technology the Story?"Journal of Economic Perspectives, vol. 14 (Fall), pp. 3-22. Oliner, Stephen D., and Daniel E. Sichel (2002). "Information Technology and Productivity: Where Are We Now and Where Are We Going?"Federal Reserve Bank of Atlanta Economic Review, vol. 87 (3rdQuarter), pp. 15-44. Oliner, Stephen D., Daniel E. Sichel, and Kevin Stiroh (2007). "Explaining a Productive Decade",Brookings Papers on Economic Activity,forthcoming. Orphanides, Athanasios (2001). "Monetary Policy Rules Based on Real-Time Data,"American Economic Review, vol. 91 (September), pp. 964-85. Orphanides, Athanasios, Richard D. Porter, David Reifschneider, Robert Tetlow, and Frederico Finan (2000). "Errors in the Measurement of the Output Gap and the Design of Monetary Policy,"Journal of Economics and Business, vol. 52, (January-April), pp. 117-41. Orphanides, Athanasios, and Simon van Norden (2002). "The Unreliability of Output Gap Estimates in Real Time,"Review of Economics and Statistics, vol. 84 (November), pp. 569-83. Perry, George L. (1970). "Changing Labor Markets and Inflation,"Brookings Papers on Economic Activity, 3: 1970,pp.411-48. Phelps, Edmund S. (1967). "Phillips Curves, Expectations of Inflation, and Optimal Inflation over Time,"Economica, vol. 34 (August), pp. 254-81. Roberts, John M. (2001). "Estimates of the Productivity Trend Using Time-Varying Parameter Techniques," Finance and Economics Discussion Series 2001-8 (Washington, D.C.: Board of Governors of the Federal Reserve Board, February). Rudebusch, Glenn D. (2000). "How Fast Can the New Economy Grow?"FRSBFEconomic Letter2000-05, Federal Reserve Bank of San Francisco, February 25. Staiger, Douglas, James H. Stock, and Mark W. Watson (1997a). "How Precise Are Estimates of the Natural Rate of Unemployment?" in Christina Romer and David Romer, eds.,Reducing Inflation: Motivation and Strategy.Chicago: University of Chicago Press, pp. 195-242. Staiger, Douglas, James H. Stock, and Mark W. Watson (1997b). "The NAIRU, Unemployment, and Monetary Policy,"Journal of Economic Perspectives,vol. 11 (Winter), pp. 33-49. Woodford, Michael (2003).Interest and Prices: Foundations of a Theory of Monetary Policy.Princeton: Princeton University Press. Footnotes 1.I want to thank Andrew Figura, Charles Fleischman, John Roberts, and William Wascher for their helpful comments and assistance on this speech.Return to text 2.The term "NAIRU" comes from a paper by Nobel prize winner Franco Modigliani and Lucas Papademos, now the vice president of the European Central Bank (Modigliani and Papademos, 1978). Although NAIRU and the natural rate of unemployment are frequently used interchangeably, there is a subtle distinction between the two. The natural rate of unemployment is the rate at which inflation would tend to gravitate to its long-run expected value, while NAIRU, as originally defined, is the unemployment rate at which inflation will have no tendency to move up or down. Depending on what shocks are hitting the economy, the NAIRU could deviate from the natural rate of unemployment (for example, see Estrella and Mishkin, 1999). Because the NAIRU terminology is more common than the natural rate of unemployment terminology, I am using the NAIRU terminology even though I think that the natural rate of unemployment terminology is more accurate.Return to text 3.Other examples of the multivariate approach include Apel and Jansson (1999), Cochrane (1994), and Dupasquier, Guay and St-Amant (1999).Return to text 4.Okun's law was originally specified as the relationship between real GDP growth and changes in the unemployment rate (see Okun, 1962).Return to text 5.See Gordon (1982 and many subsequent papers) for a description of the "triangle" model of inflation. The three sides of the triangle are inflation inertia (captured by the lags of inflation), excess demand (measured by the unemployment rate gap or GDP gap), and supply shocks--such as the relative prices of imports, food, and energy. Following George Perry's (1970) early work, it is common to adjust the NAIRU for changes in the composition of the labor force. Fallick, Fleischman, and Pingle (2006) estimate that shifts in the demographic composition of the labor force can explain a decline in the unemployment rate of nearly 1 percentage point between 1977 and 2006.Return to text 6.See, for example, Atkeson and Ohanian (2001).Return to text 7.See, for example, Altig, Fitzgerald, and Rupert (1997), Rudebusch (2000), and Groshen and Potter (2003).Return to text 8.Because official series for productivity for all sectors of the economy are not available, the growth-accounting framework most often focuses on the private nonfarm business (NFB) sector, which in the United States accounts for more than three-quarters of total output. Productivity for the overall economy is then derived from estimates for the nonfarm business sector and then cruder estimates for the other sectors (government, farm, housing services, and households and institutions) generally based on the univariate and multivariate statistical approaches described earlier.Return to text 9.See also Oliner and Sichel (2000, 2002), Corrado and Slifman (1999), and Jorgenson, Ho, and Stiroh (2004), among others.Return to text 10.See, for example, Goodfriend and King (1997) or Woodford (2003).Return to text 11.For example, Blanchard and Gali (2007) have proposed a model with real wage rigidities that, if incorporated into a DSGE model, would likely show output gap estimates that are more similar to traditional gaps.Return to text 12.See, for example, Bean (2005).Return to text 13.See also Orphanides and others, (2000) and Orphanides and van Norden (2002).Return to text
The Federal Reserve Board on Tuesday announced the approval of a final rule that would implement section 601 of the Financial Services Regulatory Relief Act of 2006, which eliminated several statutory reporting and disclosure requirements relating to insider lending by insured depository institutions. The Board proposed and supported eliminating these statutory reporting and disclosure provisions because the federal banking agencies have not found them particularly useful in monitoring insider lending or preventing insider abuse. The final rule amends the Board's Regulation O (12 CFR part 215) to reflect the elimination of these reporting and disclosure requirements. Regulation O implements statutory restrictions on the ability of insured depository institutions to extend credit to their executive officers, directors, principal shareholders, and to related interests of such persons ("insiders"). The final rule does not alter the substantive restrictions on loans by insured depository institutions to their insiders or to insiders of their correspondent banks. The Board's notice is attached.
Vice Chairman Donald L. Kohn At the Federal Reserve Bank of Atlanta's 2007 Financial Markets Conference, Sea Island, Georgia As Chairman Bernanke noted yesterday in hiskeynote address, the development and growth of the credit derivatives markets has implications for a range of public policy objectives. I will focus on the implications for our objectives for financial stability and the containment of systemic risk.1 To formulate appropriate policy responses, we first must identify how credit derivatives might be affecting systemic risk. In considering this question, we need to recognize that credit derivatives are an extension of decades-long trends. The Chicago futures exchanges introduced financial derivatives in the 1970s. Since the early 1980s, over-the-counter (OTC) derivatives have become increasingly important. Over the same period, the securitization of mortgages and other assets has been transforming regulated depository institutions from holders of interest rate and credit risk to originators and distributors of such risk. Perhaps the most significant aspect of credit derivatives has been the marriage of derivatives and securitization technologies in synthetic collateralized debt obligations (CDOs). There are good reasons to think that these developments have made the financial system more resilient to shocks originating in the real economy and have made the economy less vulnerable to shocks that start in the financial system. Borrowers have a greater variety of credit sources and are less vulnerable to the disruption of any one credit channel; risk is dispersed more broadly to people who are most willing to hold and manage it. One can see the effects of these changes in the reduced incidence of financial crises in recent years. From the 1970s through the early 1990s, we seemed to be in almost continuous crisis mode. These crises were centered on depository institutions, and because borrowers were so dependent on depository institutions for credit availability, problems at depository institutions meant problems for the financial system and for the economy more generally. To be sure, much, perhaps most, of the improvement has been due to the better performance of the overall economy--low and stable inflation and damped business cycles since the early 1980s. In addition, financial stability has been greatly enhanced by improvements in bank capital regulation that were implemented in the late 1980s and after the crisis in the early 1990s. But greater diversification of risk has also contributed significantly; we could see this in the 2001-03 period, when a sharp decline in equity prices, a spike in spreads on corporate debt, and unanticipated business failures did not threaten depository institutions or the broader financial system. But we certainly should not read this experience as meaning that we are free of systemic risk--the risk of financial-sector problems spilling into the real sector or aggravating already difficult economic circumstances. Indeed, I see several reasons for carefully considering the potential for such problems to emerge. New players and new instruments have become important since 2002, when the last adverse credit cycle peaked. New and already existing market participants are maneuvering for greater shares in a rapidly evolving market structure. Although leverage has declined in the nonfinancial businesses whose credit is being priced and traded, it may well have increased in the structure of intermediary finance. In any event, the growth of tranched CDOs and other structured credit products with substantial embedded leverage has made it more difficult to assess the degree of leverage of individual institutions or of the financial system as a whole. In addition, the extraordinarily rapid growth of credit derivatives markets in the past few years has occurred against the backdrop of relatively benign macroeconomic performance--good global growth, low inflation, historically high corporate profits and low business failures, and reasonably predictable monetary policies. Partly as a consequence, the prices of financial assets seem to embody relatively low expected volatilities and relatively little reward for taking credit risk or for extending the duration of investor portfolios. With more risk traded in markets and more participants managing that risk through portfolio adjustments made in markets, the importance of market liquidity has increased and the potential knock-on effects from an erosion of liquidity have multiplied. We could face situations in which asset price movements are exacerbated by the actions of market participants, including dynamic hedging strategies or forced liquidations of assets to meet margin calls, and those asset price movements could feed back onto the economy. Moreover, the layers of intermediation between borrower and lender that increasingly characterize the financial system may have created new channels for the transmission of shocks within the financial markets and into the economy. We have seen some indications of this in the recent experience in the subprime mortgage market. Packagers of securities whose performance is tied to subprime mortgages have suffered unanticipated losses, and as some originators have gone out of business and secondary markets have been disrupted, institutions along the chain have found themselves with unexpected exposures from warehousing or financing the holding of loans before securitization. However, thus far the dramatic widening of spreads on the riskier tranches of subprime securitizations has not produced spillovers large enough to threaten stability. Finally, although risks are better dispersed, the credit-risk transfer markets are dependent on a small set of key intermediaries. In the extreme, price variations and other adverse developments could call into question the viability of these intermediaries, threatening a larger cumulative real effect. In short, systemic risk in the financial markets most likely has declined on balance, but it still exists, and central banks and other regulators need to adapt to the evolving nature of markets and the changing character of the systemic risk. Before discussing what we are doing and what we should be doing, I want to take a few minutes to call attention to some limits and constraints on our actions. We need to accept that accidents will happen--that asset prices will fluctuate, often over wide ranges, and those fluctuations will be driven in part by trading strategies, by the cycles of greed and fear that have always been with us, and by the ebb and flow of competition for market share. The fluctuations will result in redistributions of wealth and, on occasion, will confront us with financial crises. But we cannot and should not try to prevent this process through a monetary policy that puts special emphasis on stabilizing asset prices or through regulatory policies that limit access to markets by qualified participants or that attempt to restrain competition materially. Monetary policy that proactively leans against asset price movements runs a considerable risk of yielding macroeconomic results that fall short of maximum sustainable growth and price stability. Regulatory policies that try to prevent failures of core participants or others under all conceivable circumstances will tend to stifle innovation and reduce our economy's potential for long-run growth. Systemic events in market-based financial systems are perhaps more likely to involve price fluctuations and abrupt changes in market liquidity than are systemic events in depository-based financial systems. But that is not really bad news because such events can more readily be countered by macroeconomic policy instruments than could old-fashioned crises of depository intermediation. Supplying additional liquidity and reducing borrowing costs can greatly ameliorate the effects of market events on the economy, and those types of macroeconomic interventions will carry less potential for increasing moral hazard than would the discount window lending that was a prominent feature of crisis management when depositories funded more credit. Market-intermediated finance also requires us to live with less control and less knowledge than we had when banks were dominant. Greater uncertainty about where risks are lodged is the flip side of better dispersion of those risks, especially to less regulated sectors, and of more resilience of the whole system. Gathering additional information about the risk profiles of currently less regulated institutions is unlikely to yield insights that can be acted upon and may create a false sense of comfort among market participants, which could make the system substantially more risky. We need to have confidence in the invisible hand. But confidence does not mean blind faith, a thought that brings me to what we can productively do to reduce systemic risks within the boundaries that I just described. Although credit derivatives and other derivatives have facilitated the dispersion of risk, the mechanisms for carrying out this function are highly dependent on a small number of institutions that are critical to the functioning of the markets. These institutions are the principal dealers in the OTC derivatives markets and often also among the leading clearing firms for exchange-traded derivatives. They also originate securitized assets, and provide financing to other originators, and often provide financing to the buyers of those assets, including buyers of the riskiest tranches. If their ability to perform these functions were impaired when a shock hit the economy or the financial markets, the ability of the buyers and sellers to manage their positions, provide trading liquidity, and facilitate stabilizing financial flows would in turn be impaired. Consequently, our efforts to manage the potential for systemic risk focus on these core institutions, nearly all of which already are subject to prudential supervision. In light of the possibility of unusual asset price movements, which I discussed earlier, we need to encourage these institutions to practice robust enterprise-wide risk management. A critical aspect of such risk-management efforts is the use of stress tests across the various aspects of their businesses that allow them to ascertain and appropriately limit their market and counterparty exposures in a scenario in which credit spreads widen rapidly and asset market liquidity decreases markedly. Good risk management can limit potential losses under many circumstances, but these institutions will still be vulnerable to major unexpected events, and their viability will depend on their capital cushions. As a consequence, we also need to strengthen the connection of capital to risk by moving forward with the implementation of Basel II. We should also work toward ensuring that clearing and settlement arrangements on which core institutions and other participants depend are safe and efficient. Weaknesses in such systems can be a source of systemic contagion. Conversely, when such arrangements are robust, the potential for contagion is significantly diminished. The benefits of such supervisory initiatives can extend beyond the core regulated institutions themselves because improvements in their counterparty-risk-management practices will strengthen market discipline on their unregulated counterparties. Although the critical roles that these core institutions play in global markets require us to focus on them, we need to address the possibility that this approach could increase moral hazard by reinforcing perceptions that these institutions are too big to fail. This risk can be mitigated by the steps that I have mentioned earlier, including the promotion of enhanced risk-management practices and the implementation of capital requirements that are more risk sensitive, steps that greatly reduce the chances that government intervention will be needed. In all of this work, coordination and cooperation among regulators, domestically and internationally, are critical because the same firms are the core firms in each of the principal global financial centers. Effective oversight of these firms generally can be conducted only by the home country supervisor, which alone has the authority over a firm's consolidated global operations. When supervisory coordination and cooperation exist, much good work can be accomplished relatively quickly. An excellent example is the work that the Federal Reserve Bank of New York and other prudential supervisors have undertaken over the past year and a half to encourage and support market participants' progress in addressing what were serious weaknesses in the infrastructure of the credit derivatives markets. Those supervisors are now systematically reviewing the core firms' management of counterparty exposures to hedge funds and other highly leveraged counterparties. Both market participants and public authorities should understand that, despite our best efforts, crises are inevitable, and so we need to work on crisis management as well. Here, too, cooperation among authorities here and abroad is critical. We must understand the market structures and vulnerabilities and the objectives and constraints under which authorities with different jurisdictions would be working in those circumstances. Inevitably, uncertainty on the part of market participants and public authorities will be heightened in the event of market turmoil, and that uncertainty can feed on itself. Both authorities and participants need to think through how they will handle such crises. For the authorities, that process includes considering how to resolve any failures of large institutions in ways that impose costs on shareholders and uninsured liability holders while preserving orderly markets. Such a resolution will be necessary to limit the moral hazard of any interventions that we are forced to undertake. Market participants need to consider how they would settle contracts and work with troubled borrowers in a distress situation. More planning will reduce the rise in uncertainty in a crisis and the likelihood that fear will lead to precipitous actions that are in no one's best interest. In sum, there are good reasons to think that financial innovation over the past few decades, including the emergence and growth of the credit derivatives markets, has made the financial system and the economy more resilient. But it would be foolish to think that these innovations have eliminated systemic risk. Both market participants and public authorities need to think carefully about how systemic risks might crystallize in the new world that credit derivatives have helped create. They need to identify the implications for risk management and ensure that risk-management practices are adapting to target new sources of risk. And they need to think about how they would respond to crises that sooner or later will emerge in that new world. Footnotes 1.The views expressed are my own and do not necessarily reflect those of the other members of the Board.Return to text
The Federal Open Market Committee decided today to keep its target for the federal funds rate at 5-1/4 percent. Economic growth slowed in the first part of this year and the adjustment in the housing sector is ongoing. Nevertheless, the economy seems likely to expand at a moderate pace over coming quarters. Core inflation remains somewhat elevated. Although inflation pressures seem likely to moderate over time, the high level of resource utilization has the potential to sustain those pressures. In these circumstances, the Committee's predominant policy concern remains the risk that inflation will fail to moderate as expected. Future policy adjustments will depend on the evolution of the outlook for both inflation and economic growth, as implied by incoming information. Voting for the FOMC monetary policy action were: Ben S. Bernanke, Chairman; Timothy F. Geithner, Vice Chairman; Thomas M. Hoenig; Donald L. Kohn; Randall S. Kroszner; Cathy E. Minehan; Frederic S. Mishkin; Michael H. Moskow; William Poole; and Kevin M. Warsh.
Governor Randall S. Kroszner At the Center for Financial Stability (CEF), Buenos Aires, Argentina I am delighted to be back in Argentina. Today I want to talk about some important macroeconomic and financial developments around the world. Inflation rates and interest rates are at historically low levels, and yield curves are relatively flat nearly everywhere. In addition, until recently, many emerging-market countries simply did not have yield curves because there was effectively no market for debt issued in the domestic currency beyond a very short term. I believe that the taming of inflation and the improved credibility of monetary policy have been crucial to the deepening of domestic capital markets, which is typically associated with higher economic growth. I will explore some possible explanations for these developments, focusing on the prospects for, and risks to, the long-term inflation outlook, particularly in emerging-market economies. Before I continue, please note that the opinions I express here today are my own and not necessarily shared by my colleagues on the Federal Open Market Committee.1 In brief, I argue that globalization, deregulation, and financial innovation, in part spurred by the experiences of high inflation in the 1980s, have fostered currency competition that has led to improved central bank performance and, hence, the recent reduction of worldwide inflation. Writing in the 1970s, Friedrich Hayek advocated greater competition among currencies, arguing that it would produce a race to the top rather than a race to the bottom.2In practice, regardless of what one might think of Hayek's policy proposals, we have seen increased competition among currencies issued by central banks owing to technological change in a globalized and competitive marketplace. The increased competition among currencies has changed the ability and the incentives of governments and central banks to pursue high-inflation policies. Such changes have allowed improvements in central bank governance and credibility, thereby leading to better inflation outcomes, especially in many emerging-market economies. In addition, greater central bank credibility has allowed the development of long-term bond markets in many countries and flattened yield curves around the globe as concerns about future inflation risks have declined. Deeper bond markets with a wider range of available maturities encourage long-term planning and investment and thus convey lasting gains, particularly in emerging markets. The important issue is whether the reduction of worldwide inflation will persist or be a temporary phenomenon. The Worldwide Decline in Inflation From the 1950s until the late 1960s, inflation rates were relatively contained, and episodes of high inflation were rare. Then, especially following the early-1970s collapse of the Bretton Woods fixed-exchange-rate system, inflation became a worldwide phenomenon. Even in Germany, which had the most stable prices of any country in the world, inflation eroded purchasing power by more than half between 1972 and the launch of the euro, in 1999. In terms of cumulative inflation, $480 would be required today in the United States to purchase $100 worth of goods and services at 1972 prices. For most countries reporting data to the International Monetary Fund (IMF), cumulative inflation has been even higher than that experienced in the United States. Here in Argentina, the price level is now about 177 billion times higher than it was in 1972. But Brazil takes the prize for greatest inflation of the post-World War II era: The price level in Brazil is approximately 500 billion times higher today than it was in 1972.3 Since the early 1990s, however, worldwide inflation has significantly declined. Indeed, the April 2006 issue of the IMF'sWorld Economic Outlookshows that, on average, inflation rates in the advanced economies as well as in the developing countries in recent years have been at their lowest levels since at least the early 1970s. The April 2007 issue forecasts inflation in both regions to remain near these recent lows through 2008. But is this lower inflation regime likely to persist? One way to approach this issue is to investigate what market participants think by examining measures of expected inflation. Overall, these surveys suggest that market participants do expect relatively low inflation to continue in most major industrial and emerging-market countries. In the industrial countries and a few Asian emerging-market economies, for example, long-term inflation expectations dropped below 5 percent a decade or more ago and are currently around 2 percent to 3 percent.4In Brazil and Mexico, long-term inflation expectations have declined from a range of 7 percent to 10 percent a decade ago to a fairly steady 3 percent to 4 percent in recent years. In Argentina, long-term inflation expectations are around 7 percent. In addition, the risks of high inflation appear to have decreased as well. In particular, the volatility of inflation has declined notably, especially in many emerging- market countries.5On occasion in the early to middle 1990s, the standard deviation of inflation exceeded 30 percent in Mexico and 100 percent in Argentina and Brazil. In the current decade, however, the standard deviation of inflation has been relatively stable in Brazil, at around 5 percent, and it has been declining in Mexico, where it is now around 2 percent. In Argentina, inflation volatility is currently around 15 percent. Factors Behind the Taming of Worldwide Inflation My brief review of worldwide inflation performance suggests that in general, over the past decade, inflation has become substantially lower and less volatile, and expectations of future inflation have also become substantially lower. In understanding the key factors behind this change, we can also shed further light on the question of whether this low-inflation regime will persist. In a nutshell, I believe that the factors of globalization, deregulation, and financial innovation, arising partly in response to episodes of high inflation, have effectively eroded the central bank monopoly on the provision of monetary services and have enhanced global competition among currencies. These changes have, in turn, altered the incentives for central banks to behave badly and for finance ministries to use central banks as "piggy banks" to finance their fiscal policies. The resulting constraint on monetary policy, combined with increased public understanding of the costs of inflation, have led to institutional changes in central bank governance that bolster their credibility for maintaining price stability in the future. Thus, improved central bank performance and credibility are the consequences of this combination of factors. To develop this explanation in more detail, I will start by describing how globalization, deregulation, and innovation can alter the ability and incentives of a government to pursue a high-inflation policy.6These factors are closely related and mutually reinforcing in many respects. Many countries have turned increasingly to private markets and trade to deliver growth and progress. The resulting deregulation and greater openness has boosted innovation and has helped increase global competition, or globalization, by shrinking the barriers of time and distance. Accordingly, trade and financial linkages between countries have soared to record levels in recent years. How does this affect inflation? When governments resort to printing money to finance their spending, inflation rises and nominal assets lose their value. This loss of value is also known as the inflation tax. Globalization, deregulation, and innovation make it easier for citizens to move their wealth out of nominal assets in the domestic currency should their government resort to an inflation tax. When the tax base shrinks in response to inflation, governments have a reduced incentive to resort to the inflation tax. The specific channels by which globalization, deregulation, and financial innovation affect competition among currencies are many. Increased circulation of banknotes in dollars or other hard currencies enable citizens to conduct transactions and store liquid wealth without holding inflationary currency. The fraction of U.S. currency estimated to be held in foreign countries rose dramatically over the 1980s and 1990s, from less than 20 percent to about 60 percent, and it has remained near this high level even as inflation rates have come down globally. Substantial financial innovations--including advances in electronic payment and trading systems as well as more widespread credit card networks and increased use of mutual funds--have enabled consumers, investors, and banks to shift wealth cheaply and quickly away from currencies and assets subject to inflation and related risks. Given the stronger competition among currencies, a government that pressures a central bank to pursue an inflationary policy gets much less benefit from increased inflation because people can more rapidly and conveniently switch out of the domestic currency. Indeed, the website of the Central Bank of Brazil explicitly acknowledges the role of inflation in driving financial innovations that enabled firms and households to economize on cash balances in that country. It states that, "Prior to the mid-1990s [when inflation was stabilized], changes in the payment system in Brazil were motivated by the need to cope with high inflation rates. During that time, the system achieved significant technological progress, especially aimed at enhancing the speed of processing financial transactions."7 In addition to encouraging financial innovation, the painful experience of high inflation helped to educate the public and economists about the costs of inflation.8Although the specific experiences differed across countries, public opinion almost everywhere eventually reinforced the trend against inflationary policies. Economists and central bankers also devoted great attention to understanding the causes and consequences of inflation, providing the intellectual underpinning to policies oriented toward price stability. The fundamental forces I have described today--globalization, deregulation, financial innovation, and public understanding about the costs of inflation--provided the impetus for fighting inflation and opened the path for policies that enhance central bank credibility. As the benefits of stable prices accrue and as financial markets deepen and become more sophisticated, the benefits of sound economic policies will help create support for institutional reforms that make returning to inflation harder--albeit not impossible--for future governments. Implications of Low Inflation for Bond Markets What are the implications of low inflation and low inflation volatility for interest rates and yield curves? I believe that market confidence in continued low inflation has helped drive down the slope of the yield curve around the world by reducing the premium demanded for holding long-term nominal assets. The taming of inflation also has extended bond maturities and yield curves further into the future than ever before, most notably in many emerging-market countries. The current low level of long-term yields in the United States and other advanced economies is widely acknowledged as somewhat of a puzzle, or, as some have called it, a conundrum.9Of course, flat and even inverted yield curves in advanced economies are nothing new--we know that the short end of the yield curve is dominated by monetary policy and cyclical factors. To abstract from the potential effect of cyclical factors on the yield curve, consider the pattern of forward rates many years into the future, at which point the effects of current cyclical shocks would be expected to have dissipated. The yield on a ten-year bond, for instance, can be thought of as an average of a series of consecutive forward rates. If you could borrow and lend at the same rate as the U.S. Treasury, then you could lock in a three-month loan ten years from now by borrowing for ten years and three months and simultaneously lending the same principal for ten years. The difference between the interest you pay and the interest you earn on this transaction determines the implied forward rate ten years from today. The forward rate reflects not only the market expectation of the future short-term interest rate but also a "term premium" to compensate for the risk of a commitment to extend credit so far in the future, including the risk of future inflation. At any point in time, then, we can calculate the short-term forward rate ten years ahead using the yield curve of U.S. Treasury coupon securities. This "far forward" rate has hovered around 4-1/2 percent to 5 percent over the past two years, a level about 2 percentage points below its average since 1990. Far-forward rates in other advanced economies have also declined over the past decade and are currently at or near historic lows.10 To some extent, low forward rates may reflect a persistent decline in expected future real rates of interest or in the real term premium. Chairman Bernanke has suggested that an excess of ex ante global saving relative to global investment has held down real interest rates around the world.11Some of the factors behind this excess of saving over investment include the surge in revenues of oil and commodity exporters, a retreat in Asian investment demand from the boom that preceded the late 1990s, and a reduction in fiscal deficits in some Latin American countries. But these low bond yields also have a nominal aspect. The declines in inflation rates, in the volatility of inflation, and in long-term inflation expectations all point to a reduction in the compensation required by investors for the effects of future inflation on the returns to holding long-term bonds. This development is particularly remarkable in many emerging-market countries, in which longer-dated fixed-coupon bonds issued in domestic currencies had ceased to exist during the inflationary 1970s and 1980s. The recent lengthening of maturities of domestic-currency debt has, in many cases, not only extended the yield curve but--and this is one of the key results of the taming of inflation--effectively created a domestic-currency yield curve that previously did not exist. Since 2000, ten-year nominal fixed-coupon bonds in the domestic currency have been introduced in Brazil, Chile, Colombia, Indonesia, Mexico, and Russia. Korea and Thailand introduced ten-year fixed-coupon bonds in their respective currencies in the 1990s. Last year the government of Mexico issued a thirty-year fixed-coupon bond in pesos for the first time. The proportion of domestic-currency debt in Mexico maturing within one year was nearly 90 percent in 2002 and is now less than 75 percent.12The Korean government continues to increase the proportion of its domestic-currency debt in longer maturities, with the one-year-and-under segment falling from roughly one-half in 1999 to less than one-fifth by the end of last year. Moreover, maturity extension is not limited to emerging-market countries. France and the United Kingdom, for example, issued fifty-year bonds in 2005. Besides the fact that yield curves have been extended in many countries, they have also been relatively low and flat worldwide, at least in part because of the decline in inflation. The flattening or slight inversion of yield curves in the major industrial economies, such as the United States, Japan, the euro area, the United Kingdom, and Canada is well known. For example, ten-year yields in the euro area are less than 25 basis points higher than three-month yields, and the yield curve is currently downward sloping in the United Kingdom. At the same time that maturities have been extended, bond yields in the domestic currencies of emerging-market countries have also declined. It is perhaps not surprising that, given the high rates of saving and generally high level of development in their economies, the governments of Hong Kong and Korea can borrow at levels close to those in the advanced economies. More notable, however, is that the Mexican government can borrow in pesos at a thirty-year maturity at roughly 8 percent. Although Mexico is perhaps the most striking example, it is not alone. Other middle-income emerging-market countries with single-digit yields on fixed-rate ten-year bonds in the domestic currency include Chile, Colombia, Malaysia, Russia, South Africa, and Thailand, to name but a few. The computation of forward rates for most of these countries is difficult because of the relative sparseness of the maturity distribution, but for those countries in which five-year forward rates can be computed, they have been declining and have reached very low levels in the past year or so. Overall, the combination of lower and less volatile inflation worldwide has reduced inflation expectations and perceived inflation risk and resulted in a lower premium in long rates for inflation uncertainty. I believe that these factors have been key contributors to the lower long-term yields and the flattening of yield curves, particularly in emerging markets. The establishment of markets for long-term nominal government and corporate debt in countries in which they did not exist a decade ago is powerful evidence of the faith that investors place in a future environment of price stability. Broader Economic Benefits The economic benefits of price stability are too numerous and well known for me to cover here in detail. Long-run price stability certainly is essential for achieving maximum employment. However, I would like to underscore some often-overlooked benefits related to the development of markets for long-term bonds. Price stability boosts growth by deepening financial markets. Given stable prices, savers and investors have more confidence about the ultimate value of their investments and are more willing to enter long-term financial contracts. A number of studies have concluded that the development of banking and financial markets is a key driver of economic growth. Thus, greater central bank credibility, which permits more development of local financial markets, can have an economic benefit beyond the financial sector.13 The increasing issuance of local-currency bonds is leading to an improved distribution of risk. When emerging-market countries borrowed mostly in dollars or other foreign currency, they bore the exchange rate risk while lenders bore default risk. This was a key reason why currency crises of the past few decades were so costly: Sharp depreciations of the exchange rate boosted the domestic-currency value of foreign debt and wreaked havoc with government finances and corporate balance sheets. With reduced reliance on foreign-currency borrowing, emerging-market economies should be able to weather future storms with less disruption than in the past. The development of long-term domestic-currency bond markets is one of the factors that help lower the costs of long-term planning and enhance the ability to undertake long-term investments In particular, investment decisions are less likely to be constrained by having only short-term financing available for longer-term projects, thereby allowing improved decisionmaking for governments, firms, and individuals. These improvements enhance the prospects of economic development. Higher and more-stable growth combined with a better ability to undertake long-term plans can also improve the fiscal outlook for a country. A better fiscal outlook, in turn, increases confidence, facilitates financial market development, and thus further boosts growth. And, in a virtuous cycle, it reinforces prospects for continued price stability. More-prudent fiscal policies, including lower deficits, longer debt maturities, and reduced foreign-currency debt can reduce the likelihood and potential severity of financial crises. These policies make the financial positions of emerging-market governments less vulnerable to movements in interest rates and exchange rates. A reduction in the perceived risk that a government may not be able to service its debts makes changes in investor sentiment and financial contagion less likely, thereby reducing financial market volatility. Maintaining Progress I have argued that globalization, deregulation, and financial innovation, in part spurred by recent experiences of high inflation, have fostered currency competition that has led to improved central bank performance and, hence, the reduction of inflation worldwide. The resulting enhancement of central bank governance and credibility has allowed the development of long-term bond markets in many countries and the flattening of yield curves around the globe. I want to conclude by returning to the question of whether these phenomena are likely to persist. Globalization and innovation are genies that may prove difficult to put back in their bottles. Nonetheless, although I am an optimist, I would be remiss if I did not point out some risks. In particular, deregulation and global competition may be subject to change. The difficulty of reaching agreement in the Doha Round of trade negotiations highlights the risk of renewed protectionism and backtracking on deregulation. Trade barriers and regulations are anathema to globalization and competition. Barriers to the free flow of goods, services, capital, and technology would also diminish the force of innovation that has been so beneficial in the struggle against inflation. Transaction taxes and administrative barriers may hinder the development and liquidity of bond markets, and much progress that is still required in many emerging-market countries on these fronts. High inflation can destroy an economy and result in enormous hardship for everyone involved, as Argentina painfully experienced not long ago. The benefits achieved through more-stable prices are substantial. Fortunately, economic forces have led to better central bank behavior around the world during the past decade. If citizens and politicians lose sight of these benefits, and the forces that have led to enhanced currency competition are thwarted, these gains could prove fleeting. I believe that we must continue to work hard to lock in the gains achieved so far. The lessons of the high- inflation episodes are too important to forget. Footnotes 1.Joseph E. Gagnon, of the Board's Division of International Finance, contributed to this speech, portions of which draw on Randall S. Kroszner (2006), "The Conquest of Worldwide Inflation: Currency Competition and Its Implications for Interest Rates and the Yield Curve," speech delivered at the Cato Institute Monetary Policy Conference, Washington, November 16, www.federalreserve.gov/newsevents/speech/kroszner20061116a.htm.Return to text 2.Friederich A. von Hayek (1976),Denationalisation of Money: The Argument Refined: An Analysis of the Theory and Practice of Concurrent Currencies(London: Institute of Economic Affairs).Return to text 3.Data for Germany based on 1972-88 changes in consumer prices, and data for the United States, Argentina, and Brazil based on 1972-2006 changes; IMF (various years),International Financial Statistics(Washington: IMF).Return to text 4.Long-term forecasts refer to forecasts six to ten years ahead from the April and October surveys of Consensus Economics,www.consensuseconomics.com.Return to text 5.Volatility is defined as the twenty-quarter rolling standard deviation of annualized inflation.Return to text 6.This section draws on aspects of Randall S. Kroszner (2003), "Currency Competition in the Digital Age," in David E. Altig and Bruce D. Smith, eds.,Evolution and Procedures in Central Banking(New York: Cambridge University Press), pp. 275-99; and Randall S. Kroszner (2006), "Why Are Yield Curves So Flat and Long Rates So Low Globally?" speech delivered at the Institute of International Bankers, New York, June 16, www.federalreserve.gov/newsevents/speech/kroszner20060615a.htm. Kenneth Rogoff has proposed another effect of globalization on inflation. According to Rogoff, greater competition leads not only to lower but also to more-flexible prices. When prices are more flexible, a central bank's ability to temporarily influence output is diminished, and its influence on inflation is enhanced. Thus, more-competitive markets naturally help central banks achieve price stabilization. Kenneth S. Rogoff (2003), "Globalization and Global Disinflation," inMonetary Policy and Uncertainty: Adapting to a Changing Economy, a symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyo. (Kansas City: the Reserve Bank), pp. 77-112.Return to text 7.www.bcb.gov.br/?PAYSYSREFORMReturn to text 8.This hypothesis was raised in the discussion of Rogoff, "Globalization and Global Disinflation," pp. 119-30. Evidence that voters in Latin America in recent years have punished politicians for bad inflation outcomes is in Eduardo Lora and Mauricio Oliveira (2005), "The Electoral Consequences of the Washington Consensus,"Economia, vol. 5 (Spring), pp. 1-61.Return to text 9.Alan Greenspan (2005), statement before the Committee on Banking, Housing, and Urban Affairs, U.S. Senate, February 16,www.federalreserve.gov/boarddocs/hh/2005/february/testimony.htm.Return to text 10.Although far-forward rates in yen are up about 1 percentage point from the historical lows associated with the Japanese deflation scares of 1998 and 2003, they are obviously still low in historical context.Return to text 11.Ben S. Bernanke (2005), "The Global Saving Glut and the U.S. Current Account Deficit," Sandridge Lecture at the Virginia Association of Economists, March 10, www.federalreserve.gov/boarddocs/speeches/2005/200503102.Return to text 12.I have included floating-rate debt in the one-year maturity category.Return to text 13.Refer to Ross Levine (2005), "Finance and Growth: Theory and Evidence," in Philippe Aghion and Steven Durlauf, eds.,Handbook of Economic Growth(New York: Elsevier); and Randall S. Kroszner and Philip E. Strahan (2006), "Regulation and Deregulation of the U.S. Banking Industry: Causes, Consequences, and Implications for the Future," unpublished paper.Return to text
Governor Randall S. Kroszner At the Central de la Republica Argentina (BCRA) Seminar, Central Bank of Argentina, Buenos Aires, Argentina I am delighted to be here in Buenos Aires at a sister central bank, the Banco Central de la República Argentina.1The topic of my discussion today--international capital flows--is sure to be of interest to any student of Argentina's economic history. As in all countries, the evolution of the Argentine economy has been conditioned fundamentally by the nation's own framework of laws, policies, and social practices. Nevertheless, the progression of economic developments in Argentina has always been intertwined with developments in global capital markets, and that connection will likely persist as Argentina continues to open up to the world economy. I will start by identifying three interrelated aspects of international capital flows in today's global economy. First, the scale of gross capital flows throughout the world is expanding, reflecting financial innovation, lowered barriers to capital movements, and a decline in what economists refer to as "home bias." Second, increased capital mobility is making it possible to finance ever larger current account deficits, and, indeed, these deficits have grown in recent years relative to the size of the global economy. Finally, in the aggregate, we see that capital has been flowing, on net, from emerging-market economies to industrial countries in recent years, the reverse of the pattern in previous decades.2 I would like to focus on the last of these features--the flow of capital between developing and industrial countries. We will see that the aggregate data obscure important features of the flow of capital between the two global regions. After discussing various explanations for the net flow of capital to industrial countries, I will address the steps that emerging-market economies can take to enhance their prospects for capital formation and financial investment. I will also touch on changes in emerging-market financing and how this has altered the distribution of risks in the global financial system. Please note that the opinions I'll be expressing today are my own and not necessarily those of my colleagues on the Federal Open Market Committee. The Scale and Composition of Capital FlowsLet's begin by getting some sense of the size, source, and composition of the net capital flows that are moving from developing to industrial countries. One reasonable measure of the size of these flows is the combined current account balance of the developing economies. According to estimates by the International Monetary Fund (IMF), the developing economies as a group had a current account surplus of $640 billion last year (IMF, 2007a).3Because the financial counterpart to this surplus is a deficit on the financial accounts, it represents the net capital outflow to the industrial economies. $640 billion is a big number and stands in sharp contrast to the situation preceding the Asia crisis. For example, in 1996 the combined current account balance of the developing economies was a deficit of $80 billion, representing a capital inflow of that amount from the industrial world. The sources of the $640 billion in net capital flow out of the developing economies are remarkably concentrated. Of those developing economies running current account surpluses, a mere seventeen of them--China, four other Asian economies, Russia, and eleven members of the Organization of Petroleum Exporting Countries--accounted for a combined surplus of $710 billion. And about half of that was generated by the major oil-exporting countries in the Middle East and by Russia, whose surpluses ballooned in the past several years as oil prices soared. Thus, the other 131 developing economies in our data had a combined current account deficit, or net capital inflow, of $70 billion. This is not to say that things have not changed for these 131 countries in the past decade: In 1996, their combined current account deficit was twice as large as it was last year. That's the big picture in terms of the size and country source of last year's net capital flows. Let's dig a little deeper and take a look at the gross capital inflows and outflows that constitute these net figures. Unfortunately, the information on gross capital flows is not as timely as that for the current account, and the data sets are not as consistent as we might like. Nonetheless, the estimates we have are informative and, again, a bit surprising. For example, for 2005, the latest year for which we have reasonably complete data, the developing economies as a group reported a gross capital inflow of $720 billion, more than double the inflow recorded for 1996 (IMF, 2007b). So how did we end up with a switch to net outflows? In 2005, gross capital outflows from the developing economies totaled almost $1.2 trillion--more than atriplingof the 1996 figure. Thus, we see that the question we have to answer is not, "Why has capital stopped flowing from the industrial countries to the developing economies?" In gross terms it has not stopped; in fact, the flow has accelerated! The question instead is, "Why are the developing economies investing so much in the industrial countries?" In a moment I will turn to several explanations for the recent pattern of capital flows. Before doing that, however, we should take one additional insight from the gross figures: Of the gross capital outflow from the developing economies in 2005, fully half reflects the further accumulation of foreign exchange reserves by the official sector. To be sure, a large part of this reserve accumulation was by the seventeen economies singled out earlier as large capital exporters (IMF, 2007c). But the other 131 economies also recorded substantial reserve accumulations. Once we put aside these official reserve flows, it turns out that, in 2005, private capital flowed, on net, from the industrial economies to the developing economies. Why Is Capital Flowing Uphill? Why Does it Matter?Recognizing that the aggregate data lump together the very different circumstances of different economies, it is still true that, on the whole, net capital is flowing from the developing to the industrial world. Economists sometimes refer to this phenomenon as capital flowing "uphill" because it appears to contradict economic logic (See Prasad, Rajan, and Subramanian, 2006). There are two elements of that logic. First, in developing economies, labor is generally much more available than capital; accordingly, capital should in principle be more productive in these economies and should thus flow there from the relatively labor-scarce industrial countries. Second, the relatively rapid income growth expected by developing economies as they catch up to industrial countries should provide them with incentives to borrow against their expected higher future incomes. These considerations lead economists to puzzle over both the net outflow of capital from the developing economies and its implications for the global economy. One approach to explaining the uphill flow of capital focuses on divergent patterns of growth and investment. According to one such view, the rise in U.S. productivity growth since the mid-1990s boosted perceived rates of return on U.S. assets and thus attracted capital; expectations of higher rates of return and higher incomes likely boosted U.S. investment and consumption spending as well (Erceg, Guerrieri, and Gust, 2006; Ferguson, 2005). A complementary explanation, labeled the "global saving glut" by Federal Reserve Chairman Bernanke several years ago, argues that during the past decade, declines in investment spending outside the United States--in part because of emerging-market crises--led to a surplus of saving over investment abroad that was channeled toward the U.S. economy (Bernanke, 2005; Gruber and Kamin, forthcoming). The global saving glut argument suggests that developing economies have benefited from the recent pattern of global capital flows, gaining both demand for their products and a safe return on their assets at a time when an investment slump threatened to depress domestic activity and rates of return. The implications of the U.S. productivity story are a little harder to read, but developing economies, especially in Asia, likely have benefited from the expansion of investment and production opportunities created by the revolution in information technology. Neither the global saving glut nor the U.S. advantage in productivity growth, however, can be expected to persist indefinitely. How long the differences will persist depends upon a number of factors. In rapidly developing countries that have had high savings rates such as China, for example, consumption demand is likely to increase as they grow wealthier, thereby reducing their savings rates. Concerning productivity differences, it may require more than simply the diffusion and adoption of information technology around the globe. As I will come back to later, flexible labor, product, and financial markets appear to be crucial to reaping the full benefits of the information technology revolution, so national policy choices will play an important role in maintaining or closing productivity differences. In any event, this set of explanations for the uphill flow of capital suggests that it would be likely and desirable for net capital flows to reverse direction and head back toward the developing economies at some point. A second--but not mutually exclusive--set of explanations for this phenomenon focuses on what might be more-persistent, structural differences between developing and industrial economies. The financial systems in many developing nations are relatively weak and are not effective at directing saving toward appropriate investment projects. That failing leads to inadequate investment, particularly if business activity is further impeded by inadequate property rights and faulty regulations. As a result, excess saving flows to countries with better financial systems (Prasad, Rajan, and Subramanian, 2006; Ju and Wei, 2006). A closely related point is that, compared with developing economies, industrial countries are believed to produce financial assets that are safer, less volatile, and more liquid, advantages that also draw capital out of developing economies (Caballero, Farhi, and Gourinchas, 2006; Mendoza, Quadrini, and Rios-Rull, 2007). These considerations suggest that the current pattern of international capital flows represents a win-win scenario: Developing economies gain access to better financial services, and industrial economies enjoy the larger quantities of imports they can purchase with this financing. These explanations also suggest that the uphill flow of capital will be reversed to the extent that financial systems of emerging-market economies develop and improve. Because such a process is likely to take time, this set of explanations suggests that the uphill flow of capital is likely to persist for a while. A third set of explanations traces the emergence of current account deficits in the industrial countries, especially the United States, to increases in both public and private consumption which show up as declines in national savings rates.4Some observers draw a less sanguine message from this approach than the first two mentioned above, namely, that current increases in consumption in the industrial economies could potentially cost them greater indebtedness and lower future consumption, and developing economies might then have less investment than otherwise. The high level of gross flows into emerging markets and the "downhill" flow of private capital to some extent temper this interpretation. The three sets of explanations I have just discussed are only some of the many stories that have been offered to explain the uphill flow of capital, and none of them have gained wide acceptance as the best. Elements of each of them could account for some aspects of the current state of global capital flows, and none are complete explanations for this complex phenomenon. For example, concerning structural differences, as I discussed earlier, the aggregate current account balance of the developing economies turned to surplus only in the late 1990s; before then, it was in deficit, even though the financial sectors in those economies were, if anything, even less mature than they are today. That said, the financial-sector stories as well as the productivity stories I've reviewed probably are at least part of the explanation for the global pattern of capital flows. Moreover, these stories help to identify policies that developing economies can undertake to boost domestic capital formation and enhance the attractiveness of financial assets, both for foreign and domestic investors. Such policies lay the foundation for future economic growth as well as promise to alter the current pattern of capital flows and external balances. Making Emerging-Market Economies a More Attractive Place to InvestBusinesses in many emerging-market economies face a multitude of hurdles. Red tape, rigid regulations, and weak legal systems impede the formation of businesses, their ongoing operation, and their confidence in having their contracts enforced without long and costly litigation.Accordingly, governments in these countries could greatly improve the environment for domestic capital formation by simplifying business regulations, strengthening property rights, including the rights of creditors, and improving contract enforcement (Kroszner 2003 and 2006b; Mishkin, 2006). These kinds of institutional improvements would also help ensure that capital inflows are channeled in a growth-enhancing manner (Arteta, Eichengreen, and Wyplosz, 2003). As noted above, I believe it will take more than simply investment in information technology (IT) for a country to enjoy the large productivity enhancements that can be brought about by the IT revolution (Kroszner 2003 and 2006b). The IT revolution has not simply allowed a worker to turn the crank faster on an improved machine (the traditional way we think of technological innovation) but opened the possibility of fundamentally altering the way production (or provision of a service) takes place. In this way, IT can contribute larger productivity improvements when an economy has flexible labor, product, and financial markets. To provide the greatest incentive for investment in the context of the IT revolution, business must operate in an environment that will permit them to transform themselves in ways that allow technology-intensive investment to have the highest possible effect on productivity growth. Similarly, labor markets must be flexible enough to allow for the prompt re-allocation of resources in response to changes in demand. The economy also must be competitive enough to allow useful innovations at some firms to be transmitted throughout the industry by market pressure. This underscores the importance of the overall regulatory and property rights environment to fostering investment necessary for productivity growth in emerging economies. More generally, a related set of policies should focus on strengthening the financial system so that it better channels domestic saving into appropriate domestic investment projects. Adopting international best practices in financial supervision and regulation would help promote prudent risk management and effective intermediation. Intermediation could also be enhanced by developing capital markets outside the banking system. The creation of secondary markets for mortgage debt and, as I will describe in more detail shortly, the development of local bond markets more generally has promoted deeper and more liquid financial systems in some emerging markets. Installing modern trading and electronic payment systems, which facilitate quick and easy allocation of capital, would also help. A simple, intuitive principle governs all efforts to develop markets that channel funds efficiently from a large number investors (both domestic and foreign). The principle is that all investors must believe they all have the same access to information about investments and that they all will be treated in the same way. To this end, policies to increase transparency, disclosure, and restrictions on insider advantages are critical (Gelos and Wei, 2005; Ahearne and others, 2004). Finally, prudent macroeconomic policies--fiscal consolidation and monetary policies aimed at price stability--are crucial to any effort to boost investment and attract financing (Kroszner 2003 and 2006b). Emerging-Market Financing and the Distribution of RisksEmerging-market economies have, to varying degrees, already made progress in improving their financial environment over the past decade. Inflation has been substantially reduced, and fiscal balances have been brought under control. Many countries have reformed their financial systems and modernized their business regulations. These policies have helped attract private capital inflows, even though total capital flows still move from developing to industrial economies on net. Financing mechanisms in the emerging-market economies have also evolved. Most notably, external borrowing increasingly is in the form of bonds denominated in domestic currency, often issued at fixed interest rates, and dated for long maturities, in contrast to the foreign-currency instruments that dominated external borrowing in earlier years. Government bonds of this new type were first issued by Korea and Thailand in the 1990s; Brazil, Chile, Colombia, Indonesia, Mexico, and Russia soon followed suit (Kroszner, 2006a). These new instruments have helped establish long-dated benchmark yield curves and thus encourage corporate bond issuance and mortgage lending in domestic currency and at longer maturities. The new instruments are also changing the distribution of risk. When entities in the emerging markets borrowed in foreign currencies, they bore the exchange rate risk while lenders bore default risk. This arrangement made the financial crises of the 1990s very costly: Sharp currency depreciations caused the domestic-currency value of foreign-currency debt to balloon. With domestic-currency financing, lenders now bear most of the exchange rate risk. And with fixed-rate bonds, the interest rate risk, too, is being shifted to the lenders. We would expect that emerging-market borrowers would have to pay higher yields to compensate lenders for this additional risk. But yields on the new instruments have generally been moving down. For example, Mexico, even with its history of macroeconomic instability, can borrow in pesos at a thirty-year maturity at roughly 8 percent. These low yields are part of a more general decline in compensation for risk in emerging markets, a trend also evidenced by low risk spreads on dollar-denominated bonds and rising stock prices. In part, this trend reflects the low volatility in international financial markets in recent years. However, it also reflects improvements in the economic policies and debt positions of emerging-market economies. In the past, an environment of low risk spreads contributed to overborrowing, booms, and then busts. So far, that cycle has not developed, and it is crucial that sound and prudent policies continue to guard against it's doing so. Credible macroeconomic and financial policies in the emerging-market economies provide double benefits: They help keep borrowing costs low, and, in the event of a future retreat from risk by global investors, they will help the affected economies weather any ensuing financial turbulence. ConclusionIn conclusion, I believe that the current net flow of capital toward the industrial world is not in the long-term interest of the developing economies. To raise incomes and reduce poverty, the developing economies must boost their productivity, and that, in turn, will require complementing their large and growing labor forces with increasing quantities of capital. I would add that the current pattern of net capital flows is more the deviation than the norm. The developing economies in the aggregate swung into current account surplus only in the past decade. Moreover, at present, only a subset of developing economies account for those surpluses, and even those are enjoying substantial gross capital inflows. Of course, there are better ways and worse ways to achieve a reversal in net capital flows. In the past, current account deficits in the emerging-market economies were frequently the outcome of large budget deficits and inappropriate exchange rate regimes, and I am certainly not calling for a return to such policies. Rather, a swing in net capital flows back toward the developing economies would best be achieved through policies they need--regardless of their effect on external balances--to promote capital formation and economic growth. Such policies would improve the environment for business investment, strengthen domestic financial systems, and encourage the development of more-attractive financial instruments. In particular, an increase in transparency and disclosure is important so that all investors believe they will be treated equally and have an equal chance to enjoy the returns from their investments. These steps, against the background of prudent monetary and fiscal policies, will help both to encourage capital inflows and to ensure that they are used to best advantage. By the same token, industrial countries can undertake policies to enhance their prospects for solid, sustainable growth that would also have the effect of altering the current pattern of international capital flows. In the United States, it is crucial to address the implications of demographic changes for the longer-term path of entitlement spending. Other industrial economies also face this challenge. To a certain extent, financial and economic reforms are already under way in many emerging-market economies, and private capital flows to these countries have expanded sharply over the past decade. Moreover, financial flows increasingly are in the form of fixed-rate domestic-currency bonds, which makes emerging-market borrowers less vulnerable to precipitous movements in exchange rates and other asset prices. Financial crises may materialize and disrupt economic activity, as they have in the past. However, provided that emerging-market economies continue to pursue structural reforms and stabilizing macroeconomic policies, their prospects for solid economic growth and resilience in the face of crisis will improve. References Ahearne, Alan G., William L. Griever, and Francis E. Warnock (2004). "Information Costs and Home Bias: An Analysis of U.S. Holdings of Foreign Equities,"Journal of International Economics, vol. 62 (March), pp. 313-36. Arteta, Carlos, Barry Eichengreen, and Charles Wyplosz (2003). "When Does Capital Account Liberalization Help More than It Hurts?" in Elhanan Helpman and Efraim Sadka, eds.,Economic Policy in the International Economy: Essays in Honor of Assaf Razin.New York: Cambridge University Press. Bernanke, Ben (2005). "The Global Saving Glut and the U.S. Current Account Deficit," the Homer Jones Lecture, St. Louis, Missouri, April 14,www.federalreserve.gov/boarddocs/speeches/2005/20050414/default.htm Caballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2006). "An Equilibrium Model of ‘Global Imbalances' and Low Interest Rates," NBER Working Paper Series 11996. Cambridge, Mass.: National Bureau of Economic Research,http://www.nber.org/papers/w11996 Chinn, Menzie D. (2005).Getting Serious About the Twin Deficits.Council Special Report 10. New York: Council on Foreign Relations. Cline, William R. (2005).The United States as a Debtor Nation: Risks and Policy Reform. Washington: Institute for International Economics. Erceg, Christopher J., Luca Guerrieri, and Christopher Gust (2006). "SIGMA: A New Open Economy Model for Policy Analysis,"International Journal of Central Banking, vol. 2 (March). Ferguson, Roger W., Jr. (2005). "U.S. Current Account Deficit: Causes and Consequences," speech delivered to the Economics Club of the University of North Carolina at Chapel Hill, April 20,www.federalreserve.gov/boarddocs/speeches/2005/20050420/default.htm Gelos, R. Gaston, and Shang-Jin Wei (2005). "Transparency and International Portfolio Holdings,"Journal of Finance, vol. 60 (December), pp. 2987-3020. Gruber, Joseph W., and Steven B. Kamin (forthcoming). "Explaining the Global Pattern of Current Account Imbalances,"Journal of International Money and Finance. International Monetary Fund (2007a).World Economic Outlook. Washington: IMF, April,http://www.imf.org/external/pubs/ft/weo/2007/01/data/index.aspx __________ (2007b).Global Financial Stability Report. Washington: IMF, April,http://www.imf.org/external/pubs/ft/gfsr/2007/01/pdf/statappx.pdf (794 KB PDF) __________ (2007c).International Financial Statistics. Database maintained by the Board of Governors of the Federal Reserve System. Washington: IMF. Ju, Jiandong, and Shang-Jin Wei (2006). "A Solution to Two Paradoxes of International Capital Flows," IMF Working Paper WP/06/178. Washington: International Monetary Fund. Kroszner, Randall S. (2003). "Promoting Global Economic Growth: The Productivity Challenge (64 KB PDF)," working paper. Chicago: University of Chicago, July. __________ (2006a). "Why Are Yield Curves So Flat and Long Rates So Low Globally?" speech delivered at the Institute of International Bankers, New York, New York, June 16, www.federalreserve.gov/newsevents/speech/kroszner20060615a.htm __________ (2006b). "What Drives Productivity Growth? Implications for the Economy and Prospects for the Future," speech delivered to the Forecasters Club of New York, September 27, www.federalreserve.gov/newsevents/speech/kroszner20060927a.htm Mendoza, Enrique G., Vincenzo Quadrini, and Jose-Victor Rios-Rull (2007). "Financial Integration, Financial Deepness and Global Imbalances," NBER Working Paper 12909. Cambridge, Mass.: National Bureau of Economic Research,http://www.nber.org/papers/w12909 Mishkin, Frederic S. (2006).The Next Great Globalization: How Disadvantaged Nations Can Harness Their Financial Systems to Get Rich. Princeton: Princeton University Press. Prasad, Eswar, Raghuram Rajan, and Arvind Subramanian (2006). "Foreign Capital and Economic Growth," paper presented at an IMF workshop, November,https://www.imf.org/External/NP/seminars/eng/2006/growth/as.pdf (564 KB PDF) Footnotes 1.Steve Kamin,Charles P. Thomas, andCarlos Arteta, of the Board's Division of International Finance, contributed to this speech.Return to text 2.I will use the terms "developing economies" and "emerging-market economies" interchangeably in this speech, although some observers draw distinctions between them.Return to text 3.In this section, the developing economies consist of those listed under "Other Emerging Market" and under "Developing" in the IMF'sWorld Economic Outlookplus Hong Kong SAR, Israel, Korea, Singapore, and Taiwan. The data for these countries are drawn from the database published with IMF (2007a).Return to text 4.Elaborations on the role of fiscal policy in the U.S. current account deficit are in Cline (2005) and Chinn (2005).Return to text
Karen H. Johnson, director of the Division of International Finance, will retire at the end of October, after 28 years of service with the Federal Reserve Board, including nearly 10 years as division director. "Karen's leadership of her division and her insight into the workings of the global economy have been of immeasurable value," Federal Reserve Board Chairman Ben S. Bernanke said. "We will miss her wise counsel, astute judgment, and dedicated service." Ms. Johnson advises the Chairman, Board members and the Federal Open Market Committee on economic and financial developments in foreign countries. In addition, she represents the Board at international meetings and in its contacts with foreign central banks. Ms. Johnson began her career at the Federal Reserve Board in 1979 as an economist. She was appointed assistant director in 1985 and associate director in 1997. She was appointed division director in October, 1998. Prior to joining the Board she was on the faculty at Stanford University.
The Federal Reserve Board and the Federal Open Market Committee on Wednesday released the attached minutes of the Committee meeting held on May 9, 2007. The minutes for each regularly scheduled meeting of the Committee are made available three weeks after the day of the policy decision and subsequently are published in the Board's Annual Report. The summary description of economic and financial conditions contained in these minutes is based solely on the information that was available to the Committee at the time of the meeting. FOMC minutes can be viewed on the Board’s web site atwww.federalreserve.gov/fomc. Minutes of the Federal Open Market Committee, May 9, 2007
The Federal Reserve Board on Wednesday announced the issuance of a consent Order of Assessment of a Civil Money Penalty against East West Bank, Pasadena, California, a state member bank. East West Bank, without admitting to any allegations, consented to the issuance of the Order in connection with its alleged violations of the Board’s Regulations implementing the National Flood Insurance Act. The Order requires East West Bank to pay a civil money penalty of $16,245, which will be remitted to the Federal Emergency Management Agency for deposit into the National Flood Mitigation Fund. A copy of the Order is attached.
The Federal Reserve Board on Wednesday announced the issuance of a consent Order of Assessment of a Civil Money Penalty against First Sentinel Bank, Richlands, Virginia, a state member bank. First Sentinel Bank, without admitting to any allegations, consented to the issuance of the Order in connection with its alleged violations of the Board’s Regulations implementing the National Flood Insurance Act. The Order requires First Sentinel Bank to pay a civil money penalty of $4,235, which will be remitted to the Federal Emergency Management Agency for deposit into the National Flood Mitigation Fund. A copy of the Order is attached.
The Federal Reserve Board on Wednesday announced the issuance of a consent Order of Assessment of a Civil Money Penalty against Orrstown Bank, Shippensburg, Pennsylvania, a state member bank. Orrstown Bank, without admitting to any allegations, consented to the issuance of the Order in connection with its alleged violations of the Board’s Regulations implementing the National Flood Insurance Act. The Order requires Orrstown Bank to pay a civil money penalty of $1,665, which will be remitted to the Federal Emergency Management Agency for deposit into the National Flood Mitigation Fund. A copy of the Order is attached.
Chairman Ben S. Bernanke At the Princeton Prize in Race Relations Awards Program, Washington, D.C. As a former member of the Princeton community, I am very pleased to see the university recognizing these young people--the two prize winners, John Gentile and Brianna Casey Lyons, as well as the eight certificate recipients--for demonstrating exemplary leadership in the area of race relations. Slavery and segregation cast long dark shadows on our nation's history and our society, but there have been flickers of light in the form of people of good will and courage who fought against those evils. Today, I can think of no higher calling than promoting harmony, understanding, and respect among people of different racial and ethnic backgrounds. The two prize winners, though young, have already contributed significantly. As you have heard, John energetically advocated improved race relations in his own school and helped to bring diversity concerns before a wider group of high schools in the District of Columbia metro area. Casey led a group of exurban teenagers in starting a 4-H Club at a more-urban, and racially mixed, elementary school. If you are a baseball fan, as I am, you know that we recently observed the sixtieth anniversary of an important event in the history of race relations--Jackie Robinson's breaking of the color barrier in major league baseball. Robinson was a great baseball player, but--critically, for the mission he set out to accomplish--he was also a great leader, a person of courage and character. As a second lieutenant in the Army in 1944, he refused to obey an order to move to the back of a military bus in Texas. Lieutenant Robinson was court-martialed but then acquitted by a military jury, and he received an honorable discharge. It was Jackie Robinson's character as much as his daring style of play that commanded the respect of players and fans and paved the way for other black athletes to enter the major leagues. No one who watched Robinson perform under often-hostile conditions could long deny that he was the equal of any white player, not only as an athlete but as a human being. Other flickers of light appear in this story as well, including the decision of Dodgers General Manager Branch Rickey to give Robinson a chance and the public support provided Robinson by a few of his white teammates. In a way, Jackie Robinson was lucky, because he was rewarded for his skills and courage. He was named Rookie of the Year, played on six World Series teams, and was once named the National League's Most Valuable Player. Someone less fortunate in this respect was Josh Gibson, considered the greatest power hitter of the Negro Leagues. He played right here in Washington for the Homestead Grays in the 1930s and 1940s. Some people say he was the equal of Babe Ruth as a hitter. But he never got the chance to play in the major leagues. He died at the age of thirty-five, three months before Jackie Robinson first trotted onto Ebbets Field with the Brooklyn Dodgers in 1947. Both men played the game superbly, but whereas Jackie Robinson was honored and recognized in his lifetime for his achievements, both as a baseball player and a civil rights leader, recognition of Josh Gibson came only after his death. Gibson, along with other greats of the Negro Leagues, was finally admitted to the National Baseball Hall of Fame in 1972, a quarter century after he died and a decade after Robinson was admitted. It is tragic that Gibson did not live to see the integration of major league baseball or to enjoy the honors that were due him. However, even though society's recognition of Gibson's achievements came too late for him to enjoy it, honoring him was still worthwhile. The belated recognition of Gibson illustrates a most important reason to honor achievement: We do it not so much for the person being honored but rather for ourselves. Please do not misunderstand me. I hope today is a joyous and proud day for today's prize winners and certificate recipients and their families. But I strongly suspect that when they set out on the path that earned them this recognition, they were not motivated at all by--and probably were not even aware of--the prospect of an award such as the Princeton Prize. They did what they did from inner motivation. So, if the prospect of recognition had little or nothing to do with their achievement, why go through the exercise? The reason they are being honored, and the reason we remember Jackie Robinson and Josh Gibson and countless other achievers in countless other endeavors, is because doing so provides inspiration for all of us. And, usually, the aspect of an achievement that is most worth recognizing is not the achievement itself but the spirit of energy, determination, and courage that made it possible. So, let me say to today's honorees: Thank you. Thank you not only for serving as a role model for your peers in high school but also for being exemplars for us all. Now, because we are in the midst not only of baseball season but also of graduation season, I would like to touch briefly on the theme of education. The saddest aspect of Josh Gibson's story is that he had talent but was denied an opportunity. Then as now, the principal path to opportunity is through education. As an economist, I am persuaded that a strong educational system--one that promotes lifetime learning and skill development--is a critical factor in our nation's prosperity. The economic importance of education will only increase as technology advances and as the global economy becomes increasingly integrated and complex. But education is important for non-economic reasons as well. By providing us with a broader view of the world, education helps each of us become the most complete person we can be. Many--I hope all--of the young people here today will continue their education, and I hope it leads them to work that brings financial success. But I also hope it cultivates their creativity and appreciation for other cultures and leads them to work they find personally satisfying and meaningful. I know it will help them continue to demonstrate the kind of leadership that they have already shown. Perhaps, as they acquire a deeper knowledge of places and times other than their own and a fuller understanding of people from backgrounds other than their own, it will also lead them to contribute positively at the national or international levels, as they already have done in their schools and local communities. But this evening, I don't think we should dwell entirely on the future. I hope each of the honorees will take pride in what he or she has already achieved and will celebrate that achievement with family and friends. Congratulations to all of you.
Chairman Ben S. Bernanke To the Federal Reserve Bank of Atlanta's 2007 Financial Markets Conference, Sea Island, Georgia(via satellite) Good morning. I'm pleased to be able to join you for this year's financial markets conference, albeit from afar. Last year the focus was on hedge funds, and the main theme of this year's gathering is credit derivatives. This pairing makes eminent sense, in that the increasing prominence of hedge funds and the growth of the market for credit derivatives are both aspects of the remarkable wave of financial innovation that we have seen in recent years. Both of these developments have also been the subject of public policy debates, including calls for increased regulation. In my remarks today I will address, from the 30,000-foot level, the challenges that financial innovation poses for public policy and the nature of the appropriate regulatory response. I will argue that central banks and other regulators should resist the temptation to devise ad hoc rules for each new type of financial instrument or institution. Rather, we should strive to develop common, principles-based policy responses that can be applied consistently across the financial sector to meet clearly defined objectives. In addressing the challenges and the risks that financial innovation may create, we should also always keep in view the enormous economic benefits that flow from a healthy and innovative financial sector. The increasing sophistication and depth of financial markets promote economic growth by allocating capital where it can be most productive. And the dispersion of risk more broadly across the financial system has, thus far, increased the resilience of the system and the economy to shocks. When proposing or implementing regulation, we must seek to preserve the benefits of financial innovation even as we address the risks that may accompany that innovation. Clear thinking is therefore essential. In developing a regulatory framework, we need to be explicit both about what the public policy objectives of regulation are and about how, if at all, fresh developments threaten to undermine those objectives. We should also take into account the role that the market itself can play in controlling risks to public objectives; as I noted last month, market discipline can be an important element in a well-functioning regulatory scheme. And as I have already observed this morning, any regulatory changes should fulfill the test of consistency, across both institutions and instruments. Ensuring a Consistent ApproachIn thinking about how, or whether, to regulate innovative financial institutions (such as hedge funds) or instruments (such as credit derivatives), we should be wary of drawing artificial distinctions. Are the characteristics of hedge funds or credit derivatives that arouse concern peculiar to these institutions and instruments, or are they associated with others as well? If the characteristics in question are in fact a feature of the broader financial landscape, then a narrowly focused approach to regulation will be undermined by the incentives such an approach creates for regulatory arbitrage. For example, while the complexity of new financial instruments and trading strategies is potentially a concern for policy, as I will discuss, not all credit derivatives are complex and--to state the obvious--not all complex financial instruments are linked to credit risk. Single-name credit default swaps and credit default swap indexes are relatively simple instruments, whereas derivatives based on other asset classes--such as exotic interest-rate and foreign-exchange options--can, by contrast, be quite complex. Moreover, derivatives in general are not necessarily more complex than some types of structured securities. In short, if complexity per se is the concern, we cannot address that concern by focusing on a single class of financial instruments. Similarly, hedge funds are hardly a homogeneous group of institutions, nor can their trading strategies be unambiguously distinguished from those of large global banks or of some traditional asset managers. A consistent regulatory strategy needs to be tailored to the essential characteristics of institutions or instruments that pose risks for policy objectives, not to arbitrary categories. At last year's conference, I discussed a policy proposal focused narrowly on hedge funds--namely, the development of a database of hedge fund positions and portfolios. As I noted last year, given the complexity of trading strategies and the rapidity with which positions change, creating a database that would be sufficiently timely and detailed to be of practical use to hedge funds' creditors and investors or to regulators would be extremely difficult. Collecting such information also risks moral hazard, if some traders conclude that, in gathering the data, the regulators have somehow reduced financial risk. The principle of consistency on which I am focusing today raises an additional objection to this proposal, which is that it would make little sense to collect data on hedge funds' positions without gathering the same information for other groups of market participants that use similar strategies and take similar risks. An analogous issue arises in the debate over transparency in the credit derivatives market. Some argue that policymakers should act to make trading in the credit derivatives market more transparent, on the grounds that the market and policymakers should know just who is holding the credit risk associated with a particular issuer. But if transparency about risk-bearing is important, then consistency seems to imply that full transparency should be required of credit markets broadly, not just of credit derivatives. And why stop with credit markets? Do we know exactly who is bearing the risk in equity markets or foreign exchange markets, for example? Rather than addressing specific institutions or instruments in isolation, regulators should begin by identifying their objectives and then address the implications of the broad range of financial innovations for those objectives. By returning to the basics, we can increase the coherence, consistency, and effectiveness of the regulatory framework. Public Policy ObjectivesAs public policymakers, we have three principal objectives in the financial sphere, objectives that have remained essentially unchanged over many decades even as the pace of financial innovation has accelerated. These objectives are financial stability, investor protection, and market integrity. These goals are widely shared by policymakers around the world and thus provide a basis for international cooperation. From a central banker's point of view, the objective of ensuring financial stability remains critical. Indeed, the Federal Reserve was founded in large part because of concerns about periodic bouts of instability that damaged both the financial system and the broader economy. Policymakers cannot prevent financial shocks, but we can try to mitigate their effects by ensuring that the system remains fundamentally sound. In particular, as I will discuss, we can use our supervisory authority to ensure that the large institutions that form the core of the financial system--which happen to be the leading dealers in the credit derivatives markets and the principal counterparties and creditors of hedge funds--manage the risks that they face in a safe and sound manner. Investor protection is another vital public objective. A loss of confidence in the financial system by investors, too, could undermine the system's stability and functioning. Of course, we cannot--and should not--prevent all investor losses. To avoid moral hazard and let market discipline work, investors must be allowed to bear the consequences of the decisions they make and the risks they accept. But investors are entitled to the information they need to make decisions appropriate to their personal circumstances. Closely linked to the imperative of investor protection is the third public policy objective: preserving the integrity of the market. The stability and the efficiency of the market depend on a common understanding of and adherence to the rules of the game. Thus, policymakers must attach a high priority to preventing insider trading, market manipulation, and other activities that rig the game and undermine public confidence. Challenges to Public Policy ObjectivesThe rapid pace of financial innovation creates challenges for policymakers with respect to each of these policy objectives. In particular, financial stability depends on adequate risk measurement and risk management by market participants. Failures of risk management by large institutions, or by a sufficient number of smaller ones, would threaten not only the solvency of the institutions themselves but also the health of the whole system. Of course, in some respects financial innovation makes risk management easier. Risk can now be sliced and diced, moved off the balance sheet, and hedged by derivative instruments. Indeed, the need for better risk sharing and risk management has been a primary driving force behind the recent wave of innovation. But in some respects, new instruments and trading strategies make risk measurement and management more difficult. Notably, risk-management challenges are associated with the complexity of contemporary instruments and trading strategies; the potential for market illiquidity to magnify the riskiness of those instruments and strategies; and the greater leverage that their use can entail. Complexity--especially when combined with illiquidity--amplifies the difficulty of measuring risk, both market risk and counterparty credit risk. For example, some complex instruments can be valued only with the aid of sophisticated modeling techniques. The problems of valuation and of risk measurement faced by investors in tranches of bespoke collateralized debt obligations (CDOs) are a good example. Similar problems are faced by the core financial intermediaries that often act as counterparties to hedge funds in complex synthetic CDO transactions or that finance hedge funds' investments in bespoke CDO tranches. Complex trading strategies and positions, too, can create problems. For example, counterparty risks may be underestimated because of failures to aggregate exposures to risks across instruments and counterparties. What is essentially the same risk can appear in different forms; for example, investments in a CDO tranche, a bond, and a credit default swap may all entail credit risk to a given obligor. Illiquidity, or the potential for illiquidity under some conditions, is also a problem for managers of market risk and counterparty credit risk. Substantial market risk may be associated with holdings of illiquid instruments; again, tranches of bespoke CDOs illustrate this well. A pattern of crowded trades may lead to market illiquidity--sometimes in surprising locations--when risk aversion heightens. In particular, counterparty exposures can be significantly increased if the closeout of positions of one or more hedge funds by their dealer counterparties leads to, or exacerbates, market illiquidity. Market liquidity depends not only on the presence of willing buyers and sellers but also on the underlying infrastructure, including market-making capacity and the system for clearing and settling financial transactions. Twenty years ago this fall, the 1987 stock market crash was significantly worsened by the inability of trade-processing systems to keep up with order flows, including orders resulting from program trading. Of course, automated trading is far more pervasive today, and overall trading volumes have expanded greatly. As trading volumes grow, market infrastructures must adapt. Until 2005, reliance on paper-based procedures for confirming trades in the rapidly growing credit derivatives markets sometimes resulted in large backlogs of unconfirmed trades, which increased the risks to market participants. With leadership from their prudential regulators, dealers in those markets have adopted electronic confirmation platforms and greatly reduced the backlogs. Currently, regulators and market participants are beginning to address large backlogs of confirmations in the equity derivatives markets. Theleveragethat can be embedded in new financial instruments and trading strategies compounds the difficulties of risk management. Embedded leverage can be difficult to measure; at the same time, like conventional leverage, it may increase investor vulnerability to market shocks. Some credit derivatives do make it easier for investors to take leveraged exposures to credit risk. For example, the first-loss tranche of the investment-grade CDX credit default swap index is exposed to the first 3 percent of losses on the index portfolio. Holding a $3 million position in this tranche exposes an investor to losses on an underlying portfolio of $100 million. A dealer taking the other side of the trade obviously needs to enhance its counterparty risk-management practices to take this greater leverage into account. Complexity, illiquidity, and embedded leverage also create challenges for policymakers with respect to the objectives of protecting investors and maintaining market integrity. If hedge funds and the large banks that are hedge funds' counterparties and creditors have difficulty assessing the risks associated with complex financial instruments, many investors will find gaining a sufficient understanding of the risks even more burdensome. Investors may also not appreciate the extent to which they may have multiple exposures to the same source of risk--for example, arising from effective exposures to the same hedge fund through funds of funds or from investments in different funds with similar trading strategies. Current restrictions on hedge fund investors, which limit direct investors to institutions or wealthy individuals, reflect the recognition of the difficulties that a retail investor would face in adequately assessing these types of risk. But as instruments and trading strategies become more complex and intertwined, even the most sophisticated investors will be challenged to make reliable judgments about their risk exposures. Likewise, complex and difficult-to-value financial instruments could be exploited as vehicles for profiting from insider trading or market manipulation, although, as history shows, simpler instruments can be used in this way as well. Policymakers must be confident of their ability to detect such market abuses when they occur. A Principles-Based, Risk-Focused ApproachHow best to respond to these daunting challenges? As I noted, there are powerful arguments against ad hoc instrument-specific or institution-specific regulation. The better alternative is a consistent, principles-based, and risk-focused approach that takes account of the benefits as well as the risks that accompany financial innovation. Some commentators have sought to draw a sharp distinction between the approach to financial regulation in the United States and that in the United Kingdom. These observers have characterized the British approach as being principles-based and as using a "light touch"--the implication being that these two features somehow go together. In a speech in February of this year, Sir Callum McCarthy, the head of the United Kingdom's Financial Services Authority (FSA), took issue with this interpretation.1Sir Callum confirmed that the FSA's approach is built on a framework of principles, although he noted that the FSA also has an 8,500-page rulebook to accompany the eleven principles it has laid out. But the FSA head rejected the view that their approach is "light touch." Rather, he said, it is risk-based, which means that regulatory resources and attention are devoted to firms, markets, or instruments in proportion to the perceived risks to the FSA's regulatory objectives. In fact, as in the United Kingdom, the principles-based, risk-focused approach to regulation has had considerable influence on this side of the Atlantic as well. For example, as you may know, the President's Working Group on Financial Markets (PWG) recently issued a statement of principles--ten in this case--relating to the regulation of private pools of capital, including hedge funds. Our aim in presenting these principles was to spell out how a combination of market discipline and government oversight could be most effective in addressing the challenges to public policy objectives that I have described. The principles make clear that regulators and supervisors should adopt the risk-focused approach described by Sir Callum. In particular, they emphasize that risks to financial stability are best addressed by focusing our attention on the large institutions at the core of the financial system. Some care is needed in applying a risk-focused approach to regulation, however. In particular, when the government singles out particular institutions or markets as being especially critical to the stability of the system, moral hazard concerns may well follow. A perception that some institutions are "too big to fail" may create incentives for excessive risk-taking on the part of those institutions or their creditors. For that reason, part of an effective risk-focused approach is the promotion of market discipline as the first line of defense whenever possible. Market discipline is enhanced whenever regulators take positive steps to ensure that investors and managers bear the consequences of their financial decisions. Reliance on market discipline should not be confused with a policy of laissez-faire or benign neglect. To the contrary, as the PWG's principles spell out, market discipline often needs to be buttressed by government oversight. Notably, supervisors must diligently ensure that regulated firms--especially those core financial firms that act as creditors, counterparties, and clearing firms for highly leveraged entities, including hedge funds--adopt and implement best practices for monitoring and managing risks. These best practices could include those identified through cooperative private-sector initiatives, such as those of the Counterparty Risk Policy Management Group II. Importantly, best practices must address the challenges I mentioned earlier, including those relating to the complexity of instruments and strategies (which can make exposures difficult to measure), the illiquidity or potential illiquidity of positions held by the firm or its counterparties, and the risks of embedded as well as explicit leverage. In implementing risk-focused and principles-based policies, we must also face the reality that finance does not stop at the water's edge. Financial globalization and financial innovation are closely tied, with each trend promoting the other. As a consequence, global regulatory coordination and collaboration are more vital than ever. We already work closely with our counterparts in the major industrial countries as well as in international forums such as the Basel Committee on Banking Supervision and the International Organization of Securities Commissions (IOSCO). To the extent possible, we should work toward common principles and approaches as well as improved information sharing. International cooperation is also essential for establishing and maintaining effective oversight of the payment and settlement systems that constitute the infrastructure of global financial markets. Organizations such as the Committee on Payments and Settlements Systems (CPSS) and IOSCO have developed shared international principles to ensure the safety and efficiency of payment systems. Investor protection can also be addressed in a risk-focused, principles-based manner. Most important, disclosures and protections should be tailored to the level of sophistication of the investor. Mutual funds, for example, must provide disclosures sufficient to help retail investors make informed choices. When instruments and strategies are so complex that an unsophisticated investor could not be expected to effectively evaluate and manage the associated risks, U.S. regulators have chosen to limit the exposure of those investors. For example, most retail investors are effectively precluded from engaging in over-the-counter credit derivative transactions or from investing directly in hedge funds unless they meet various criteria regarding income and net worth. Retail investors may have indirect exposures to complex instruments and strategies--for example, through pension funds. The appropriate principle for investor protection in this case is that the investors' agents--pension fund managers, for example--must apply sound risk-management practices and take risks consistent with the stated objectives of the ultimate investors. Regulators have a role to play in imposing fiduciary duties and standards on the investors' agents. For example, the Employee Retirement Income Security Act (ERISA) sets standards for private pension fund managers, including the requirements that, as fiduciaries, they act prudently and solely in the interest of the pension fund participants. Supervision of these fiduciaries must ensure that these standards are consistently met and that fiduciaries themselves fully understand the nature of their risk exposure. Market integrity is the third public policy objective that I noted earlier. Consistent with a principles-based approach, U.S. securities laws against insider trading and market manipulation apply broadly to all financial institutions, including hedge funds, and to trading in a wide range of financial instruments, including securities-based over-the-counter derivatives transactions. Just as institutions and other investors need to adopt best practices to measure and manage risk, they should also have robust internal controls to ensure that the laws are not violated. For example, some market participants have expressed a concern that a bank may use nonpublic information in the credit derivatives market that it has obtained through its lending activities. To protect against such abuses, private-sector groups have proposed practices and principles for handling material nonpublic information--for example, by creating barriers between the staff members with access to such information and others. Risk-focused regulators and supervisors in turn should encourage effective implementation of these best practices, particularly in situations in which the potential for misuse, either intentional or unintentional, is high. ConclusionFinancial innovation has great benefits for our economy. The goal of regulation should be to preserve those benefits while achieving important public policy objectives, including financial stability, investor protection, and market integrity. Although financial innovation promotes those objectives in some ways, for example by allowing better sharing of risks, certain aspects of financial innovation--including the complexity of financial instruments and trading strategies, the illiquidity or potential illiquidity of certain instruments, and explicit or embedded leverage--may pose significant risks. These risks should not be taken lightly. Devising an appropriate regulatory response to financial innovation is challenging. I have argued today that we should strive to implement a regulatory regime that is principles-based, risk-focused, and consistently applied. Enhancing market discipline can complement and strengthen such an approach. As in the United Kingdom, a principles-based approach is not inconsistent with the use of rules, which can provide needed clarity or a safe haven from legal and regulatory risks. However, rules should implement principles rather than develop in an ad hoc manner. Admittedly, a fully consistent regulatory framework that focuses on the most significant threats to public policy objectives is an ideal that may never be fully realized, either here or abroad. However, determined efforts to work toward such a regime could provide substantial economic and social benefits. Footnotes 1.See Callum McCarthy (2007), "Financial Regulation: Myth and Reality," speech delivered at the British American Business London Insight Series and Financial Services Forum, February 13.Return to text
The Federal Reserve Board on Tuesday announced the approval of amendments to Appendix A of Regulation CC that reflect the restructuring of the check processing operations of the Federal Reserve Bank of Atlanta and provide notice relating to future changes to Appendix A. Appendix A provides a routing symbol guide that helps depository institutions determine the maximum permissible hold periods for most deposited checks. To ensure that the information in Appendix A accurately describes the structure of check processing operations within the Federal Reserve System, the Board is amending the list of routing symbols in Appendix A associated with the Federal Reserve Bank of Atlanta to reflect the transfer of check processing operations from that Reserve Bank’s Nashville branch office to its head office. These amendments are effective July 21, 2007, to coincide with the effective date of the underlying reassignment of check processing functions. As a result of these changes, some checks deposited in the affected regions that currently are nonlocal checks will become local checks that are subject to shorter permissible hold periods. Theattachmentalso provides advance notice that the Reserve Banks have decided to transfer the check-processing operations of two offices in the second half of 2007. Specifically, checks currently processed at the Helena branch office of the Federal Reserve Bank of Minneapolis will be processed at the Denver branch office of the Federal Reserve Bank of Kansas City, and checks currently processed at the head office of the Federal Reserve Bank of San Francisco will be processed at the Los Angeles branch office of that Reserve Bank. The Board intends to publish the associated amendments to appendix A at least sixty days prior to the effective date of the amendment in order to give affected banks ample time to make processing changes and, if necessary, amend their availability schedules and related disclosures and provide their customers with notice of any changes to their availability schedules. The Board’s notice is attached.
Governor Randall S. Kroszner At the 2007 Payments Conference Competitive Forces Shaping the Payments Environment: What's Next?, Federal Reserve Bank of Chicago, Chicago, Illinois I am pleased to have the opportunity to speak at this conference on competitive forces shaping the payments environment.1Spurred by a period of rapid innovation, we are at a crucial juncture in the evolution of the U.S. payments system. The long-predicted decline of the paper check is materializing as consumers and businesses continue to embrace alternative ways of making and clearing payments. A 2004 Federal Reserve study of retail payments revealed that electronic payments have now surpassed the use of checks as the preferred means of making noncash payments.2The use of debit cards has grown strongly, and the number of checks being converted into ACH payments has grown to nearly 3 billion annually. Electronic check clearing has begun to grow exponentially in response to changes in check law. As a consequence of the accelerating pace of change, we participants in the payments system cannot help but challenge our fundamental assumptions about payment operations, which were based on long-standing processes for clearing paper. And adjustments are being made. The Federal Reserve Banks, for example, have cut the number of offices at which they process checks in half since 2003, and more consolidations are planned for later this year. Check transportation networks, particularly air transportation networks, are also beginning to shrink. Our conference organizers are to be applauded for bringing together industry participants, regulators, and academics at this crucial juncture to consider "what’s next" for the payments system. After briefly describing the evolution of the payments system, I will discuss how recent regulatory changes and technological innovation have interacted to affect the payments system--that is, how regulatory changes have affected the use of technology in the payments system and how technological innovations have affected how the payments system is regulated. I will then discuss some key characteristics of successful payments innovations and highlight some challenges and tradeoffs, such as the tradeoff between convenience and security, that need to be considered as the payments system continues to evolve. Finally, I will discuss the future of electronic check clearing and the important and complementary roles the Federal Reserve and the private sector will need to play in the continued evolution of the payments system. Evolution in the Structure of the Payments SystemThe different forces now shaping the evolution of the payments system have been gathering for decades. From a legal and regulatory perspective, a series of fundamental changes in U.S. banking laws, especially the laws governing interstate banking, have facilitated a long-term consolidation of banking across geographic boundaries in this country.3Banking consolidation, in turn, has fostered the ongoing consolidation of payments infrastructure both within banks and among the clearinghouses, networks, and other financial utilities that serve the banking industry. From a technological perspective, decades of investment by the financial industry, businesses, and more recently households have broadened and deepened the infrastructure for supplying and accessing electronic payments. Payment cards and other access devices have proliferated, and the demand for electronic payments has grown apace. As a result, the use of electronic payments has doubled over the first half of this decade. From a historical perspective, it is clear that the Federal Reserve has an important role to play in the evolution of the payments system. Indeed, the Federal Reserve was founded, in part, to address significant problems in the payments system, such as nonpar check collection and financial stability issues that existed in the nineteenth and early twentieth centuries. Regulation and TechnologyTurning now to regulation and technology, technological change can create the need for regulatory change. And regulatory change can stimulate new applications of technology that foster greater efficiency and growth. At times, there is a complex interplay between changing technology and regulation. In the payments arena, regulators and rulemakers need to be aware of how technology is changing the industry and, when appropriate, remove artificial barriers to innovation. Let me highlight several important examples of recent adjustments to rules and regulations that have changed the way payments are initiated and processed. Beginning in the late 1990s, the National Automated Clearing House Association (NACHA) changed its rules to permit the so-called conversion of checks to electronic fund transfers via the ACH system; subsequently, the Board modified its staff commentary to clarify the application of Regulation E to these transactions.4Today, businesses can use the information on eligible checks they receive over the counter and at lockbox locations to create ACH debit transactions. Partly as a result of the private sector’s expanding use of check conversion, the total volume of checks collected by Federal Reserve Banks has in recent years fallen faster than the estimated decline in the number of checks being written. In 2003, Congress passed the Check Clearing for the 21stCentury Act (Check 21).5Broadly speaking, Check 21 was designed to foster market-based improvements in the check collection and return system, mainly by authorizing--but not requiring--banks to truncate or stop the flow of original paper checks and to create legally equivalent substitute checks for presentment to the paying bank.6 In 2004, the Board published regulatory changes to implement Check 21. The legal and regulatory changes associated with Check 21 are encouraging the banking industry to use new technologies to create and process digital images of checks and to print substitute checks only when necessary to meet legal presentment or customer requirements. In a recent report to Congress on Check 21, the Board noted that the adoption of new clearing techniques was slow at first but has accelerated significantly in the past year.7For example, between March 2006 and January 2007, the banking industry’s use of substitute checks increased three-fold and its use of electronic check images increased five-fold. This pattern of adoption is consistent with early conjecture from the banking industry that the scale and scope of required changes to individual bank technology systems and operations would take time to implement. In addition, Check 21 has started to alleviate the check system’s dependence on large-scale air transportation to move checks around the country, a vulnerability that was highlighted when planes were grounded following the events of September 11. To address a barrier to the use of electronic payments, the Federal Reserve has recently proposed modifications to Regulation E that would eliminate the requirement for paper receipts on small-dollar payments.8The Federal Reserve must, however, also be mindful of how changing payment practices can affect risk in the payments system and take regulatory action, when appropriate. For example, the Federal Reserve recently modified Regulation CC to reallocate the liability for unauthorized remotely created checks among depository institutions, shifting liability to institutions that are better positioned to understand and mitigate those risks.9 Clearly, both regulators and the private sector have a role to play in the continuing evolution of the payments system. Regulators must continue to evaluate and adjust their rules in light of new realities in the marketplace. At the same time, the private sector must put forward sound and prudent innovations that address the needs of the marketplace, including the need to control risk. Characteristics of Successful InnovationOur conference organizers have challenged us to think about "what’s next." One tool to help understand the future is to analyze why certain innovations have been successful in the past. Infrastructure changes have been one source of successful innovation. Much of the innovation in the early days of electronic payments involved building new electronic processing systems for ACH and card systems, and then gradually expanding electronic access to these core systems. The goal of these infrastructure changes was typically to speed up payments and reduce the societal costs of dependence on paper. Following the implementation of Check 21, the banking industry and the Reserve Banks are again making major infrastructure changes. The expansion of access to this infrastructure and the development of tools for using it may well follow the path of earlier innovation and foster additional change over the next few years. Experience in the late 1990s, however, gives us reason for caution. At that time, there were attempts to introduce whole new payments systems for card and Internet payments. A few of these attempts succeeded, but most failed. Thus, the introduction of new technology alone is not sufficient for successful innovation; innovations must also meet important market demands. A key characteristic of successful innovation is that it generally reduces cost or increases the convenience of making one or more types of payments. Examples include the introduction of ATM transactions many years ago, as well as new methods for making payments over the Internet. Both of these examples highlight the importance payment system end-users place on theconvenienceof making their payments, specifically the time and location of their transactions. In the case of ATMs, banking customers shifted their payment activity from inside a bank branch to a more convenient time and location. ATMs also provided banks with a lower-cost way to serve their customers. In the case of Internet and telephone payments, the use of credit cards, new person-to-person systems, and new ACH payment types allowed payments to be made more rapidly at any time of the day, even when the parties to the transaction were thousands of miles apart. The information linked to a payment has also emerged as an important component of end-users’ demand for payment innovations. This point challenges us to think of payments as more than simple instructions to debit and credit bank accounts when we attempt to predict the needs of consumers and businesses for innovative payment products. In business-to-business remittance payments, for example, firms need to link traditional payment information to information about the bills being paid in order to post and reconcile their accounts. Over the years, businesses have made significant investments to automate their internal accounting processes for check payments. As a result, checks are still very heavily used for corporate remittances. After years of industry discussion, it is now clear that linking billing information to electronic payment instructions is a key to the greater automation of business payments.10Payments system operators, banks, and businesses must continue to cooperate on standards and encourage the necessary software changes to enable the broad-based automation of business payments. This is no simple task, as there are competing standards both domestically and internationally. Nonetheless, business users of the payments system continue to call for change, and we all need to press forward on this issue. Challenges to InnovationAlthough improving convenience has been an important force behind successful innovation, consumers and businesses have increasingly demanded greater security in their electronic payments, particularly as more information is linked to these payments. In general, there is often a basic tradeoff between security and convenience: the easier a system is to use and access, the less secure it tends to be. Striking the appropriate balance between convenience and security is a key challenge. How can we manage fraud and operational risks, along with credit and other risks, without unduly interfering with the ease of using a particular system? As I noted earlier, technological change can help stimulate successful innovations and make it more convenient for businesses and consumers to make and receive payments and link information to those payments. But technological change can also generate new methods of perpetrating fraud and disrupting payments systems--and thus require us to develop new responses to these challenges and risks. Check fraud has long been an important issue for the banking system and has been increasing recently, as described in the Board’s Check 21 report. In the electronic sphere, card systems have also had to deal with fraud since their inception. Naturally, cost-benefit calculations guide the pace of innovation to address fraud. These costs typically include technology and labor costs, as well as the time and other requirements needed to authenticate and authorize transactions. Benefits typically include the monetary losses, customer problems, and legal costs that are avoided. Important but more difficult-to-quantify benefits include the avoidance of reputational damage to payments system participants, as well as sustained public confidence in the payments system. In the context of this cost-benefit framework, we can anticipate that when the costs of prevention fall or fraud begins to increase, banks, businesses, and consumers, will react by implementing or demanding changes in policies, business processes, and technology to address risk. This dynamic balancing process is part of the ongoing development of the payments system. In the past, the banking industry has taken steps to address its own security concerns, as well as those of its customers. The experience with card systems and the ACH are instructive. In the 1970s, major credit card companies began to deploy electronic authorization systems for transactions. This step was strongly influenced by the desire of banks and merchants to control fraud. The more recent development of intelligent detection systems represents yet a further step in combating fraud. Other new technologies are beginning to be deployed, such as cards that have computer chips, to further reduce fraud and to introduce new services to the market. In the ACH system, the original risk design relied heavily on trusted, long-term relationships among known counterparties. Key participants were supervised depository institutions that originated and received the electronic payments. The primary types of commercial payments were electronic payroll deposits and recurring payments for utility bills. Fraud concerns did not justify establishing centralized controls at the system level. The risk model, however, has been changing as parties have begun to use the ACH to make one-time payments over the telephone and Internet, payments that are not necessarily based on long-term, trusted relationships. As the ACH network has grown and become more complex, layers of nonbank service providers may now be involved in originating certain types of payments, which further attenuates the trust relationships on which the network was founded. To address these emerging risks, ACH operators and NACHA have been working cooperatively with the industry to control new occurrences and types of fraud and other closely related risks. ACH operators are now providing their customers with innovative risk-management services, and NACHA has initiated a risk-monitoring program to better identify problems. NACHA is also developing programs to better monitor and control the ACH originations of depository institution customers. While the ultimate success of these efforts cannot yet be assessed, they represent important steps in the right direction. As the banking industry develops new payments solutions, it must be proactive in balancing convenience and risks, as well as cost, to ensure continued customer confidence in the payments system. The Future of Electronic Check ClearingPerhaps the greatest current opportunity in the retail payments system is for the banking industry to move rapidly to the electronic clearing of checks. As envisioned by Congress, Check 21 has created a strategic vision for moving the U.S. check clearing system into the new century. The historic infrastructure for paper check clearing is consolidating rapidly. Banks are changing their internal systems so they can accept deposits and collect checks electronically and are increasingly accepting their check presentments electronically. Bank technology vendors are playing an important role in facilitating change. And the Reserve Banks are working to implement the vision of Check 21, both by enhancing their electronic check infrastructure and by working closely with other payments system operators and the industry. In this environment of changing rules, infrastructure, and, yes, costs, it is imperative for banks and their customers to look closely at their own payment policies, operations, and technologies. Banks will need to develop broad and thoughtful payment strategies to navigate the changing environment and work constructively within the industry. Inevitably, banks will also need to change their operations. The Role of the Federal ReserveThe Federal Reserve will continue to play an important role in fostering a smoothly functioning payments system that is safe, efficient, and accessible. We also need to be flexible in carrying out our traditional payments system functions--provider of payment services, regulator, and catalyst for change--in the rapidly changing payments landscape. Since its inception, the Federal Reserve’s broad role in the payments system has been to improve efficiency and foster financial stability. When the Federal Reserve was formed almost one hundred years ago, the U.S. banking system was highly fragmented and checks were not cleared at par. To address this situation, the Federal Reserve began providing a national check-clearing service to banks that joined the Federal Reserve System. This service and other Federal Reserve policies helped guide the nation toward a more unified payments system. In its role as service provider, the Federal Reserve will continue to promote the efficiency and stability of the nation’s payments system. The Reserve Banks are now pricing their check services to encourage greater use of electronic check clearing. The Reserve Banks are also leaders in providing Check 21 services that encourage depository institutions to shift to a greater use of electronics in check processing and are working collaboratively with the industry on electronic check standards and other technical issues. Most importantly, the Reserve Banks will continue to compete as payment services providers on a fair and equitable basis by pricing their services to recover their costs, including imputed profits and taxes, over the long run, as required by the Monetary Control Act of 1980. In its role as a regulator, the Federal Reserve will need to be alert to the application of regulations in changing circumstances. As I have already noted, the Federal Reserve has, in recent years, modified its regulations to facilitate the greater use of electronics in the payments system and to address emerging risks. When considering potential regulatory changes, the Federal Reserve must also ensure that any proposed changes are consistent with the changing technological environment and adequately protect consumers. Finally, in its role as a catalyst for change, the Federal Reserve continues to work with the private sector to identify and, when appropriate, address barriers to payments system innovation. This past March, I participated in a roundtable in Minneapolis on retail payments fraud that was sponsored by the Payments System Policy Advisory Committee. The roundtable promoted dialogue on key fraud issues with a wide range of participants in the retail payments systems. It is our objective to continue to sponsor different types of forums over time as an important part of our public outreach activities. We believe that through its payments system roles, the Federal Reserve is well positioned to encourage both future payments system evolution and the appropriate balancing of efficiency and risk as new products and services are developed. ConclusionWe are living in a period of rapid innovation and transition in the payments system. Powerful forces have been converging to reshape the retail payments system. Yet the United States continues to enjoy safe, efficient, and reliable systems for making payments. As innovations occur, market forces will ultimately sort out which of these will best serve the needs of consumers and businesses. Both the private and public sectors have contributed to the evolution of the national payment system of the United States; clearly, both will have an important role to play in the future. As we ask each other "what’s next" during this time of transition, I believe that dialogue among payments system participants and users is critically important. Information and different points of view will help us all identify and address issues of innovation, risk, and efficiency in a balanced and thoughtful manner. This conference is a welcome and constructive element in this important dialogue. Footnotes 1.Helena L. Tenenholtz, Jeffrey S. H. Yeganeh, Jack K.Walton II, and Jeffrey C. Marquardt of the Board’s Division of Reserve Bank Operations and Payments Systems contributed to this speech.Return to text 2.See Gerdes, Geoffrey R., Jack K. Walton II, May X. Liu, and Darrel W. Parke, "Trends in the Use of Payment Instruments in the United States,"Federal Reserve Bulletin, Spring 2005, pp. 180-201. (http://www.federalreserve.gov/pubs/bulletin/2005/spring05_payment.pdf)Return to text 3.See, for example, Kroszner, Randall S., "The Effect of Removing Geographic Restrictions on Banking in the United States: Lessons for Europe." Conference on the Future of Financial Regulation, London School of Economics, April 6, 2006. See also Kroszner, Randall S., "What Drives Deregulation? Economics and Politics of the Relaxation of Bank Branching Restrictions,"Quarterly Journal of Economics, November 1999, pp. 1437-67, with Philip Strahan.Return to text 4.The term "conversion" generally refers to "check-to-ACH conversion," in which data from a check is used to create an electronic funds transfer that is cleared and settled over the ACH network. Such transactions include accounts receivable (ARC), point-of-purchase (POP), and back-office conversion (BOC) transactions.Return to text 5.Check 21 became effective in October 2004.Return to text 6.Before Check 21, banks were required to present the original paper check to the paying bank unless the paying bank had agreed to accept presentment of the check electronically.Return to text 7.See Board of Governors of the Federal Reserve System,Report to the Congress on the Check Clearing for the 21stCentury Act of 2003,April 2007.http://www.federalreserve.gov/boarddocs/rptcongress/check21/check21.pdfReturn to text 8.See71 FR 69500 (72 KB PDF)(December 1, 2006).Return to text 9.See70 FR 71218 (84 KB PDF)(November 28, 2005).Return to text 10.The Clearing House and FRB Financial Services, "Business-to-Business Wire Transfer Payments: Customer Preferences and Opportunities for Financial Institutions," (October 2006).http://www.frbservices.org/Wholesale/pdf/wire_transfer_research.pdf "A Summary of the Roundtable Discussion on the Role of Wire Transfers in Making Low-value Payments," Federal Reserve Bank of New York (May 2006).http://www.federalreserve.gov/paymentsystems/lowvaluepay/default.htmReturn to text
Chairman Ben S. Bernanke At the Federal Reserve Bank of Chicago’s 43rd Annual Conference on Bank Structure and Competition, Chicago, Illinois The recent sharp increases in subprime mortgage loan delinquencies and in the number of homes entering foreclosure raise important economic, social, and regulatory issues. Today I will address a series of questions related to these developments. Why have delinquencies and initiations of foreclosure proceedings risen so sharply? How have subprime mortgage markets adjusted? How have Federal Reserve and other policymakers responded, and what additional actions might be considered? How might the problems in the market for subprime mortgages affect housing markets and the economy more broadly? The Development of the Subprime Mortgage MarketLet me begin with some background. Subprime mortgages are loans made to borrowers who are perceived to have high credit risk, often because they lack a strong credit history or have other characteristics that are associated with high probabilities of default. Having emerged more than two decades ago, subprime mortgage lending began to expand in earnest in the mid-1990s, the expansion spurred in large part by innovations that reduced the costs for lenders of assessing and pricing risks. In particular, technological advances facilitated credit scoring by making it easier for lenders to collect and disseminate information on the creditworthiness of prospective borrowers. In addition, lenders developed new techniques for using this information to determine underwriting standards, set interest rates, and manage their risks. The ongoing growth and development of the secondary mortgage market has reinforced the effect of these innovations. Whereas once most lenders held mortgages on their books until the loans were repaid, regulatory changes and other developments have permitted lenders to more easily sell mortgages to financial intermediaries, who in turn pool mortgages and sell the cash flows as structured securities. These securities typically offer various risk profiles and durations to meet the investment strategies of a wide range of investors. The growth of the secondary market has thus given mortgage lenders greater access to the capital markets, lowered transaction costs, and spread risk more broadly, thereby increasing the supply of mortgage credit to all types of households. These factors laid the groundwork for an expansion of higher-risk mortgage lending over the past fifteen years or so. Growth in the market has not proceeded at a uniform pace, but on net it has been dramatic. About 7-1/2 million first-lien subprime mortgages are now outstanding, accounting for about 14 percent of all first-lien mortgages.1So-called near-prime loans--loans to borrowers who typically have higher credit scores than subprime borrowers but whose applications may have other higher-risk aspects--account for an additional 8 to 10 percent of mortgages.2 The expansion of subprime mortgage lending has made homeownership possible for households that in the past might not have qualified for a mortgage and has thereby contributed to the rise in the homeownership rate since the mid-1990s. In 2006, 69 percent of households owned their homes; in 1995, 65 percent did. The increase in homeownership has been broadly based, but minority households and households in lower-income census tracts have recorded some of the largest gains in percentage terms. Not only the new homeowners but also their communities have benefited from these trends. Studies point to various ways in which homeownership helps strengthen neighborhoods. For example, homeowners are more likely than renters to maintain their properties and to participate in civic organizations. Homeownership has also helped many families build wealth, and accumulated home equity may serve as a financial reserve that can be tapped as needed at a lower cost than most other forms of credit. Broader access to mortgage credit is not without its downside, however. Not surprisingly, in light of their weaker credit histories and financial conditions, subprime borrowers face higher costs of borrowing than prime borrowers do and are more likely to default than prime borrowers are. For borrowers, the consequences of defaulting can be severe--possibly including foreclosure, the loss of accumulated home equity, and reduced access to credit. Their neighbors may suffer as well, as geographically concentrated foreclosures tend to reduce property values in the surrounding area. The Recent Problems in the Subprime Mortgage SectorWith this background in mind, I turn now to the recent problems in the subprime mortgage sector. In general, mortgage credit quality has been very solid in recent years. However, that statement is no longer true of subprime mortgages with adjustable interest rates, which currently account for about two-thirds of subprime first-lien mortgages or about 9 percent of all first-lien mortgages outstanding. For these mortgages, the rate of serious delinquencies--corresponding to mortgages in foreclosure or with payments ninety days or more overdue--rose sharply during 2006 and recently stood at about 11 percent, about double the recent low seen in mid-2005.3The rate of serious delinquencies has also risen somewhat among some types of near-prime mortgages, although the rate in that category remains much lower than the rate in the subprime market. The rise in delinquencies has begun to show through to foreclosures. In the fourth quarter of 2006, about 310,000 foreclosure proceedings were initiated, whereas for the preceding two years the quarterly average was roughly 230,000.4Subprime mortgages accounted for more than half of the foreclosures started in the fourth quarter. The sharp rise in serious delinquencies among subprime adjustable-rate mortgages (ARMs) has multiple causes. "Seasoned" mortgages--mortgages that borrowers have paid on for several years--tend to have higher delinquency rates. That fact, together with the moderation in economic growth, would have been expected to produce some deterioration in credit quality from the exceptionally strong levels seen a few years ago. But other factors, too, have been at work. After rising at an annual rate of nearly 9 percent from 2000 through 2005, house prices have decelerated, even falling in some markets. At the same time, interest rates on both fixed- and adjustable-rate mortgage loans moved upward, reaching multi-year highs in mid-2006. Some subprime borrowers with ARMs, who may have counted on refinancing before their payments rose, may not have had enough home equity to qualify for a new loan given the sluggishness in house prices. In addition, some owners with little equity may have walked away from their properties, especially owner-investors who do not occupy the home and thus have little attachment to it beyond purely financial considerations. Regional economic problems have played a role as well; for example, some of the states with the highest delinquency and foreclosure rates are among those most hard-hit by job cuts in the auto industry. The practices of some mortgage originators have also contributed to the problems in the subprime sector. As the underlying pace of mortgage originations began to slow, but with investor demand for securities with high yields still strong, some lenders evidently loosened underwriting standards. So-called risk-layering--combining weak borrower credit histories with other risk factors, such as incomplete income documentation or very high cumulative loan-to-value ratios--became more common. These looser standards were likely an important source of the pronounced rise in "early payment defaults"--defaults occurring within a few months of origination--among subprime ARMs, especially those originated in 2006. Although the development of the secondary market has had great benefits for mortgage-market participants, as I noted earlier, in this episode the practice of selling mortgages to investors may have contributed to the weakening of underwriting standards. Depending on the terms of the sale, when an originator sells a loan and its servicing rights, the risks (including, of course, any risks associated with poor underwriting) are largely passed on to the investors rather than being borne primarily by the company that originated the loan. In addition, incentive structures that tied originator revenue to the number of loans closed made increasing loan volume, rather than ensuring quality, the objective of some lenders. Investors normally have the right to put early-payment-default loans back to the originator, and one might expect such provisions to exert some discipline on the underwriting process. However, in the most recent episode, some originators had little capital at stake and did not meet their buy-back obligations after the sharp rise in delinquencies.5Intense competition for subprime mortgage business--in part the result of the excess capacity in the lending industry left over from the refinancing boom earlier in the decade--may also have led to a weakening of standards. In sum, some misalignment of incentives, together with a highly competitive lending environment and, perhaps, the fact that industry experience with subprime mortgage lending is relatively short, likely compromised the quality of underwriting. The accuracy of much of the information on which the underwriting was based is also open to question. Mortgage applications with little documentation were vulnerable to misrepresentation or overestimation of repayment capacity by both lenders and borrowers, perhaps with the expectation that rising house prices would come to the rescue of otherwise unsound loans. Some borrowers may have been misled about the feasibility of paying back their mortgages, and others may simply have not understood the sometimes complex terms of the contracts they signed. As the problems in the subprime mortgage market have become manifest, we have seen some signs of self-correction in the market. Investors are scrutinizing subprime loans more carefully and, in turn, lenders have tightened underwriting standards. Credit spreads on new subprime securitizations have risen, and the volume of mortgage-backed securities issued indicates that subprime originations have slowed. But although the supply of credit to this market has been reduced--and probably appropriately so--credit has by no means evaporated. For example, even as purchases of securitized subprime mortgages for collateralized debt obligations--an important source of demand--have declined, increased purchases by investment banks, hedge funds, and other private pools of capital are beginning to fill the void. Some subprime originators have gone out of business as their lenders have cancelled credit lines, but others have been purchased by large financial institutions and remain in operation. Importantly, we see no serious broader spillover to banks or thrift institutions from the problems in the subprime market; the troubled lenders, for the most part, have not been institutions with federally insured deposits. What about borrowers already in distress? The Board and other federal supervisory agencies havetaken actionsto encourage the banks and thrift institutions we supervise to work with borrowers who may be having trouble meeting their mortgage obligations. Often, loan workouts are in the interest of both parties. With effective loan restructuring, borrowers facing temporary economic setbacks may be able to work through their problems while staying in their homes, and lenders may be able to avoid the costs of foreclosure and the losses usually associated with selling a repossessed home. Servicers of loans aim to minimize losses, and they appear to be actively working with thousands of individual borrowers to modify their mortgages. To some extent, the dispersed ownership of mortgages may combine with legal and accounting rules to make successful workouts more difficult to achieve. For example, the "pooling and servicing agreement" associated with a given securitized mortgage pool may restrict the share of accounts that can be modified. Accounting rules that, in some cases, require substantially modified pools to be brought back on the originator’s balance sheet may dissuade lenders from undertaking workouts. And extensive modifications that reallocate expected cash flows across different securities associated with the pool could trigger a review of those securities by the ratings agencies. At the same time, if workouts are economically viable, then an incentive exists for third parties to purchase distressed pools at a discount and to undertake the workout process. We see these purchases taking place in the marketplace, a development that should help to increase the number of successful workouts. Also, local community organizations that work to promote homeownership and prevent foreclosures have stepped up their efforts. For example, NeighborWorks America advises borrowers about restructuring their mortgages. A survey conducted by this group found that many homeowners do not understand that lenders also want to avoid foreclosure. Thus, the simple step of encouraging borrowers in trouble to contact their lenders can be very productive. The Federal Reserve and the other supervisory agencies have encouraged financial institutions to identify and contact borrowers who, with counseling and financial assistance, may be able to avoid entering delinquency or foreclosure. Indeed, some lenders are being proactive in this regard--for example, by contacting borrowers to discuss possible options well before a scheduled interest-rate reset. Possible Regulatory ResponsesLooking forward, the Federal Reserve, other regulators, and the Congress must evaluate what we have learned from the recent episode and decide what additional regulation or oversight may be needed to prevent a recurrence. In deciding what actions to take, regulators must walk a fine line; we must do what we can to prevent abuses or bad practices, but at the same time we do not want to curtail responsible subprime lending or close off refinancing options that would be beneficial to borrowers. Broadly speaking, financial regulators have four types of tools to protect consumers and to promote safe and sound underwriting practices. First, they can require disclosures by lenders that help consumers make informed choices. Second, they can prohibit clearly abusive practices through appropriate rules. Third, they can offer principles-based guidance combined with supervisory oversight. Finally, regulators can take less formal steps, such as working with industry participants to establish and encourage best practices or supporting counseling and financial education for potential borrowers. In the area of disclosure, the Federal Reserve is responsible for writing the regulation that implements the Truth in Lending Act (TILA), known as Regulation Z. The purpose of Regulation Z is to ensure that lenders provide borrowers or potential borrowers with clear, accurate, and timely information about the terms and conditions of loans. The Federal Reserve is also authorized to write rules; notably, the Home Ownership Equity Protection Act (HOEPA) gives the Board the power to prohibit acts and practices in mortgage lending deemed "unfair" or "deceptive."6Both the disclosures required by TILA and the rules developed under HOEPA (which is part of TILA) apply to all lenders, not just banks. In cooperation with the other federal banking regulators, the Board can also draft supervisory guidance and back it up with regular examinations. Supervisory guidance applies only to banks and thrift institutions, although state regulators of nonbank lenders can and sometimes do adopt guidance written by the federal regulators. In my judgment, effective disclosures should be the first line of defense against improper lending. If consumers are well informed, they are in a much better position to make decisions in their own best interest. However, combating bad lending practices, including deliberate fraud or abuse, may require additional measures. Rules are useful if they can be drawn sharply, with bright lines, and address practices that are never, or almost never, legitimate. Sometimes, however, specific lending practices that may be viewed as inappropriate in some circumstances are appropriate in others, and the conditions under which those practices are appropriate cannot be sharply delineated in advance. In such cases, supervisory guidance that establishes principles or guidelines is, when applicable, probably the better approach. Guidance can be modified as needed to apply to different situations, and thus can be a more flexible tool than rules for accomplishing regulators’ goals. As I noted, markets are adjusting to the problems in the subprime market, but the regulatory agencies must consider what additional steps might be needed. The Federal Reserve is currently undertaking a thorough review of all its options under the law. Under its TILA authority, the Board last summer began a top-to-bottom evaluation of mortgage-related disclosures with a series offour open hearingsaround the country, in which we heard public concerns about various mortgage-related issues, including predatory lending and the effectiveness of the currently required disclosures. Using consumer testing, we will be working to improve the disclosures associated with mortgage lending and to fight deceptive marketing practices. This effort will draw heavily on our nearly-completed review of disclosures relating to open-end credit, including credit cards, for which we made extensive use of consumer testing to determine which disclosure formats are most effective and informative.7 Of course, the information provided by even the best-designed disclosures can be useful only when it is well understood. Accordingly, the Federal Reserve produces and regularly updates a range of materials, including abookletthat lenders are required to provide to potential ARM borrowers, to help consumers understand ARMs and other alternative mortgages; and we will continue to promote financial education through a variety of partnerships with outside organizations. Federal Reserve Banks around the country will also continue their cooperation with educational and community organizations that provide counseling about mortgage products and the responsibilities of homeownership. We are also actively reviewing the possible use of our rule-making authority to prohibit certain specific practices. In 2001, the Board acted under its HOEPA authority to ban several practices for high-cost loans that were determined to be unfair or deceptive, such as loan flipping--frequent and repeated refinancing to generate fees for lenders. The Board will consider whether other lending practices meet the legal definition of unfair and deceptive and thus should be prohibited under HOEPA. Any new rules that we issue should be sharply drawn, however. As lenders are subject not only to regulatory enforcement action but possibly also to private lawsuits for redress of HOEPA violations, insufficiently clear rules could create legal and regulatory uncertainty and have the unintended effect of substantially reducing legitimate subprime lending. Next month, we will conduct apublic hearingto consider how we might further use our HOEPA authority to curb abuses while preserving access to credit. We have invited people representing all sides of the debate to present their views. We have also used, and will continue to use, supervisory guidance to help mitigate problems in the subprime sector. Earlier this year, the Board and other federal bank and thrift regulators issued draft supervisory guidance to address concerns about underwriting and disclosure practices, particularly of subprime ARMs. Many industry and consumer groups have responded to our proposal, and we are now reviewing the comments. Regulators in 1999 issued guidance on subprime lending and in 2001 expanded that guidance. Last year, we issued guidance concerning so-called nontraditional mortgages, such as interest-only mortgages and option ARMs. For both subprime and nontraditional mortgages, our guidance has reminded lenders of the importance of maintaining sound underwriting standards and of providing consumers with clear, balanced, and timely disclosures about the risks and benefits of these mortgages. The patchwork nature of enforcement authority in subprime lending--in particular, the fact that the authority to make rules and the responsibility to enforce those rules are often held by different agencies--poses additional challenges. For example, rules issued by the Board under TILA or HOEPA apply to all mortgage lenders but are enforced--depending on the lender--by one of five federal regulators of depository institutions, the Federal Trade Commission (FTC), or state regulators. To ensure consistent and effective enforcement, close cooperation and coordination among the regulators are essential. The Board remains committed to working closely with other regulators to achieve uniform and effective enforcement. We can continue to improve the sharing of information and the coordination of some activities, such as examiner training, through the Federal Financial Institution Examination Council, which the Conference of State Banking Supervisors (CSBS) recently joined, as well as through other channels, such as the CSBS’s State/Federal Working Group. We will also draw on the expertise of other regulators as we consider changes in required disclosures and rules. Macroeconomic ImplicationsThe problems in the subprime mortgage market have occurred in the context of a slowdown in overall economic growth. Real gross domestic product has expanded a little more than 2 percent over the past year, compared with an average annual growth rate of 3-3/4 percent over the preceding three years. The cooling of the housing market is an important source of this slowdown. Sales of both new and existing homes have dropped sharply from their peak in the summer of 2005, the inventory of unsold homes has risen substantially, and single-family housing starts have fallen by roughly one-third since the beginning of 2006. Although a leveling-off of sales late last year suggested some stabilization of housing demand, the latest readings indicate a further stepdown in the first quarter. Sales of new homes moved down to an appreciably lower level in February and March, and sales of existing homes have also come down on net since the beginning of this year. How will developments in the subprime market affect the evolution of the housing market? We know from data gathered under the Home Mortgage Disclosure Act that a significant share of new loans used to purchase homes in 2005 (the most recent year for which these data are available) were nonprime (subprime or near-prime). In addition, the share of securitized mortgages that are subprime climbed in 2005 and in the first half of 2006. The rise in subprime mortgage lending likely boosted home sales somewhat, and curbs on this lending are expected to be a source of some restraint on home purchases and residential investment in coming quarters. Moreover, we are likely to see further increases in delinquencies and foreclosures this year and next as many adjustable-rate loans face interest-rate resets. All that said, given the fundamental factors in place that should support the demand for housing, we believe the effect of the troubles in the subprime sector on the broader housing market will likely be limited, and we do not expect significant spillovers from the subprime market to the rest of the economy or to the financial system. The vast majority of mortgages, including even subprime mortgages, continue to perform well. Past gains in house prices have left most homeowners with significant amounts of home equity, and growth in jobs and incomes should help keep the financial obligations of most households manageable. ConclusionCredit market innovations have expanded opportunities for many households. Markets can overshoot, but, ultimately, market forces also work to rein in excesses. For some, the self-correcting pullback may seem too late and too severe. But I believe that, in the long run, markets are better than regulators at allocating credit. We at the Federal Reserve will do all that we can to prevent fraud and abusive lending and to ensure that lenders employ sound underwriting practices and make effective disclosures to consumers. At the same time, we must be careful not to inadvertently suppress responsible lending or eliminate refinancing opportunities for subprime borrowers. Together with other regulators and the Congress, our success in balancing these objectives will have significant implications for the financial well-being, access to credit, and opportunities for homeownership of many of our fellow citizens. Footnotes 1.This estimate is based on data from the Mortgage Bankers Association, adjusted to reflect the limited coverage of the association’s sample.Return to text 2.Near-prime loans include those securitized in "alt-A" pools and similar loans that are held on lenders’ books.Return to text 3.Estimates of delinquencies are based on data from First American LoanPerformance. The rate of serious delinquencies for variable-rate subprime mortgages also reached about 11 percent in late 2001 and early 2002.Return to text 4.Foreclosure starts are based on data from the Mortgage Bankers Association, adjusted to reflect the limited coverage of their sample.Return to text 5.Many mortgage brokers are subject to minimum licensing standards and bonding or net worth criteria, but these standards and criteria vary across states.Return to text 6.For home refinance loans, the Board can prohibit practices that it finds to be associated with abusive practices or not in the best interest of the borrower.Return to text 7.The results of the review of disclosures for open-end credit and the associated notice of proposed rule-making will be discussed at an open meeting of the Board of Governors on May 23, 2007.Return to text